<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><!-- InstanceBegin template="/Templates/mw2007-papers.dwt" codeOutsideHTMLIsLocked="false" -->

<!-- Mirrored from www.museumsandtheweb.com/mw2007/papers/robinson/robinson.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 17:29:00 GMT -->
<head>
<!-- #BeginEditable "HeadPageTitle" -->
<title>Archives &amp; Museum Informatics: Museums and the Web 2007: Papers: Robinson,
L., et al., My Evidence: Who's the Authority Here?</title>
<!-- #EndEditable -->
<!-- #BeginEditable "metaTitle" -->
<meta name="title" content="Archives  &amp; Museum Informatics: Museums and the Web 2007" />
<!-- #EndEditable -->
<!-- #BeginEditable "Keywords" -->
<meta name="Keywords" content="on-line community, Web 2.0, creative process,
				  interface design, database, scientific evidence, design process, articles, papers, archives &amp; museum informatics, archives, museums, informatics, digital museums, digital archives, digital art, museums online, archives online, libraries online. world wide web, www, conferences, professional papers, peer-reviewed, digital libraries, online exhibits, online exhibitions, on-line" />
<!-- #EndEditable -->
<!-- #BeginEditable "Description" -->
<meta name="Description" content="Museums and the Web 2007: the international conference for culture and heritage on-line" />
<!-- #EndEditable -->
<!-- #BeginEditable "copyright" -->
<meta name="copyright" content="Archives &amp; Museum Informatics, 2007" />
<!-- #EndEditable -->
<meta name="document-class" content="Published" />
<meta name="document-rating" content="General" />
<meta http-equiv="Content-Language" content="EN" />
<meta name="document-rights" content="Copyrighted Work" />
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
	<link rel="stylesheet" href="../../css/mw2007.css" type="text/css" media="screen" />
	<link rel="stylesheet" href="../../css/print.css" type="text/css" media="print" />
	<link rel="stylesheet" href="../../css/mw2007-noNews.css" type="text/css"  media="print, screen" />
	<link rel="stylesheet" href="../../css/papers.css" type="text/css"  media="print, screen" />

<!-- InstanceBeginEditable name="ImageRotateScript" -->

<!-- InstanceEndEditable -->

<!-- InstanceBeginEditable name="PageScript" -->

<!-- InstanceEndEditable -->
</head>
<body  onload="initImgRotation()">
	<div id="container">
		<div id="header" onclick="location.href='../index.html';" style="cursor:pointer;">
		</div>
		<div id="top-nav">
			<ul id="top-nav-list">
				<li><a href="../../register/index.html">Register</a></li>
				<li><a href="../../dates/index.html">Key Dates</a></li>
				<li><a href="../../sescal/index.html">Schedule</a></li>
				<li><a href="../../local/index.html">Local Info</a></li>
			</ul>
		</div>
		<div id="header-photo">
			<a href="../../images/credits.html">
			<!-- InstanceBeginEditable name="header-photo" -->
			<img src="../../images/rotate/header-pic.jpg" alt="MW-photo" name="img1" width="229"  height="132" id="img1" />
			<!-- InstanceEndEditable -->	
			</a>
		</div>
		<div id="date">
			April 11-14, 2007<br />
			San Francisco, California
		</div>
		<div  id="title">
			<h1> 
				<!-- InstanceBeginEditable name="PageTitle" -->My Evidence: Who&rsquo;s the Authority Here?<!-- InstanceEndEditable -->
   			</h1>
		</div>
		<div id="main-content">
		  <div id="callout">          </div>
		  <div id="intro-paragraph">
				<!-- #BeginEditable "IntroParagraph" -->
				<h2 class="Author">Lowell Robinson, David Beck, Pearl Tesler, Exploratorium,
				  and Valerie Knight-Williams, Knight-Williams Research, USA</h2>
				<p class="URL"><a href="../http://www.exploratorium.edu/evidence/" target="_blank">http://www.exploratorium.edu/evidence/</a></p>
				<h3 class="abstract">Abstract</h3>
				<p class="abstract">The Exploratorium &ndash; a museum of science, art and
				  human perception in San Francisco &ndash; is currently in the process of
				  developing a Web-based tool that will help visitors understand and &lsquo;map
				  out&rsquo; their own belief systems. This community-based application was
				  created in order to provide visitors with some context in understanding
				  scientific evidence by examining evidence of how they know what they know.
				  But can we map out what we believe? What if our beliefs are factually incorrect?
				  What roles do museums have as arbitrators of truth? My Evidence is an experimental
				  on-line application that challenges visitors to examine what they think
				  they know, and also reminds them that the evaluation of evidence is a fluid
				  process that requires us to continually re-examine our assumptions. </p>
				<p class="keywords">Keywords: on-line community, Web 2.0, creative process,
				  interface design, database, scientific evidence, design process</p>
				<!-- #EndEditable -->		  </div>
				<!-- #BeginEditable "BodyText" -->

  <h2 class="PaperTitle">Introduction</h2>
  <p class="BlockQuoteAuthor">&ldquo;I believe the earth travels around the sun.&rdquo;</p>
  <p >Today we can say this with collective confidence, but
    four hundred years ago, Galileo was tried and convicted for this statement.
    Seeking an audience for his then-radical ideas, Galileo authored a book, <em>Dialogue
      Concerning the Two Chief World Systems,</em> intended for the public as well
    as his peers. It reads as a conversation between two philosophers, allowing
    the reader to be a &lsquo;fly on the wall&rsquo; of scientific discourse.</p>
  <p >If Galileo were alive today, he&rsquo;d probably have a blog.
    What better way to reach the masses? Touted as the great equalizing platform
    of information, the Web&rsquo;s multiplicity of voices destabilizes authority.
    Yet this destabilization cuts both ways. On the Web, we find true alongside
    false, valid amid invalid, and fact next to fiction, leaving users with the
    important responsibility of deciding what to believe and what not to believe. </p>
  <p >This process of knowledge construction is at the heart
    of the Exploratorium&rsquo;s latest project, called <em>Evidence</em>. Funded by
    a grant from the National Science Foundation, the <em>Evidence</em> project
    probes the foundations of science in addressing two simple questions: &ldquo;How
    do we know what we know?&rdquo; and &ldquo;How do we choose what to believe?&rdquo; The <em>Evidence</em> team
    is comprised of scientists, educators, content and media developers, researchers
    from the Exploratorium, and the project&rsquo;s outside evaluator:</p>
  <ul>
    <li> Rob
      Semper, Principal Investigator </li>
    <li> Melissa
      Alexander, Co-Principal Investigator and Project Director</li>
    <li> Thomas
      Humphrey, Senior Scientist </li>
    <li> Pearl
      Tesler, Science Writer</li>
    <li> Lowell
      Robinson, New Media Designer</li>
    <li> Adrian
      Van Allen, New Media Designer</li>
    <li> Susan
      Schwartzenberg, Senior Artist</li>
    <li> Mary
      Miller, Science Writer/Producer</li>
    <li> David
      Beck, New Media Designer/Programmer</li>
    <li> Liz
      Spencer, Videographer</li>
    <li> Sherry
      Hsi, New Media Researcher</li>
    <li> Valerie
      Knight-Williams, Independent Evaluator</li>
	  </ul>
  <p >Created for the <em>Evidence</em> project, <strong>My Evidence</strong> is
    an on-line application intended to help users better understand their own
    belief systems and processes of knowledge construction. My Evidence begins
    by posing a series of statements, such as, &ldquo;I believe the world is spinning,&rdquo; and
    &ldquo;I believe global warming is caused by humans.&rdquo; Users choose from among these
    statements and create their own Evidence Maps, visual tools that help categorize
    the users&rsquo; knowledge according to how it was acquired. As users enter more
    and more data, patterns in their growing Evidence Maps give insights into
    what is personally salient to them in their own knowledge construction. My
    Evidence also allows users to compare their evidence maps to other users&rsquo; maps.</p>
  <h2>From Abstraction To Vision</h2>
  <h3>Addressing Challenges</h3>
  <p >How do you convey an abstract idea through the medium
    of the Web? Before work on the <em>Evidence</em> Web site could begin, Project
    Director Melissa Alexander and her team had to contend with some serious
    conceptual and practical challenges. Their task was to design a visually
    engaging, conceptually meaningful way to address the question, &ldquo;How do we
    know what we know?&rdquo; while providing users with authentic science experiences,
    creating redundancy to reinforce key ideas, developing innovative Web tools
    and techniques, and offering compelling narratives to explore current science. </p>
  <p >Melissa proposed using a <em>charrette</em> to kick off
    design and development efforts. A charrette is a kind of planning process
    that incorporates the concerns and ideas of multiple stakeholders. In architecture
    and urban planning, the stakeholders are typically clients, community members,
    city officials, and business interests. For our purposes, stakeholders were
    the project&rsquo;s actualizers (designers, developers, writers, editors, media
    makers, evaluators, and producers), content heads (senior scientists and
    artists, PIs and co-PIs), and audiences (end users, funders, and the museum
    field). </p>
  <p >Initial brainstorming was done in small groups, but prototypes
    presented at a more intensive two-day design charrette demonstrated the difficulties
    inherent in expecting the public to think meaningfully about scientific evidence,
    as opposed to the anecdotal evidence that guides most day-to-day decisions.
    It soon became apparent that there needed to be multiple paths for various
    mindsets in order to tackle what scientific evidence was. One of those paths
    was My Evidence, an interactive way for users to examine their own (largely
    unconscious) processes of evaluating information.</p>
  <h3>Checking Expectations and Assumptions</h3>
  <p >During this early design phase, independent evaluator
    Valerie Knight-Williams put together three front-end literature reviews to
    help us get a better sense of how the <em>Evidence</em> site might fit with
    activities currently on the Web. These three reviews helped us think strategically
    about the content and context of our project: </p>
  <p >The first review informed us about the range of scholars,
    educators, and researchers currently focused on the public&rsquo;s understanding
    of scientific evidence. It uncovered an impressive body of work addressing
    many of the questions we had been discussing, such as: What is &ndash; and isn&rsquo;t &ndash; scientific
    evidence? How is it gathered? What methods have been used to educate the
    public about scientific evidence? And finally, what does the public know
    and understand about scientific evidence? These leads helped ground us in
    the current work in the field and enabled us to quickly identify and acquire
    relevant resource materials. </p>
  <p >The second review gave us a glimpse of how other Internet
    projects were currently educating public audiences about scientific evidence.
    We identified three main themes from 28 projects. First, we found that while
    most touched on aspects of evidence, they were more broadly concerned with
    promoting scientific inquiry or conveying the scientific method. Second,
    we discovered that most of the projects were designed for students in grades
    4&ndash;12, and were not generally positioned to appeal to adults or the public
    at large. Finally, we saw little opportunity for people to have in-depth
    interactions with scientific evidence or a means to analyze or reflect on
    what scientific evidence means to them personally. </p>
  <p >The third review focused on what a visitor to the Web
    encountered when searching on the topic of scientific evidence. To find out,
    Valerie&rsquo;s team conducted four Google searches for terms or phrases involving
    &ldquo;evidence&rdquo; or &ldquo;scientific evidence,&rdquo; and then performed a content analysis
    for each of the first 50 search results. We were surprised to learn, for
    example, that 32% of these Web sites addressed health issues; 30% focused
    on scientific evidence in legal contexts; and 22% discussed scientific evidence
    in the context of evolution and creationism. Only 6% of the sites discussed
    evidence gathered in current research projects &ndash; with the topics in this
    case ranging from the lost continent of Atlantis, to the use of trap-neuter-return
    (TNR) among feral cats, to the human-like nature of birds! One Web site (2%)
    was about paranormal phenomena, presenting &ldquo;evidence&rdquo; for the afterlife.
    Another three (6%) addressed other topics that couldn&rsquo;t be categorized. Most
    surprising to us, though, was that only one site (2%) formally defined scientific
    evidence and then went on to explain the concepts of scientific evidence
    and provide a framework for understanding the relationship between data and
    evidence.</p>
  <h2>Early Ideas of an Interactive Model</h2>
  <h3>Thinking Things Through</h3>
  <p >As work on the site progressed, we talked about ways to
    integrate its design with some of the science content themes we had been
    discussing, such as climate change, mapping human history through DNA, and
    gravity waves. But an intellectual discussion doesn&rsquo;t necessarily have to
    be about something academic; it can be about something personal as well.
    My Evidence needed to find a way to use the process of questioning in the
    same way scientists use the process of questioning, but in the context of
    a user&rsquo;s everyday experiences. The ultimate decision was to ask people to
    apply a scientific mindset while examining statements about the world that
    felt familiar to them. </p>
  <p >During this time, <em>Evidence</em> team members were working
    intensively to think through the issues of creating the overall site. Regular
    meetings, research, brainstorms, and retreats created an atmosphere of open
    investigation that would eventually lead media developer Lowell Robinson
    to begin thinking about why people adopt some ideas, but dismiss others.
    He began playing with ways to capture the process visually and interactively.
    With support of team members (and his wife  Gradiva), the vision began to
    solidify, taking the form of an on-line application in which visitors could
    examine the reasoning behind their own belief systems. </p>
  <p class="caption"><a name="Fig1" id="Fig1"></a><a href="robinson-fig1.html"><img src="robinson.fig1.small.jpg" alt="Fig 1: This Photoshop mockup of My Evidence was the first visualization of the project. It preceded the paper version tested on the museum floor." width="400" height="299" border="0" /></a></p>
  <p class="caption">Fig 1: This Photoshop mockup of My Evidence was the first
    visualization of the project. It preceded the paper version tested on the
    museum floor.</p>
  <p >We began by planning for a design prototype that posed
    the belief statement, &ldquo;I believe the world is round.&rdquo; Users would be asked
    to think about the statement, and then choose a category with which to respond.
    The five categories were:</p>
  <ol>
    <li> &ldquo;I
      observed...&rdquo;</li>
    <li> &ldquo;I
      was told...&rdquo;</li>
    <li> &ldquo;I
      read...&rdquo;</li>
    <li> &ldquo;I
      experienced...&rdquo;</li>
    <li> &ldquo;I
      was shown...&rdquo;</li>
	  </ol>
  <p >When a user clicked on a category, a new screen would
    come up, and the user could type in something like, &ldquo;I read...<em> that the
      world was round in my third-grade science text</em>,&rdquo; or &ldquo;I was told...<em> by
        my grandfather that the world was round.</em>&rdquo; Each item of evidence
    created in this way would make a &lsquo;thought bubble in the form of a colored
    circle on the screen. Each category would have its own color, and each bubble
    could be sized by the user to represent a more or less important item of
    evidence. In this way, users would be able to create individual &lsquo;maps&rsquo; of
    how they &lsquo;knew&rsquo; about the statement. </p>
  <p >This plan would also allow users to cluster the thought
    bubbles by evidence type, importance, or topic. Why cluster the bubbles?
    In team meetings, there was a great deal of discussion about the difference
    between data and evidence. Data provide raw material: you have to filter
    data to get evidence. Using clustering was designer/developer Lowell Robinson&rsquo;s
    way of actualizing this conversation &ndash; in essence, mimicking the scientific
    community&rsquo;s process of filtering large quantities of data to formulate scientific
    evidence. The hope was that users entering a large number of ideas into My
    Evidence could filter them to see something they might not otherwise have
    seen. For example, if most of your data is in the category &lsquo;I read,&rsquo; but
    the ones you weigh most heavily are in &lsquo;I observed,&rsquo; then you might have
    an interesting understanding of what types of evidence are most important
    to you. This idea was the basis of making this a tool rather than a scrapbook.</p>
  <h3>Evaluating the Model</h3>
  <p >The design team found this prototype interesting, but
    wondered if others would agree. Before going through the process of building
    the interactive application, we decided to create a paper mockup for use
    in evaluation. By using a paper model, we could focus on content rather than
    usability.</p>
  <p >To gather feedback on the prototype, independent evaluator
    Valerie Knight-Williams conducted in-depth interviews with a small group
    of Exploratorium visitors. From this process, we hoped to answer a variety
    of questions:</p>
  <ul>
    <li> Are
      people interested in and able to generate evidence in response to a statement
      like, &ldquo;I believe the world is round&rdquo;?</li>
    <li> How
      much are people likely to write in response to such a statement? What other
      kinds of statements would they like to respond to?</li>
    <li>Do
      people prefer to write open-ended responses, or would they prefer to click
      on predetermined choices?</li>
    <li>Do
      people feel the current response categories capture the kinds of evidence
      they would likely provide?</li>
    <li>How
      do people feel about rating their own evidence? How about having other visitors
      review, rate, and comment on their evidence?</li>
    <li>Are
      people willing to provide basic personal information to develop a personal
      profile at the site?</li>
	  </ul>
  <p >Prototype testing occurred on a weekend day at the Exploratorium.
    Besides the convenience of working on-site, we chose our museum setting because
    it drew visitors who represented probable users of the Web site. As Valerie
    recruited visitors, she sought to find a balanced group of users in terms
    of age, gender, and science background / knowledge. Visitors who agreed to
    participate were escorted to a table in a quiet area of the museum, were
    offered a donut in exchange for their participation, and then responded to
    a set of questions relating to four draft Web pages.</p>
  <h4>Responses to the Prototype</h4>
  <p >Although the visitor group recruited was small, Valerie
    found that these 12 individuals quickly became engaged in the process of
    generating and reflecting on their own ideas about evidence. Their feedback
    on specific features of My Evidence was often consistent, although each visitor
    also offered a unique perspective on how he or she interacted with and made
    meaning from the activity as well. We discovered, for instance, that all
    12 visitors liked and were able to generate evidence relating to the statement, &ldquo;I
    believe the world is round.&rdquo; Most often they said they: </p>
  <ul>
    <li>were
      told/taught by an educator or authority figure, </li>
    <li> saw
      pictures of the world from space, </li>
    <li>looked
      at a globe/map, </li>
    <li>read
      it in a text/science book, </li>
    <li>viewed
      the horizon from an airplane, and/or experienced it in a sailboat.</li>
	  </ul>
  <p >When asked to estimate the amount they would be willing
    to write about their evidence, most visitors said they expected to write
    2&ndash;3 sentences. In actuality, estimates fell short of what they actually offered
    during the interview (5 sentences on average). </p>
  <p >When asked to categorize their own evidence (&ldquo;What kind
    of evidence is this?&rdquo;), visitors had mixed reactions about the appropriateness
    of the response options, &ldquo; I observed, I was told, I read, I experienced,
    and I was shown&rdquo;. A few felt that the categories adequately fit the evidence
    described, while others questioned the basis for the existing options or
    suggested that the Web team add branches to each category.</p>
  <p >Other responses addressed ease of use, preference for
    clicking versus writing (visitors said they did not mind doing some writing,
    but wanted clicking to be the predominate experience), and issues of use
    and privacy (most were comfortable providing limited personal information,
    and all 12 visitors said they were comfortable having other people review
    their evidence entries, but only 6 felt willing to have people rate or critique
    them). </p>
  <p >Visitors&rsquo; other comments tended to focus on the point
    or payoff of the activity. Some wanted to be informed about the &ldquo;real&rdquo; answer
    or wanted to see some explanation about why we do know the world is round.
    Others wanted to see the personal implications of My Evidence addressed in
    terms of what one should learn from the activity about constructing evidence.
    Visitors also offered suggestions for My Evidence, including the use of more
    controversial topics, science topics in the news, and so on.</p>
  <h3>Revising the Model</h3>
  <p >After the evaluation, the <em>Evidence</em> team used the
    reactions and recommendations from Val&rsquo;s study to guide us in a new round
    of revisions. We learned a lot. </p>
  <p >Most important, people liked it; they enjoyed the process
    and the challenge. Usability was going to be important: people did not want
    to have to type too much, but they did want the results to do something interesting.
    People wanted to know the &ldquo;right&rdquo; answer. They wanted to compare their answer
    to real scientific evidence, and they wanted a payoff (&quot;I want to know
    how to think more scientifically&quot;).</p>
  <p >Ultimately, team discussion came around to the larger
    challenge of choosing the right belief statements. We knew the statements
    had to really &ldquo;grab&rdquo; visitors, but how scientific should they be? Could they
    be controversial? Lyrical or whimsical? (&quot;I believe love is the
    answer.&quot;) We worried controversial statements would be more likely to
    provoke negative reactions than invite mental probing. As an exercise, we
    sat in a group and asked ourselves to analyze three sample statements as
    they might be used in My Evidence:</p>
  <ul>
    <li> I
      believe global warming is caused by humans.</li>
    <li>I
      believe love is a product of evolution.</li>
    <li> I
      believe the earth is spinning.</li>
	  </ul>
  <p >For each statement, the group was asked to write up ideas
    about their own personal evidence. Few people in the group, however, wanted
    to work on all three statements. And while there were certainly many answers
    that overlapped, there were many responses that were unique and spoke to
    the personality of the authors, as well. When Melissa and Lowell got caught
    up in a debate about personal beliefs, we felt that there might be some value
    after all in offering an &ldquo;authority&rdquo; or some kind of moderation. What would
    happen when the users on-line looked at each other&rsquo;s Evidence Maps and saw
    something they didn&rsquo;t believe in or agree with? All of these questions were
    discussed and debated by the group.</p>
  <p >In the midst of these conversations and debates, senior
    scientist Thomas Humphrey became interested in eliciting feedback from a
    larger group. He sent an e-mail to the entire Exploratorium list-serv &ndash; 300
    people, many of them scientists &ndash; posing the three sample statements and
    seeking responses in the five answer formats (&ldquo;I observed...,&rdquo; &ldquo;I was told...,&rdquo; etc.).
    Everyone on the team received a variety of responses. One stand-out response
    came from Exploratorium staff biologist Charles Carlson, who compiled a long
    and varied list of possible answers.</p>
 <a name="Fig2" id="Fig2"></a> <p class="caption"><a name="fig2" id="fig2"></a><a href="robinson-fig2.html"><img src="robinson.fig2.small.gif" alt="Fig 2: When the Evidence team asked for My Evidence test responses from Exploratorium staff, Life Sciences Director Charles Carlson created this sample list of belief statements. Staff responses like this one helped us identify some of the project&rsquo;s design and language issues" width="400" height="393" border="0" /></a></p>
  <p class="caption">Fig 2: When the Evidence team asked for My Evidence test
    responses from Exploratorium staff, Life Sciences Director Charles Carlson
    created this sample list of belief statements. Staff responses like this
    one helped us identify some of the project&rsquo;s design and language issues.</p>
  <p >This, the first unmoderated test of the idea, was fun
    and interesting for the <em>Evidence</em> team. It was encouraging that the
    tool might actually be cool &ndash; the list on its own was cool, and if you could
    add additional tools, it would be even more cool. The list also provided
    some insights into needed improvements: After seeing Charlie&rsquo;s responses,
    for instance, the team realized that they needed to refine the words used
    in the belief statements. Other issues had to be addressed, as well.</p>
  <h2>Refining the Design</h2>
  <p >At this point, Lowell began meeting with developer/programmer
    David Beck, and together they brainstormed many of the finer points of the
    design. New on staff, David had not been part of the development team up
    to this time, and brought a fresh perspective to the project, as well as
    programming and design expertise.</p>
  <p >In several sessions, Lowell and David reworked a prototype
    model, incorporating features that better matched what came out of the evaluation
    and group discussions. The original prototype was kept as a paper, non-interactive
    mockup to preserve its flexibility and allow input from non-technical team
    members. As the prototype migrated from paper to interactive mockup, however,
    it locked down programming and design decisions and made it more difficult
    for non-interactive developers to participate in its creation.</p>
  <p >In conversation and on paper, Lowell and David explored
    a wide range of design questions addressing everything from privacy and authority
    to the visual design. Each of these issues needed careful consideration:</p>
  <h4>Usability</h4>
  <ul>
    <li> How
      can we engage the visitor? What can we do to allow users some immediate gratification?</li>
    <li> Will
      registration be required or can it be kept simple so users can explore without
      going through an arduous process?</li>
    <li> What
      about privacy issues? How can we create a private, safe space that will allow
      people to explore ideas, things they might not feel totally confident about?
      At what point can you invite them to share that?</li>
    <li> What
      information would we need from users that could help us build a database
      of responses to be shared? Age, gender, scientist/non-scientist, etc.?</li>
    <li> A
      lot of 2.0 applications are big on the idea of sharing, but only allow sharing
      on a very superficial level. How can we design in a way that offers tools
      that address the needs of intellectual complexity?</li>
    <li> How
      can we figure out whether people will want to browse each others&rsquo; Evidence
      Maps &ndash; by popularity, by maps that are most like or unlike mine, by scientists,
      by women?</li>
	  </ul>
  <h4>Moderation and Authority</h4>
  <ul>
    <li> Should
      the Exploratorium moderate, edit, or censor Evidence Maps?</li>
    <li> How
      do we deal with the possibility of users putting incorrect (and uncorrected)
      scientific information on their Evidence Maps, which then becomes part of
      the Exploratorium&rsquo;s site?</li>
    <li> How
      do we create a system that allows people to look at and comment on each other&rsquo;s
      evidence without igniting a flame war or jeopardizing each individual&rsquo;s safe
      space for exploration? </li>
	  </ul>
  <h4>Interactive Design Considerations</h4>
  <ul>
    <li> How
      can we address the evaluation finding that people wanted something more than
      just to look at a list of information? If we use more advanced ways of filtering
      or comparing data, are there more interesting findings that users might be
      able to see?</li>
    <li> How
      can our design be functional both for people who don&rsquo;t want to write very
      much, as well as for people who want to have a more freeform entry? </li>
    <li> How
      can we allow people to get their ideas out quickly if they don&rsquo;t want to
      go through all the steps of creating a Map.</li>
    <li> Based
      on the evaluation, people wanted a &ldquo;deep thought&rdquo; to come out of the experience.
      Would it make sense to ask people to add a note or comment, at the end of
      the process, or are we demanding too much from the user?</li>
    <li> Some
      people in the evaluation asked for a chronological aspect of the Evidence
      Map. Was there a way to do this?</li>
	  </ul>
  <h2>Working Through the Words</h2>
  <p >Once Lowell and David had hashed out these issues, they
    met with science writer Pearl Tesler to refine some of the nomenclature for
    the tool. Working as a three-person team, Lowell, David, and Pearl revisited
    the idea of changing the wording of the response categories, known to be
    a problem. Our advisors had also noted semantic issues we knew we needed
    to deal with. Geneticist Svante P&auml;&auml;bo, for example, was uncomfortable with
    the word &ldquo;believe&rdquo;
    because he separated the meaning of &ldquo;to think&rdquo; from &ldquo;to believe,&rdquo; in that
    you can &ldquo;think&rdquo; one thing today, and something else tomorrow; for him, &ldquo;belief&rdquo;
    felt too rigid and permanent.</p>
  <p >In response, Pearl, David, and Lowell changed the five
    original categories: (I observed...I was told...I read...I experienced...I
    was shown...) to a list of four more complex possibilities that included
    sub-categories. These revised categories did a better job of identifying
    primary and secondary experiences: </p>
  <ol>
    <li> I
      noticed...(implies primary experience and takes the place of I observed)</li>
    <li> I
      viewed...(implies passivity: TVs, movies)</li>
    <li> I
      was told...(teacher, parent, friend, peer, stranger)</li>
    <li> I
      read...(text book, science journal, popular magazine, newspaper, Web site)</li>
	  </ol>
  <p >Because David Beck and Lowell Robinson each have skills
    in both programming and art, the interactive development process did not
    follow the traditional pattern of a designer giving an Illustrator file to
    a Flash developer, and then the Flash developer doing all the programming
    individually. Rather, Lowell and David worked in parallel. David did the
    majority of the technical design, and Lowell did the majority of the visual
    design, but each was able to alter and finesse the other&rsquo;s work. The master
    files were shared on an Exploratorium server for ease of access.</p>
  <p >David, who has expertise in database and community building,
    began the process by developing a map for the data tables that would exist,
    and figuring out how they would be interrelated. He also sketched out a code
    architecture &ndash; a programming plan would serve as a working guide &ndash;
    especially important since more than one developer was working on the tool. </p>
  <p class="caption"><img src="robinson.fig3.jpg" alt="Fig 3. The My Evidence code architecture describes the hierarchy of the object-oriented programming" width="400" height="479" /></p>
  <p class="caption">Fig 3. The My Evidence code architecture describes the
    hierarchy of the object-oriented programming</p>
  <p >The application consists of a Flash front-end supported
    by server-side MySQL and PHP, with XML being the primary data-transfer medium.
    The Flash was developed in nested, modular pieces which assemble at run-time,
    thereby enabling simultaneous work by multiple developers on different areas
    of My Evidence.</p>
  <h2>Accessibility</h2>
  <p >We felt it was important to make My Evidence as accessible
    as possible to our visitors. In addition to streamlining the usability of
    the Evidence Maps, we focused on two functions that would open the tool to
    a broader audience and make saving and revisiting maps less difficult.</p>
  <p >First, the Flash application is built to be language-independent.
    All language elements (button labels, pull-down menus, etc.) are stored in
    a database and indexed to a languages table, which then populates the My
    Evidence application when the user specifies his or her desired language.
    Adding a new language becomes a (somewhat) simple matter of adding new text
    via an on-line table of function labels cross-referenced to languages.</p>
  <p >Second, although Evidence Maps may be created without
    logging in, we do require a user log-in for saving and publishing maps. In
    this initial build-out, we streamlined this process for people within the
    established Exploratorium community by repurposing an existing user-authentication
    system.</p>
  <p class="caption"><img src="robinson.fig4.gif" alt="Fig 4: The data scheme for My Evidence describes the structure of the MySQL database and defines relationships between collections of data." width="400" height="510" /></p>
  <p class="caption">Fig 4: The data scheme for My Evidence describes the structure
    of the MySQL database and defines relationships between collections of data. </p>
  <h2>Building the First Interactive Version of <em>My Evidence</em></h2>
  <h3>Working in Tandem</h3>
  <p >At this point, the concept of My Evidence was solid, but
    depending on the design of the <em>Evidence</em> Web site, there were still
    many possibilities for how it could be deployed (download, popup window,
    internal to the site). Since these decisions would affect the visual design
    of the tool and how much screen space it was allowed, Lowell and David needed
    at least a rough idea of the overall site design. While this might have proved
    awkward or created a time crunch if a different team had been handling the
    site&rsquo;s design, in this case Lowell was able to do the initial design pass
    on the <em>Evidence</em> site and get preliminary approval. This was enough
    to provide a working space for the My Evidence project to proceed.</p>
  <p >David built the first interactive version of My Evidence
    using placeholder art. When this version was partially functioning, with
    some interactivity in place, Lowell then worked on the tool&rsquo;s visual design,
    incorporating knowledge about how it would be integrated into the overall
    site, what screen real estate would be available, and so on. Because both
    were skilled in design and programming, questions of capability rarely came
    up. Instead, the challenge was capacity: Lowell and David needed to be careful
    about setting realistic goals so that an end product could be created. </p>
  <h3>Competing Interests</h3>
  <p >We wanted the site to be fun and easy to understand, to
    foster self-discovery and a better understanding of commonalities or differences
    of experience, and to feel safe. Yet working toward one goal often negatively
    impacted another. Would creating a visually appealing element detract from
    the meaning conveyed by the relationships between pieces of evidence? Would
    requiring personal information raise fears of loss of privacy or of opening
    oneself to the judgment of others? The more complex the data, the deeper
    the meaning conveyed by the system &ndash; and yet we wanted the initial learning
    curve to be very shallow.</p>
  <p >The design process became one of balancing goals for the
    site. The site needed to &lsquo;pop&rsquo;; it required that &lsquo;cool&rsquo; factor that gets
    attention on the increasingly dynamic Internet &ndash; yet we didn't want dynamism
    purely for dynamism's sake. Movement, color, and sheen had to contribute
    to the meaningfulness of the tool, without complicating users&rsquo; experience. </p>
  <p >We needed to create an interface that would be understood
    quickly by users without limiting the possibility of deeper inquiries into
    an individual&rsquo;s own learning process. But we also wanted the users to experience
    an &ldquo;aha&rdquo; moment after entering only a few pieces of evidence. As a result,
    the visual design had to create obvious relationships between the bits of
    evidence.</p>
  <p >A fully developed map would be a complex matrix of narratives
    cross-indexed by time and place. We needed to supply visualization tools
    to allow the users to glean subtler meanings from the data, while also being
    able to compare their maps to the maps of others in meaningful ways.</p>
  <p >It was imperative that the users know they could use the
    system in complete anonymity and security. We didn't want anyone to feel
    bad after creating a map &ndash; that wasn't the point of the exercise. Nor did
    we want people to fear judgment from others if they decided to publish their
    maps.</p>
  <p >Ultimately, the success of My Evidence will depend on
    how adeptly we've integrated these various interests into a simple yet deeply
    rewarding space.</p>
  <h2>Next Steps</h2>
  <p >As of this writing, in early 2007, we are looking forward
    to the final stages of interactive development for My Evidence. To be fully
    effective, the tool will need to handle not only the needs of individual
    users, but also a host of more complex interactions. By incorporating intelligent
    search functions, we&rsquo;re planning to offer the ability not only to store and
    search through each individual&rsquo;s data, but also to share, rate, and compare
    one another&rsquo;s data. At this point, a new round of evaluation &ndash; this time
    a more extensive on-line survey &ndash; will help guide our work, providing feedback
    from a broader group of adults fitting target audience criteria from diverse
    regions of the country. </p>
  <p >When the tool&rsquo;s design is final, we&rsquo;ll have one more major
    development task before offering My Evidence to the public, and that is to
    make sure the system doesn&rsquo;t start out empty. The team has always wanted
    to seed My Evidence with Evidence Maps offered by working scientists. Besides
    being of interest in and of themselves, these maps will provide thoughtful
    models and baselines for user comparisons, setting a tone of quality and
    professionalism that will help ensure (as much as possible within the environment
    of the Internet) that the tool is used safely and appropriately. As part
    of the larger <em>Evidence</em> project, this initial content will also enrich
    the audience&rsquo;s understanding of some of the scientists profiled elsewhere
    on the site, and give users the opportunity to identify on a personal basis
    with working scientists. If all goes well, users of My Evidence will ultimately
    have rich personal experiences that will help them think critically about
    their own &ndash; as well as others&rsquo; &ndash; patterns of thinking and learning.</p>
  <h2>Acknowledgments</h2>
  <p class="AcknowedgementsText">At the Exploratorium, no one works alone. But
    in particular, I would like to thank Ruth Brown, who is one hell of an editor.
    And I would also like to thank my wife, Gradiva, who is evidence of love,
    support, and beauty; I love you deeply. &ndash; Lowell Robinson</p>
  <p class="AcknowedgementsText">This material is based upon work supported by
    the National Science Foundation under Grant No. 0452128.</p>
				<!-- #EndEditable -->
				<h4>Cite as:</h4>
				<p class="references"><!-- #BeginEditable "OnlineCitation" --> Robinson,
				    L., et al., My Evidence: Who&rsquo;s the Authority Here? <!-- #EndEditable -->, 
				in J. Trant and D. Bearman (eds.). <em>Museums and the Web 2007: Proceedings</em>,
				 Toronto: Archives &amp; Museum Informatics, published March 1, 2007  Consulted  

                 <script language="JavaScript" type="text/javascript">
               <!-- <![CDATA[
// current date - based on http://rainbow.arch.scriptmania.com/scripts
// Array of day names
var dayNames = new Array("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday");

var monthNames = new Array("January","February","March","April","May","June","July",
                           "August","September","October","November","December");

var dt = new Date();
var y  = dt.getYear();

// Y2K compliant
if (y < 1000) y +=1900;

document.write(monthNames[dt.getMonth()] + " " + dt.getDate() + ", " + y + ". ");
	                // ]]> -->
				  </script>
http://www.archimuse.com/mw2007/papers/<!-- #BeginEditable "URL" -->robinson/robinson.html<br />
		    <br />
		    Note: Acknowledgements updated at authors' request.
		  <!-- #EndEditable --></p>
				<p class="references"><em><!-- InstanceBeginEditable name="Editorial Note" -->Editorial Note<!-- InstanceEndEditable --></em> </p>
	  </div>
<div id="sidebar">
			<div id="side-nav">
				<ul id="side-nav-list">
					    <li id="workshops"> <a href="../../workshops/index.html" class="menu">Workshops</a> </li>
						<li id="sessions"> <a href="../../sessions/index.html" class="menu" >Sessions</a> </li>
						<li id="speakers"> <a href="../../speakers/index.html" class="menu" >Speakers</a> </li>
						<li id="interactions"> <a href="../../interact/index.html" class="menu">Interactions</a> </li>
						<li id="demonstrations"> <a href="../../demos/index.html" class="menu">Demonstrations</a> </li>
						<li id="events"> <a href="../../events/index.html" class="menu">Events</a> </li>
						<li id="exhibits"> <a href="../../exhibit/index.html" class="menu">Exhibits</a> </li>
						<li id="best"> <a href="../../best/index.html" class="menu">Best of the Web </a></li>
				</ul>
			</div>
			<div id="search-site">
				<form method="post" action="../http://search.archimuse.com/cgi-bin/htsearch">
					<input type="hidden" name="format" value="builtin-long" />
					<input type="hidden" name="method" value="and" />
					<input type="hidden" name="config" value="htdig-mw2007" />
					<input type="hidden" name="restrict" value="" />
					<input type="hidden" name="exclude" value="" />
					<input type="text" size="20" name="words" value="" id="searchmw" />
					<input type="image" src="../../images/searchmw2007.gif" id="searchbox" name="search" />
				</form>
			</div>
				<div id="sidebar-links">
				<ul id="sidebar-links-list">
					<li><a href="../../../index.html" class="produced-by">produced by<br />
					    <img src="../../images/sidelogo.gif" width="144" height="37" alt="AMI logo" /></a></li>
					<li><a href="../../../index.html">Join our mailing list</a></li>
					<li><a href="../http://search.museumsandtheweb.com/search">Search A&amp;MI<br />
					<img src="../../../external.gif?link=http://www.archimuse.com/ami.images/search.gif" alt="search" width="24" height="25" /></a></li>
				</ul>
		  </div>
		</div>
		<div id="footer">
		  <div id="last-updated">
          published: April 11, 2007<br />
			last updated:<!-- #BeginDate format:Am1a -->October 28, 2010 12:23 PM<!-- #EndDate -->
		        <div id="cc">
        <!--htdig_noindex-->
        <a rel="license" href="../http://creativecommons.org/licenses/by-nc-nd/3.0/"><img src="../http://i.creativecommons.org/l/by-nc-nd/3.0/88x31.png" alt="Creative Commons Attribution-Noncommercial-No Derivative Works 3.0  License" width="88" height="31" style="border-width:0" /></a>
        <!--/htdig_noindex-->
      </div>
		  </div>
			<div id="footer-content">
				Archives &amp; Museum Informatics, 158 Lee Avenue, Toronto, Ontario, M4E 2P3 Canada<br />
				Telephone: +1 416 691 2516 | Fax: +1 416 352 6025 | E-mail:
				
				<script language="JavaScript" type="text/javascript">
               <!-- <![CDATA[
	           user = "mw2007";
	           site = "archimuse.com";
	           position = "Page Footer";
	           document.write('<a href=\"mailto:' + user + '@' + site + '\?subject=Response from MW2007 Web Site: ' + position + '\">');
	           document.write( user  + ' @ ' + site + '<\/a>');
	                // ]]> -->
				</script>	

		<br />
				Copyright &copy; 2006 - Archives &amp; Museum Informatics - All rights reserved.<br />
			</div>
			<div style="clear:both"></div>
		</div>
	</div>
<!-- analytics scripts -->
<!-- tynt script -->
<script type="text/javascript">tyntVariables = {"ap":"Read more: "};</script> 
<script type="text/javascript" src="../http://tcr.tynt.com/javascripts/Tracer.js?user=aTNeQ-tzOr36a6adbiUzgI&amp;s=130&amp;cc=6&amp;st=1"></script>
<noscript></noscript>

<!-- google analytics script -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26332456-1']);
  _gaq.push(['_setDomainName', '.archimuse.com']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!--chartbeat script -->
<script type="text/javascript">
var _sf_async_config={uid:3385,domain:"archimuse.com"};
(function(){
  function loadChartbeat() {
    window._sf_endpt=(new Date()).getTime();
    var e = document.createElement('script');
    e.setAttribute('language', 'javascript');
    e.setAttribute('type', 'text/javascript');
    e.setAttribute('src',
       (("https:" == document.location.protocol) ? "https://s3.amazonaws.com/" : "http://") +
       "static.chartbeat.com/js/chartbeat.js");
    document.body.appendChild(e);
  }
  var oldonload = window.onload;
  window.onload = (typeof window.onload != 'function') ?
     loadChartbeat : function() { oldonload(); loadChartbeat(); };
})();

</script>


</script>
<!--/htdig_noindex-->
</body>
<!-- InstanceEnd -->
<!-- Mirrored from www.museumsandtheweb.com/mw2007/papers/robinson/robinson.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 17:29:00 GMT -->
</html>
					