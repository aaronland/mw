<!DOCTYPE html>
<html lang="en-US" class="no-js no-svg">

<!-- Mirrored from mw20.museweb.net/paper/ai-sees-what-the-good-the-bad-and-the-ugly-of-machine-vision-for-museum-collections/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 11 May 2022 19:08:26 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="profile" href="https://gmpg.org/xfn/11">

<script>(function(html){html.className = html.className.replace(/\bno-js\b/,'js')})(document.documentElement);</script>
<title>AI Sees What? The Good, the Bad, and the Ugly of Machine Vision for Museum Collections &#8211; MW20 | Online</title>
<link rel='dns-prefetch' href='../../index.html' />
<link rel='dns-prefetch' href='http://fonts.googleapis.com/' />
<link rel='dns-prefetch' href='http://s.w.org/' />
<link href='https://fonts.gstatic.com/' crossorigin rel='preconnect' />
<link rel="alternate" type="application/rss+xml" title="MW20 | Online &raquo; Feed" href="../../feed/index.html" />
<link rel="alternate" type="application/rss+xml" title="MW20 | Online &raquo; Comments Feed" href="../../comments/feed/index.html" />
		<script>
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/mw20.museweb.net\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.6"}};
			!function(e,a,t){var r,n,o,i,p=a.createElement("canvas"),s=p.getContext&&p.getContext("2d");function c(e,t){var a=String.fromCharCode;s.clearRect(0,0,p.width,p.height),s.fillText(a.apply(this,e),0,0);var r=p.toDataURL();return s.clearRect(0,0,p.width,p.height),s.fillText(a.apply(this,t),0,0),r===p.toDataURL()}function l(e){if(!s||!s.fillText)return!1;switch(s.textBaseline="top",s.font="600 32px Arial",e){case"flag":return!c([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])&&(!c([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!c([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]));case"emoji":return!c([55357,56424,8205,55356,57212],[55357,56424,8203,55356,57212])}return!1}function d(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(i=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},o=0;o<i.length;o++)t.supports[i[o]]=l(i[o]),t.supports.everything=t.supports.everything&&t.supports[i[o]],"flag"!==i[o]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[i[o]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(r=t.source||{}).concatemoji?d(r.concatemoji):r.wpemoji&&r.twemoji&&(d(r.twemoji),d(r.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style>
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='wp-block-library-css'  href='../../wp-includes/css/dist/block-library/style.min40df.css?ver=5.6' media='all' />
<link rel='stylesheet' id='wp-block-library-theme-css'  href='../../wp-includes/css/dist/block-library/theme.min40df.css?ver=5.6' media='all' />
<link rel='stylesheet' id='sidebar-login-css'  href='../../wp-content/plugins/sidebar-login/build/sidebar-login4274.css?ver=1604076739' media='all' />
<link rel='stylesheet' id='parent-style-css'  href='../../wp-content/themes/twentyseventeen/style40df.css?ver=5.6' media='all' />
<link rel='stylesheet' id='child-style-css'  href='../../wp-content/themes/mwconf/style40df.css?ver=5.6' media='all' />
<link rel='stylesheet' id='twentyseventeen-fonts-css'  href='https://fonts.googleapis.com/css?family=Libre+Franklin%3A300%2C300i%2C400%2C400i%2C600%2C600i%2C800%2C800i&amp;subset=latin%2Clatin-ext&amp;display=fallback' media='all' />
<link rel='stylesheet' id='twentyseventeen-style-css'  href='../../wp-content/themes/mwconf/style3ce7.css?ver=20201208' media='all' />
<link rel='stylesheet' id='twentyseventeen-block-style-css'  href='../../wp-content/themes/twentyseventeen/assets/css/blocksfbfa.css?ver=20190105' media='all' />
<!--[if lt IE 9]>
<link rel='stylesheet' id='twentyseventeen-ie8-css'  href='https://mw20.museweb.net/wp-content/themes/twentyseventeen/assets/css/ie8.css?ver=20161202' media='all' />
<![endif]-->
<!--[if lt IE 9]>
<script src='https://mw20.museweb.net/wp-content/themes/twentyseventeen/assets/js/html5.js?ver=20161020' id='html5-js'></script>
<![endif]-->
<script src='../../wp-includes/js/jquery/jquery.min9d52.js?ver=3.5.1' id='jquery-core-js'></script>
<script src='../../wp-includes/js/jquery/jquery-migrate.mind617.js?ver=3.3.2' id='jquery-migrate-js'></script>
<link rel="https://api.w.org/" href="../../wp-json/index.html" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="../../xmlrpc0db0.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="../../wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 5.6" />
<link rel="canonical" href="index.html" />
<link rel='shortlink' href='../../index4511.html?p=1261' />
<link rel="alternate" type="application/json+oembed" href="../../wp-json/oembed/1.0/embed0dd3.json?url=https%3A%2F%2Fmw20.museweb.net%2Fpaper%2Fai-sees-what-the-good-the-bad-and-the-ugly-of-machine-vision-for-museum-collections%2F" />
<link rel="alternate" type="text/xml+oembed" href="../../wp-json/oembed/1.0/embed91a8?url=https%3A%2F%2Fmw20.museweb.net%2Fpaper%2Fai-sees-what-the-good-the-bad-and-the-ugly-of-machine-vision-for-museum-collections%2F&amp;format=xml" />
		<style id="wp-custom-css">
			h1 { 
  display: block;
  font-size: 2em;
  margin-top: 0.57em;
  margin-bottom: 0.57em;
  margin-left: 0;
  margin-right: 0;
  font-weight: 500;
}

h2 { 
  display: block;
  font-size: 1.7em;
  margin-top: -1em;
  margin-bottom: .1em;
	color: #000;
}

h3 {
	font-weight:500;
}

hr
	{ margin-bottom:2em;
		margin-top:2em;
}

p {
	font-size:16px;
}

li {
	
	font-size:12pt;
}

li:not(:last-child) {
    margin-bottom: -10px;
}

ul {
	margin-left:3em;
}

ol {
		margin-left:1.5em;

}

/*Gets rid of underlined links*/
.entry-content a, .entry-content 

a:hover {
	text-decoration: none;
	box-shadow: none;
	color:darkcyan;
}

a:link {
box-shadow: none;
	color:darkred;
	font-weight:600;
}
a:visited {
box-shadow: none;
	color:darkred;

}
a:hover {
box-shadow: none;
	color:lightgray;
	border-bottom:none;
}

/* Changes size of title */
.site-title, .site-title a 
{
	font-size:1.7em !important;
	color:#000;
}

/* Moves title block to right slightly */
.wrap {
max-width: 95%;
padding-left: 1.5em;
}

select { height: 1.5em !important; }

/*Changes size of subtitle where it says Boston, Ma*/
body.has-header-image .site-description, body.has-header-video .site-description {
color: #fff;
font-size: 24.5px;
padding-top: .0em;
padding-bottom:.3em;
}
/* Changes size and color page titles*/
.entry-title, .entry-title a {
color: darkgray !important;
font-weight:bold;
font-size: 30px !important;
}

/* Changes nav size and color*/
#top-menu  li.menu-item a {
color:darkred;
	font-size:16px;
	padding-top:22px;

} 

/*Spaces nav menu items out*/
.main-navigation a {
    padding: 1em;

}

/* Adds gray box over nav on hover*/
#top-menu  li.menu-item a:hover {
background-color:#eee;
color:#666;
border-radius:1px;
margin-left:0px !important;
}

/* Gets rid of navigation arrow*/
a.menu-scroll-down {
    display: none!important;
}

/* Lessens the gap between header and content section*/
#content {
padding-top: 40px;
}

/*Removes page title and closes gap*/
.page #content {
padding-top: 3em !important;
}

/*Takes off individual page title*/
.page .entry-header {
display: none !important;
}


/*Changes the size of the header image*/

.has-header-image.twentyseventeen-front-page .custom-header,
.has-header-video.twentyseventeen-front-page .custom-header,
.has-header-image.home.blog .custom-header,
.has-header-video.home.blog .custom-header {
display: block;
height: 600px;
}

/*Ensures that the full title will appear in mobile view*/
.entry-title{
    font-size: 25px !important;
}

/*Reduces the gap between the menu and the content*/
@media screen and (min-width: 48em){
.panel-content .wrap {
    padding-top: 10px;
}
.page.page-one-column .entry-header, .twentyseventeen-front-page.page-one-column .entry-header, .archive.page-one-column:not(.has-sidebar) .page-header {
    margin-bottom: 20px;
}
}


/** call-to-action button **/
.cta {
  background:#ccc;
  background-image: -webkit-linear-gradient(top, #ccc, #ccc);
  background-image: -moz-linear-gradient(top, #ccc, #ccc);
  background-image: -ms-linear-gradient(top, #ccc, #ccc);
  background-image: -o-linear-gradient(top, #ccc, #ccc);
  background-image: linear-gradient(to bottom, #ccc, #ccc);
  -webkit-border-radius: 4;
  -moz-border-radius: 4;
  border-radius: 4px;
  -webkit-box-shadow: 2px 2px 5px #3366cc;
  -moz-box-shadow: 2px 2px 5px #ccc;
  box-shadow: 2px 2px 5px #ccc;
  color: #ffffff;
  font-size: 20px;
  padding: 15px 25px 15px 25px;
  text-decoration: none;
}
 .cta:hover { 
  background: #ddd;
  background-image: -webkit-linear-gradient(top, #ddd, #ddd);
  background-image: -moz-linear-gradient(top, #ddd, #ddd);
  background-image: -ms-linear-gradient(top, #ddd, #ddd);
  background-image: -o-linear-gradient(top, #ddd, #ddd);
  background-image: linear-gradient(to bottom, #ddd, darkgay);
  text-decoration: none;
}


/*Removes comments*/
#comments {
display: none !important;
}

#colophon {
background: #E91249;
}

/*Changes footer color*/
#colophon * {
color: white !important;
list-style: none !important;
border: none !important;
box-shadow: none !important;
}

/*Changes font size and color in widget sidebar*/
.widget-title {
background: darkred;
font-size: 12px !important;
color: white !important;
font-family:Libre Franklin !important;
padding-top: .8em !important;
padding-bottom:.8em;
}

/* Footer 1 Wider content */
@media screen and (min-width: 48em) {
.site-footer .widget-column.footer-widget-1 {
    /* float: left; */
    width: 47%;
	/* margin-left:4em; */
 }
}
/* Footer 2 content */
@media screen and (min-width: 48em) {
.site-footer .widget-column.footer-widget-2 {
    /* float: right; */
    width: 47%;
 }
}
/* Social icons */
@media screen and (min-width: 48em) {
.social-navigation {
    /* clear: left; */
    /* float: left; */
    /* margin-bottom: 0; */
    width: 47%;
	/* margin-left:4em */
 }
}

/*Makes the main body content wider*/
.wrap {
	/* margin-left: auto; */
	/* margin-right: auto; */
	max-width: 90%;
	/* padding-left: 2em; */
	/* padding-right: 2em; */
}
 
@media screen and (min-width: 48em) {
	.wrap {
		max-width: 80%;
		/* padding-left: 1em; */
		/* padding-right: 1em; */
	}
}
 
.page.page-one-column:not(.twentyseventeen-front-page) #primary {
	/*margin-left: auto;*/
	/*margin-right: auto;*/
	max-width: 100%;
}

@media screen and (min-width: 30em) {
	.page-one-column .panel-content .wrap
	{
		max-width: 80%;
	}
}

.wrap {
	/* margin-left: auto; */
	/* margin-right: auto; */
	max-width: 95%;
	/* padding-left: 2em; */
	/* padding-right: 2em; */
}
 
@media screen and (min-width: 48em) {
	.wrap {
		max-width: 95%;
		/* padding-left: 3em; */
		/* padding-right: 3em; */
	}
}
 
.page.page-one-column:not(.twentyseventeen-front-page) #primary {
	/*margin-left: auto;*/
	/*margin-right: auto;*/
	max-width: 95%;
}

@media screen and (min-width: 30em) {
	.page-one-column .panel-content .wrap
	{
		max-width: 95%;
	}
}

@media screen and (min-width: 48em) {
.has-sidebar:not(.error404) #primary {
	width: 74%;		
}

.has-sidebar #secondary {
	width: 20%;
}
}

.widget {
	padding-bottom: 2.5em;
	padding-top: 1.0em;
}

h2.widget-title {
	margin-top: 1em;
	margin-bottom: 2em;
	text-align: center;
	background-color:#E91249;
}

.textwidget {
	/* text-align: center; */
}

.sponsor-img {
	max-width: 80%;
}

p {
margin: 0 0 .4em;
padding-top:.2em;
padding-bottom:.5em;
line-height:29px;
}

li {
	line-height:29px;
	padding-top:5px
}

		</style>
		</head>

<body class="paper-template-default single single-paper postid-1261 wp-embed-responsive has-sidebar group-blog has-header-image colors-light">
<div id="page" class="site">
	<a class="skip-link screen-reader-text" href="#content">Skip to content</a>

	<header id="masthead" class="site-header" role="banner">

		<div class="custom-header">

		<div class="custom-header-media">
			<div id="wp-custom-header" class="wp-custom-header"><img src="../../wp-content/uploads/2019/08/cropped-los-angeles-1584089_1920-Pixabay.jpg" width="2000" height="1200" alt="MW20 | Online" srcset="https://mw20.museweb.net/wp-content/uploads/2019/08/cropped-los-angeles-1584089_1920-Pixabay.jpg 2000w, https://mw20.museweb.net/wp-content/uploads/2019/08/cropped-los-angeles-1584089_1920-Pixabay-300x180.jpg 300w, https://mw20.museweb.net/wp-content/uploads/2019/08/cropped-los-angeles-1584089_1920-Pixabay-768x461.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2019/08/cropped-los-angeles-1584089_1920-Pixabay-1024x614.jpg 1024w" sizes="100vw" /></div>		</div>

	<div class="site-branding">
	<div class="wrap">

		
		<div class="site-branding-text">
							<p class="site-title"><a href="../../index.html" rel="home">MW20 | Online</a></p>
			
							<p class="site-description">Online | March 31-April 4, 2020</p>
					</div><!-- .site-branding-text -->

		
	</div><!-- .wrap -->
</div><!-- .site-branding -->

</div><!-- .custom-header -->

					<div class="navigation-top">
				<div class="wrap">
					<nav id="site-navigation" class="main-navigation" role="navigation" aria-label="Top Menu">
	<button class="menu-toggle" aria-controls="top-menu" aria-expanded="false">
		<svg class="icon icon-bars" aria-hidden="true" role="img"> <use href="#icon-bars" xlink:href="#icon-bars"></use> </svg><svg class="icon icon-close" aria-hidden="true" role="img"> <use href="#icon-close" xlink:href="#icon-close"></use> </svg>Menu	</button>

	<div class="menu-main-menu-container"><ul id="top-menu" class="menu"><li id="menu-item-180" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-180"><a href="http://museweb.net/">MuseWeb</a></li>
<li id="menu-item-23" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-has-children menu-item-23"><a href="../../index.html">About<svg class="icon icon-angle-down" aria-hidden="true" role="img"> <use href="#icon-angle-down" xlink:href="#icon-angle-down"></use> </svg></a>
<ul class="sub-menu">
	<li id="menu-item-183" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-183"><a href="../../index.html">About</a></li>
	<li id="menu-item-181" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-181"><a href="../../conference-faqs/index.html">Conference FAQs</a></li>
	<li id="menu-item-182" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-182"><a href="../../key-dates/index.html">Key Dates</a></li>
</ul>
</li>
<li id="menu-item-184" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-184"><a href="../../attending/index.html">Attending<svg class="icon icon-angle-down" aria-hidden="true" role="img"> <use href="#icon-angle-down" xlink:href="#icon-angle-down"></use> </svg></a>
<ul class="sub-menu">
	<li id="menu-item-185" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-185"><a title="Registration Rates" href="../../attending/index.html">Registration Rates</a></li>
	<li id="menu-item-980" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-980"><a href="../../registration/index.html">Registration</a></li>
	<li id="menu-item-186" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-186"><a href="../../conference-hotel/index.html">Conference Hotel</a></li>
	<li id="menu-item-187" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-187"><a href="../../volunteering/index.html">Volunteering</a></li>
	<li id="menu-item-188" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-188"><a href="../../scholarships/index.html">Scholarships</a></li>
	<li id="menu-item-191" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-191"><a href="../../visa-and-invitation-letters/index.html">Visa and Invitation Letters</a></li>
</ul>
</li>
<li id="menu-item-192" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-192"><a href="../../call-for-proposals/index.html">Presenting<svg class="icon icon-angle-down" aria-hidden="true" role="img"> <use href="#icon-angle-down" xlink:href="#icon-angle-down"></use> </svg></a>
<ul class="sub-menu">
	<li id="menu-item-193" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-193"><a href="../../call-for-proposals/index.html">Call for Proposals</a></li>
	<li id="menu-item-194" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-194"><a href="../../submit-proposal/index.html">Submit Your Proposal</a></li>
	<li id="menu-item-196" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-196"><a href="../../paper-guidelines/index.html">Paper Guidelines</a></li>
	<li id="menu-item-309" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-309"><a href="../../guidelines-for-proposals/index.html">Guidelines for Proposals</a></li>
	<li id="menu-item-197" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-197"><a href="../../presentation-guidelines/index.html">Presentation Guidelines</a></li>
	<li id="menu-item-198" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-198"><a href="../../terms-and-conditions/index.html">Terms and Conditions</a></li>
</ul>
</li>
<li id="menu-item-199" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-199"><a href="../../exhibiting-and-presenting/index.html">Exhibiting<svg class="icon icon-angle-down" aria-hidden="true" role="img"> <use href="#icon-angle-down" xlink:href="#icon-angle-down"></use> </svg></a>
<ul class="sub-menu">
	<li id="menu-item-200" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-200"><a href="../../exhibiting-and-presenting/index.html">Exhibiting and Presenting</a></li>
	<li id="menu-item-201" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-201"><a href="../../exhibitor-registration/index.html">Exhibitor Registration</a></li>
	<li id="menu-item-202" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-202"><a href="../../sponsorship-opportunities/index.html">Sponsorship Opportunities</a></li>
	<li id="menu-item-203" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-203"><a href="../../advertising/index.html">Advertising</a></li>
	<li id="menu-item-206" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-206"><a href="../../exhibit-hall-information/index.html">Exhibit Hall Information</a></li>
</ul>
</li>
<li id="menu-item-898" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-898"><a href="../../program/index.html">Conference<svg class="icon icon-angle-down" aria-hidden="true" role="img"> <use href="#icon-angle-down" xlink:href="#icon-angle-down"></use> </svg></a>
<ul class="sub-menu">
	<li id="menu-item-902" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-902"><a href="../../program/index.html">Program</a></li>
	<li id="menu-item-3131" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3131"><a href="../../papers/index.html">Papers</a></li>
	<li id="menu-item-508" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-508"><a href="../../committees/index.html">Committees</a></li>
	<li id="menu-item-1582" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1582"><a href="../../glami-awards/index.html">GLAMi Awards<svg class="icon icon-angle-down" aria-hidden="true" role="img"> <use href="#icon-angle-down" xlink:href="#icon-angle-down"></use> </svg></a>
	<ul class="sub-menu">
		<li id="menu-item-3027" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3027"><a href="../../glami-award-finalists/index.html">GLAMi Award Finalists</a></li>
	</ul>
</li>
	<li id="menu-item-899" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-899"><a href="../../attendees/index.html">Attendees</a></li>
	<li id="menu-item-531" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-531"><a href="../../mwx/index.html">MWX</a></li>
</ul>
</li>
</ul></div>
	</nav><!-- #site-navigation -->
				</div><!-- .wrap -->
			</div><!-- .navigation-top -->
		
	</header><!-- #masthead -->

	
	<div class="site-content-contain">
		<div id="content" class="site-content">

<div class="wrap">
	<div id="primary" class="content-area">
		<main id="main" class="site-main" role="main">

<style type="text/css">
h2 { font-weight: bold; font-size: 18px; }
h3, h4, h5, h6 { font-weight: bold; font-size: 16px; }

td, th { padding: 5px; }
th { background-color: #ccc; font-weight: bold; }
tr:nth-child(odd) { background-color: #eee }
</style>


<h2>AI Sees What? The Good, the Bad, and the Ugly of Machine Vision for Museum Collections</h2>

<p><a target="_blank" href="https://www.museweb.net/member/brendanciecko/">Brendan Ciecko</a>, Cuseum, USA</p></p>

<h2>Abstract</h2>
Recently, as artificial intelligence (AI) has become more widespread and accessible, museums have begun to make use of this technology. One tool in particular, machine vision, has made a considerable splash in museums in recent years. Machine vision is the ability for computers to understand what they are seeing. Although the application of machine vision to museums is still in its early stages, the results show promise. In this session, we will explore the strengths and successes of this new technology, as well as the areas of concern and ethical dilemmas it produces as museums look towards machine vision as a move to effortless aid in the generation of metadata and descriptive text for their collections.

Over the course of several months, we have collected data on how machine vision perceives collection images. This study represents a sustained effort to analyze the performance and accuracy of various machine vision tools (such as Google Cloud Vision, Microsoft Cognitive Services, AWS Rekognition, etc.) at describing images in museum collection databases. In addition to thoroughly assessing the AI-generated outputs, we have shared the results with several prominent curators, and museum digital technology specialists, collecting expert commentary from such museum professionals on the fruits of this research.

Now, we strive to share our results. Our study represents over 100 hours worth of time invested in technical analysis, data collection, and interpretation, and we want to share this knowledge to advance the conversation in the museum field.

The goal of this paper is to spark a discussion around machine vision in museums and encourage the community to engage with ongoing ethical considerations related to this technology. While machine vision may unlock new potentials for the cultural sector, when it comes to analyzing culturally-sensitive artifacts, it is essential to scrutinize the ways that machine vision can perpetuate biases, conflate non-Western cultures, and generate confusion.</p>
<p><b>Keywords:</b> artificial intelligence, machine vision, museum collections</p>
<p><span style="font-weight: 400">A</span><span style="font-weight: 400">rtificial intelligence (AI) is already reshaping all aspects of society, business, and culture. </span><span style="font-weight: 400">From offering up personalized Netflix recommendations to auto-completing our sentences in Gmail, AI already underlies many routine aspects of our lives in ways we do not even realize.</span></p>
<p><span style="font-weight: 400">AI has transformed the commercial sector in myriad ways. While most of us may be familiar with chatbots and predictive engines, it goes far beyond this. From offering contextual marketing messaging, transferring and cross-referencing data, deciding personal injury claims for insurance firms, to enabling financial fraud detection, innovative applications of artificial intelligence technology are popping up everywhere.</span></p>
<p><span style="font-weight: 400">Recently, as AI has become more widespread and accessible, museums have begun to make use of this technology. One tool in particular, machine vision, has made a considerable splash in museums in recent years. Machine vision is the ability of computers to understand what they are seeing. Although the application of machine vision to museums is still in its early stages, the results show promise. In this paper, we will explore the strengths and successes of this new technology, as well as the areas of concern and ethical dilemmas it produces as museums look towards machine vision as a move to aid in the generation of metadata and descriptive text for their collections.</span></p>
<p><span style="font-weight: 400">In an effort to advance our understanding of machine vision&#8217;s potential impacts, over the course of several months, we have collected data on how machine vision perceives collection images. This study represents a sustained effort to analyze the performance and accuracy of various machine vision tools (such as Google Cloud Vision, Microsoft Cognitive Services, and AWS Rekognition) at describing images in museum collection databases. In addition to thoroughly assessing the AI-generated outputs, we have shared the results with several prominent curators and museum digital technology specialists, collecting expert commentary from such museum professionals on the fruits of this research.</span></p>
<p><span style="font-weight: 400">Our study represents over 100 hours worth of time invested in technical analysis, data collection, and interpretation, which we hope will help advance the conversation in the museum, art, and cultural heritage field.</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">In conjunction with strides in digitizing collections, moving towards open access, and linking open data, as well as the growing application of emerging digital tools across the museum sector, machine vision has the potential to accelerate the value created from these important foundational initiatives.</span></p>
<p><span style="font-weight: 400">The goal of our exploration of this technology is to spark a discussion around machine vision in museums and encourage the community to engage with ongoing ethical considerations related to this technology. While machine vision may unlock new potentials for the cultural sector, when it comes to analyzing culturally-sensitive artifacts, it is essential to scrutinize the ways that machine vision can perpetuate biases, conflate non-Western cultures, and generate confusion.</span></p>
<h2><b>What is Machine Vision?</b></h2>
<p><b></b><b></b><a href="https://www.cognex.com/what-is/machine-vision/what-is-machine-vision"><span style="font-weight: 400">Machine vision</span></a><span style="font-weight: 400"> is quickly becoming one of the most important applications of artificial </span><span style="font-weight: 400">intelligence </span><span style="font-weight: 400">(Cognex, 2019)</span><span style="font-weight: 400">. I</span><span style="font-weight: 400">n the most simple terms, machine vision can be understood as &#8220;the eyes of a </span><span style="font-weight: 400">machine.&#8221; </span><a href="https://www.forbes.com/sites/bernardmarr/2019/10/11/what-is-machine-vision-and-how-is-it-used-in-business-today/#22f9846a6939"><span style="font-weight: 400">According to Forbes</span></a><span style="font-weight: 400">, this technology has a variety of applications in business including for &#8220;quality control purposes,&#8221; and helping businesses in many ways today for &#8220;identification, inspection, guidance and more&#8221; </span><span style="font-weight: 400">(Marr, 2019).</span><span style="font-weight: 400"> Machine vision is the underlying technology behind facial recognition, such as that of Facebook face tagging and Apple&#8217;</span><span style="font-weight: 400">s novel methods of unlocking iPhones, Google&#8217;s Lens for visual search, and even autonomous vehicles. Like many emerging technologies, the average consumer is likely to interact with machine vision daily and might not even know it.</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">Even though it may appear that machine vision has only recently emerged on the scene, this technology has been in development since the 1960s (</span><span style="font-weight: 400">Papert, 1966)</span><span style="font-weight: 400">. Now, almost sixty years later, we are still developing this technology and unlocking exciting new use cases. Every major technology company has leveraged machine vision to advance their own products and services, and they have made their platforms commercially available to enhance the appeal and power of their cloud-computing solutions.</span></p>
<h2><b>Machine Vision in Museums</b><b></b></h2>
<p><span style="font-weight: 400">Recently, as machine vision and AI have become more widespread and accessible, museums have also begun to make use of this technology. Several museums, including The Metropolitan Museum of Art, the Barnes Foundation, and Harvard Art Museums, have employed machine vision to analyze, categorize, and interpret their collection images. Although the application of machine vision to museums is still in its early stages, the results show promise. </span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">From basic subject detection to complex semantic segmentation aided by deep learning, optical character recognition, and color composition, there are different ways in which machine vision can be used. As accuracy improves and more sophisticated models of machine vision come into play, it will almost certainly change the way museum collection images can be further explored, dissected, and disseminated.</span><span style="font-weight: 400"><br />
</span></p>
<figure id="attachment_1213" aria-describedby="caption-attachment-1213" style="width: 440px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1213" src="../../wp-content/uploads/2020/01/ciecko.fig1_-300x169.jpg" alt="Painting of the Grand Canal in Venice, Italy, featuring numerous boats and grand palaces." width="440" height="248" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig1_-300x169.jpg 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig1_-768x432.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig1_.jpg 800w" sizes="(max-width: 440px) 100vw, 440px" /><figcaption id="caption-attachment-1213" class="wp-caption-text">Figure 1: Image of &#8220;The Grand Canal in Venice from Palazzo Flangini to Campo San Marcuola,&#8221; by Canaletto (Giovanni Antonio Canal), from the collection of: J. Paul Getty Museum</figcaption></figure>
<p>&nbsp;</p>
<figure id="attachment_1218" aria-describedby="caption-attachment-1218" style="width: 432px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1218" src="../../wp-content/uploads/2020/01/ciecko.fig2_-1-300x169.png" alt="Color-segmented image showing what a computer sees when analyzing the painting described in Figure 1." width="432" height="243" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig2_-1-300x169.png 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig2_-1-768x432.png 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig2_-1.png 800w" sizes="(max-width: 432px) 100vw, 432px" /><figcaption id="caption-attachment-1218" class="wp-caption-text">Figure 2: Image of machine vision analysis of work depicted in Figure 1</figcaption></figure>
<p><span style="font-weight: 400">Museums often have thousands of objects logged in their collections, with limited information on them. For collections to become easier to analyze and search, it is essential to collect or generate metadata on these objects.</span></p>
<h2><b>What is Metadata?</b><b><br />
</b></h2>
<p><span style="font-weight: 400">In simple terms, metadata is data that describes data. In television and film, a piece of data might be the name of a movie. For example, </span><i><span style="font-weight: 400">To Be or Not to Be</span></i><span style="font-weight: 400">. For every piece of data, like the film itself, one can assemble a body of further metadata. In this case, one could describe the movie with information like: </span><span style="font-weight: 400"><br />
</span></p>
<table style="height: 298px" width="430">
<tbody>
<tr>
<td><img loading="lazy" class="alignnone wp-image-1219 size-medium" src="../../wp-content/uploads/2020/01/ciecko.fig3_-203x300.jpg" alt="Movie poster for &quot;To Be or Not To Be&quot; depicting the faces of the lead actor and actress." width="203" height="300" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig3_-203x300.jpg 203w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig3_-691x1024.jpg 691w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig3_-768x1138.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig3_.jpg 800w" sizes="(max-width: 203px) 100vw, 203px" /></td>
<td><span style="font-weight: 400"><strong>Director:</strong> Ernst Lubitsch</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><strong>Starring:</strong> Carole Lombard, Jack Benny</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><strong>Genre:</strong> Comedy<br />
</span><span style="font-weight: 400"><strong>Release Date:</strong> March 6, 1942</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><strong>Language:</strong> English</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><strong>Running Time:</strong> 99 minutes</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><strong>Awards:</strong> Academy Award for Best Original Music Score</span></td>
</tr>
</tbody>
</table>
<p>Figure 3: Image of &#8220;To Be or Not to Be&#8221; movie poster.</p>
<p><span style="font-weight: 400">Increasingly sophisticated metadata can be collected and attached to this film, based on the content, theme, and emotive response it may generate. For example, it can also be tagged with </span>&#8220;satire,&#8221; &#8220;war&#8221; and &#8220;comedy.&#8221; That means that when a user logs onto Netflix or Hulu to search for a movie, options can be suggested to fit their interests based on algorithmic analytics paired with the wealth of metadata associated with their past viewing behavior.</p>
<p><span style="font-weight: 400">This is equally important in the context of museums. </span><a href="http://www.getty.edu/publications/intrometadata"><span style="font-weight: 400">According to the Getty</span></a><span style="font-weight: 400">, metadata can reflect three different features about objects: content, context, and structure (</span><span style="font-weight: 400">Baca, 2008)</span><span style="font-weight: 400">. Creating robust datasets that describe museum collections is essential because without them, even open-access collections are limited in their value. Only a robust tagging system that describes various features and contexts of artworks and artifacts enables them to become searchable and discoverable within databases. In other words, metadata can amplify the value of existing data sets, making them usable by researchers, curators, artists, historians, and the public.</span></p>
<p><span style="font-weight: 400">There are an increasing number of approaches available to generate and expand metadata within museum collections. Over a decade ago, a project called &#8220;steve.museum&#8221; began as a cross-institutional experiment in the world of &#8220;social tagging,&#8221; also known as folksonomy, for museum objects. Over the course of two years, over 2,000 users generated over 36,000 tags across 1,782 works of art (</span><span style="font-weight: 400">Leason, 2009)</span><span style="font-weight: 400">. While that initiative is long past gone, the ambition around enriching metadata through external sources remains. Even to this day, museums such as the Philadelphia Museum of Art include user-generated social tags on their object pages. Now, advanced machine vision is emerging as a promising tool to </span><i><span style="font-weight: 400">automatically</span></i><span style="font-weight: 400"> generate discoverable descriptive text around museum collections with close to no limitation on speed or scale.</span></p>
<h2><b>Generating Metadata and Descriptive Text</b></h2>
<p><span style="font-weight: 400">Machine vision has become advanced enough to detect the subject matter and objects depicted in any type of visual including paintings, photographs, and sculptures. This can help expand and enrich existing meta tags, as well as fill gaps where meta tags are lacking or completely void. For instance, since many objects in collections might be logged simply as &#8220;Untitled&#8221; or &#8220;Plate&#8221; or &#8220;Print&#8221; even if they contain many significant identifying details. These objects are virtually invisible as they lack any level of sufficient terms to aid in their discoverability. </span></p>
<p><span style="font-weight: 400">Such an object might be of unknown origins, yet contain important images, symbols, carvings, or details. To make such objects discoverable for research purposes, it is essential that they are tagged with information that can offer greater insight and specificity into their visual contents.</span><span style="font-weight: 400"><br />
</span></p>
<figure id="attachment_1220" aria-describedby="caption-attachment-1220" style="width: 281px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1220" src="../../wp-content/uploads/2020/01/ciecko.fig4_-225x300.jpg" alt="Decorated plate with a painted figure of a man with a sword who is riding a horse." width="281" height="374" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig4_-225x300.jpg 225w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig4_-768x1023.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig4_.jpg 800w" sizes="(max-width: 281px) 100vw, 281px" /><figcaption id="caption-attachment-1220" class="wp-caption-text">Figure 4: Image of &#8220;Plate&#8221; from the collection of: Metropolitan Museum of Art</figcaption></figure>
<p><span style="font-weight: 400">Nothing in this object&#8217;s metadata or description makes it searchable via the term &#8220;horse,&#8221; which is obviously the focal point of the plate. Yet, Microsoft Computer Vision tags this image with the term &#8220;horse,&#8221; and does so with 98% confidence. This means that the plate can become searchable and discoverable based on its visual elements, rather than just a title that offers little specific information.</span><span style="font-weight: 400"><br />
</span></p>
<figure id="attachment_1221" aria-describedby="caption-attachment-1221" style="width: 280px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1221" src="../../wp-content/uploads/2020/01/ciecko.fig5_-209x300.jpg" alt="Print of two women in formal Japanese clothing." width="280" height="402" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig5_-209x300.jpg 209w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig5_-714x1024.jpg 714w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig5_-768x1102.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig5_.jpg 800w" sizes="(max-width: 280px) 100vw, 280px" /><figcaption id="caption-attachment-1221" class="wp-caption-text">Figure 5: Image of &#8220;Print&#8221; in the collection of: Metropolitan Museum of Art</figcaption></figure>
<p><span style="font-weight: 400">This work is simply titled &#8220;Print&#8221; and there is no metadata or description associated with it. Microsoft Machine Vision returns object detection that there are two people depicted in the work, with a high level of confidence that they are women. Google Vision is able to get even more specific, tagging this image with the term &#8220;geisha.&#8221;</span></p>
<p><span style="font-weight: 400">This type of precise tagging is key to making objects which are functionally invisible some level of discoverable. Indeed, these examples of objects simply identified as &#8220;plate&#8221; or &#8220;print&#8221; are likely representative of millions of objects in far-flung museum collections throughout the world. Digitizing collections and making them &#8220;open access&#8221; is just the first step in making them more accessible. To unleash the untapped potential of digital collections, and to augment and transform human knowledge of cultural relics, it is necessary to make data </span><i><span style="font-weight: 400">searchable</span></i><span style="font-weight: 400">. Machine vision is increasingly making this possible.</span></p>
<p><span style="font-weight: 400">Over the past few years, museums such as the Museum of Modern Art (MoMA), San Francisco Museum of Modern Art (SFMOMA), Barnes Foundation, Harvard Art Museum, Auckland Art Gallery, and National Museum in Warsaw have made headlines for taking advantage of machine vision for enriching and supplementing their metadata. The early application of this technology in such museums has already shown enormous promise.</span></p>
<h2><b>Research Results: How Well Does Machine Vision Perform?</b><b></b></h2>
<p><span style="font-weight: 400">From this, it has become clear that machine vision has a number of clear and beneficial use cases when it comes to museum collections. Now, the question arises: just how well does machine vision do? Can it offer accurate tags? Is the metadata generated useful and correct?</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">Over the past few years, the accuracy of machine vision has improved significantly. According to research by Electronic Frontier Foundation, a group measuring the progress of artificial intelligence, the error rate has fallen from around 30% in 2010 to approximately 4% in 2016, making it on-par with humans.</span></p>
<figure id="attachment_1222" aria-describedby="caption-attachment-1222" style="width: 450px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1222" src="../../wp-content/uploads/2020/01/ciecko.fig6_-300x288.png" alt="Line graph showing the rapid decline in vision error rate from 30% in 2010 to under 5% in 2016." width="450" height="432" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig6_-300x288.png 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig6_-768x737.png 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig6_.png 800w" sizes="(max-width: 450px) 100vw, 450px" /><figcaption id="caption-attachment-1222" class="wp-caption-text">Figure 6: Graph by Electronic Frontier Foundation</figcaption></figure>
<p><span style="font-weight: 400">In 2016, members of the Cuseum team began to explore the capabilities of machine vision in museums when we first published findings and predicted use cases. Now, years later, we are expanding upon our primary investigation.</span></p>
<p><span style="font-weight: 400">Over the course of several months, we collected data on how machine vision perceives collection images. This study represents a sustained effort to analyze the performance and accuracy of various machine vision tools (such as Google Cloud Vision, Microsoft Computer Vision, AWS Rekognition, etc.) at describing images in collection databases at </span><a href="https://www.metmuseum.org/"><span style="font-weight: 400">The Metropolitan Museum of Art</span></a><span style="font-weight: 400">, </span><a href="https://new.artsmia.org/"><span style="font-weight: 400">Minneapolis Institute of Art</span></a><span style="font-weight: 400">, </span><a href="https://philamuseum.org/"><span style="font-weight: 400">Philadelphia Museum of Art</span></a><span style="font-weight: 400">, and the </span><a href="https://ago.ca/"><span style="font-weight: 400">Art Gallery of Ontario</span></a><span style="font-weight: 400">. </span></p>
<p><span style="font-weight: 400">By running a set of digitized collection images from each of these institutions through six major computer vision tools, we were able to assess the accuracy, potential, and limitations of a range of machine vision platforms.</span></p>
<h2><b>Which machine vision services were evaluated?</b></h2>
<p><span style="font-weight: 400">Today, there are numerous commercially available machine vision services. Many of these services offer free trials and are more accessible than ever </span><span style="font-weight: 400">–</span><span style="font-weight: 400"> you do not require advanced computer science experience or access to sophisticated hardware in order to use these. It is possible to tap into the power of these services via online interfaces, APIs, and other easy-to-use methods.</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">We initially selected the following six machine vision solutions based on past familiarity and experience:</span></p>
<ul>
<li style="font-weight: 400"><span style="font-weight: 400">Google Cloud Vision</span></li>
<li style="font-weight: 400"><span style="font-weight: 400">Microsoft Cognitive Service</span></li>
</ul>
<ul>
<li style="font-weight: 400"><span style="font-weight: 400">IBM Watson Visual Recognition </span><span style="font-weight: 400"> </span></li>
<li style="font-weight: 400"><span style="font-weight: 400">AWS Rekognition</span></li>
<li style="font-weight: 400"><span style="font-weight: 400">Clarifai</span></li>
<li style="font-weight: 400"><span style="font-weight: 400">CloudSight</span></li>
</ul>
<p><span style="font-weight: 400">Recent third-party industry research and evaluation by Forrester Research reinforces our overall selections, with the exception of CloudSight.</span><span style="font-weight: 400"><br />
</span></p>
<figure id="attachment_1223" aria-describedby="caption-attachment-1223" style="width: 500px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1223" src="../../wp-content/uploads/2020/01/ciecko.fig7_-293x300.png" alt="Graph comparing the leading machine vision platform which include Google, Microsoft, Clarifai, and Amazon Web Services." width="500" height="512" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig7_-293x300.png 293w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig7_.png 592w" sizes="(max-width: 500px) 100vw, 500px" /><figcaption id="caption-attachment-1223" class="wp-caption-text">Figure 7: The Forrester New Wave: Computer Vision Platforms, Q4 2019</figcaption></figure>
<p><b>Note:</b><span style="font-weight: 400"> All machine vision services were served the exact same image files, and were tested in an &#8220;as-is,&#8221; &#8220;untrained&#8221; capacity; the services were not fed images and their accurate adjacent data sets in advance.</span></p>
<h2><b>Examples of Successful Results</b></h2>
<p><span style="font-weight: 400">One of the greatest merits proven by this study was the ability of machine vision to accurately identify places and people depicted in artworks.</span></p>
<figure id="attachment_1224" aria-describedby="caption-attachment-1224" style="width: 449px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1224" src="../../wp-content/uploads/2020/01/ciecko.fig8_-300x183.jpg" alt="Painting of Piazza San Marco in Venice, Italy with dozens of people walking near the Gothic tower of Saint Mark's Basilica." width="449" height="274" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig8_-300x183.jpg 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig8_.jpg 754w" sizes="(max-width: 449px) 100vw, 449px" /><figcaption id="caption-attachment-1224" class="wp-caption-text">Figure 8: Image of &#8220;Piazza San Marco&#8221; by Canaletto (Giovanni Antonio Canal) from the collection of: Metropolitan Museum of Art</figcaption></figure>
<p><span style="font-weight: 400">Microsoft Computer Vision was able to successfully identify this painting as &#8220;a group of people walking in front of Piazza San Marco&#8221; Other machine vision services offered similarly accurate yet less specific tags, such as &#8220;building,&#8221; &#8220;architecture,&#8221; &#8220;tower,&#8221; &#8220;urban,&#8221; &#8220;plaza,&#8221; and &#8220;city.&#8221;</span></p>
<figure id="attachment_1225" aria-describedby="caption-attachment-1225" style="width: 290px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1225" src="../../wp-content/uploads/2020/01/ciecko.fig9_-216x300.jpg" alt="Painting of woman with orange hair, wearing gown, and staring." width="290" height="403" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig9_-216x300.jpg 216w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig9_-738x1024.jpg 738w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig9_.jpg 755w" sizes="(max-width: 290px) 100vw, 290px" /><figcaption id="caption-attachment-1225" class="wp-caption-text">Figure 9: Image of &#8220;The Marchesa Casati&#8221; by Augustus John from the collection of: Art Gallery of Ontario</figcaption></figure>
<p><span style="font-weight: 400">Microsoft Computer Vision was similarly able to recognize this image as &#8220;Luisa Casati looking at the camera.&#8221; Other machine vision services tagged this image as &#8220;woman in white dress painting&#8221; and &#8220;retro style&#8221; and most understood this image to be a painting of a person.</span></p>
<figure id="attachment_1226" aria-describedby="caption-attachment-1226" style="width: 300px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1226" src="../../wp-content/uploads/2020/01/ciecko.fig10-224x300.jpg" alt="Classical sculpture of a nude man, missing one arm from the elbow down." width="300" height="402" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig10-224x300.jpg 224w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig10.jpg 679w" sizes="(max-width: 300px) 100vw, 300px" /><figcaption id="caption-attachment-1226" class="wp-caption-text">Figure 10: Image of &#8220;The Doryphoros&#8221; from the collection of: Minneapolis Institute of Art</figcaption></figure>
<p><span style="font-weight: 400">Machine vision has proved an excellent tool for identifying key pieces of information like style and time period. One prime example is the Doryphoros, a sculpture at the Minneapolis Institute of Art.</span></p>
<p><span style="font-weight: 400">Microsoft Computer Vision returned the description &#8220;a sculpture of a man.&#8221; Services like Clarifai and Google Vision were able to identify this as a &#8220;classic&#8221; object. The sculpture was overall accurately examined by machine vision with the majority of machine vision services labeled the object with tags such as &#8220;art,&#8221; &#8220;standing,&#8221; &#8220;male,&#8221; &#8220;human body,&#8221; &#8220;sculpture,&#8221; &#8220;person,&#8221; &#8220;statue,&#8221; &#8220;marble,&#8221; &#8220;nude,&#8221; and other accurate terms.</span></p>
<figure id="attachment_1227" aria-describedby="caption-attachment-1227" style="width: 340px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1227" src="../../wp-content/uploads/2020/01/ciecko.fig11-300x216.jpg" alt="Abstract painting of the sky." width="340" height="245" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig11-300x216.jpg 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig11.jpg 767w" sizes="(max-width: 340px) 100vw, 340px" /><figcaption id="caption-attachment-1227" class="wp-caption-text">Figure 11: Image of &#8220;Upward Trend&#8221; by Emily Carr from the collection of: Art Gallery of Ontario</figcaption></figure>
<p><span style="font-weight: 400">One of the hypothesized limitations of machine vision was its limited capacity to flag and tag more abstract art, which is a more challenging task than identifying photographs, portraiture, or landscapes. All services understood this image was a work of art, a painting, etc. Here, we were pleasantly surprised.</span></p>
<p><span style="font-weight: 400">CloudSight was able to identify this as &#8220;green and blue abstract painting,&#8221; while Google Cloud Vision tagged this as &#8220;painting,&#8221; &#8220;acrylic paint,&#8221; &#8220;art,&#8221; &#8220;water,&#8221; &#8220;watercolor paint,&#8221; &#8220;visual arts,&#8221; &#8220;wave,&#8221; &#8220;modern art,&#8221; &#8220;landscape,&#8221; and &#8220;wind wave.&#8221;</span><b><br />
</b><b></b></p>
<figure id="attachment_1228" aria-describedby="caption-attachment-1228" style="width: 300px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1228" src="../../wp-content/uploads/2020/01/ciecko.fig12-230x300.jpg" alt="Painting of &quot;Madonna and Child&quot; with religious icons featured." width="300" height="391" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig12-230x300.jpg 230w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig12.jpg 769w" sizes="(max-width: 300px) 100vw, 300px" /><figcaption id="caption-attachment-1228" class="wp-caption-text">Figure 12: Image of &#8220;Madonna and Child Enthroned with Saints&#8221; from the collection of: The Metropolitan Museum of Art</figcaption></figure>
<p><span style="font-weight: 400">Machine vision proved remarkably successful at identifying religious, and especially Christian, iconography. Various tools tagged this image accurately, using phrases that included &#8220;saint,&#8221; &#8220;religion,&#8221; &#8220;Mary,&#8221; &#8220;church,&#8221; &#8220;painting,&#8221; &#8220;God,&#8221; &#8220;kneeling,&#8221; &#8220;cross,&#8221; &#8220;chapel,&#8221; &#8220;veil,&#8221; &#8220;cathedral,&#8221; &#8220;throne,&#8221; &#8220;aura,&#8221; and &#8220;apostle.&#8221;</span><b><br />
</b></p>
<figure id="attachment_1229" aria-describedby="caption-attachment-1229" style="width: 390px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1229" src="../../wp-content/uploads/2020/01/ciecko.fig13-300x231.jpg" alt="Image of the Art Gallery of Ontario, the Toronto View from Grange Park." width="390" height="300" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig13-300x231.jpg 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig13.jpg 767w" sizes="(max-width: 390px) 100vw, 390px" /><figcaption id="caption-attachment-1229" class="wp-caption-text">Figure 13: Image of &#8220;Art Gallery of Ontario: Toronto View from Grange Park&#8221; by Edward Burtynsky from the collection of: Art Gallery of Ontario</figcaption></figure>
<p><span style="font-weight: 400">Within the Art Gallery of Ontario collections, there are many photographs. </span><span style="font-weight: 400">In general, machine vision tools tend to produce more accurate tags for photos, as opposed to paintings or sculptures, for the simple reason that most algorithms and programs are developed using primarily real photos. </span></p>
<p><span style="font-weight: 400">Microsoft Computer Vision gave a particularly apt description of this photograph, labeling it: &#8220;A large brick building with grass in front of a house with Art Gallery of Ontario in the background.&#8221;</span></p>
<h2><b>Examples of Poor Accuracy</b><b></b></h2>
<figure id="attachment_1230" aria-describedby="caption-attachment-1230" style="width: 400px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1230" src="../../wp-content/uploads/2020/01/ciecko.fig14-300x233.jpg" alt="Painting of Christ Driving the Money Changers from the Temple." width="400" height="311" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig14-300x233.jpg 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig14.jpg 721w" sizes="(max-width: 400px) 100vw, 400px" /><figcaption id="caption-attachment-1230" class="wp-caption-text">Figure 14: Image of &#8220;Christ Driving the Money Changers from the Temple&#8221; by El Greco (Domenikos Theotokopoulous), from the collection of: Minneapolis Institute of Art</figcaption></figure>
<p><span style="font-weight: 400">While machine vision tools proved quite adept at recognizing and generating accurate metadata on certain kinds of images, in other cases, these tools produced misleading tags.</span></p>
<p><b></b><b></b><b></b><b></b><span style="font-weight: 400">Many machine vision tools mistook this image as a screensaver. It is possible that the machine vision services are picking up on all the colors and many images typically labeled as &#8220;screensaver&#8221; in training datasets often based on monetizable use cases and products, which is why this piece may be mistaken for a brightly-colored LCD. Furthermore, this painting contains many complexities and figures, rather than one object of focus. In general, machine vision struggles more to accurately describe such pieces. In these cases, the services will cast a wide net, which can generate many conflicting tags.</span><span style="font-weight: 400"><br />
</span></p>
<p><span style="font-weight: 400">In this casting wide net, some of the tags still turn out to be accurate. For example, one machine vision services tagged this image as &#8220;Renaissance&#8221; and &#8220;Baroque.&#8221; This work, authored in 1568, indeed straddles the Renaissance and Baroque periods in European History.</span></p>
<p><span style="font-weight: 400">Microsoft Computer Vision returned an amusing description many months ago with &#8220;a group of stuffed animals sitting on top of a building,&#8221; but a recent re-analysis returned an updated description &#8220;a group of people standing in front of a building&#8221;, demonstrating the possibility of improvements in accuracy over time.</span><b><br />
</b><b></b></p>
<figure id="attachment_1232" aria-describedby="caption-attachment-1232" style="width: 400px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1232" src="../../wp-content/uploads/2020/01/ciecko.fig15-300x267.jpg" alt="Abstract sculpture resembling a jacket composed of metal." width="400" height="356" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig15-300x267.jpg 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig15.jpg 708w" sizes="(max-width: 400px) 100vw, 400px" /><figcaption id="caption-attachment-1232" class="wp-caption-text">Figure 15: Image of &#8220;Some/One&#8221; by Do Ho Suh, from the collection of: Minneapolis Institute of Art</figcaption></figure>
<p><b></b><span style="font-weight: 400">Abstract art is one area where machine vision proves to be less accurate. This piece by Do Ho Suh is an abstract sculpture inspired by his time in the Korean military. It thus resembles a jacket or uniform. Machine vision did manage to generate some accurate tags, including &#8220;design,&#8221; &#8220;fashion,&#8221; &#8220;decoration,&#8221; &#8220;chrome,&#8221; &#8220;sculpture,&#8221; &#8220;metal,&#8221; &#8220;silver,&#8221; and &#8220;art.&#8221;</span></p>
<p><span style="font-weight: 400">However, machine vision programs also returned completely inaccurate tags. Microsoft Computer Vision offered labels such as &#8220;elephant,&#8221; &#8220;desk,&#8221; &#8220;mouse,&#8221; &#8220;cat,&#8221; &#8220;computer,&#8221; &#8220;keyboard,&#8221; and &#8220;apple.&#8221;</span></p>
<p><span style="font-weight: 400">IBM Watson Visual Recognition generated similarly inaccurate tags, including, &#8220;pedestal table,&#8221; &#8220;candlestick,&#8221; &#8220;propeller,&#8221; &#8220;mechanical device,&#8221; &#8220;ax,&#8221; &#8220;tool,&#8221; &#8220;cutlery.&#8221;</span></p>
<p><span style="font-weight: 400">In cases like these, the machine vision struggles to find anything non-abstract other than the primary </span><i><span style="font-weight: 400">material</span></i><span style="font-weight: 400"> of this object. Many tools were able to understand the object as metallic in composition; however, this resulted in a series of inaccurate associations with common objects of similar materials. Indeed Amazon Rekognition flagged this image as &#8220;sink faucet,&#8221; Google Vision as &#8220;bar stool&#8221;, and CloudSight as &#8220;gray and black leather handbag.&#8221;</span></p>
<figure id="attachment_1233" aria-describedby="caption-attachment-1233" style="width: 375px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1233" src="../../wp-content/uploads/2020/01/ciecko.fig16-300x225.jpg" alt="Carved stone sculpture depicting a village scene with a mountain." width="375" height="281" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig16-300x225.jpg 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig16-768x576.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig16.jpg 772w" sizes="(max-width: 375px) 100vw, 375px" /><figcaption id="caption-attachment-1233" class="wp-caption-text">Figure 16: Image of &#8220;Jade Mountain Illustrating the Gathering of Scholars at the Lanting Pavilion,&#8221; from collection of: Minneapolis Institute of Art</figcaption></figure>
<p><span style="font-weight: 400">While not an abstract piece, this sculpture is more monochrome with details difficult to decipher by a computer. Out of the six different machine vision services used, four of them returned terms related to &#8220;food,&#8221; &#8220;cake,” and/or &#8220;ice cream.&#8221; It is likely that services are matching the picture with ice cream due to similarities in shape and color, while completely missing the small details of trees and houses due to their limited contrast. </span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">Only Google Vision returned remotely satisfactory terms, including &#8220;stone carving,&#8221; &#8220;sculpture,&#8221; &#8220;carving,&#8221; &#8220;rock,&#8221; &#8220;figurine.&#8221;</span><b><br />
</b><b></b></p>
<figure id="attachment_1234" aria-describedby="caption-attachment-1234" style="width: 400px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1234" src="../../wp-content/uploads/2020/01/ciecko.fig17-300x292.jpg" alt="Small metal brazier." width="400" height="389" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig17-300x292.jpg 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig17.jpg 760w" sizes="(max-width: 400px) 100vw, 400px" /><figcaption id="caption-attachment-1234" class="wp-caption-text">Figure 17: Image of &#8220;Brazier of Sultan al-Malik al-Muzaffar Shams al-Din Yusuf ibn &#8216;Umar,&#8221; in the collection of: The Metropolitan Museum of Art</figcaption></figure>
<p><b></b><span style="font-weight: 400">A brazier is fairly uncommon within the image datasets used to train various machine vision services. These image datasets likely have very few braziers but quite a few tables, due to their common occurrence in everyday life and in e-commerce datasets. Additionally, their shapes are similar enough that all of the machine vision tools mistook this object for a table. While humans may quickly understand context and scale, computers do not yet have this ability. Even though this brazier is not a common object we see, it is pretty easy for the human eye to discern that it is a diminutive object (13&#8243; width x 12&#8243; depth x 16&#8243; height), and fall smaller than a table. </span></p>
<p><span style="font-weight: 400">Only Clarifai returned useful terms such as &#8220;metalwork,&#8221; &#8220;art,&#8221; &#8220;antique,&#8221; &#8220;gold,&#8221; &#8220;ornate,&#8221; &#8220;luxury,&#8221; &#8220;gilt,&#8221; &#8220;ancient,&#8221; &#8220;bronze,&#8221; and &#8220;wealth.&#8221;</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">All of the other machine vision services returned incorrect tags and terms related to furniture such as &#8220;brown wooden wall mount rack,&#8221; &#8220;furniture,&#8221; &#8220;settee,&#8221; and &#8220;a gold clock sitting on top of a table.&#8221;</span><b><br />
</b><b></b></p>
<h2><b>Examples of Problematic Results</b><b><br />
</b></h2>
<p><span style="font-weight: 400">While machine vision showed great promise for many works of art, our and others&#8217; research has also illustrated its limitations and biases, particularly gender and cultural biases. With significant efforts being made towards equity, diversity, and inclusion, the chance of an insensitive or potentially offensive tag presents new risks to museums.</span><span style="font-weight: 400"><br />
</span></p>
<p><b>Gender Bias </b></p>
<p><b></b><span style="font-weight: 400">Take, for example, these two portraits by Chuck Close. &#8220;Big Self Portrait&#8221; depicts the artist with a cigarette in his mouth, and the other, a young woman with a cigarette in her mouth. Both have nearly identical expressions. While the man was tagged by Clarifai using descriptors like &#8220;funny&#8221; and &#8220;crazy,&#8221; the woman was tagged by the same tool as &#8220;pretty,&#8221; &#8220;cute,&#8221; and &#8220;sexy.&#8221;</span></p>
<figure id="attachment_1235" aria-describedby="caption-attachment-1235" style="width: 235px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1235 size-medium" src="../../wp-content/uploads/2020/01/ciecko.fig18-235x300.jpg" alt="Chuck Close self portrait, depicting Close with glasses and a cigarette." width="235" height="300" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig18-235x300.jpg 235w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig18-768x980.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig18.jpg 800w" sizes="(max-width: 235px) 100vw, 235px" /><figcaption id="caption-attachment-1235" class="wp-caption-text">Figure 18: Image of &#8220;Big Self Portrait&#8221; by Chuck Close from the collection of: Walker Art Center</figcaption></figure>
<p>&nbsp;</p>
<figure id="attachment_1236" aria-describedby="caption-attachment-1236" style="width: 236px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1236 size-medium" src="../../wp-content/uploads/2020/01/ciecko.fig19-236x300.jpg" alt="Chuck Close portrait, depicting a woman with glasses and a cigarette. " width="236" height="300" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig19-236x300.jpg 236w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig19-768x976.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig19.jpg 800w" sizes="(max-width: 236px) 100vw, 236px" /><figcaption id="caption-attachment-1236" class="wp-caption-text">Figure 19: Image of untitled portrait by Chuck Close</figcaption></figure>
<p><span style="font-weight: 400">In this similar work by Chuck Close, &#8220;Frank,&#8221; housed at the Minneapolis Institute of Art, Clarifai tagged the work, as &#8220;writer&#8221; and &#8220;scientist,&#8221; drawing attention to the fact that men in glasses are often associated with intellectualism. When examining a similar work by Close, &#8220;Susan,&#8221; depicting a woman in glasses, Clarifai flagged the work as &#8220;model,&#8221; &#8220;smile&#8221; &#8220;pretty,&#8221; &#8220;beautiful,&#8221; &#8220;cute,&#8221; and &#8220;actor.&#8221;</span></p>
<figure id="attachment_1237" aria-describedby="caption-attachment-1237" style="width: 229px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1237 size-medium" src="../../wp-content/uploads/2020/01/ciecko.fig20-229x300.jpg" alt="Chuck Close portrait, depicting a man with glasses and curly hair." width="229" height="300" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig20-229x300.jpg 229w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig20.jpg 607w" sizes="(max-width: 229px) 100vw, 229px" /><figcaption id="caption-attachment-1237" class="wp-caption-text">Figure 20: Image of &#8220;Frank&#8221; by Chuck Close from the collection of: Minneapolis Institute of Art</figcaption></figure>
<p>&nbsp;</p>
<figure id="attachment_1239" aria-describedby="caption-attachment-1239" style="width: 269px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1239 size-medium" src="../../wp-content/uploads/2020/01/ciecko.fig21-269x300.jpg" alt="Chuck Close portrait, depicting a woman with aviator glasses." width="269" height="300" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig21-269x300.jpg 269w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig21-768x856.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig21.jpg 788w" sizes="(max-width: 269px) 100vw, 269px" /><figcaption id="caption-attachment-1239" class="wp-caption-text">Figure 21: Image of &#8220;Susan&#8221; by Chuck Close</figcaption></figure>
<p><b>Western Cultural Bias</b></p>
<p><b></b><span style="font-weight: 400">While machine vision tools were able to frequently identify Christian iconography, it left much to be desired when identifying non-Western art, particularly Asian and African art. Take, for example, this terracotta shrine head from Yoruba. This Nigerian work was mistaken as &#8220;Buddha&#8221; across various machine vision services</span><span style="font-weight: 400">.</span></p>
<figure id="attachment_1240" aria-describedby="caption-attachment-1240" style="width: 310px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1240" src="../../wp-content/uploads/2020/01/ciecko.fig22-202x300.jpg" alt="Nigerian sculpture, which depicts a woman's head and neck." width="310" height="460" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig22-202x300.jpg 202w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig22-691x1024.jpg 691w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig22-768x1139.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig22.jpg 800w" sizes="(max-width: 310px) 100vw, 310px" /><figcaption id="caption-attachment-1240" class="wp-caption-text">Figure 22: Image of &#8220;Shrine Head&#8221; from the collection of: Minneapolis Institute of Art</figcaption></figure>
<p><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">This </span><span style="font-weight: 400">red-and-blue-laced Suit of Armor from Japan was also mistaken as &#8220;Buddha&#8221; by machine vision services. This begins to suggest a pattern of conflating non-Western cultures.</span><span style="font-weight: 400"><br />
</span></p>
<figure id="attachment_1241" aria-describedby="caption-attachment-1241" style="width: 350px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1241" src="../../wp-content/uploads/2020/01/ciecko.fig23-196x300.jpg" alt="Japanese suit of armor." width="350" height="536" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig23-196x300.jpg 196w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig23-668x1024.jpg 668w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig23-768x1178.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig23.jpg 800w" sizes="(max-width: 350px) 100vw, 350px" /><figcaption id="caption-attachment-1241" class="wp-caption-text">Figure 23: Image of &#8220;red-and-blue-laced Suit of Armor&#8221; from the collection of: Minneapolis Institute of Art</figcaption></figure>
<h2><b>Sensitive Topics</b><b><br />
</b><b></b></h2>
<p><span style="font-weight: 400">Should museums set boundaries as to what types of images they use machine vision to analyze? With complex and highly sensitive topics such as colonization, slavery, genocide, and other forms of oppression, it might be advised that the use of machine vision be avoided altogether.</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">During the Yale-Smithsonian Partnership&#8217;s &#8220;Machine Vision for Cultural Heritage &amp; Natural Science Collections&#8221; symposium last year, Peter Leonard, Director of Yale&#8217;s Digital Humanities Lab, discussed a variety of scenarios where machine vision could go wrong. Leonard ran an image from Sydney, Australia&#8217;s Museum of Applied Arts and Sciences through a machine vision service that returned terms such as &#8220;Fashion Accessory&#8221; and &#8220;Jewelry,&#8221; when in fact the object was manacles from Australia&#8217;s convict history, to which he added, &#8220;you can only imagine the valence of this in an American context with African American history&#8221; (Leonard, 2019).</span></p>
<figure id="attachment_1243" aria-describedby="caption-attachment-1243" style="width: 375px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1243" src="../../wp-content/uploads/2020/01/ciecko.fig24-300x219.jpg" alt="Iron manacles lying flat." width="375" height="274" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig24-300x219.jpg 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig24-768x561.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig24.jpg 800w" sizes="(max-width: 375px) 100vw, 375px" /><figcaption id="caption-attachment-1243" class="wp-caption-text">Figure 24: Image of Iron Leg Manacles from the collection of: Museum of Applied Arts and Sciences</figcaption></figure>
<p><span style="font-weight: 400">In the near future it is likely that museums dedicated to non-Western art and culture or those focused on objects of a sensitive nature or relating to historically marginalized communities will steer clear of machine-generated metadata and descriptive text. But, every type of museum should consider these potential risks and plan accordingly.</span><span style="font-weight: 400"><br />
</span><b></b></p>
<h2><b>Potential for success through proper training and hybrid models</b><b><br />
</b></h2>
<p><span style="font-weight: 400">At this time, despite success in certain areas, no single machine vision service performs with complete or near complete accuracy. </span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">If a museum wanted to leverage machine vision and increase overall precision, could the answer be as simple as training with large sets of high-quality, human-verified data from the world&#8217;s most esteemed cultural institutions? Or, could one aggregate the output and results across a plurality of machine vision tools, and only accept terms of a specific frequency, the threshold of accuracy, and/or human verification via Mechanical Turks, volunteers, or the broader public?</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">Hybrid approaches will likely emerge that allow museums to easily try a machine vision model with their collection images and adjacent data, as well as leverage human verification and the results of multiple machine vision services.</span><b><br />
</b><b></b></p>
<h2><b>How have museums begun to use machine vision?</b></h2>
<p><span style="font-weight: 400">Given the enormous potential of various machine vision services to assist in generating metadata for museum collections, many institutions have already begun to harness these tools in effective as well as creative ways. Some examples include:</span></p>
<p><b>Harvard Art Museum<br />
</b><span style="font-weight: 400">Harvard Art Museum exhibits one of the best displays of machine vision to generate metadata in museums. </span><a href="https://www.thecrimson.com/article/2018/10/30/how-machines-see-art/"><span style="font-weight: 400">The museum is using multiple machine vision tools to start tagging the 250,000 works in the collections</span></a><span style="font-weight: 400">, with the hope of eventually using &#8220;AI-generated descriptions as keywords or search terms for people searching for art on Harvard&#8217;s databases&#8221; (</span><span style="font-weight: 400">Yao, 2</span><span style="font-weight: 400">018).</span></p>
<p><b>MoMA<br />
</b><span style="font-weight: 400">The </span><a href="https://www.moma.org/calendar/exhibitions/history/identifying-art"><span style="font-weight: 400">Museum of Modern Art (MoMA) partnered with Google Arts and Culture</span></a><span style="font-weight: 400"> &#8220;to comb through over 30,000 exhibition photos&#8221; using machine vision. The result was the creation of &#8220;a vast network of new links&#8221; between MoMA&#8217;s exhibition history and the online collection.</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><b>Cleveland Museum of Art</b><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">Cleveland Museum of Art&#8217;s </span><a href="https://www.clevelandart.org/microsoft-corporation"><span style="font-weight: 400">Art Explorer</span></a><span style="font-weight: 400"> is powered by Microsoft&#8217;s Cognitive Search, which uses AI algorithms to enrich the metadata for the artworks.</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><b>The Barnes Foundation<br />
</b><span style="font-weight: 400">The Barnes Foundation has a </span><a href="https://www.digitaltrends.com/computing/philadelphia-art-gallery-the-barnes-foundation-uses-machine-learning/"><span style="font-weight: 400">program that interprets and pairs digital artwork together</span></a><span style="font-weight: 400"> to recognize art style, objects, and basic elements in an artwork (</span><span style="font-weight: 400">Jones, 2018).</span><span style="font-weight: 400"> It is a notable step forward in art-historical analysis. </span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><b>Auckland Art Gallery</b><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">One recent example of the merits of AI-generated tags can be seen at the Auckland Art Gallery.</span> <a href="https://www.aucklandartgallery.com/page/auckland-art-gallerys-new-chatbot-demonstrates-art-ificial-intelligence-to-give-new-access-to-17000-artworks"><span style="font-weight: 400">This organization has utilized more than 100,000 human-sourced and machine-generated tags to categorize artworks</span></a><span style="font-weight: 400"> as part of a larger chatbot initiative (</span><span style="font-weight: 400">Auckland Art Gallery, 2018)</span><span style="font-weight: 400">.</span></p>
<figure id="attachment_1245" aria-describedby="caption-attachment-1245" style="width: 449px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1245" src="../../wp-content/uploads/2020/01/ciecko.fig25-300x169.png" alt="Screenshot of Art Institute of Chicago's online collection section, featuring a color wheel and objects with the selected color." width="449" height="253" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig25-300x169.png 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig25-768x432.png 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig25.png 800w" sizes="(max-width: 449px) 100vw, 449px" /><figcaption id="caption-attachment-1245" class="wp-caption-text">Figure 25: Art Institute of Chicago introduces new search experience with the Color Wheel</figcaption></figure>
<p><span style="font-weight: 400">An array of museums including the </span><a href="https://www.artic.edu/articles/759/the-color-of-serendipity-searching-with-the-color-wheel"><span style="font-weight: 400">Art Institute of Chicago</span></a><span style="font-weight: 400">, </span><a href="https://labs.cooperhewitt.org/2013/giv-do/"><span style="font-weight: 400">the Cooper-Hewitt</span></a><span style="font-weight: 400">, </span><a href="https://collections.mplus.org.hk/en/colours"><span style="font-weight: 400">M+</span></a><span style="font-weight: 400">, as well as </span><a href="https://artsexperiments.withgoogle.com/artpalette/colors"><span style="font-weight: 400">Google Art and Culture</span></a><span style="font-weight: 400"> and Artsy, have offered new pathways into their collections by leveraging machine-extracted color metadata such as palette, partitions, and histogram data.</span></p>
<h2><b>Perspectives from the Museum Community</b><b><br />
</b></h2>
<p><span style="font-weight: 400">With any new technology, a variety of perspectives and opinions are sure to follow. Artificial intelligence has become a growing topic of interest amongst museum technologists, the art world, and curators alike.</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">In SFMOMA&#8217;s renowned project, Send Me SFMOMA, the museum explored the possibility of leveraging machine-generated tags, but found the terms to be too formal, literal, and uninspired. In an interview with Vox, a representative from the museum remarked that &#8220;the intuition and the humanness of the way that our staff has been tagging&#8221; is what is interesting, &#8220;versus the linearity of the computer vision approach, [which] just makes you miss out on all of the sublime&#8221; (</span><span style="font-weight: 400">Grady, 2017).</span></p>
<p><span style="font-weight: 400">Taking a contrary point of view, Jeff Stewart, Director of Digital Infrastructure and Emerging Technology at the Harvard Art Museum believes that machine-extracted terms and vocabularies can sometimes be more human than the lofty or excessively intellectual statements written by an academic or curator. Indeed, a painting in their collection, &#8220;Still Life with Watermelon&#8221; by Sarah Miriam Peale, was described as &#8220;juicy,&#8221; &#8220;sweet,&#8221; and &#8220;delicious,&#8221; suggesting machine vision&#8217;s ability to provide approachable and sensational dynamics to the equation in ways that curators may not.</span><span style="font-weight: 400"><br />
</span></p>
<figure id="attachment_1248" aria-describedby="caption-attachment-1248" style="width: 418px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1248" src="../../wp-content/uploads/2020/01/ciecko.fig26-300x209.jpg" alt="Painting featuring watermelon, guava, grapes, and other fruits." width="418" height="291" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig26-300x209.jpg 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig26-768x534.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig26.jpg 800w" sizes="(max-width: 418px) 100vw, 418px" /><figcaption id="caption-attachment-1248" class="wp-caption-text">Figure 26: Image of &#8220;Still Life with Watermelon&#8221; by Sarah Miriam Peale from the collection of: Harvard Art Museum</figcaption></figure>
<p><span style="font-weight: 400">Upon receiving a computer-generated description of Miro&#8217;s &#8220;Dog Barking at the Moon,&#8221; a notable piece from Philadelphia Museum of Art&#8217;s collection, </span><span style="font-weight: 400">Michael Taylor, Chief Curator and Deputy Director of Virginia Museum of Fine Arts, shared his positive and amused reaction.</span></p>
<figure id="attachment_1250" aria-describedby="caption-attachment-1250" style="width: 373px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1250" src="../../wp-content/uploads/2020/01/ciecko.fig27-300x240.jpg" alt="Abstract painting of a dog and ladder." width="373" height="298" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig27-300x240.jpg 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig27-768x615.jpg 768w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig27.jpg 800w" sizes="(max-width: 373px) 100vw, 373px" /><figcaption id="caption-attachment-1250" class="wp-caption-text">Figure 27: Image of &#8220;Dog Barking at the Moon,&#8221; by Joan Miró from the collection of: Philadelphia Museum of Art</figcaption></figure>
<p><span style="font-weight: 400">The machine-generated description was &#8220;white, blue and brown two legged animated animal near ladder illustration&#8221; which is fairly accurate to the literal depiction but doesn&#8217;</span><span style="font-weight: 400">t capture the conceptual, abstract nuances, or well-studied interpretation of the work only a curator can provide. Compare that to Taylor&#8217;s description of the same work:</span><span style="font-weight: 400"><br />
</span></p>
<blockquote><p><i><span style="font-weight: 400">&#8220;At once engaging and perplexing, Joan Miró&#8217;s Dog Barking at the Moon exemplifies the Spanish artist&#8217;s sophisticated blend of pictorial wit and abstraction. Like many of the works that the artist painted in Paris, this work registers Miró&#8217;s memories of his native Catalonian landscape, which remained the emotional center and source of his imagery for much of his life.  The work&#8217;s genesis can be found in a preparatory sketch showing the moon rejecting a dog&#8217;s plaintive yelps, saying in Catalan, &#8220;You know, I don’t give a damn.&#8221; Although these words were excluded in the finished painting, their meaning is conveyed through the vacant space between the few pictorial elements that compose this stark, yet whimsical image of frustrated longing and nocturnal isolation. Against the simple background of the brown earth and black night sky, the artist has painted a colorful dog, moon, and a ladder that stretches across the meandering horizon line and recedes into the sky, perhaps suggesting the dream of escape. This remarkable combination of earthiness, mysticism, and humor marks Miró&#8217;s successful merging of international artistic preoccupations with an emphatically regional outlook to arrive at his distinctively personal and deeply poetic sensibility.&#8221;</span></i></p></blockquote>
<p><span style="font-weight: 400">One could surmise and easily agree that artificial intelligence and computer vision are unable to deliver a comparable description, rich with art historical context and deep interpretation – at least today.</span></p>
<h2><b>Machine Vision Bias: The Ethical Considerations</b><b><br />
</b></h2>
<p><span style="font-weight: 400">While machine vision may unlock new potentials for the cultural sector, it is essential to scrutinize the ways that machine vision can perpetuate biases, conflate non-Western cultures, and generate confusion.</span><span style="font-weight: 400"><br />
</span></p>
<figure id="attachment_1251" aria-describedby="caption-attachment-1251" style="width: 400px" class="wp-caption aligncenter"><img loading="lazy" class="wp-image-1251" src="../../wp-content/uploads/2020/01/ciecko.fig28-300x227.png" alt="Screenshot of Google Arts and Culture &quot;Art Selfie&quot; app that shows its ethnic bias." width="400" height="303" srcset="https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig28-300x227.png 300w, https://mw20.museweb.net/wp-content/uploads/2020/01/ciecko.fig28.png 640w" sizes="(max-width: 400px) 100vw, 400px" /><figcaption id="caption-attachment-1251" class="wp-caption-text">Figure 28: Image of Google Art Selfie featured in TechCrunch</figcaption></figure>
<p><span style="font-weight: 400">Two recent projects amplified the topics of AI bias within the art and cultural world. Google&#8217;s Art Selfie project, an app that matched a user&#8217;s face with a similar piece of art, was easily one of the most viral phenomenons of 2018, yet it faced criticism from people of color due to limited results which exemplified racial stereotypes or otherwise produced inappropriate and offensive &#8220;lookalikes.&#8221;</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">In 2019, an art project by researcher Kate Crawford and artist Trevor Paglen called &#8220;Training Humans&#8221; sparked a dialogue about the problematic bias of facial recognition software. The project led ImageNet, one of the leading image databases used to train the machine vision model, to remove more than half a million images.</span></p>
<p><span style="font-weight: 400">Advancements in AI technology will help but not necessarily solve these potential issues. In fact, one prediction by technologist Roman Yampolskiy published in the Harvard Business Review warned that &#8220;the frequency and seriousness of AI failures will steadily increase as AIs become more capable.&#8221;</span><span style="font-weight: 400"><br />
</span></p>
<p><span style="font-weight: 400">That being said, there is an upside. </span><a href="https://www.nytimes.com/2019/12/06/business/algorithm-bias-fix.html"><span style="font-weight: 400">According to the New York Times</span></a><span style="font-weight: 400">, &#8220;biased algorithms are easier to fix than biased people&#8221; (</span><span style="font-weight: 400">Cook, 2019).</span><span style="font-weight: 400"> Whereas it can prove difficult to &#8220;reprogram&#8221; our hearts and minds, software can be updated when biases are uncovered. This suggests that discrimination and bias in AI can be detected and remedied helping us overcome some of its biggest challenges.</span></p>
<h2><b>Conclusion</b><b><br />
</b></h2>
<p><span style="font-weight: 400">Our broad research and experience suggest that technologies like machine vision are getting better, faster, and more accessible and that AI&#8217;s bias is wholly recognized and being addressed. In the years to come, we can anticipate an increase in the use of machine vision in museum collections, as well as the heightened accuracy and decreased bias of machine vision tools. This has the potential to make collections discoverable in a new way, unlocking the full value of digitization initiative by creating a body of metadata that will make collections exponentially more searchable.</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><a href="https://www.artnews.com/art-news/market/curating-involves-daily-protest-forgetting-hans-ulrich-obrist-waxes-poetic-armory-show-9948/"><span style="font-weight: 400">According to Hans Ulrich Obrist</span></a><span style="font-weight: 400">, renowned curator and co-director of The Serpentine Galleries, &#8220;we need new experiments in art and technology&#8221; (</span><span style="font-weight: 400">Selvin, 2018). </span><span style="font-weight: 400">Machine vision just may prove one of the key tools that will advance the museum field.</span></p>
<p><span style="font-weight: 400">It is equally important to consider the potential of AI and machine vision to generate new insights that are different or go beyond what a human eye or mind might generate. According to technologist and AI expert Amir Husain in his book </span><i><span style="font-weight: 400">The Sentient Machine, </span></i><span style="font-weight: 400">&#8220;</span><span style="font-weight: 400">Too often, we frame our discussion of AI around its anthropological characteristics: How much does it resemble us?&#8221; Further adding &#8220;Do we really imagine that human intelligence is the only kind of intelligence worth imitating? Is mimicry really the ultimate goal? Machines have much to teach us about &#8216;thoughts&#8217; that have nothing to do with human thought&#8221; (</span><span style="font-weight: 400">Husain, 2017).</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400">This introduces the idea that the end goal of harnessing machine vision in museums may not even be all about </span><i><span style="font-weight: 400">mirroring</span></i><span style="font-weight: 400"> what a human, curator, educator, or scholar could do. Machine vision opens up doors for a new kind of analysis and introduces a different type of interpretation and understanding of a work that may or may not reflect the cognitive limitations or learning frameworks of the human mind.</span></p>
<p><span style="font-weight: 400">In the next decade, the computing power and abilities of machine vision will be great multiples more significant than it is today. Today we are just at the beginning. If prioritized, budding partnerships between museums and technology companies will help build models and algorithms specifically for cultural and artistic use and help alleviate some of the obstacles holding us back today.</span></p>
<p><span style="font-weight: 400">In anticipation of this, now is the time to act and steer the future of collections. In order to ensure the accurate and ethical application of machine vision to museums, standards and policies that will guide how we employ this technology must be set and adhered to. By entering into a thoughtful dialogue, we can reshape the practice of collections management and enable the discovery and analysis of objects and cultures on a new level. To maximize the position of museums in this rapidly changing landscape, there is no better time to discuss, challenge, and explore the value of new technology.</span></p>
<p><span style="font-weight: 400">Yes, museums should proceed with caution and thoughtful consideration, but we should not act out of fear. The more organizations and key stakeholders are involved in this exploration, the greater the value that will be created and shared across the field, and our contributions to making cultural heritage accessible to as many people as possible. We are still in the preliminary and experimental stages of this journey and are optimistic for what lies ahead. The future of museums will be many things – and we will require both vision and machines to get there.</span></p>
<h2>References</h2>
<p><span style="font-weight: 400">&#8220;Art+Tech Summit at Christie&#8217;s: The A.I. Revolution.&#8221; </span><i><span style="font-weight: 400">Art+Tech Summit at Christie&#8217;s 2019</span></i><span style="font-weight: 400">. Consulted January 2020. </span><a href="https://www.christies.com/exhibitions/art-tech-summit-ai-revolution#overview_Nav"><span style="font-weight: 400">https://www.christies.com/exhibitions/art-tech-summit-ai-revolution</span></a></p>
<p><span style="font-weight: 400">Auckland Art Gallery (2018)</span><span style="font-weight: 400">. &#8220;Auckland Art Gallery&#8217;s new chatbot demonstrates artificial intelligence to give new access to 17,000 artworks.&#8221; </span><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.aucklandartgallery.com/page/auckland-art-gallerys-new-chatbot-demonstrates-art-ificial-intelligence-to-give-new-access-to-17000-artworks"><span style="font-weight: 400">https://www.aucklandartgallery.com/page/auckland-art-gallerys-new-chatbot-demonstrates-art-ificial-intelligence-to-give-new-access-to-17000-artworks</span></a></p>
<p><span style="font-weight: 400">Baca, M. (2008). &#8220;Introduction to Metadata.&#8221; </span><i><span style="font-weight: 400">The Getty Research Institute. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.getty.edu/publications/intrometadata/"><span style="font-weight: 400">https://www.getty.edu/publications/intrometadata</span></a></p>
<p><span style="font-weight: 400">Bailey, J. (2019). &#8220;Solving Art&#8217;s Data Problem &#8211; Part One, Museums.&#8221; </span><i><span style="font-weight: 400">Art Nome. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.artnome.com/news/2019/4/29/solving-arts-data-problem-part-one-museums"><span style="font-weight: 400">https://www.artnome.com/news/2019/4/29/solving-arts-data-problem-part-one-museums</span></a></p>
<p><span style="font-weight: 400">Cates, M. (2019). &#8220;</span><span style="font-weight: 400">The Met, Microsoft, and MIT Explore the Impact of Artificial Intelligence on How Global Audiences Connect with Art.&#8221; </span><i><span style="font-weight: 400">MIT Open Learning. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://openlearning.mit.edu/news/met-microsoft-and-mit-explore-impact-artificial-intelligence-how-global-audiences-connect-art"><span style="font-weight: 400">https://openlearning.mit.edu/news/met-microsoft-and-mit-explore-impact-artificial-intelligence-how-global-audiences-connect-art</span></a></p>
<p><span style="font-weight: 400">CapTech Consulting (2017). &#8220;Accuracy of Six Leading Image Recognition Technologies Assessed by New CapTech Study.&#8221; </span><i><span style="font-weight: 400">CapTech. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://captechconsulting.com/news/accuracy-of-six-leading-image-recognition-technologies-assessed-by-new-captech-study"><span style="font-weight: 400">https://captechconsulting.com/news/accuracy-of-six-leading-image-recognition-technologies-assessed-by-new-captech-study</span></a></p>
<p><span style="font-weight: 400">Ciecko, B.(2017). &#8220;Examining The Impact Of Artificial Intelligence In Museums.&#8221; </span><i><span style="font-weight: 400">Museums and the Web 2017</span></i><span style="font-weight: 400">. Consulted January 2020. </span><a href="https://mw17.mwconf.org/paper/exploring-artificial-intelligence-in-museums/"><span style="font-weight: 400">https://mw17.mwconf.org/paper/exploring-artificial-intelligence-in-museums/</span></a></p>
<p><span style="font-weight: 400">Cognex (2019). &#8220;What is Machine Vision.&#8221; Consulted January 2020. </span><a href="https://www.cognex.com/what-is/machine-vision/what-is-machine-vision"><span style="font-weight: 400">https://www.cognex.com/what-is/machine-vision/what-is-machine-vision</span></a></p>
<p><span style="font-weight: 400">Cook, T. (2019). &#8220;Biased Algorithms are Easier to Fix than Biased People.&#8221; </span><i><span style="font-weight: 400">New York Times</span></i><span style="font-weight: 400">. Consulted January 2020. </span><a href="https://www.nytimes.com/2019/12/06/business/algorithm-bias-fix.html"><span style="font-weight: 400">https://www.nytimes.com/2019/12/06/business/algorithm-bias-fix.html</span></a></p>
<p><span style="font-weight: 400">Cooper Hewitt (2013). &#8220;A</span><span style="font-weight: 400">ll your color are belong to Giv.&#8221; </span><span style="font-weight: 400">Consulted January 2020. </span><a href="https://labs.cooperhewitt.org/2013/giv-do/"><span style="font-weight: 400">https://labs.cooperhewitt.org/2013/giv-do</span></a></p>
<p><span style="font-weight: 400">Engel, C. &amp; Mangiafico P. &amp; Issavi, J. &amp; Lukas, D. (2019). &#8220;Computer vision and image recognition in archaeology.&#8221; </span><i><span style="font-weight: 400">Proceedings of the Conference on Artificial Intelligence for Data Discovery and Reuse 2019. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://dl.acm.org/doi/10.1145/3359115.3359117"><span style="font-weight: 400">https://dl.acm.org/doi/10.1145/3359115.3359117</span></a></p>
<p><span style="font-weight: 400">Fenstermaker, W. (2019). &#8220;How Artificial Intelligence Can Change the Way We Explore Visual Collections.&#8221; </span><i><span style="font-weight: 400">Met Museum Blog. </span></i><span style="font-weight: 400">Consulted September 2019. </span><a href="https://www.metmuseum.org/blogs/now-at-the-met/2019/artificial-intelligence-machine-learning-art-authorship"><span style="font-weight: 400">https://www.metmuseum.org/blogs/now-at-the-met/2019/artificial-intelligence-machine-learning-art-authorship</span></a></p>
<p><span style="font-weight: 400">Grady, C. (2017). &#8220;</span><span style="font-weight: 400">How the SFMOMA&#8217;s artbot responds to text message requests with personally curated art.&#8221; </span><i><span style="font-weight: 400">Vox. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.vox.com/culture/2017/7/11/15949872/sfmomas-artbot-send-me-text-message"><span style="font-weight: 400">https://www.vox.com/culture/2017/7/11/15949872/sfmomas-artbot-send-me-text-message</span></a></p>
<p><span style="font-weight: 400">Harvard Business Review. (2019). &#8220;Artificial Intelligence: The Insights You Need from Harvard Business Review.&#8221; Cambridge: Harvard Business School Press.</span></p>
<p><span style="font-weight: 400">Hao, K. (2019). &#8220;This is how AI bias really happens—and why it&#8217;s so hard to fix.&#8221; </span><i><span style="font-weight: 400">Technology Review. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.technologyreview.com/s/612876/this-is-how-ai-bias-really-happensand-why-its-so-hard-to-fix/"><span style="font-weight: 400">https://www.technologyreview.com/s/612876/this-is-how-ai-bias-really-happensand-why-its-so-hard-to-fix</span></a></p>
<p><span style="font-weight: 400">Husain, A. (2017). </span><i><span style="font-weight: 400">The Sentient Machine</span></i><span style="font-weight: 400">. New York: Scribner.</span></p>
<p><span style="font-weight: 400">Jones, B. (2018). &#8220;C</span><span style="font-weight: 400">omputers saw Jesus, graffiti, and selfies in this art, and critics were floored.&#8221; </span><i><span style="font-weight: 400">Digital Trends. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.digitaltrends.com/computing/philadelphia-art-gallery-the-barnes-foundation-uses-machine-learning/"><span style="font-weight: 400">https://www.digitaltrends.com/computing/philadelphia-art-gallery-the-barnes-foundation-uses-machine-learning</span></a></p>
<p><span style="font-weight: 400">Kessler, M. (2019). &#8220;The Met x Microsoft x MIT: A Closer Look at the Collaboration.&#8221; </span><i><span style="font-weight: 400">The Met Blog. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.metmuseum.org/blogs/now-at-the-met/2019/met-microsoft-mit-reveal-event-video"><span style="font-weight: 400">https://www.metmuseum.org/blogs/now-at-the-met/2019/met-microsoft-mit-reveal-event-video</span></a></p>
<p><span style="font-weight: 400">Knott, J. (2017). &#8220;Using AI to analyze collections.&#8221; </span><i><span style="font-weight: 400">Museum Association. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.museumsassociation.org/museum-practice/artificial-intelligence/14022017-using-ai-to-analyse-collections"><span style="font-weight: 400">https://www.museumsassociation.org/museum-practice/artificial-intelligence/14022017-using-ai-to-analyse-collections</span></a></p>
<p><span style="font-weight: 400">Leason, T. and steve.museum, Steve (2009). &#8220;The Art Museum Social Tagging Project: A Report on the Tag Contributor Experience.&#8221; In J. Trant and D. Bearman (eds). </span><i><span style="font-weight: 400">Museums and the Web 2009: Proceedings</span></i><span style="font-weight: 400">. Toronto: Archives &amp; Museum Informatics. </span><span style="font-weight: 400">Consulted January 2020. </span><a href="http://www.archimuse.com/mw2009/papers/leason/leason.html"><span style="font-weight: 400">http://www.archimuse.com/mw2009/papers/leason/leason.html</span></a></p>
<p><span style="font-weight: 400">Leonard, P. (2019). &#8220;</span><span style="font-weight: 400">The Yale-Smithsonian Partnership presents: Machine Vision for Cultural Heritage &amp; Natural Science Collections.&#8221; </span><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.youtube.com/watch?v=6dmV-ocRJUI"><span style="font-weight: 400">https://www.youtube.com/watch?v=6dmV-ocRJUI</span></a></p>
<p><span style="font-weight: 400">Marr, B. (2019). &#8220;What is Machine Vision And How Is It Used In Business Today?&#8221; </span><i><span style="font-weight: 400">Forbes. </span></i><span style="font-weight: 400">Consulted January</span><span style="font-weight: 400"> 2020</span><i><span style="font-weight: 400">. </span></i><a href="https://www.forbes.com/sites/bernardmarr/2019/10/11/what-is-machine-vision-and-how-is-it-used-in-business-today/#446185ad6939"><span style="font-weight: 400">https://www.forbes.com/sites/bernardmarr/2019/10/11/what-is-machine-vision-and-how-is-it-used-in-business-today</span><span style="font-weight: 400"><br />
</span><span style="font-weight: 400"><br />
</span></a><span style="font-weight: 400">McAfee, A., &amp; Brynjolfsson, E. (2018). Machine, platform, crowd: harnessing our digital revolution. New York: W.W. Norton et Company.</span></p>
<p><span style="font-weight: 400">Merrit, E. (2017). &#8220;</span><span style="font-weight: 400">Artificial Intelligence The Rise Of The Intelligent Machine.&#8221; </span><i><span style="font-weight: 400">AAM Center for the Future of Museums Blog.</span></i> <span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.aam-us.org/2017/05/01/artificial-intelligence-the-rise-of-the-intelligent-machine/"><span style="font-weight: 400">https://www.aam-us.org/2017/05/01/artificial-intelligence-the-rise-of-the-intelligent-machine</span></a></p>
<p><span style="font-weight: 400">Merritt, E. (2018). &#8220;Exploring the Explosion of Museum AI.&#8221; </span><i><span style="font-weight: 400">American Alliance of Museums. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.aam-us.org/2018/10/02/exploring-the-explosion-of-museum-ai/"><span style="font-weight: 400">https://www.aam-us.org/2018/10/02/exploring-the-explosion-of-museum-ai</span></a></p>
<p><span style="font-weight: 400">Moriarty, A. (2019). &#8220;</span><span style="font-weight: 400">A Crisis of Capacity: How can Museums use Machine Learning, the Gig Economy and the Power of the Crowd to Tackle Our Backlogs.&#8221; </span><i><span style="font-weight: 400">Museum and the Web 2019. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://mw19.mwconf.org/paper/a-crisis-of-capacity-how-can-museums-use-machine-learning-the-gig-economy-and-the-power-of-the-crowd-to-tackle-our-backlogs/"><span style="font-weight: 400">https://mw19.mwconf.org/paper/a-crisis-of-capacity-how-can-museums-use-machine-learning-the-gig-economy-and-the-power-of-the-crowd-to-tackle-our-backlogs</span></a></p>
<p><span style="font-weight: 400">Ngo, T. and Tsang, W. (2017). &#8220;Classify Art using TensorFlow.&#8221; </span><i><span style="font-weight: 400">IBM. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://developer.ibm.com/patterns/classify-art-using-tensorflow-model/"><span style="font-weight: 400">https://developer.ibm.com/patterns/classify-art-using-tensorflow-model</span></a></p>
<p><span style="font-weight: 400">Nunez, M. (2018). &#8220;The Google Arts and Culture app has a race problem.&#8221; </span><i><span style="font-weight: 400">Mashable. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://mashable.com/2018/01/16/google-arts-culture-app-race-problem-racist/"><span style="font-weight: 400">https://mashable.com/2018/01/16/google-arts-culture-app-race-problem-racist</span></a></p>
<p><span style="font-weight: 400">Papert, S. (1966). &#8220;The Summer Vision Project.&#8221; Consulted January 2020. </span><a href="http://people.csail.mit.edu/brooks/idocs/AIM-100.pdf"><span style="font-weight: 400">http://people.csail.mit.edu/brooks/idocs/AIM-100.pdf</span></a></p>
<p><span style="font-weight: 400">Rao, N. (2019). &#8220;How ImageNet Roulette, an Art Project That Went Viral by Exposing Facial Recognition&#8217;s Biases, Is Changing People&#8217;s Minds About AI.&#8221; </span><i><span style="font-weight: 400">ArtNet. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://news.artnet.com/art-world/imagenet-roulette-trevor-paglen-kate-crawford-1658305"><span style="font-weight: 400">https</span><span style="font-weight: 400">://news.artnet.com/art-world/imagenet-roulette-trevor-paglen-kate-crawford-1658305</span></a></p>
<p><span style="font-weight: 400">Rao, S. (2019). &#8220;Illuminating Colonization Through Augmented Reality.&#8221; </span><i><span style="font-weight: 400">Museum and the Web 2019. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://mw19.mwconf.org/paper/illuminating-colonization-through-augmented-reality/"><span style="font-weight: 400">https://mw19.mwconf.org/paper/illuminating-colonization-through-augmented-reality</span></a></p>
<p><span style="font-weight: 400">Robinson, S. (2017). &#8220;When art meets big data: Analyzing 200,000 items from The Met collection in BigQuery.&#8221; Consulted January 2020. </span><a href="https://cloud.google.com/blog/products/gcp/when-art-meets-big-data-analyzing-200000-items-from-the-met-collection-in-bigquery"><span style="font-weight: 400">https://cloud.google.com/blog/products/gcp/when-art-meets-big-data-analyzing-200000-items-from-the-met-collection-in-bigquery</span></a></p>
<p><span style="font-weight: 400">Ruiz, C. (2019). &#8220;Leading online database to remove 600,000 images after art project reveals its racist bias.&#8221; </span><i><span style="font-weight: 400">The Art Newspaper</span></i><span style="font-weight: 400">. </span><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.theartnewspaper.com/news/trevor-paglen"><span style="font-weight: 400">https://www.theartnewspaper.com/news/trevor-paglen</span></a></p>
<p><span style="font-weight: 400">Schneider, T. (2019). &#8220;The Gray Market: How the Met&#8217;s Artificial Intelligence Initiative Masks the Technology&#8217;s Larger Threats.&#8221; </span><i><span style="font-weight: 400">ArtNet. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://news.artnet.com/opinion/metropolitan-museum-artificial-intelligence-1461730"><span style="font-weight: 400">https://news.artnet.com/opinion/metropolitan-museum-artificial-intelligence-1461730</span></a></p>
<p><span style="font-weight: 400">Selvin, C. (2018). &#8220;&#8216;</span><span style="font-weight: 400">Curating Involves a Daily Protest Against Forgetting&#8217;: Hans Ulrich Obrist Waxes Poetic at Armory Show.&#8221; </span><i><span style="font-weight: 400">ArtNews</span></i><span style="font-weight: 400">. </span><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.artnews.com/art-news/market/curating-involves-daily-protest-forgetting-hans-ulrich-obrist-waxes-poetic-armory-show-9948/"><span style="font-weight: 400">https://www.artnews.com/art-news/market/curating-involves-daily-protest-forgetting-hans-ulrich-obrist-waxes-poetic-armory-show-9948</span></a></p>
<p><span style="font-weight: 400">Shu, C. (2018). &#8220;Why inclusion in the Google Arts &amp; Culture selfie feature matters.&#8221; </span><i><span style="font-weight: 400">Tech Crunch. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://techcrunch.com/2018/01/21/why-inclusion-in-the-google-arts-culture-selfie-feature-matters/"><span style="font-weight: 400">https://techcrunch.com/2018/01/21/why-inclusion-in-the-google-arts-culture-selfie-feature-matters</span></a></p>
<p><span style="font-weight: 400">Smith, R. (2017). &#8220;How Artificial Intelligence Could Revolutionize Archival Museum Research.&#8221; </span><i><span style="font-weight: 400">Smithsonian Magazine. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.smithsonianmag.com/smithsonian-institution/how-artificial-intelligence-could-revolutionize-museum-research-180967065/"><span style="font-weight: 400">https://www.smithsonianmag.com/smithsonian-institution/how-artificial-intelligence-could-revolutionize-museum-research-180967065</span></a></p>
<p><span style="font-weight: 400">Summers, K. (2019). &#8220;Magical machinery: what AI can do for museums.&#8221; </span><i><span style="font-weight: 400">American Alliance of Museums. </span></i><span style="font-weight: 400">Consulted January 2020. Consulted January 2020. </span><a href="https://www.aam-us.org/2019/05/03/magical-machinery-what-ai-can-do-for-museums/"><span style="font-weight: 400">https://www.aam-us.org/2019/05/03/magical-machinery-what-ai-can-do-for-museums</span></a></p>
<p><span style="font-weight: 400">Swant, M. (2018). &#8220;How the Cooper Hewitt Museum and R/GA Are Showing the Evolution of Technology and Design.&#8221; </span><i><span style="font-weight: 400">AdWeek. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.adweek.com/brand-marketing/how-the-cooper-hewitt-museum-and-r-ga-are-showing-the-evolution-of-technology-and-design/"><span style="font-weight: 400">https://www.adweek.com/brand-marketing/how-the-cooper-hewitt-museum-and-r-ga-are-showing-the-evolution-of-technology-and-design</span></a></p>
<p><span style="font-weight: 400">Trivedi, N. (2019). &#8220;</span><span style="font-weight: 400">The Color of Serendipity: Searching with the Color Wheel.&#8221; </span><i><span style="font-weight: 400">Art Institute of Chicago. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.artic.edu/articles/759/the-color-of-serendipity-searching-with-the-color-wheel"><i><span style="font-weight: 400">https://www.artic.edu/articles/759/the-color-of-serendipity-searching-with-the-color-wheel</span></i></a></p>
<p><span style="font-weight: 400">Winsor, R. (2016). &#8220;</span><span style="font-weight: 400">Clarifai vs Google Vision: Two Visual Recognition APIs Compared.&#8221; </span><i><span style="font-weight: 400">DAM News. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://digitalassetmanagementnews.org/emerging-dam-technologies/clarifai-vs-google-vision-two-visual-recognition-apis-compared/"><span style="font-weight: 400">https://digitalassetmanagementnews.org/emerging-dam-technologies/clarifai-vs-google-vision-two-visual-recognition-apis-compared</span></a></p>
<p><span style="font-weight: 400">Yao, S. (2</span><span style="font-weight: 400">018). &#8220;A Probe into How Machines See Art.&#8221; </span><i><span style="font-weight: 400">The Crimson. </span></i><span style="font-weight: 400">Consulted January 2020. </span><a href="https://www.thecrimson.com/article/2018/10/30/how-machines-see-art/"><i><span style="font-weight: 400">https://www.thecrimson.com/article/2018/10/30/how-machines-see-art</span></i></a></p>
<hr>

<script type="text/javascript">
var d=new Date();
var month=new Array();
month[0]="January";
month[1]="February";
month[2]="March";
month[3]="April";
month[4]="May";
month[5]="June";
month[6]="July";
month[7]="August";
month[8]="September";
month[9]="October";
month[10]="November";
month[11]="December";

var day_number=d.getDate();
var month_name=month[d.getMonth()];
var year=d.getFullYear();
var full_date = month_name+" "+day_number+", "+year;
</script>

Cite as:<br /> 

Ciecko, Brendan. "AI Sees What? The Good, the Bad, and the Ugly of Machine Vision for Museum Collections." <i>MW20: MW 2020</i>. Published January 15, 2020. Consulted <script type="text/javascript">document.write(full_date);</script>.<br />
https://mw20.museweb.net/paper/ai-sees-what-the-good-the-bad-and-the-ugly-of-machine-vision-for-museum-collections/<br /><br />
		</main><!-- #main -->
	</div><!-- #primary -->
	
<aside id="secondary" class="widget-area" role="complementary" aria-label="Blog Sidebar">
	<section id="custom_html-3" class="widget_text widget widget_custom_html"><div class="textwidget custom-html-widget"><div style="text-align: center;">	
<h2 id="global-sponsor" class="widget-title">Global Sponsor</h2>
<a title="Microsoft" href="https://www.microsoft.com/en-us/education" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="https://mw19.mwconf.org/wp-content/themes/mwconf-2017/images/microsoft-250-75.jpg" alt="Microsoft" /></a>
<h2 id="gold-sponsor" class="widget-title">Gold Sponsors</h2>
<a title="Google" href="https://artsandculture.google.com/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="../../wp-content/themes/mwconf/images/google-250-75.jpg" alt="Google" /></a>
	<a title="Piction" href="https://www.piction.com/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="../../wp-content/themes/mwconf/images/piction-250-75.jpg" alt="Piction" /></a>
	<h2 id="silver-sponsor" class="widget-title">Silver Sponsor</h2>
<a title="Brightcove" href="https://brightcove.com/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="https://mw19.mwconf.org/wp-content/themes/mwconf-2017/images/bc-250-75.jpg" alt="Brightcove" /></a>
<h2 id="bronze" class="widget-title">Bronze Sponsors</h2>
<a title="Axiell" href="https://alm.axiell.com/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="../../wp-content/themes/mwconf/images/axiell-250-75.jpg" alt="Axiell" /></a>
<a title="Livdeo" href="https://www.livdeo.com/en/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="../../wp-content/themes/mwconf/images/livdeo-250-75.jpg" alt="Livdeo" /></a>
<a title="Lucidea" href="https://lucidea.com/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="../../wp-content/themes/mwconf/images/lucidea-250-75.jpg" alt="Lucidea" /></a>
<a title="Forum One" href="https://forumone.com/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="../../wp-content/themes/mwconf/images/forum-one-250-75.jpg" alt="Forum One" /></a>
<a title="CDW" href="https://cdw.com/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="../../wp-content/themes/mwconf/images/cdw-250-75.jpg" alt="CDW" /></a>
<h2 id="partner" class="widget-title">Partners</h2>
<a title="Virtual Ability" href="https://virtualability.org/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="../../wp-content/themes/mwconf/images/virtual-250-75.jpg" alt="Virtual Ability" /></a>
<a title="Linden Lab" href="https://secondlife.com/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="../../wp-content/themes/mwconf/images/linden-250-75.jpg" alt="Linden Lab" /></a>
</div></div></section><section id="custom_html-2" class="widget_text widget widget_custom_html"><h2 class="widget-title">Mailing List</h2><div class="textwidget custom-html-widget"><hr>
<!-- Begin MailChimp Signup Form -->
<link href="http://cdn-images.mailchimp.com/embedcode/slim-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
	#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }
	/* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
	   We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="https://museumsandtheweb.us4.list-manage.com/subscribe/post?u=71f2b910406e41b9c635e9fc4&amp;id=6a115c18d7" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<label for="mce-EMAIL">Subscribe to get our free MuseLetter and conference updates! </label>
	<input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_71f2b910406e41b9c635e9fc4_6a115c18d7" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup--></div></section></aside><!-- #secondary -->
</div><!-- .wrap -->


		</div><!-- #content -->

		<footer id="colophon" class="site-footer" role="contentinfo">
			<div class="wrap">
				

	<aside class="widget-area" role="complementary" aria-label="Footer">
					<div class="widget-column footer-widget-1">
				<section id="text-2" class="widget widget_text">			<div class="textwidget"><p><strong>Presented by Museums and the Web, LLC</strong><br />
703 Dale Drive, Silver Spring, MD, 20910, USA<br />
<a href="mailto:info@museweb.net">info@museweb.net</a></p>
<p><strong>Founded by Archives and Museum Informatics</strong><br />
<a href="http://www.archimuse.com/">www.archimuse.com</a></p>
</div>
		</section>			</div>
				</aside><!-- .widget-area -->

			</div><!-- .wrap -->
		</footer><!-- #colophon -->
	</div><!-- .site-content-contain -->
</div><!-- #page -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-26332456-1"></script>
<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'UA-26332456-1', {
  		'linker': {
    	'domains': ['museweb.net', 'mwconf.org', 'museumsandtheweb.com']
  }
});
</script>

<script id='twentyseventeen-skip-link-focus-fix-js-extra'>
var twentyseventeenScreenReaderText = {"quote":"<svg class=\"icon icon-quote-right\" aria-hidden=\"true\" role=\"img\"> <use href=\"#icon-quote-right\" xlink:href=\"#icon-quote-right\"><\/use> <\/svg>","expand":"Expand child menu","collapse":"Collapse child menu","icon":"<svg class=\"icon icon-angle-down\" aria-hidden=\"true\" role=\"img\"> <use href=\"#icon-angle-down\" xlink:href=\"#icon-angle-down\"><\/use> <span class=\"svg-fallback icon-angle-down\"><\/span><\/svg>"};
</script>
<script src='../../wp-content/themes/twentyseventeen/assets/js/skip-link-focus-fixb448.js?ver=20161114' id='twentyseventeen-skip-link-focus-fix-js'></script>
<script src='../../wp-content/themes/twentyseventeen/assets/js/navigation6877.js?ver=20161203' id='twentyseventeen-navigation-js'></script>
<script src='../../wp-content/themes/twentyseventeen/assets/js/global5841.js?ver=20190121' id='twentyseventeen-global-js'></script>
<script src='../../wp-content/themes/twentyseventeen/assets/js/jquery.scrollTo431f.js?ver=2.1.2' id='jquery-scrollto-js'></script>
<script src='../../wp-includes/js/wp-embed.min40df.js?ver=5.6' id='wp-embed-js'></script>
<svg style="position: absolute; width: 0; height: 0; overflow: hidden;" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<defs>
<symbol id="icon-behance" viewBox="0 0 37 32">
<path class="path1" d="M33 6.054h-9.125v2.214h9.125v-2.214zM28.5 13.661q-1.607 0-2.607 0.938t-1.107 2.545h7.286q-0.321-3.482-3.571-3.482zM28.786 24.107q1.125 0 2.179-0.571t1.357-1.554h3.946q-1.786 5.482-7.625 5.482-3.821 0-6.080-2.357t-2.259-6.196q0-3.714 2.33-6.17t6.009-2.455q2.464 0 4.295 1.214t2.732 3.196 0.902 4.429q0 0.304-0.036 0.839h-11.75q0 1.982 1.027 3.063t2.973 1.080zM4.946 23.214h5.286q3.661 0 3.661-2.982 0-3.214-3.554-3.214h-5.393v6.196zM4.946 13.625h5.018q1.393 0 2.205-0.652t0.813-2.027q0-2.571-3.393-2.571h-4.643v5.25zM0 4.536h10.607q1.554 0 2.768 0.25t2.259 0.848 1.607 1.723 0.563 2.75q0 3.232-3.071 4.696 2.036 0.571 3.071 2.054t1.036 3.643q0 1.339-0.438 2.438t-1.179 1.848-1.759 1.268-2.161 0.75-2.393 0.232h-10.911v-22.5z"></path>
</symbol>
<symbol id="icon-deviantart" viewBox="0 0 18 32">
<path class="path1" d="M18.286 5.411l-5.411 10.393 0.429 0.554h4.982v7.411h-9.054l-0.786 0.536-2.536 4.875-0.536 0.536h-5.375v-5.411l5.411-10.411-0.429-0.536h-4.982v-7.411h9.054l0.786-0.536 2.536-4.875 0.536-0.536h5.375v5.411z"></path>
</symbol>
<symbol id="icon-medium" viewBox="0 0 32 32">
<path class="path1" d="M10.661 7.518v20.946q0 0.446-0.223 0.759t-0.652 0.313q-0.304 0-0.589-0.143l-8.304-4.161q-0.375-0.179-0.634-0.598t-0.259-0.83v-20.357q0-0.357 0.179-0.607t0.518-0.25q0.25 0 0.786 0.268l9.125 4.571q0.054 0.054 0.054 0.089zM11.804 9.321l9.536 15.464-9.536-4.75v-10.714zM32 9.643v18.821q0 0.446-0.25 0.723t-0.679 0.277-0.839-0.232l-7.875-3.929zM31.946 7.5q0 0.054-4.58 7.491t-5.366 8.705l-6.964-11.321 5.786-9.411q0.304-0.5 0.929-0.5 0.25 0 0.464 0.107l9.661 4.821q0.071 0.036 0.071 0.107z"></path>
</symbol>
<symbol id="icon-slideshare" viewBox="0 0 32 32">
<path class="path1" d="M15.589 13.214q0 1.482-1.134 2.545t-2.723 1.063-2.723-1.063-1.134-2.545q0-1.5 1.134-2.554t2.723-1.054 2.723 1.054 1.134 2.554zM24.554 13.214q0 1.482-1.125 2.545t-2.732 1.063q-1.589 0-2.723-1.063t-1.134-2.545q0-1.5 1.134-2.554t2.723-1.054q1.607 0 2.732 1.054t1.125 2.554zM28.571 16.429v-11.911q0-1.554-0.571-2.205t-1.982-0.652h-19.857q-1.482 0-2.009 0.607t-0.527 2.25v12.018q0.768 0.411 1.58 0.714t1.446 0.5 1.446 0.33 1.268 0.196 1.25 0.071 1.045 0.009 1.009-0.036 0.795-0.036q1.214-0.018 1.696 0.482 0.107 0.107 0.179 0.161 0.464 0.446 1.089 0.911 0.125-1.625 2.107-1.554 0.089 0 0.652 0.027t0.768 0.036 0.813 0.018 0.946-0.018 0.973-0.080 1.089-0.152 1.107-0.241 1.196-0.348 1.205-0.482 1.286-0.616zM31.482 16.339q-2.161 2.661-6.643 4.5 1.5 5.089-0.411 8.304-1.179 2.018-3.268 2.643-1.857 0.571-3.25-0.268-1.536-0.911-1.464-2.929l-0.018-5.821v-0.018q-0.143-0.036-0.438-0.107t-0.42-0.089l-0.018 6.036q0.071 2.036-1.482 2.929-1.411 0.839-3.268 0.268-2.089-0.643-3.25-2.679-1.875-3.214-0.393-8.268-4.482-1.839-6.643-4.5-0.446-0.661-0.071-1.125t1.071 0.018q0.054 0.036 0.196 0.125t0.196 0.143v-12.393q0-1.286 0.839-2.196t2.036-0.911h22.446q1.196 0 2.036 0.911t0.839 2.196v12.393l0.375-0.268q0.696-0.482 1.071-0.018t-0.071 1.125z"></path>
</symbol>
<symbol id="icon-snapchat-ghost" viewBox="0 0 30 32">
<path class="path1" d="M15.143 2.286q2.393-0.018 4.295 1.223t2.92 3.438q0.482 1.036 0.482 3.196 0 0.839-0.161 3.411 0.25 0.125 0.5 0.125 0.321 0 0.911-0.241t0.911-0.241q0.518 0 1 0.321t0.482 0.821q0 0.571-0.563 0.964t-1.232 0.563-1.232 0.518-0.563 0.848q0 0.268 0.214 0.768 0.661 1.464 1.83 2.679t2.58 1.804q0.5 0.214 1.429 0.411 0.5 0.107 0.5 0.625 0 1.25-3.911 1.839-0.125 0.196-0.196 0.696t-0.25 0.83-0.589 0.33q-0.357 0-1.107-0.116t-1.143-0.116q-0.661 0-1.107 0.089-0.571 0.089-1.125 0.402t-1.036 0.679-1.036 0.723-1.357 0.598-1.768 0.241q-0.929 0-1.723-0.241t-1.339-0.598-1.027-0.723-1.036-0.679-1.107-0.402q-0.464-0.089-1.125-0.089-0.429 0-1.17 0.134t-1.045 0.134q-0.446 0-0.625-0.33t-0.25-0.848-0.196-0.714q-3.911-0.589-3.911-1.839 0-0.518 0.5-0.625 0.929-0.196 1.429-0.411 1.393-0.571 2.58-1.804t1.83-2.679q0.214-0.5 0.214-0.768 0-0.5-0.563-0.848t-1.241-0.527-1.241-0.563-0.563-0.938q0-0.482 0.464-0.813t0.982-0.33q0.268 0 0.857 0.232t0.946 0.232q0.321 0 0.571-0.125-0.161-2.536-0.161-3.393 0-2.179 0.482-3.214 1.143-2.446 3.071-3.536t4.714-1.125z"></path>
</symbol>
<symbol id="icon-yelp" viewBox="0 0 27 32">
<path class="path1" d="M13.804 23.554v2.268q-0.018 5.214-0.107 5.446-0.214 0.571-0.911 0.714-0.964 0.161-3.241-0.679t-2.902-1.589q-0.232-0.268-0.304-0.643-0.018-0.214 0.071-0.464 0.071-0.179 0.607-0.839t3.232-3.857q0.018 0 1.071-1.25 0.268-0.339 0.705-0.438t0.884 0.063q0.429 0.179 0.67 0.518t0.223 0.75zM11.143 19.071q-0.054 0.982-0.929 1.25l-2.143 0.696q-4.911 1.571-5.214 1.571-0.625-0.036-0.964-0.643-0.214-0.446-0.304-1.339-0.143-1.357 0.018-2.973t0.536-2.223 1-0.571q0.232 0 3.607 1.375 1.25 0.518 2.054 0.839l1.5 0.607q0.411 0.161 0.634 0.545t0.205 0.866zM25.893 24.375q-0.125 0.964-1.634 2.875t-2.42 2.268q-0.661 0.25-1.125-0.125-0.25-0.179-3.286-5.125l-0.839-1.375q-0.25-0.375-0.205-0.821t0.348-0.821q0.625-0.768 1.482-0.464 0.018 0.018 2.125 0.714 3.625 1.179 4.321 1.42t0.839 0.366q0.5 0.393 0.393 1.089zM13.893 13.089q0.089 1.821-0.964 2.179-1.036 0.304-2.036-1.268l-6.75-10.679q-0.143-0.625 0.339-1.107 0.732-0.768 3.705-1.598t4.009-0.563q0.714 0.179 0.875 0.804 0.054 0.321 0.393 5.455t0.429 6.777zM25.714 15.018q0.054 0.696-0.464 1.054-0.268 0.179-5.875 1.536-1.196 0.268-1.625 0.411l0.018-0.036q-0.411 0.107-0.821-0.071t-0.661-0.571q-0.536-0.839 0-1.554 0.018-0.018 1.339-1.821 2.232-3.054 2.679-3.643t0.607-0.696q0.5-0.339 1.161-0.036 0.857 0.411 2.196 2.384t1.446 2.991v0.054z"></path>
</symbol>
<symbol id="icon-vine" viewBox="0 0 27 32">
<path class="path1" d="M26.732 14.768v3.536q-1.804 0.411-3.536 0.411-1.161 2.429-2.955 4.839t-3.241 3.848-2.286 1.902q-1.429 0.804-2.893-0.054-0.5-0.304-1.080-0.777t-1.518-1.491-1.83-2.295-1.92-3.286-1.884-4.357-1.634-5.616-1.259-6.964h5.054q0.464 3.893 1.25 7.116t1.866 5.661 2.17 4.205 2.5 3.482q3.018-3.018 5.125-7.25-2.536-1.286-3.982-3.929t-1.446-5.946q0-3.429 1.857-5.616t5.071-2.188q3.179 0 4.875 1.884t1.696 5.313q0 2.839-1.036 5.107-0.125 0.018-0.348 0.054t-0.821 0.036-1.125-0.107-1.107-0.455-0.902-0.92q0.554-1.839 0.554-3.286 0-1.554-0.518-2.357t-1.411-0.804q-0.946 0-1.518 0.884t-0.571 2.509q0 3.321 1.875 5.241t4.768 1.92q1.107 0 2.161-0.25z"></path>
</symbol>
<symbol id="icon-vk" viewBox="0 0 35 32">
<path class="path1" d="M34.232 9.286q0.411 1.143-2.679 5.25-0.429 0.571-1.161 1.518-1.393 1.786-1.607 2.339-0.304 0.732 0.25 1.446 0.304 0.375 1.446 1.464h0.018l0.071 0.071q2.518 2.339 3.411 3.946 0.054 0.089 0.116 0.223t0.125 0.473-0.009 0.607-0.446 0.491-1.054 0.223l-4.571 0.071q-0.429 0.089-1-0.089t-0.929-0.393l-0.357-0.214q-0.536-0.375-1.25-1.143t-1.223-1.384-1.089-1.036-1.009-0.277q-0.054 0.018-0.143 0.063t-0.304 0.259-0.384 0.527-0.304 0.929-0.116 1.384q0 0.268-0.063 0.491t-0.134 0.33l-0.071 0.089q-0.321 0.339-0.946 0.393h-2.054q-1.268 0.071-2.607-0.295t-2.348-0.946-1.839-1.179-1.259-1.027l-0.446-0.429q-0.179-0.179-0.491-0.536t-1.277-1.625-1.893-2.696-2.188-3.768-2.33-4.857q-0.107-0.286-0.107-0.482t0.054-0.286l0.071-0.107q0.268-0.339 1.018-0.339l4.893-0.036q0.214 0.036 0.411 0.116t0.286 0.152l0.089 0.054q0.286 0.196 0.429 0.571 0.357 0.893 0.821 1.848t0.732 1.455l0.286 0.518q0.518 1.071 1 1.857t0.866 1.223 0.741 0.688 0.607 0.25 0.482-0.089q0.036-0.018 0.089-0.089t0.214-0.393 0.241-0.839 0.17-1.446 0-2.232q-0.036-0.714-0.161-1.304t-0.25-0.821l-0.107-0.214q-0.446-0.607-1.518-0.768-0.232-0.036 0.089-0.429 0.304-0.339 0.679-0.536 0.946-0.464 4.268-0.429 1.464 0.018 2.411 0.232 0.357 0.089 0.598 0.241t0.366 0.429 0.188 0.571 0.063 0.813-0.018 0.982-0.045 1.259-0.027 1.473q0 0.196-0.018 0.75t-0.009 0.857 0.063 0.723 0.205 0.696 0.402 0.438q0.143 0.036 0.304 0.071t0.464-0.196 0.679-0.616 0.929-1.196 1.214-1.92q1.071-1.857 1.911-4.018 0.071-0.179 0.179-0.313t0.196-0.188l0.071-0.054 0.089-0.045t0.232-0.054 0.357-0.009l5.143-0.036q0.696-0.089 1.143 0.045t0.554 0.295z"></path>
</symbol>
<symbol id="icon-search" viewBox="0 0 30 32">
<path class="path1" d="M20.571 14.857q0-3.304-2.348-5.652t-5.652-2.348-5.652 2.348-2.348 5.652 2.348 5.652 5.652 2.348 5.652-2.348 2.348-5.652zM29.714 29.714q0 0.929-0.679 1.607t-1.607 0.679q-0.964 0-1.607-0.679l-6.125-6.107q-3.196 2.214-7.125 2.214-2.554 0-4.884-0.991t-4.018-2.679-2.679-4.018-0.991-4.884 0.991-4.884 2.679-4.018 4.018-2.679 4.884-0.991 4.884 0.991 4.018 2.679 2.679 4.018 0.991 4.884q0 3.929-2.214 7.125l6.125 6.125q0.661 0.661 0.661 1.607z"></path>
</symbol>
<symbol id="icon-envelope-o" viewBox="0 0 32 32">
<path class="path1" d="M29.714 26.857v-13.714q-0.571 0.643-1.232 1.179-4.786 3.679-7.607 6.036-0.911 0.768-1.482 1.196t-1.545 0.866-1.83 0.438h-0.036q-0.857 0-1.83-0.438t-1.545-0.866-1.482-1.196q-2.821-2.357-7.607-6.036-0.661-0.536-1.232-1.179v13.714q0 0.232 0.17 0.402t0.402 0.17h26.286q0.232 0 0.402-0.17t0.17-0.402zM29.714 8.089v-0.438t-0.009-0.232-0.054-0.223-0.098-0.161-0.161-0.134-0.25-0.045h-26.286q-0.232 0-0.402 0.17t-0.17 0.402q0 3 2.625 5.071 3.446 2.714 7.161 5.661 0.107 0.089 0.625 0.527t0.821 0.67 0.795 0.563 0.902 0.491 0.768 0.161h0.036q0.357 0 0.768-0.161t0.902-0.491 0.795-0.563 0.821-0.67 0.625-0.527q3.714-2.946 7.161-5.661 0.964-0.768 1.795-2.063t0.83-2.348zM32 7.429v19.429q0 1.179-0.839 2.018t-2.018 0.839h-26.286q-1.179 0-2.018-0.839t-0.839-2.018v-19.429q0-1.179 0.839-2.018t2.018-0.839h26.286q1.179 0 2.018 0.839t0.839 2.018z"></path>
</symbol>
<symbol id="icon-close" viewBox="0 0 25 32">
<path class="path1" d="M23.179 23.607q0 0.714-0.5 1.214l-2.429 2.429q-0.5 0.5-1.214 0.5t-1.214-0.5l-5.25-5.25-5.25 5.25q-0.5 0.5-1.214 0.5t-1.214-0.5l-2.429-2.429q-0.5-0.5-0.5-1.214t0.5-1.214l5.25-5.25-5.25-5.25q-0.5-0.5-0.5-1.214t0.5-1.214l2.429-2.429q0.5-0.5 1.214-0.5t1.214 0.5l5.25 5.25 5.25-5.25q0.5-0.5 1.214-0.5t1.214 0.5l2.429 2.429q0.5 0.5 0.5 1.214t-0.5 1.214l-5.25 5.25 5.25 5.25q0.5 0.5 0.5 1.214z"></path>
</symbol>
<symbol id="icon-angle-down" viewBox="0 0 21 32">
<path class="path1" d="M19.196 13.143q0 0.232-0.179 0.411l-8.321 8.321q-0.179 0.179-0.411 0.179t-0.411-0.179l-8.321-8.321q-0.179-0.179-0.179-0.411t0.179-0.411l0.893-0.893q0.179-0.179 0.411-0.179t0.411 0.179l7.018 7.018 7.018-7.018q0.179-0.179 0.411-0.179t0.411 0.179l0.893 0.893q0.179 0.179 0.179 0.411z"></path>
</symbol>
<symbol id="icon-folder-open" viewBox="0 0 34 32">
<path class="path1" d="M33.554 17q0 0.554-0.554 1.179l-6 7.071q-0.768 0.911-2.152 1.545t-2.563 0.634h-19.429q-0.607 0-1.080-0.232t-0.473-0.768q0-0.554 0.554-1.179l6-7.071q0.768-0.911 2.152-1.545t2.563-0.634h19.429q0.607 0 1.080 0.232t0.473 0.768zM27.429 10.857v2.857h-14.857q-1.679 0-3.518 0.848t-2.929 2.134l-6.107 7.179q0-0.071-0.009-0.223t-0.009-0.223v-17.143q0-1.643 1.179-2.821t2.821-1.179h5.714q1.643 0 2.821 1.179t1.179 2.821v0.571h9.714q1.643 0 2.821 1.179t1.179 2.821z"></path>
</symbol>
<symbol id="icon-twitter" viewBox="0 0 30 32">
<path class="path1" d="M28.929 7.286q-1.196 1.75-2.893 2.982 0.018 0.25 0.018 0.75 0 2.321-0.679 4.634t-2.063 4.437-3.295 3.759-4.607 2.607-5.768 0.973q-4.839 0-8.857-2.589 0.625 0.071 1.393 0.071 4.018 0 7.161-2.464-1.875-0.036-3.357-1.152t-2.036-2.848q0.589 0.089 1.089 0.089 0.768 0 1.518-0.196-2-0.411-3.313-1.991t-1.313-3.67v-0.071q1.214 0.679 2.607 0.732-1.179-0.786-1.875-2.054t-0.696-2.75q0-1.571 0.786-2.911 2.161 2.661 5.259 4.259t6.634 1.777q-0.143-0.679-0.143-1.321 0-2.393 1.688-4.080t4.080-1.688q2.5 0 4.214 1.821 1.946-0.375 3.661-1.393-0.661 2.054-2.536 3.179 1.661-0.179 3.321-0.893z"></path>
</symbol>
<symbol id="icon-facebook" viewBox="0 0 19 32">
<path class="path1" d="M17.125 0.214v4.714h-2.804q-1.536 0-2.071 0.643t-0.536 1.929v3.375h5.232l-0.696 5.286h-4.536v13.554h-5.464v-13.554h-4.554v-5.286h4.554v-3.893q0-3.321 1.857-5.152t4.946-1.83q2.625 0 4.071 0.214z"></path>
</symbol>
<symbol id="icon-github" viewBox="0 0 27 32">
<path class="path1" d="M13.714 2.286q3.732 0 6.884 1.839t4.991 4.991 1.839 6.884q0 4.482-2.616 8.063t-6.759 4.955q-0.482 0.089-0.714-0.125t-0.232-0.536q0-0.054 0.009-1.366t0.009-2.402q0-1.732-0.929-2.536 1.018-0.107 1.83-0.321t1.679-0.696 1.446-1.188 0.946-1.875 0.366-2.688q0-2.125-1.411-3.679 0.661-1.625-0.143-3.643-0.5-0.161-1.446 0.196t-1.643 0.786l-0.679 0.429q-1.661-0.464-3.429-0.464t-3.429 0.464q-0.286-0.196-0.759-0.482t-1.491-0.688-1.518-0.241q-0.804 2.018-0.143 3.643-1.411 1.554-1.411 3.679 0 1.518 0.366 2.679t0.938 1.875 1.438 1.196 1.679 0.696 1.83 0.321q-0.696 0.643-0.875 1.839-0.375 0.179-0.804 0.268t-1.018 0.089-1.17-0.384-0.991-1.116q-0.339-0.571-0.866-0.929t-0.884-0.429l-0.357-0.054q-0.375 0-0.518 0.080t-0.089 0.205 0.161 0.25 0.232 0.214l0.125 0.089q0.393 0.179 0.777 0.679t0.563 0.911l0.179 0.411q0.232 0.679 0.786 1.098t1.196 0.536 1.241 0.125 0.991-0.063l0.411-0.071q0 0.679 0.009 1.58t0.009 0.973q0 0.321-0.232 0.536t-0.714 0.125q-4.143-1.375-6.759-4.955t-2.616-8.063q0-3.732 1.839-6.884t4.991-4.991 6.884-1.839zM5.196 21.982q0.054-0.125-0.125-0.214-0.179-0.054-0.232 0.036-0.054 0.125 0.125 0.214 0.161 0.107 0.232-0.036zM5.75 22.589q0.125-0.089-0.036-0.286-0.179-0.161-0.286-0.054-0.125 0.089 0.036 0.286 0.179 0.179 0.286 0.054zM6.286 23.393q0.161-0.125 0-0.339-0.143-0.232-0.304-0.107-0.161 0.089 0 0.321t0.304 0.125zM7.036 24.143q0.143-0.143-0.071-0.339-0.214-0.214-0.357-0.054-0.161 0.143 0.071 0.339 0.214 0.214 0.357 0.054zM8.054 24.589q0.054-0.196-0.232-0.286-0.268-0.071-0.339 0.125t0.232 0.268q0.268 0.107 0.339-0.107zM9.179 24.679q0-0.232-0.304-0.196-0.286 0-0.286 0.196 0 0.232 0.304 0.196 0.286 0 0.286-0.196zM10.214 24.5q-0.036-0.196-0.321-0.161-0.286 0.054-0.25 0.268t0.321 0.143 0.25-0.25z"></path>
</symbol>
<symbol id="icon-bars" viewBox="0 0 27 32">
<path class="path1" d="M27.429 24v2.286q0 0.464-0.339 0.804t-0.804 0.339h-25.143q-0.464 0-0.804-0.339t-0.339-0.804v-2.286q0-0.464 0.339-0.804t0.804-0.339h25.143q0.464 0 0.804 0.339t0.339 0.804zM27.429 14.857v2.286q0 0.464-0.339 0.804t-0.804 0.339h-25.143q-0.464 0-0.804-0.339t-0.339-0.804v-2.286q0-0.464 0.339-0.804t0.804-0.339h25.143q0.464 0 0.804 0.339t0.339 0.804zM27.429 5.714v2.286q0 0.464-0.339 0.804t-0.804 0.339h-25.143q-0.464 0-0.804-0.339t-0.339-0.804v-2.286q0-0.464 0.339-0.804t0.804-0.339h25.143q0.464 0 0.804 0.339t0.339 0.804z"></path>
</symbol>
<symbol id="icon-google-plus" viewBox="0 0 41 32">
<path class="path1" d="M25.661 16.304q0 3.714-1.554 6.616t-4.429 4.536-6.589 1.634q-2.661 0-5.089-1.036t-4.179-2.786-2.786-4.179-1.036-5.089 1.036-5.089 2.786-4.179 4.179-2.786 5.089-1.036q5.107 0 8.768 3.429l-3.554 3.411q-2.089-2.018-5.214-2.018-2.196 0-4.063 1.107t-2.955 3.009-1.089 4.152 1.089 4.152 2.955 3.009 4.063 1.107q1.482 0 2.723-0.411t2.045-1.027 1.402-1.402 0.875-1.482 0.384-1.321h-7.429v-4.5h12.357q0.214 1.125 0.214 2.179zM41.143 14.125v3.75h-3.732v3.732h-3.75v-3.732h-3.732v-3.75h3.732v-3.732h3.75v3.732h3.732z"></path>
</symbol>
<symbol id="icon-linkedin" viewBox="0 0 27 32">
<path class="path1" d="M6.232 11.161v17.696h-5.893v-17.696h5.893zM6.607 5.696q0.018 1.304-0.902 2.179t-2.42 0.875h-0.036q-1.464 0-2.357-0.875t-0.893-2.179q0-1.321 0.92-2.188t2.402-0.866 2.375 0.866 0.911 2.188zM27.429 18.714v10.143h-5.875v-9.464q0-1.875-0.723-2.938t-2.259-1.063q-1.125 0-1.884 0.616t-1.134 1.527q-0.196 0.536-0.196 1.446v9.875h-5.875q0.036-7.125 0.036-11.554t-0.018-5.286l-0.018-0.857h5.875v2.571h-0.036q0.357-0.571 0.732-1t1.009-0.929 1.554-0.777 2.045-0.277q3.054 0 4.911 2.027t1.857 5.938z"></path>
</symbol>
<symbol id="icon-quote-right" viewBox="0 0 30 32">
<path class="path1" d="M13.714 5.714v12.571q0 1.857-0.723 3.545t-1.955 2.92-2.92 1.955-3.545 0.723h-1.143q-0.464 0-0.804-0.339t-0.339-0.804v-2.286q0-0.464 0.339-0.804t0.804-0.339h1.143q1.893 0 3.232-1.339t1.339-3.232v-0.571q0-0.714-0.5-1.214t-1.214-0.5h-4q-1.429 0-2.429-1t-1-2.429v-6.857q0-1.429 1-2.429t2.429-1h6.857q1.429 0 2.429 1t1 2.429zM29.714 5.714v12.571q0 1.857-0.723 3.545t-1.955 2.92-2.92 1.955-3.545 0.723h-1.143q-0.464 0-0.804-0.339t-0.339-0.804v-2.286q0-0.464 0.339-0.804t0.804-0.339h1.143q1.893 0 3.232-1.339t1.339-3.232v-0.571q0-0.714-0.5-1.214t-1.214-0.5h-4q-1.429 0-2.429-1t-1-2.429v-6.857q0-1.429 1-2.429t2.429-1h6.857q1.429 0 2.429 1t1 2.429z"></path>
</symbol>
<symbol id="icon-mail-reply" viewBox="0 0 32 32">
<path class="path1" d="M32 20q0 2.964-2.268 8.054-0.054 0.125-0.188 0.429t-0.241 0.536-0.232 0.393q-0.214 0.304-0.5 0.304-0.268 0-0.42-0.179t-0.152-0.446q0-0.161 0.045-0.473t0.045-0.42q0.089-1.214 0.089-2.196 0-1.804-0.313-3.232t-0.866-2.473-1.429-1.804-1.884-1.241-2.375-0.759-2.75-0.384-3.134-0.107h-4v4.571q0 0.464-0.339 0.804t-0.804 0.339-0.804-0.339l-9.143-9.143q-0.339-0.339-0.339-0.804t0.339-0.804l9.143-9.143q0.339-0.339 0.804-0.339t0.804 0.339 0.339 0.804v4.571h4q12.732 0 15.625 7.196 0.946 2.393 0.946 5.946z"></path>
</symbol>
<symbol id="icon-youtube" viewBox="0 0 27 32">
<path class="path1" d="M17.339 22.214v3.768q0 1.196-0.696 1.196-0.411 0-0.804-0.393v-5.375q0.393-0.393 0.804-0.393 0.696 0 0.696 1.196zM23.375 22.232v0.821h-1.607v-0.821q0-1.214 0.804-1.214t0.804 1.214zM6.125 18.339h1.911v-1.679h-5.571v1.679h1.875v10.161h1.786v-10.161zM11.268 28.5h1.589v-8.821h-1.589v6.75q-0.536 0.75-1.018 0.75-0.321 0-0.375-0.375-0.018-0.054-0.018-0.625v-6.5h-1.589v6.982q0 0.875 0.143 1.304 0.214 0.661 1.036 0.661 0.857 0 1.821-1.089v0.964zM18.929 25.857v-3.518q0-1.304-0.161-1.768-0.304-1-1.268-1-0.893 0-1.661 0.964v-3.875h-1.589v11.839h1.589v-0.857q0.804 0.982 1.661 0.982 0.964 0 1.268-0.982 0.161-0.482 0.161-1.786zM24.964 25.679v-0.232h-1.625q0 0.911-0.036 1.089-0.125 0.643-0.714 0.643-0.821 0-0.821-1.232v-1.554h3.196v-1.839q0-1.411-0.482-2.071-0.696-0.911-1.893-0.911-1.214 0-1.911 0.911-0.5 0.661-0.5 2.071v3.089q0 1.411 0.518 2.071 0.696 0.911 1.929 0.911 1.286 0 1.929-0.946 0.321-0.482 0.375-0.964 0.036-0.161 0.036-1.036zM14.107 9.375v-3.75q0-1.232-0.768-1.232t-0.768 1.232v3.75q0 1.25 0.768 1.25t0.768-1.25zM26.946 22.786q0 4.179-0.464 6.25-0.25 1.054-1.036 1.768t-1.821 0.821q-3.286 0.375-9.911 0.375t-9.911-0.375q-1.036-0.107-1.83-0.821t-1.027-1.768q-0.464-2-0.464-6.25 0-4.179 0.464-6.25 0.25-1.054 1.036-1.768t1.839-0.839q3.268-0.357 9.893-0.357t9.911 0.357q1.036 0.125 1.83 0.839t1.027 1.768q0.464 2 0.464 6.25zM9.125 0h1.821l-2.161 7.125v4.839h-1.786v-4.839q-0.25-1.321-1.089-3.786-0.661-1.839-1.161-3.339h1.893l1.268 4.696zM15.732 5.946v3.125q0 1.446-0.5 2.107-0.661 0.911-1.893 0.911-1.196 0-1.875-0.911-0.5-0.679-0.5-2.107v-3.125q0-1.429 0.5-2.089 0.679-0.911 1.875-0.911 1.232 0 1.893 0.911 0.5 0.661 0.5 2.089zM21.714 3.054v8.911h-1.625v-0.982q-0.946 1.107-1.839 1.107-0.821 0-1.054-0.661-0.143-0.429-0.143-1.339v-7.036h1.625v6.554q0 0.589 0.018 0.625 0.054 0.393 0.375 0.393 0.482 0 1.018-0.768v-6.804h1.625z"></path>
</symbol>
<symbol id="icon-dropbox" viewBox="0 0 32 32">
<path class="path1" d="M7.179 12.625l8.821 5.446-6.107 5.089-8.75-5.696zM24.786 22.536v1.929l-8.75 5.232v0.018l-0.018-0.018-0.018 0.018v-0.018l-8.732-5.232v-1.929l2.625 1.714 6.107-5.071v-0.036l0.018 0.018 0.018-0.018v0.036l6.125 5.071zM9.893 2.107l6.107 5.089-8.821 5.429-6.036-4.821zM24.821 12.625l6.036 4.839-8.732 5.696-6.125-5.089zM22.125 2.107l8.732 5.696-6.036 4.821-8.821-5.429z"></path>
</symbol>
<symbol id="icon-instagram" viewBox="0 0 27 32">
<path class="path1" d="M18.286 16q0-1.893-1.339-3.232t-3.232-1.339-3.232 1.339-1.339 3.232 1.339 3.232 3.232 1.339 3.232-1.339 1.339-3.232zM20.75 16q0 2.929-2.054 4.982t-4.982 2.054-4.982-2.054-2.054-4.982 2.054-4.982 4.982-2.054 4.982 2.054 2.054 4.982zM22.679 8.679q0 0.679-0.482 1.161t-1.161 0.482-1.161-0.482-0.482-1.161 0.482-1.161 1.161-0.482 1.161 0.482 0.482 1.161zM13.714 4.75q-0.125 0-1.366-0.009t-1.884 0-1.723 0.054-1.839 0.179-1.277 0.33q-0.893 0.357-1.571 1.036t-1.036 1.571q-0.196 0.518-0.33 1.277t-0.179 1.839-0.054 1.723 0 1.884 0.009 1.366-0.009 1.366 0 1.884 0.054 1.723 0.179 1.839 0.33 1.277q0.357 0.893 1.036 1.571t1.571 1.036q0.518 0.196 1.277 0.33t1.839 0.179 1.723 0.054 1.884 0 1.366-0.009 1.366 0.009 1.884 0 1.723-0.054 1.839-0.179 1.277-0.33q0.893-0.357 1.571-1.036t1.036-1.571q0.196-0.518 0.33-1.277t0.179-1.839 0.054-1.723 0-1.884-0.009-1.366 0.009-1.366 0-1.884-0.054-1.723-0.179-1.839-0.33-1.277q-0.357-0.893-1.036-1.571t-1.571-1.036q-0.518-0.196-1.277-0.33t-1.839-0.179-1.723-0.054-1.884 0-1.366 0.009zM27.429 16q0 4.089-0.089 5.661-0.179 3.714-2.214 5.75t-5.75 2.214q-1.571 0.089-5.661 0.089t-5.661-0.089q-3.714-0.179-5.75-2.214t-2.214-5.75q-0.089-1.571-0.089-5.661t0.089-5.661q0.179-3.714 2.214-5.75t5.75-2.214q1.571-0.089 5.661-0.089t5.661 0.089q3.714 0.179 5.75 2.214t2.214 5.75q0.089 1.571 0.089 5.661z"></path>
</symbol>
<symbol id="icon-flickr" viewBox="0 0 27 32">
<path class="path1" d="M22.286 2.286q2.125 0 3.634 1.509t1.509 3.634v17.143q0 2.125-1.509 3.634t-3.634 1.509h-17.143q-2.125 0-3.634-1.509t-1.509-3.634v-17.143q0-2.125 1.509-3.634t3.634-1.509h17.143zM12.464 16q0-1.571-1.107-2.679t-2.679-1.107-2.679 1.107-1.107 2.679 1.107 2.679 2.679 1.107 2.679-1.107 1.107-2.679zM22.536 16q0-1.571-1.107-2.679t-2.679-1.107-2.679 1.107-1.107 2.679 1.107 2.679 2.679 1.107 2.679-1.107 1.107-2.679z"></path>
</symbol>
<symbol id="icon-tumblr" viewBox="0 0 19 32">
<path class="path1" d="M16.857 23.732l1.429 4.232q-0.411 0.625-1.982 1.179t-3.161 0.571q-1.857 0.036-3.402-0.464t-2.545-1.321-1.696-1.893-0.991-2.143-0.295-2.107v-9.714h-3v-3.839q1.286-0.464 2.304-1.241t1.625-1.607 1.036-1.821 0.607-1.768 0.268-1.58q0.018-0.089 0.080-0.152t0.134-0.063h4.357v7.571h5.946v4.5h-5.964v9.25q0 0.536 0.116 1t0.402 0.938 0.884 0.741 1.455 0.25q1.393-0.036 2.393-0.518z"></path>
</symbol>
<symbol id="icon-dockerhub" viewBox="0 0 24 28">
<path class="path1" d="M1.597 10.257h2.911v2.83H1.597v-2.83zm3.573 0h2.91v2.83H5.17v-2.83zm0-3.627h2.91v2.829H5.17V6.63zm3.57 3.627h2.912v2.83H8.74v-2.83zm0-3.627h2.912v2.829H8.74V6.63zm3.573 3.627h2.911v2.83h-2.911v-2.83zm0-3.627h2.911v2.829h-2.911V6.63zm3.572 3.627h2.911v2.83h-2.911v-2.83zM12.313 3h2.911v2.83h-2.911V3zm-6.65 14.173c-.449 0-.812.354-.812.788 0 .435.364.788.812.788.447 0 .811-.353.811-.788 0-.434-.363-.788-.811-.788"></path>
<path class="path2" d="M28.172 11.721c-.978-.549-2.278-.624-3.388-.306-.136-1.146-.91-2.149-1.83-2.869l-.366-.286-.307.345c-.618.692-.8 1.845-.718 2.73.063.651.273 1.312.685 1.834-.313.183-.668.328-.985.434-.646.212-1.347.33-2.028.33H.083l-.042.429c-.137 1.432.065 2.866.674 4.173l.262.519.03.048c1.8 2.973 4.963 4.225 8.41 4.225 6.672 0 12.174-2.896 14.702-9.015 1.689.085 3.417-.4 4.243-1.968l.211-.4-.401-.223zM5.664 19.458c-.85 0-1.542-.671-1.542-1.497 0-.825.691-1.498 1.541-1.498.849 0 1.54.672 1.54 1.497s-.69 1.498-1.539 1.498z"></path>
</symbol>
<symbol id="icon-dribbble" viewBox="0 0 27 32">
<path class="path1" d="M18.286 26.786q-0.75-4.304-2.5-8.893h-0.036l-0.036 0.018q-0.286 0.107-0.768 0.295t-1.804 0.875-2.446 1.464-2.339 2.045-1.839 2.643l-0.268-0.196q3.286 2.679 7.464 2.679 2.357 0 4.571-0.929zM14.982 15.946q-0.375-0.875-0.946-1.982-5.554 1.661-12.018 1.661-0.018 0.125-0.018 0.375 0 2.214 0.786 4.223t2.214 3.598q0.893-1.589 2.205-2.973t2.545-2.223 2.33-1.446 1.777-0.857l0.661-0.232q0.071-0.018 0.232-0.063t0.232-0.080zM13.071 12.161q-2.143-3.804-4.357-6.75-2.464 1.161-4.179 3.321t-2.286 4.857q5.393 0 10.821-1.429zM25.286 17.857q-3.75-1.071-7.304-0.518 1.554 4.268 2.286 8.375 1.982-1.339 3.304-3.384t1.714-4.473zM10.911 4.625q-0.018 0-0.036 0.018 0.018-0.018 0.036-0.018zM21.446 7.214q-3.304-2.929-7.732-2.929-1.357 0-2.768 0.339 2.339 3.036 4.393 6.821 1.232-0.464 2.321-1.080t1.723-1.098 1.17-1.018 0.67-0.723zM25.429 15.875q-0.054-4.143-2.661-7.321l-0.018 0.018q-0.161 0.214-0.339 0.438t-0.777 0.795-1.268 1.080-1.786 1.161-2.348 1.152q0.446 0.946 0.786 1.696 0.036 0.107 0.116 0.313t0.134 0.295q0.643-0.089 1.33-0.125t1.313-0.036 1.232 0.027 1.143 0.071 1.009 0.098 0.857 0.116 0.652 0.107 0.446 0.080zM27.429 16q0 3.732-1.839 6.884t-4.991 4.991-6.884 1.839-6.884-1.839-4.991-4.991-1.839-6.884 1.839-6.884 4.991-4.991 6.884-1.839 6.884 1.839 4.991 4.991 1.839 6.884z"></path>
</symbol>
<symbol id="icon-skype" viewBox="0 0 27 32">
<path class="path1" d="M20.946 18.982q0-0.893-0.348-1.634t-0.866-1.223-1.304-0.875-1.473-0.607-1.563-0.411l-1.857-0.429q-0.536-0.125-0.786-0.188t-0.625-0.205-0.536-0.286-0.295-0.375-0.134-0.536q0-1.375 2.571-1.375 0.768 0 1.375 0.214t0.964 0.509 0.679 0.598 0.714 0.518 0.857 0.214q0.839 0 1.348-0.571t0.509-1.375q0-0.982-1-1.777t-2.536-1.205-3.25-0.411q-1.214 0-2.357 0.277t-2.134 0.839-1.589 1.554-0.598 2.295q0 1.089 0.339 1.902t1 1.348 1.429 0.866 1.839 0.58l2.607 0.643q1.607 0.393 2 0.643 0.571 0.357 0.571 1.071 0 0.696-0.714 1.152t-1.875 0.455q-0.911 0-1.634-0.286t-1.161-0.688-0.813-0.804-0.821-0.688-0.964-0.286q-0.893 0-1.348 0.536t-0.455 1.339q0 1.643 2.179 2.813t5.196 1.17q1.304 0 2.5-0.33t2.188-0.955 1.58-1.67 0.589-2.348zM27.429 22.857q0 2.839-2.009 4.848t-4.848 2.009q-2.321 0-4.179-1.429-1.375 0.286-2.679 0.286-2.554 0-4.884-0.991t-4.018-2.679-2.679-4.018-0.991-4.884q0-1.304 0.286-2.679-1.429-1.857-1.429-4.179 0-2.839 2.009-4.848t4.848-2.009q2.321 0 4.179 1.429 1.375-0.286 2.679-0.286 2.554 0 4.884 0.991t4.018 2.679 2.679 4.018 0.991 4.884q0 1.304-0.286 2.679 1.429 1.857 1.429 4.179z"></path>
</symbol>
<symbol id="icon-foursquare" viewBox="0 0 23 32">
<path class="path1" d="M17.857 7.75l0.661-3.464q0.089-0.411-0.161-0.714t-0.625-0.304h-12.714q-0.411 0-0.688 0.304t-0.277 0.661v19.661q0 0.125 0.107 0.018l5.196-6.286q0.411-0.464 0.679-0.598t0.857-0.134h4.268q0.393 0 0.661-0.259t0.321-0.527q0.429-2.321 0.661-3.411 0.071-0.375-0.205-0.714t-0.652-0.339h-5.25q-0.518 0-0.857-0.339t-0.339-0.857v-0.75q0-0.518 0.339-0.848t0.857-0.33h6.179q0.321 0 0.625-0.241t0.357-0.527zM21.911 3.786q-0.268 1.304-0.955 4.759t-1.241 6.25-0.625 3.098q-0.107 0.393-0.161 0.58t-0.25 0.58-0.438 0.589-0.688 0.375-1.036 0.179h-4.839q-0.232 0-0.393 0.179-0.143 0.161-7.607 8.821-0.393 0.446-1.045 0.509t-0.866-0.098q-0.982-0.393-0.982-1.75v-25.179q0-0.982 0.679-1.83t2.143-0.848h15.857q1.696 0 2.268 0.946t0.179 2.839zM21.911 3.786l-2.821 14.107q0.071-0.304 0.625-3.098t1.241-6.25 0.955-4.759z"></path>
</symbol>
<symbol id="icon-wordpress" viewBox="0 0 32 32">
<path class="path1" d="M2.268 16q0-2.911 1.196-5.589l6.554 17.946q-3.5-1.696-5.625-5.018t-2.125-7.339zM25.268 15.304q0 0.339-0.045 0.688t-0.179 0.884-0.205 0.786-0.313 1.054-0.313 1.036l-1.357 4.571-4.964-14.75q0.821-0.054 1.571-0.143 0.339-0.036 0.464-0.33t-0.045-0.554-0.509-0.241l-3.661 0.179q-1.339-0.018-3.607-0.179-0.214-0.018-0.366 0.089t-0.205 0.268-0.027 0.33 0.161 0.295 0.348 0.143l1.429 0.143 2.143 5.857-3 9-5-14.857q0.821-0.054 1.571-0.143 0.339-0.036 0.464-0.33t-0.045-0.554-0.509-0.241l-3.661 0.179q-0.125 0-0.411-0.009t-0.464-0.009q1.875-2.857 4.902-4.527t6.563-1.67q2.625 0 5.009 0.946t4.259 2.661h-0.179q-0.982 0-1.643 0.723t-0.661 1.705q0 0.214 0.036 0.429t0.071 0.384 0.143 0.411 0.161 0.375 0.214 0.402 0.223 0.375 0.259 0.429 0.25 0.411q1.125 1.911 1.125 3.786zM16.232 17.196l4.232 11.554q0.018 0.107 0.089 0.196-2.25 0.786-4.554 0.786-2 0-3.875-0.571zM28.036 9.411q1.696 3.107 1.696 6.589 0 3.732-1.857 6.884t-4.982 4.973l4.196-12.107q1.054-3.018 1.054-4.929 0-0.75-0.107-1.411zM16 0q3.25 0 6.214 1.268t5.107 3.411 3.411 5.107 1.268 6.214-1.268 6.214-3.411 5.107-5.107 3.411-6.214 1.268-6.214-1.268-5.107-3.411-3.411-5.107-1.268-6.214 1.268-6.214 3.411-5.107 5.107-3.411 6.214-1.268zM16 31.268q3.089 0 5.92-1.214t4.875-3.259 3.259-4.875 1.214-5.92-1.214-5.92-3.259-4.875-4.875-3.259-5.92-1.214-5.92 1.214-4.875 3.259-3.259 4.875-1.214 5.92 1.214 5.92 3.259 4.875 4.875 3.259 5.92 1.214z"></path>
</symbol>
<symbol id="icon-stumbleupon" viewBox="0 0 34 32">
<path class="path1" d="M18.964 12.714v-2.107q0-0.75-0.536-1.286t-1.286-0.536-1.286 0.536-0.536 1.286v10.929q0 3.125-2.25 5.339t-5.411 2.214q-3.179 0-5.42-2.241t-2.241-5.42v-4.75h5.857v4.679q0 0.768 0.536 1.295t1.286 0.527 1.286-0.527 0.536-1.295v-11.071q0-3.054 2.259-5.214t5.384-2.161q3.143 0 5.393 2.179t2.25 5.25v2.429l-3.482 1.036zM28.429 16.679h5.857v4.75q0 3.179-2.241 5.42t-5.42 2.241q-3.161 0-5.411-2.223t-2.25-5.366v-4.786l2.339 1.089 3.482-1.036v4.821q0 0.75 0.536 1.277t1.286 0.527 1.286-0.527 0.536-1.277v-4.911z"></path>
</symbol>
<symbol id="icon-digg" viewBox="0 0 37 32">
<path class="path1" d="M5.857 5.036h3.643v17.554h-9.5v-12.446h5.857v-5.107zM5.857 19.661v-6.589h-2.196v6.589h2.196zM10.964 10.143v12.446h3.661v-12.446h-3.661zM10.964 5.036v3.643h3.661v-3.643h-3.661zM16.089 10.143h9.518v16.821h-9.518v-2.911h5.857v-1.464h-5.857v-12.446zM21.946 19.661v-6.589h-2.196v6.589h2.196zM27.071 10.143h9.5v16.821h-9.5v-2.911h5.839v-1.464h-5.839v-12.446zM32.911 19.661v-6.589h-2.196v6.589h2.196z"></path>
</symbol>
<symbol id="icon-spotify" viewBox="0 0 27 32">
<path class="path1" d="M20.125 21.607q0-0.571-0.536-0.911-3.446-2.054-7.982-2.054-2.375 0-5.125 0.607-0.75 0.161-0.75 0.929 0 0.357 0.241 0.616t0.634 0.259q0.089 0 0.661-0.143 2.357-0.482 4.339-0.482 4.036 0 7.089 1.839 0.339 0.196 0.589 0.196 0.339 0 0.589-0.241t0.25-0.616zM21.839 17.768q0-0.714-0.625-1.089-4.232-2.518-9.786-2.518-2.732 0-5.411 0.75-0.857 0.232-0.857 1.143 0 0.446 0.313 0.759t0.759 0.313q0.125 0 0.661-0.143 2.179-0.589 4.482-0.589 4.982 0 8.714 2.214 0.429 0.232 0.679 0.232 0.446 0 0.759-0.313t0.313-0.759zM23.768 13.339q0-0.839-0.714-1.25-2.25-1.304-5.232-1.973t-6.125-0.67q-3.643 0-6.5 0.839-0.411 0.125-0.688 0.455t-0.277 0.866q0 0.554 0.366 0.929t0.92 0.375q0.196 0 0.714-0.143 2.375-0.661 5.482-0.661 2.839 0 5.527 0.607t4.527 1.696q0.375 0.214 0.714 0.214 0.518 0 0.902-0.366t0.384-0.92zM27.429 16q0 3.732-1.839 6.884t-4.991 4.991-6.884 1.839-6.884-1.839-4.991-4.991-1.839-6.884 1.839-6.884 4.991-4.991 6.884-1.839 6.884 1.839 4.991 4.991 1.839 6.884z"></path>
</symbol>
<symbol id="icon-soundcloud" viewBox="0 0 41 32">
<path class="path1" d="M14 24.5l0.286-4.304-0.286-9.339q-0.018-0.179-0.134-0.304t-0.295-0.125q-0.161 0-0.286 0.125t-0.125 0.304l-0.25 9.339 0.25 4.304q0.018 0.179 0.134 0.295t0.277 0.116q0.393 0 0.429-0.411zM19.286 23.982l0.196-3.768-0.214-10.464q0-0.286-0.232-0.429-0.143-0.089-0.286-0.089t-0.286 0.089q-0.232 0.143-0.232 0.429l-0.018 0.107-0.179 10.339q0 0.018 0.196 4.214v0.018q0 0.179 0.107 0.304 0.161 0.196 0.411 0.196 0.196 0 0.357-0.161 0.161-0.125 0.161-0.357zM0.625 17.911l0.357 2.286-0.357 2.25q-0.036 0.161-0.161 0.161t-0.161-0.161l-0.304-2.25 0.304-2.286q0.036-0.161 0.161-0.161t0.161 0.161zM2.161 16.5l0.464 3.696-0.464 3.625q-0.036 0.161-0.179 0.161-0.161 0-0.161-0.179l-0.411-3.607 0.411-3.696q0-0.161 0.161-0.161 0.143 0 0.179 0.161zM3.804 15.821l0.446 4.375-0.446 4.232q0 0.196-0.196 0.196-0.179 0-0.214-0.196l-0.375-4.232 0.375-4.375q0.036-0.214 0.214-0.214 0.196 0 0.196 0.214zM5.482 15.696l0.411 4.5-0.411 4.357q-0.036 0.232-0.25 0.232-0.232 0-0.232-0.232l-0.375-4.357 0.375-4.5q0-0.232 0.232-0.232 0.214 0 0.25 0.232zM7.161 16.018l0.375 4.179-0.375 4.393q-0.036 0.286-0.286 0.286-0.107 0-0.188-0.080t-0.080-0.205l-0.357-4.393 0.357-4.179q0-0.107 0.080-0.188t0.188-0.080q0.25 0 0.286 0.268zM8.839 13.411l0.375 6.786-0.375 4.393q0 0.125-0.089 0.223t-0.214 0.098q-0.286 0-0.321-0.321l-0.321-4.393 0.321-6.786q0.036-0.321 0.321-0.321 0.125 0 0.214 0.098t0.089 0.223zM10.518 11.875l0.339 8.357-0.339 4.357q0 0.143-0.098 0.241t-0.241 0.098q-0.321 0-0.357-0.339l-0.286-4.357 0.286-8.357q0.036-0.339 0.357-0.339 0.143 0 0.241 0.098t0.098 0.241zM12.268 11.161l0.321 9.036-0.321 4.321q-0.036 0.375-0.393 0.375-0.339 0-0.375-0.375l-0.286-4.321 0.286-9.036q0-0.161 0.116-0.277t0.259-0.116q0.161 0 0.268 0.116t0.125 0.277zM19.268 24.411v0 0zM15.732 11.089l0.268 9.107-0.268 4.268q0 0.179-0.134 0.313t-0.313 0.134-0.304-0.125-0.143-0.321l-0.25-4.268 0.25-9.107q0-0.196 0.134-0.321t0.313-0.125 0.313 0.125 0.134 0.321zM17.5 11.429l0.25 8.786-0.25 4.214q0 0.196-0.143 0.339t-0.339 0.143-0.339-0.143-0.161-0.339l-0.214-4.214 0.214-8.786q0.018-0.214 0.161-0.357t0.339-0.143 0.33 0.143 0.152 0.357zM21.286 20.214l-0.25 4.125q0 0.232-0.161 0.393t-0.393 0.161-0.393-0.161-0.179-0.393l-0.107-2.036-0.107-2.089 0.214-11.357v-0.054q0.036-0.268 0.214-0.429 0.161-0.125 0.357-0.125 0.143 0 0.268 0.089 0.25 0.143 0.286 0.464zM41.143 19.875q0 2.089-1.482 3.563t-3.571 1.473h-14.036q-0.232-0.036-0.393-0.196t-0.161-0.393v-16.054q0-0.411 0.5-0.589 1.518-0.607 3.232-0.607 3.482 0 6.036 2.348t2.857 5.777q0.946-0.393 1.964-0.393 2.089 0 3.571 1.482t1.482 3.589z"></path>
</symbol>
<symbol id="icon-codepen" viewBox="0 0 32 32">
<path class="path1" d="M3.857 20.875l10.768 7.179v-6.411l-5.964-3.982zM2.75 18.304l3.446-2.304-3.446-2.304v4.607zM17.375 28.054l10.768-7.179-4.804-3.214-5.964 3.982v6.411zM16 19.25l4.857-3.25-4.857-3.25-4.857 3.25zM8.661 14.339l5.964-3.982v-6.411l-10.768 7.179zM25.804 16l3.446 2.304v-4.607zM23.339 14.339l4.804-3.214-10.768-7.179v6.411zM32 11.125v9.75q0 0.732-0.607 1.143l-14.625 9.75q-0.375 0.232-0.768 0.232t-0.768-0.232l-14.625-9.75q-0.607-0.411-0.607-1.143v-9.75q0-0.732 0.607-1.143l14.625-9.75q0.375-0.232 0.768-0.232t0.768 0.232l14.625 9.75q0.607 0.411 0.607 1.143z"></path>
</symbol>
<symbol id="icon-twitch" viewBox="0 0 32 32">
<path class="path1" d="M16 7.75v7.75h-2.589v-7.75h2.589zM23.107 7.75v7.75h-2.589v-7.75h2.589zM23.107 21.321l4.518-4.536v-14.196h-21.321v18.732h5.821v3.875l3.875-3.875h7.107zM30.214 0v18.089l-7.75 7.75h-5.821l-3.875 3.875h-3.875v-3.875h-7.107v-20.679l1.946-5.161h26.482z"></path>
</symbol>
<symbol id="icon-meanpath" viewBox="0 0 27 32">
<path class="path1" d="M23.411 15.036v2.036q0 0.429-0.241 0.679t-0.67 0.25h-3.607q-0.429 0-0.679-0.25t-0.25-0.679v-2.036q0-0.429 0.25-0.679t0.679-0.25h3.607q0.429 0 0.67 0.25t0.241 0.679zM14.661 19.143v-4.464q0-0.946-0.58-1.527t-1.527-0.58h-2.375q-1.214 0-1.714 0.929-0.5-0.929-1.714-0.929h-2.321q-0.946 0-1.527 0.58t-0.58 1.527v4.464q0 0.393 0.375 0.393h0.982q0.393 0 0.393-0.393v-4.107q0-0.429 0.241-0.679t0.688-0.25h1.679q0.429 0 0.679 0.25t0.25 0.679v4.107q0 0.393 0.375 0.393h0.964q0.393 0 0.393-0.393v-4.107q0-0.429 0.25-0.679t0.679-0.25h1.732q0.429 0 0.67 0.25t0.241 0.679v4.107q0 0.393 0.393 0.393h0.982q0.375 0 0.375-0.393zM25.179 17.429v-2.75q0-0.946-0.589-1.527t-1.536-0.58h-4.714q-0.946 0-1.536 0.58t-0.589 1.527v7.321q0 0.375 0.393 0.375h0.982q0.375 0 0.375-0.375v-3.214q0.554 0.75 1.679 0.75h3.411q0.946 0 1.536-0.58t0.589-1.527zM27.429 6.429v19.143q0 1.714-1.214 2.929t-2.929 1.214h-19.143q-1.714 0-2.929-1.214t-1.214-2.929v-19.143q0-1.714 1.214-2.929t2.929-1.214h19.143q1.714 0 2.929 1.214t1.214 2.929z"></path>
</symbol>
<symbol id="icon-pinterest-p" viewBox="0 0 23 32">
<path class="path1" d="M0 10.661q0-1.929 0.67-3.634t1.848-2.973 2.714-2.196 3.304-1.393 3.607-0.464q2.821 0 5.25 1.188t3.946 3.455 1.518 5.125q0 1.714-0.339 3.357t-1.071 3.161-1.786 2.67-2.589 1.839-3.375 0.688q-1.214 0-2.411-0.571t-1.714-1.571q-0.179 0.696-0.5 2.009t-0.42 1.696-0.366 1.268-0.464 1.268-0.571 1.116-0.821 1.384-1.107 1.545l-0.25 0.089-0.161-0.179q-0.268-2.804-0.268-3.357 0-1.643 0.384-3.688t1.188-5.134 0.929-3.625q-0.571-1.161-0.571-3.018 0-1.482 0.929-2.786t2.357-1.304q1.089 0 1.696 0.723t0.607 1.83q0 1.179-0.786 3.411t-0.786 3.339q0 1.125 0.804 1.866t1.946 0.741q0.982 0 1.821-0.446t1.402-1.214 1-1.696 0.679-1.973 0.357-1.982 0.116-1.777q0-3.089-1.955-4.813t-5.098-1.723q-3.571 0-5.964 2.313t-2.393 5.866q0 0.786 0.223 1.518t0.482 1.161 0.482 0.813 0.223 0.545q0 0.5-0.268 1.304t-0.661 0.804q-0.036 0-0.304-0.054-0.911-0.268-1.616-1t-1.089-1.688-0.58-1.929-0.196-1.902z"></path>
</symbol>
<symbol id="icon-periscope" viewBox="0 0 24 28">
<path class="path1" d="M12.285,1C6.696,1,2.277,5.643,2.277,11.243c0,5.851,7.77,14.578,10.007,14.578c1.959,0,9.729-8.728,9.729-14.578 C22.015,5.643,17.596,1,12.285,1z M12.317,16.551c-3.473,0-6.152-2.611-6.152-5.664c0-1.292,0.39-2.472,1.065-3.438 c0.206,1.084,1.18,1.906,2.352,1.906c1.322,0,2.393-1.043,2.393-2.333c0-0.832-0.447-1.561-1.119-1.975 c0.467-0.105,0.955-0.161,1.46-0.161c3.133,0,5.81,2.611,5.81,5.998C18.126,13.94,15.449,16.551,12.317,16.551z"></path>
</symbol>
<symbol id="icon-get-pocket" viewBox="0 0 31 32">
<path class="path1" d="M27.946 2.286q1.161 0 1.964 0.813t0.804 1.973v9.268q0 3.143-1.214 6t-3.259 4.911-4.893 3.259-5.973 1.205q-3.143 0-5.991-1.205t-4.902-3.259-3.268-4.911-1.214-6v-9.268q0-1.143 0.821-1.964t1.964-0.821h25.161zM15.375 21.286q0.839 0 1.464-0.589l7.214-6.929q0.661-0.625 0.661-1.518 0-0.875-0.616-1.491t-1.491-0.616q-0.839 0-1.464 0.589l-5.768 5.536-5.768-5.536q-0.625-0.589-1.446-0.589-0.875 0-1.491 0.616t-0.616 1.491q0 0.911 0.643 1.518l7.232 6.929q0.589 0.589 1.446 0.589z"></path>
</symbol>
<symbol id="icon-vimeo" viewBox="0 0 32 32">
<path class="path1" d="M30.518 9.25q-0.179 4.214-5.929 11.625-5.946 7.696-10.036 7.696-2.536 0-4.286-4.696-0.786-2.857-2.357-8.607-1.286-4.679-2.804-4.679-0.321 0-2.268 1.357l-1.375-1.75q0.429-0.375 1.929-1.723t2.321-2.063q2.786-2.464 4.304-2.607 1.696-0.161 2.732 0.991t1.446 3.634q0.786 5.125 1.179 6.661 0.982 4.446 2.143 4.446 0.911 0 2.75-2.875 1.804-2.875 1.946-4.393 0.232-2.482-1.946-2.482-1.018 0-2.161 0.464 2.143-7.018 8.196-6.821 4.482 0.143 4.214 5.821z"></path>
</symbol>
<symbol id="icon-reddit-alien" viewBox="0 0 32 32">
<path class="path1" d="M32 15.107q0 1.036-0.527 1.884t-1.42 1.295q0.214 0.821 0.214 1.714 0 2.768-1.902 5.125t-5.188 3.723-7.143 1.366-7.134-1.366-5.179-3.723-1.902-5.125q0-0.839 0.196-1.679-0.911-0.446-1.464-1.313t-0.554-1.902q0-1.464 1.036-2.509t2.518-1.045q1.518 0 2.589 1.125 3.893-2.714 9.196-2.893l2.071-9.304q0.054-0.232 0.268-0.375t0.464-0.089l6.589 1.446q0.321-0.661 0.964-1.063t1.411-0.402q1.107 0 1.893 0.777t0.786 1.884-0.786 1.893-1.893 0.786-1.884-0.777-0.777-1.884l-5.964-1.321-1.857 8.429q5.357 0.161 9.268 2.857 1.036-1.089 2.554-1.089 1.482 0 2.518 1.045t1.036 2.509zM7.464 18.661q0 1.107 0.777 1.893t1.884 0.786 1.893-0.786 0.786-1.893-0.786-1.884-1.893-0.777q-1.089 0-1.875 0.786t-0.786 1.875zM21.929 25q0.196-0.196 0.196-0.464t-0.196-0.464q-0.179-0.179-0.446-0.179t-0.464 0.179q-0.732 0.75-2.161 1.107t-2.857 0.357-2.857-0.357-2.161-1.107q-0.196-0.179-0.464-0.179t-0.446 0.179q-0.196 0.179-0.196 0.455t0.196 0.473q0.768 0.768 2.116 1.214t2.188 0.527 1.625 0.080 1.625-0.080 2.188-0.527 2.116-1.214zM21.875 21.339q1.107 0 1.884-0.786t0.777-1.893q0-1.089-0.786-1.875t-1.875-0.786q-1.107 0-1.893 0.777t-0.786 1.884 0.786 1.893 1.893 0.786z"></path>
</symbol>
<symbol id="icon-whatsapp" viewBox="0 0 32 32">
<path d="M15.968 2.003a14.03 13.978 0 0 0-14.03 13.978 14.03 13.978 0 0 0 2.132 7.391L1.938 29.96l6.745-2.052a14.03 13.978 0 0 0 7.285 2.052 14.03 13.978 0 0 0 14.03-13.978 14.03 13.978 0 0 0-14.03-13.978z" stroke-width=".2000562"/>
<path d="M10.454 8.236a2.57 3.401 51.533 0 0-1.475 3.184v.015c.01 2.04 4.045 10.076 10.017 12.688l.017-.013a2.57 3.401 51.533 0 0 3.454-.706 2.57 3.401 51.533 0 0 1.064-4.129 2.57 3.401 51.533 0 0-4.262.103 2.57 3.401 51.533 0 0-.505.473c-1.346-.639-2.952-1.463-4.168-2.98-.771-.962-1.257-2.732-1.549-4.206a2.57 3.401 51.533 0 0 .605-.403 2.57 3.401 51.533 0 0 1.064-4.129 2.57 3.401 51.533 0 0-4.262.103z" stroke-width=".372"/>
</symbol>
<symbol id="icon-telegram" viewBox="0 0 32 32">
<path d="M30.8,2.2L0.6,13.9c-0.8,0.3-0.7,1.3,0,1.6l7.4,2.8l2.9,9.2c0.2,0.6,0.9,0.8,1.4,0.4l4.1-3.4 c0.4-0.4,1-0.4,1.5,0l7.4,5.4c0.5,0.4,1.2,0.1,1.4-0.5L32,3.2C32.1,2.5,31.4,1.9,30.8,2.2z M25,8.3l-11.9,11 c-0.4,0.4-0.7,0.9-0.8,1.5l-0.4,3c-0.1,0.4-0.6,0.4-0.7,0.1l-1.6-5.5c-0.2-0.6,0.1-1.3,0.6-1.6l14.4-8.9C25,7.7,25.3,8.1,25,8.3z"/>
</symbol>
<symbol id="icon-hashtag" viewBox="0 0 32 32">
<path class="path1" d="M17.696 18.286l1.143-4.571h-4.536l-1.143 4.571h4.536zM31.411 9.286l-1 4q-0.125 0.429-0.554 0.429h-5.839l-1.143 4.571h5.554q0.268 0 0.446 0.214 0.179 0.25 0.107 0.5l-1 4q-0.089 0.429-0.554 0.429h-5.839l-1.446 5.857q-0.125 0.429-0.554 0.429h-4q-0.286 0-0.464-0.214-0.161-0.214-0.107-0.5l1.393-5.571h-4.536l-1.446 5.857q-0.125 0.429-0.554 0.429h-4.018q-0.268 0-0.446-0.214-0.161-0.214-0.107-0.5l1.393-5.571h-5.554q-0.268 0-0.446-0.214-0.161-0.214-0.107-0.5l1-4q0.125-0.429 0.554-0.429h5.839l1.143-4.571h-5.554q-0.268 0-0.446-0.214-0.179-0.25-0.107-0.5l1-4q0.089-0.429 0.554-0.429h5.839l1.446-5.857q0.125-0.429 0.571-0.429h4q0.268 0 0.446 0.214 0.161 0.214 0.107 0.5l-1.393 5.571h4.536l1.446-5.857q0.125-0.429 0.571-0.429h4q0.268 0 0.446 0.214 0.161 0.214 0.107 0.5l-1.393 5.571h5.554q0.268 0 0.446 0.214 0.161 0.214 0.107 0.5z"></path>
</symbol>
<symbol id="icon-chain" viewBox="0 0 30 32">
<path class="path1" d="M26 21.714q0-0.714-0.5-1.214l-3.714-3.714q-0.5-0.5-1.214-0.5-0.75 0-1.286 0.571 0.054 0.054 0.339 0.33t0.384 0.384 0.268 0.339 0.232 0.455 0.063 0.491q0 0.714-0.5 1.214t-1.214 0.5q-0.268 0-0.491-0.063t-0.455-0.232-0.339-0.268-0.384-0.384-0.33-0.339q-0.589 0.554-0.589 1.304 0 0.714 0.5 1.214l3.679 3.696q0.482 0.482 1.214 0.482 0.714 0 1.214-0.464l2.625-2.607q0.5-0.5 0.5-1.196zM13.446 9.125q0-0.714-0.5-1.214l-3.679-3.696q-0.5-0.5-1.214-0.5-0.696 0-1.214 0.482l-2.625 2.607q-0.5 0.5-0.5 1.196 0 0.714 0.5 1.214l3.714 3.714q0.482 0.482 1.214 0.482 0.75 0 1.286-0.554-0.054-0.054-0.339-0.33t-0.384-0.384-0.268-0.339-0.232-0.455-0.063-0.491q0-0.714 0.5-1.214t1.214-0.5q0.268 0 0.491 0.063t0.455 0.232 0.339 0.268 0.384 0.384 0.33 0.339q0.589-0.554 0.589-1.304zM29.429 21.714q0 2.143-1.518 3.625l-2.625 2.607q-1.482 1.482-3.625 1.482-2.161 0-3.643-1.518l-3.679-3.696q-1.482-1.482-1.482-3.625 0-2.196 1.571-3.732l-1.571-1.571q-1.536 1.571-3.714 1.571-2.143 0-3.643-1.5l-3.714-3.714q-1.5-1.5-1.5-3.643t1.518-3.625l2.625-2.607q1.482-1.482 3.625-1.482 2.161 0 3.643 1.518l3.679 3.696q1.482 1.482 1.482 3.625 0 2.196-1.571 3.732l1.571 1.571q1.536-1.571 3.714-1.571 2.143 0 3.643 1.5l3.714 3.714q1.5 1.5 1.5 3.643z"></path>
</symbol>
<symbol id="icon-thumb-tack" viewBox="0 0 21 32">
<path class="path1" d="M8.571 15.429v-8q0-0.25-0.161-0.411t-0.411-0.161-0.411 0.161-0.161 0.411v8q0 0.25 0.161 0.411t0.411 0.161 0.411-0.161 0.161-0.411zM20.571 21.714q0 0.464-0.339 0.804t-0.804 0.339h-7.661l-0.911 8.625q-0.036 0.214-0.188 0.366t-0.366 0.152h-0.018q-0.482 0-0.571-0.482l-1.357-8.661h-7.214q-0.464 0-0.804-0.339t-0.339-0.804q0-2.196 1.402-3.955t3.17-1.759v-9.143q-0.929 0-1.607-0.679t-0.679-1.607 0.679-1.607 1.607-0.679h11.429q0.929 0 1.607 0.679t0.679 1.607-0.679 1.607-1.607 0.679v9.143q1.768 0 3.17 1.759t1.402 3.955z"></path>
</symbol>
<symbol id="icon-arrow-left" viewBox="0 0 43 32">
<path class="path1" d="M42.311 14.044c-0.178-0.178-0.533-0.356-0.711-0.356h-33.778l10.311-10.489c0.178-0.178 0.356-0.533 0.356-0.711 0-0.356-0.178-0.533-0.356-0.711l-1.6-1.422c-0.356-0.178-0.533-0.356-0.889-0.356s-0.533 0.178-0.711 0.356l-14.578 14.933c-0.178 0.178-0.356 0.533-0.356 0.711s0.178 0.533 0.356 0.711l14.756 14.933c0 0.178 0.356 0.356 0.533 0.356s0.533-0.178 0.711-0.356l1.6-1.6c0.178-0.178 0.356-0.533 0.356-0.711s-0.178-0.533-0.356-0.711l-10.311-10.489h33.778c0.178 0 0.533-0.178 0.711-0.356 0.356-0.178 0.533-0.356 0.533-0.711v-2.133c0-0.356-0.178-0.711-0.356-0.889z"></path>
</symbol>
<symbol id="icon-arrow-right" viewBox="0 0 43 32">
<path class="path1" d="M0.356 17.956c0.178 0.178 0.533 0.356 0.711 0.356h33.778l-10.311 10.489c-0.178 0.178-0.356 0.533-0.356 0.711 0 0.356 0.178 0.533 0.356 0.711l1.6 1.6c0.178 0.178 0.533 0.356 0.711 0.356s0.533-0.178 0.711-0.356l14.756-14.933c0.178-0.356 0.356-0.711 0.356-0.889s-0.178-0.533-0.356-0.711l-14.756-14.933c0-0.178-0.356-0.356-0.533-0.356s-0.533 0.178-0.711 0.356l-1.6 1.6c-0.178 0.178-0.356 0.533-0.356 0.711s0.178 0.533 0.356 0.711l10.311 10.489h-33.778c-0.178 0-0.533 0.178-0.711 0.356-0.356 0.178-0.533 0.356-0.533 0.711v2.311c0 0.178 0.178 0.533 0.356 0.711z"></path>
</symbol>
<symbol id="icon-play" viewBox="0 0 22 28">
<path d="M21.625 14.484l-20.75 11.531c-0.484 0.266-0.875 0.031-0.875-0.516v-23c0-0.547 0.391-0.781 0.875-0.516l20.75 11.531c0.484 0.266 0.484 0.703 0 0.969z"></path>
</symbol>
<symbol id="icon-pause" viewBox="0 0 24 28">
<path d="M24 3v22c0 0.547-0.453 1-1 1h-8c-0.547 0-1-0.453-1-1v-22c0-0.547 0.453-1 1-1h8c0.547 0 1 0.453 1 1zM10 3v22c0 0.547-0.453 1-1 1h-8c-0.547 0-1-0.453-1-1v-22c0-0.547 0.453-1 1-1h8c0.547 0 1 0.453 1 1z"></path>
</symbol>
</defs>
</svg>

</body>

<!-- Mirrored from mw20.museweb.net/paper/ai-sees-what-the-good-the-bad-and-the-ugly-of-machine-vision-for-museum-collections/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 11 May 2022 19:08:56 GMT -->
</html>
