<html><!-- #BeginTemplate "/Templates/mw2003-papers.dwt" --><!-- DW6 -->

<!-- Mirrored from www.museumsandtheweb.com/mw2003/papers/grotke/grotke.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 20:32:30 GMT -->
<head>
<!-- #BeginEditable "doctitle" --> 
<title>Museums and the Web 2003: Papers: Grotke</title>
<!-- #EndEditable --> 
<meta name="keywords" content="Museums and the Web 2003, Archives & Museum Informatics, museums online, on-line, cultural heritage online, museum digitization, internet, conference, symposium, workshop, meeting, international, papers, presentations, multimedia, interactive, education, exhibits, evaluation, virtual reality, digitization, information architecture, information design, interface design, digital library, digital libraries ">
<!-- #BeginEditable "page keywords" --> 
<meta name="keywords" content="Web archiving, born digital, preservation, digital library, MINERVA">
<!-- #EndEditable --> 
<meta http-equiv="Content-Type" content="text/html; charset=">
<!-- #BeginEditable "script" --><!-- #EndEditable --> 
<link rel="stylesheet" href="../../Library/mw2003.css" type="text/css">
<script language="JavaScript">
<!--
function MM_swapImgRestore() { //v3.0
  var i,x,a=document.MM_sr; for(i=0;a&&i<a.length&&(x=a[i])&&x.oSrc;i++) x.src=x.oSrc;
}

function MM_preloadImages() { //v3.0
  var d=document; if(d.images){ if(!d.MM_p) d.MM_p=new Array();
    var i,j=d.MM_p.length,a=MM_preloadImages.arguments; for(i=0; i<a.length; i++)
    if (a[i].indexOf("#")!=0){ d.MM_p[j]=new Image; d.MM_p[j++].src=a[i];}}
}

function MM_findObj(n, d) { //v4.0
  var p,i,x;  if(!d) d=document; if((p=n.indexOf("?"))>0&&parent.frames.length) {
    d=parent.frames[n.substring(p+1)].document; n=n.substring(0,p);}
  if(!(x=d[n])&&d.all) x=d.all[n]; for (i=0;!x&&i<d.forms.length;i++) x=d.forms[i][n];
  for(i=0;!x&&d.layers&&i<d.layers.length;i++) x=MM_findObj(n,d.layers[i].document);
  if(!x && document.getElementById) x=document.getElementById(n); return x;
}

function MM_swapImage() { //v3.0
  var i,j=0,x,a=MM_swapImage.arguments; document.MM_sr=new Array; for(i=0;i<(a.length-2);i+=3)
   if ((x=MM_findObj(a[i]))!=null){document.MM_sr[j++]=x; if(!x.oSrc) x.oSrc=x.src; x.src=a[i+2];}
}
//-->
</script>
</head>

<body bgcolor="#FFFFFF" background="../../../mw2002/images/mw2002.bg.gif" text="#000000" link="#660099" vlink="#000066" onLoad="MM_preloadImages('../../images/register_on.gif','../../images/workshops_on.gif','../../images/sessions_on.gif','../../images/speakers_on.gif','../../images/interact_on.gif','../../images/demos_on.gif','../../images/exhibits_on.gif','../../images/events_on.gif','../../images/best_on.gif','../../images/dates_on.gif','../../images/charlotte_on.gif','../../images/sponsors_on.gif')">
<table width="600" border="0" cellspacing="2" cellpadding="5">
  <tr> 
    <td width="145" align="LEFT" valign="TOP"> 
      <p><a href="../../index.html"><img src="../../images/mw.gif" width="112" height="155" border="0" alt="/mw/"></a></p>
      <p> <a href="../../register/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('register','','../../images/register_on.gif',1)"><img name="register" border="0" src="../../images/register_off.gif" width="112" height="18"></a><br>
        <a href="../../workshops/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('workshops','','../../images/workshops_on.gif',1)"><img name="workshops" border="0" src="../../images/workshops_off.gif" width="112" height="18"></a><br>
        <a href="../../sessions/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('sessions','','../../images/sessions_on.gif',1)"><img name="sessions" border="0" src="../../images/sessions_off.gif" width="112" height="18"></a><br>
        <a href="../../speakers/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('speakers','','../../images/speakers_on.gif',1)"><img name="speakers" border="0" src="../../images/speakers_off.gif" width="112" height="18"></a><br>
        <a href="../../interact/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('interactions','','../../images/interact_on.gif',1)"><img name="interactions" border="0" src="../../images/interact_off.gif" width="112" height="18"></a><br>
        <a href="../../demos/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('demonstrations','','../../images/demos_on.gif',1)"><img name="demonstrations" border="0" src="../../images/demos_off.gif" width="112" height="16"></a><br>
        <a href="../../exhibit/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('exhibits','','../../images/exhibits_on.gif',1)"><img name="exhibits" border="0" src="../../images/exhibits_off.gif" width="112" height="19"></a><br>
        <a href="../../events/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('events','','../../images/events_on.gif',1)"><img name="events" border="0" src="../../images/events_off.gif" width="112" height="18"></a><br>
        <a href="../../best/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('best','','../../images/best_on.gif',1)"><img name="best" border="0" src="../../images/best_off.gif" width="112" height="18"></a><br>
        <a href="../../dates/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('dates','','../../images/dates_on.gif',1)"><img name="dates" border="0" src="../../images/dates_off.gif" width="112" height="18"></a><br>
        <a href="../../charlotte/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('charlotte','','../../images/charlotte_on.gif',1)"><img name="charlotte" border="0" src="../../images/charlotte_off.gif" width="112" height="18"></a><br>
        <a href="../../sponsor/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('sponsors','','../../images/sponsors_on.gif',1)"><img name="sponsors" border="0" src="../../images/sponsors_off.gif" width="112" height="21"></a> 
        <br>
        <br>
        <a href="http://www.archimuse.com/" target="_top"><img src="../../images/nav_ami.gif" width="135" height="25" border="0" alt="A&amp;MI home"></a> 
        <br>
        <span class="small">Archives & Museum Informatics<br>
        158 Lee Avenue<br>
        Toronto Ontario<br>
        M4E 2P3 Canada</span></p>
      <p class="small">ph: +1 416-691-2516<br>
        fx: +1 416-352-6025</p>
      <p><span class="small">info @ archimuse.com</span><span class="small"><br>
		<a href="http://www.archimuse.com/">www.archimuse.com</a></span></p>
      <table width="74">
        <tr> 
          <td> <a href="http://search.museumsandtheweb.com/search" target="_top"> <img src="../../images/search.gif" width="24" height="25" alt="Search" border="0" name="Search"></a> 
          </td>
          <td valign="MIDDLE"> <a href="http://search.museumsandtheweb.com/search"> 
            <span class="verysmall">Search<br></span></a> </td>
        </tr>
      </table>
      <p><font face="Arial, Helvetica, sans-serif" class="verysmall"><span class="small">Join 
        our <a href="http://search.museumsandtheweb.com/mailinglist/"> Mailing List</a>. 
        <br>
        <a href="http://search.museumsandtheweb.com/terms-of-use-privacy/"> Privacy</a>.</span></font> 
      </p>
      <p>&nbsp; </p>
 <p><span class="verysmall">published: March 2004<br>
        analytic scripts updated:<br>
		  <!-- #BeginDate format:Am1 -->October 28, 2010<!-- #EndDate -->
        </span>
         </p>
     <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/3.0/"><img src="http://i.creativecommons.org/l/by-nc-nd/3.0/88x31.png" alt="Creative Commons Attribution-Noncommercial-No Derivative Works 3.0  License" width="88" height="31" style="border-width:0" /></a>
     </td>
    <td width="455" align="LEFT" valign="TOP" class="normal"><a href="../../speakers/index.html"><img src="../../images/PAPERS.gif" width="390" height="55" border="0" alt="Museums and the Web 2003 Papers"></a> 
	  <br>
	  <p>&nbsp;</p>
	 <!-- #BeginEditable "Body of Page" --> 
	  <div class=Section1> 
		<p class=PaperTitle>Web Preservation Projects at Library of Congress</p>
		<p class=Author>Abigail Grotke and Gina Jones, Library of Congress, USA</p>
		<p class=AbstractTitle>&nbsp;Abstract</p>
		<p class=AbstractText>The Library of Congress' mission is to make its 
		  resources available and useful to the Congress and the American people 
		  and to sustain and preserve a universal collection of knowledge and 
		  creativity for future generations. </p>
		<p class=AbstractText>An ever-increasing amount of the world's cultural 
		  and intellectual output is presently created in digital formats and 
		  does not exist in any physical form. Such materials are colloquially 
		  described as &quot;born digital.&quot; This born digital realm includes 
		  open access materials on the World Wide Web. </p>
		<p class=AbstractText>The MINERVA Web Preservation Project was established 
		  to initiate a broad program to collect and preserve these primary source 
		  materials. A multi disciplinary team of Library staff representing cataloging, 
		  legal, public services, and technology services is studying methods 
		  to evaluate, select, collect, catalog, provide access to, and preserve 
		  these materials for future generations of researchers.</p>
		<p class=AbstractText>This paper will provide a report on the Library 
		  of Congress Web harvesting activities, describing experiences to date 
		  selecting, capturing, and providing access to topic-based collections, 
		  including U.S. Presidential Candidate Election 2000, September 11, 2001, 
		  the 2002 Olympics, and the 2002 Election.</p>
		<p class=keywords>Keywords: Web archiving, born digital, preservation, 
		  digital library, MINERVA</p>
		<p class=SubHeader><b>Introduction</b></p>
		<p class=normal>Since the launch of the Library of Congress Web site in 
		  1994, LC has been on the forefront of the creation of digital library 
		  content, most notably with its American Memory program, converting historical 
		  materials from analog to digital form and presenting them on the Web. 
		  But with all this creation of content <i>for</i> and <i>on</i> the Web, 
		  there had been little discussion at the Library about how to save the 
		  growing number of Web sites that were being created around the world. 
		  Other National Libraries had already begun work to archive their own 
		  countrys Web resources, with different approaches: the National Library 
		  of Australia began selective collecting in 1996 with their PANDORA archive 
		  (http://pandora.nla.gov.au/index.html), and the Swedish Royal Librarys 
		  Kulturaw3 project (http://www.kb.se/kw3/ENG/Default.htm) began bulk 
		  collecting of Swedish Web sites. Although the Internet itself was still 
		  in its infancy, the Library and archival community had already begun 
		  to recognize the need to preserve these at-risk materials for researchers 
		  and future generations, for the frequency in which Web sites were created 
		  and disappeared was astonishing.</p>
		<p class=normal>The time for the Library of Congress to act had come.</p>
		<p class=normal>An ever-increasing amount of primary source materials 
		  are being created in digital formats and distributed on the web, and 
		  do not exist in any other form. Future scholars will need them to understand 
		  the cultural, economic, political and scientific activities of today 
		  and, in particular, the changes that have been stimulated by computing 
		  and the Internet. the National Research Council [has] emphasized the 
		  important role of the Library of Congress in collecting and preserving 
		  these digital materials. <i>A Digital Strategy for the Library of Congress</i> 
		  praised the Librarys plans to address the challenges and urged the Library 
		  to move ahead rapidly (Arms, January 2001).</p>
		<p class=normal>In the summer of 2000, a team was formed with staff from 
		  across the Library of Congress cataloging, legal, public services, and 
		  technology services to embark upon a study to evaluate, select, collect, 
		  catalogue, provide access to, and preserve electronic resources on the 
		  World Wide Web for future generations of researchers. The outcome of 
		  this study was two reports on the Web Preservation Project (an interim 
		  dated January 15, 2001, and a final onr, September 3, 2001) written 
		  by consultant William Arms of Cornell University. Arms describes in 
		  detail the pilot project, nicknamed MINERVA (Mapping the Internet: Electronic 
		  Resources Virtual Archive). Using HTTrack mirroring software, a small 
		  number of sites were selected and snapshots of sites were downloaded 
		  to the Librarys servers. OCLCs Cooperative Online Research Cataloguing 
		  service (CORC) was used to created catalog records for the sites, and 
		  the records were loaded into the Librarys ILS system for access. User 
		  testing and quality studies were performed and reported upon in Armss 
		  final report. </p>
		<p class=normal>&nbsp;</p>
		<p class=MsoNormal align="center"><img src="grotke.fig1.jpg" width="400" height="496"></p>
		<p class=MsoCaption>Fig. 1: MINERVA Web site (http://www.loc.gov/minerva)</p>
		<p class=normal>About the same time, a parallel project was initiated 
		  by the Library of Congress to capture Web sites relating to the Fall 
		  2000 presidential election, using the crawling services of the Internet 
		  Archive, a 501(c)(3) public nonprofit (see Partners below). It was a 
		  practical test case for a large-scale collection effort using the Internet 
		  Archive.</p>
		<h1 class="SubHeader">What Have We Learned?</h1>
		<p class=normal>Archiving the Web, or even portions of the Web, is no 
		  easy task, as the library community, including the Library of Congress, 
		  soon discovered. Many questions were raised during this period, and 
		  the MINERVA Web preservation project team continues to explore answers 
		  and options. </p>
		<h2 class="SubHeaderSmall">Which sites should be collected? </h2>
		<p class=normal>Based on recommendations stemming from the pilot and experiences 
		  to date, the Library has opted to perform selective collecting at this 
		  time, with a focus on event-based collections. Once an event is selected, 
		  a collection strategy for it is mapped out and categories for collection 
		  are defined. Recommending officers suggest sites relating to the event, 
		  and a technical team reviews sites to ensure that the crawler will grab 
		  the relevant content (see technical issues below). </p>
		<p class=normal>The Library is currently drafting a formal collection 
		  policy statement for Web archiving, and is expanding activities in FY03 
		  to include subject-based collecting rather than exclusively event-based. 
		  Examples include the 107<sup>th</sup> Congress sites recently captured, 
		  or federal government or state government Web sitesto complement a Mellon-funded 
		  project from the California Digital Library.</p>
		<h2 class="SubHeaderSmall">How often should snapshots be made?</h2>
		<p class=normal>The Library has tested a variety of frequencies of capture, 
		  from a one-time capture of the 107<sup>th</sup> Congress sites to a 
		  once-every-hour capture on Election Day 2002. The frequency depends 
		  on the content on the page or broad categories of types of sites (press, 
		  individual, government), and varies depending on the type of site and 
		  event that is being archived. <b></b></p>
		<h2 class="SubHeaderSmall">What constitutes a Web site? What will researches 
		  expect when they visit a Web archive?<i></i></h2>
		<p class=normal>The MINERVA team contemplates the answer to this basic 
		  question the definition of a Web site. How deep does a site go? How 
		  much should we capture or expect to capture, in order to replicate the 
		  experience of a Web site? How much will researchers <i>want</i> in order 
		  to make the archive useful to them? For now, we study the statistics 
		  of the crawls that we do, improve the quality as we can, and understand 
		  that there are limitations that must be anticipated, so we are ready 
		  to alert users of the archive to the limitations.</p>
		<h4 class="SubHeaderSmall">What technical challenges do we face? Are we 
		  getting what we want?</h4>
		<p class=normal>Archiving Web sites is not an exact science. The crawlers 
		  used for these activities have been superb tools for large-scale collection 
		  capture. However, there are limitations in their capability. Some examples 
		  weve discovered:</p>
	  </div>
	  <ul>
		<li> 
		  <div class=normal> 
			<div class=MsoNormal> Macromedia Flash<sup>TM</sup> sites are captured, 
			  but the program is not alterable. If the Flash<sup>TM</sup> program 
			  provides the initial site navigation for the user, it will send 
			  the users to the live Web site or to a 404-not found if the site 
			  no longer exists.</div>
		  </div>
		</li>
		<li> 
		  <div class=MsoNormal> Sites that require log-ins, either free or pay 
			sites, will not be crawled more in-depth than what the crawler can 
			get to without logging in. Recent disappointing experiences with press 
			sites, particularly in the Election 2002 collection, have caused us 
			to rethink our approach to such sites. </div>
		</li>
		<li> 
		  <div class=MsoNormal> Due to crawling technology and the structure of 
			dynamic Web sites, content on dynamically-generated Web pages is not 
			captured. </div>
		</li>
		<li> 
		  <div class=MsoNormal> The crawler will generally not be successful in 
			crawling a site that has dynamic menus or menus/links that are created 
			through a script rewrite.</div>
		</li>
	  </ul>
	  <div class=Section1> 
		<p class=normal>Related to the breadth and depth of Web sites, there are 
		  issues that we are just beginning to understand. Weve been able to spend 
		  more time recently reviewing crawling statistics for the archives and 
		  performing time-consuming quality review of the sites that weve collected. 
		  As we learn more about crawling technology, well be better able to refine 
		  our activities to get the most value out of a particular archived site. 
		</p>
		<h2 class="SubHeaderSmall">How do we provide access to archived collections? 
		  What level of access do we provide?</h2>
		<p class=normal>Its one thing to collect Web sites; its another thing 
		  to make them available to researchers. Cataloging, interface, and access 
		  issues must all be addressed.</p>
		<p class=SubHeader>Cataloging</p>
		<p class=normal>The MINERVA prototype experimented in the cataloging of 
		  Web sites on the item level and on the collection level (for a group 
		  of sites), using OCLCs Cooperative Online Research Cataloging service 
		  (now apart of OCLC's Connexion service (http://www.oclc.org/connexion/). 
		  The Library will continue provide collection level records for inclusion 
		  in the ILS, and is planning to assign more in-depth descriptive cataloguing 
		  at the Web site level for selected sites, based on the Library of Congress 
		  <a
href="http://www.loc.gov/standards/mods/">Metadata Object Description Schema (MODS)</a> 
		  (http://www.loc.gov/standards/mods/) for the Olympics 2002, Election 
		  2002, and selected portions of the September 11 Web Archive. Metadata 
		  includes: </p>
	  </div>
	  <ul>
		<li> 
		  <div class=MsoNormal> Name (Creator or issuing publisher) </div>
		</li>
		<li> 
		  <div class=MsoNormal> Abstract </div>
		</li>
		<li> 
		  <div class=MsoNormal> Capture date </div>
		</li>
		<li> 
		  <div class=MsoNormal> Genre </div>
		</li>
		<li> 
		  <div class=MsoNormal> Physical Description/Format </div>
		</li>
		<li> 
		  <div class=MsoNormal> Language </div>
		</li>
		<li> 
		  <div class=MsoNormal> Subject </div>
		</li>
		<li> 
		  <div class=MsoNormal> Access Conditions </div>
		</li>
	  </ul>
	  <div class=Section1> 
		<p class=normal>Additionally, machine generated administrative and preservation 
		  metadata for each base URL in the collection will enable the Library 
		  to provide long-term preservation of the collection. These include:</p>
	  </div>
	  <ul>
		<li> 
		  <div class=MsoNormal> URL </div>
		</li>
		<li> 
		  <div class=MsoNormal> Internet-protocol (IP) address </div>
		</li>
		<li> 
		  <div class=MsoNormal> owner or creator </div>
		</li>
		<li> 
		  <div class=MsoNormal> date and time of collection </div>
		</li>
		<li> 
		  <div class=MsoNormal> file content type </div>
		</li>
		<li> 
		  <div class=MsoNormal> archive length </div>
		</li>
	  </ul>
	  <div class=Section1> 
		<p class=normal>Some of the cataloging continues to be performed in-house, 
		  while the Library has contracted with WebArchivist.org to perform cataloging 
		  work based on Library of Congress specifications. Cataloging of individual 
		  sites is a time-consuming effort, and automatic processes must be balanced 
		  against human cataloging to ensure a proper level of access for potentially 
		  massive amounts of data.</p>
		<h1 class="SubHeader">Access and Interface</h1>
		<p class=normal>The prototype was made available on campus at the Library 
		  of Congress ,and records were included in the Library's catalog. In 
		  addition, the Election 2000 Web Archive and the September 11 Web Archive 
		  have been made available through the Internet Archive, with collection 
		  information available on the MINERVA Web site, including a link to the 
		  respective archive. WebArchivist.org created a model interface to the 
		  September 11 Web Archive (http://september11.archive.org/), which was 
		  initially released on October 11, 2001, and redesigned in September 
		  2002. Further interface issues will be addressed with the release of 
		  candidate Web sites as a part of the Election 2002 Web Archive in March 
		  2003.</p>
		<p class=normal>In the coming year, the Library of Congress will be working 
		  on the interface and display of these archived materials. The MINERVA 
		  Web preservation project team, with assistance from the Librarys Information 
		  Technology office, has been exploring means of indexing archived Web 
		  sites based on recommendations from the prototype reports, and has been 
		  discussing interface options for display of these materials with a variety 
		  of Library experts. IT staff are working closely with Internet Archive 
		  to ensure proper transfer of materials from the acquisitions agent to 
		  Library of Congress servers, and have assisted with technical issues 
		  related to this work. </p>
		<h2 class="SubHeaderSmall">What are the legal challenges?</h2>
		<p class=normal>The MINERVA pilot explored, with support from the Office 
		  of the General Counsel, issues relating to copyright and legal issues, 
		  and further discussions and recommendations have followed for each of 
		  the ensuing collections. </p>
		<p class=normal>While preserving open access materials from the Web falls 
		  within the Library of Congresss mission to collect and preserve the 
		  cultural and intellectual artifacts of today for the benefit of future 
		  generations&quot; (Arms, January 2001), the Library doesnt explicitly 
		  have the right to do so under the current copyright law. </p>
		<p class=normal>The Copyright Office is working with the Library to make 
		  its requirements clear, with the goal in mind to propose to Congress 
		  an amendment to Section 407 of the Copyright Act to permit downloading 
		  of open access materials that are on the Internet. Arms's final report 
		  included a desire for the importance of the Library extending its view 
		  of copyright deposit to include web materials; however, new regulations 
		  will be needed to implement them, such as revising the definition of 
		  best edition. (Arms, September 2001).</p>
		<p class=normal>The Library's legal counsel has determined that the Library 
		  of Congress has the right to acquire these materials for the Library's 
		  collections and the right to serve these materials to researchers who 
		  visit the Library. The Librarys mission states, The Congress has now 
		  recognized that, in an age in which information is increasingly communicated 
		  and stored in electronic form, the Library should provide remote access 
		  electronically to key materials. With remote access in mind, the Library 
		  has adopted an opt-in/opt-out policy to allow content providers the 
		  ability to opt-out of any remote presentations of Web archives. As a 
		  site is harvested, a notification is sent to the content provider notifying 
		  it of our activities. An example of this from the Election 2002 Web 
		  Archive -- follows:</p>
	  </div>
	  <blockquote> 
		<div class=Section1><span class="BlockQuote">On behalf of the United States 
		  Library of Congress, the Internet Archive will be harvesting content 
		  from your website at regular intervals during the 2002 election cycle 
		  for inclusion in the Library's Election 2002 historic Internet collection. 
		  This collection is a pilot project of the Library in connection with 
		  its mandate from Congress to collect and preserve <a>ephemeral</a> digital 
		  materials for this and future generations. In March 2003, the Library 
		  will make this collection available to researchers onsite at Library 
		  facilities. The Library also wishes to make the collection available 
		  to offsite researchers by hosting the collection on the Library's public 
		  access website. The Library hopes that you share its vision of preserving 
		  Web materials about Election 2002 and permitting researchers from across 
		  the world to access them. If you do not wish to permit offsite access 
		  to your materials through the Library's website, please email the Library's 
		  MINERVA Project (Mapping the Internet Electronic Resources Virtual Archive) 
		  at: election2002@loc.gov at your earliest convenience. </span></div>
		<div class=Section1><span class="BlockQuote">We thank you in advance for 
		  your cooperation.</span></div>
		<div class=Section1></div>
		<div class=Section1><span class="BlockQuote">The Library of Congress</span></div>
	  </blockquote>
	  <div class=Section1> 
		<p class=normal>Once the collections are prepared for access, the wishes 
		  of content providers that opt-out of remote access to their archived 
		  sites will be granted, and the sites will only be available to researchers 
		  on-site at the Library of Congress. Catalog records for these items 
		  may be viewed remotely, if technically feasible.</p>
		<h2 class="SubHeader">Partners</h2>
		<h4 class="SubHeaderSmall">Internet Archive (http://www.archive.org)</h4>
		<p class=normal>The Internet Archive has been a major partner in the collection 
		  and development of the Librarys Web archives to date. The Library has 
		  contracted with the Internet Archive to harvest sites for the three 
		  collections reviewed in detail later in this paper, as well as three 
		  additional collections currently underway. Founded in 1996, the Archive 
		  has been receiving data donations (over 100 terabytes to date) from 
		  Alexa Internet and others to build their digital library of Internet 
		  sites. (http://archive.org/about/about.php). </p>
		<p class=normal>The Internet Archive has used technology available under 
		  partnership with Alexa Internet to harvest, manage, and provide access 
		  to the Librarys Web archive data. And as stated before, two collections 
		  (Election 2000 and September 11) are temporarily available for viewing 
		  at the Internet Archive Web site as production on these collections 
		  continues at the Library of Congress to make them available from our 
		  site.</p>
		<p class=normal>Alexa Internet, in cooperation with the Internet Archive, 
		  designed the Wayback Machine, a three dimensional index that allows 
		  browsing of web documents over multiple time periods. (http://www.archive.org) 
		  This tool was made available to users on October 2001 to search and 
		  navigate the Internet Archives &quot;Internet Library.&quot; The technology 
		  has been subsequently made available to the Library of Congress to help 
		  provide access the Librarys Web archive collections.</p>
		<p class=normal>In terms of crawler technology used in the creation of 
		  the Librarys Web archive, Compaq Computer, working with Internet Archive, 
		  undertook the task of collecting and archiving sites for the Election 
		  2000 Web Archive. Internet Archive collected and archived Web sites 
		  for the Olympics 2002 Web Archive and September 11<sup>th</sup> Web 
		  Archive and has participated with the Library on its three most recent 
		  projects: Election 2002, September 11 Remembrance, and the 107<sup>th</sup> 
		  Congress.</p>
		<h4 class="SubHeaderSmall">WebArchivist.org: University of Washington 
		  and the State University of New York, Information Technology (SUNYIT)<i></i></h4>
		<p class=normal>WebArchivist.org's mission is To develop systems for identifying, 
		  collecting, cataloguing and analyzing large-scale archives of Web objects. 
		  (http://www.webarchivist.org) This organization has partnered with the 
		  Library of Congress on its Web archiving projects currently underway, 
		  including the September 11<sup>th</sup> Web Archive, and the Election 
		  2002 Web Archive.</p>
		<h1 class="SubHeaderSmall">The Web Archives</h1>
		<p class=normal>Detailed information is provided below on three collections 
		  that the Library has produced to date, providing a basic analysis of 
		  each collection and the objects within them, including:</p>
		<p class=MsoNormal><u>General Infor<span class="normal">mation:</span></u><span class="normal"> 
		  Covers the collection in a general sense by providing the objective, 
		  a brief analysis of the Web site collection composite, period and frequency 
		  of crawl, and any other pertinent collection information.</span></p>
		<p class=normal><u>Detailed Collection Information:</u> Provides a detailed 
		  sense of the Web site collection composite, the crawlers activities 
		  for the URLs in the collection, and the extent of the Librarys quality 
		  review process during the crawl period.</p>
		<p class=normal><u>Collection File Analysis</u>: Provides, as best can 
		  be determined during this initial review period, the detailed collection 
		  composite.</p>
		<p class=normal>Additional information about cataloging or interface design 
		  is provided below if available.</p>
		<p class=MsoBodyText><span class="normal">Note: For the following collections, 
		  staff wa</span>s limited and could generally perform site selection 
		  only during crawl periods. No quality review was done on the collections 
		  during the time of the crawl, nor was it possible to investigate and 
		  resolve the not found and the redirect error codes. Statistics were 
		  limited in these early days, and it is difficult to characterize these 
		  Web collections with any certainty for link rot (links that no longer 
		  work) or other associated Not Found analysis. A good object is any object 
		  returned with a found HTTP code. Recently, more staff has been hired 
		  and statistics are improving, so we anticipate knowing more about future 
		  collections and being able to correct problems during the testing and 
		  collection period, rather than examining after the fact.</p>
		<h1 class="SubHeader">Election 2000<u></u></h1>
		<p class=normal>The Election 2000 Collection is important because it contributes 
		  to the historical record of the U.S. presidential election, capturing 
		  information that could otherwise have been lost. With the growing role 
		  of the Web as an influential medium, records of historical events such 
		  as the U.S. presidential election could be considered incomplete without 
		  materials that were &quot;born digital&quot; and never printed on paper. 
		  Because Internet content changes at a very rapid pace, especially on 
		  those sites related to an election, many important election sites have 
		  already disappeared from the Web. For the Election 2000 Collection, 
		  rapidly changing sites were archived daily, or even twice and three 
		  times in a day, in an attempt to capture the dynamic nature of Internet 
		  content. &quot;This was the first presidential election in which the 
		  Web played an important role, and there would have been a gap in the 
		  historical record of this period without a collection such as this,&quot; 
		  said Winston Tabb, Associate Librarian for Library Services of the Library 
		  of Congress. (http://www.loc.gov/today/pr/2001/01-091.html)</p>
		<h2 class="SubHeaderSmall">General Information</h2>
		<p class=MsoNormal>The Election 2000 Web Archive, the first Web collection 
		  developed by the Library, cons<span class="normal">ists of 800 gigabytes 
		  of archived digital materials and is a selective collection of nearly 
		  800 sites archived daily between August 1, 2000, and January 21, 2001, 
		  covering the United States national election period. </span></p>
		<p class=normal>The Library of Congress commissioned the Internet Archive 
		  to assist the Library in the harvesting of sites. Compaq Computer Corporation, 
		  using the Mercator crawler, captured and stored all the data. The Election 
		  2000 Collection was made available to the public in June of 2001 and 
		  is accessible online at the Internet Archive at the following URL: http://web.archive.org/collections/e2k.html. 
		</p>
		<p class=normal>The Library has received the archive and is processing 
		  it for long-term preservation and access. Once processing and production 
		  of a Library interface for the collection is complete, the Election 
		  2000 Web Archive will be made available to the public from the MINERVA 
		  Web site.</p>
		<h2 class="SubHeaderSmall">Collection Interface</h2>
		<p class=normal>While the Election 2000 Web Archive is hosted by the Internet 
		  Archive, it is searchable by date, URL, and by category via the Wayback 
		  Machine.</p>
		<h2 class="SubHeaderSmall">Detailed Collection Information<u></u></h2>
		<p class=normal>The 797 sites in the archive consist of the following:</p>
		<table border=1 cellspacing=0 cellpadding=0 width=85% align="center" bordercolor="#CCCCCC">
		  <tr> 
			<td width=198 valign=top class="normal"> 
			  <p>39 Conservation District </p>
			  <p>86 Democratic Party</p>
			  <p>&nbsp; 6 Government </p>
			  <p>11 Green Party</p>
			  <p>24 Humor &amp; Criticism</p>
			  <p>11 League of Women Voters </p>
			  <p>45 Libertarian Party </p>
			  <p>38 News</p>
			</td>
			<td width=234 valign=top class="normal"> 
			  <p>167 Other Election 2000 Sites</p>
			  <p>&nbsp;52 Presidential and Party Candidate </p>
			  <p>&nbsp;63 Reform Party </p>
			  <p>&nbsp;60 Republican Party </p>
			  <p>&nbsp;51 U.S. House </p>
			  <p>130 U.S. Senate </p>
			  <p>&nbsp;14 Vote Trading </p>
			</td>
		  </tr>
		</table>
		<p class=MsoCaption><b><i>Chart 1: General statistical overview of the 
		  Election 2000 Web Archive</i></b>.</p>
		<table border=1 cellspacing=0 cellpadding=3  width="85%" align="center" bordercolor="#CCCCCC">
		  <tr> 
			<td width=221 valign=top class="SubHeaderSmaller"> 
			  <p>URLS/web sites</p>
			</td>
			<td width=221 valign=top class="SubHeaderSmaller"> 
			  <p>797</p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>Crawl Dates</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>August 1, 2000 to January 21, 2001</p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>Crawler</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>Internet Archive/Compaq Mercator</p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>Crawl Periodicity</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>Daily</p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>HTTP Code 200</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>72,135,149 objects</p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>HTTP Code 400</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>12,642,026 </p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>HTTP Code 300</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>2,646,940 </p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>HTTP Code 500</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>56,804</p>
			</td>
		  </tr>
		</table>
		<p class=MsoCaption><b><i>Chart 2: HTTP return codes for all objects in 
		  the collection</i></b>. </p>
		<p class=normal>See Appendix A for a complete listing of the Election 
		  2000 Web Archive HTTP codes and a link to a description of codes.</p>
		<h2 class="SubHeaderSmall">Collection File Analysis</h2>
		<p class=normal>Upon completion of the five-month crawl, the Election 
		  2000 Web Archive consisted of 72,135,149 (the HTTP Return Code 200), 
		  valid (good) objects collected. Internet Archive did a cursory pre-shipment 
		  de-duping -- where duplicate documents are deleted from the collection 
		  -- and removed 59,429,760 duplicate objects. Despite this, some duplicates 
		  remain: the Election 2000 Web Archive consists of 12,705,359 valid objects; 
		  however, a checksum analysis of the archive files indicates that of 
		  the 12,705,359 valid objects, only 9,972,695 are unique objects. </p>
		<p class=normal>Chart 3 provides a breakdown of the Election 2000 Web 
		  Archive file formats for HTTP Code 200. The majority of the archive 
		  format is document type information files (HTML, Word, PDF, RTF) and 
		  images files, probably associated with the document type files. File 
		  formats for this collection are as follows:</p>
		<table border=1 cellspacing=0 cellpadding=3  width="85%" align="center">
		  <tr> 
			<td width=148 valign=top class="SubHeaderSmall"> 
			  <p>File Format</p>
			</td>
			<td width=148 valign=top class="SubHeaderSmall"> 
			  <p>Count (12,705,359) </p>
			</td>
			<td width=148 valign=top class="SubHeaderSmall"> 
			  <p>Unique (9,972,695)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>HTML/TEXT/RTF</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>11,134,391 (88%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>9,246,786 (92%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>JAVASCRIPT/CSS</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>1215 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>248 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>MS/WORD</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>9225 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>2897 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>PDF</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>74,365 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>21,664 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>IMAGES</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>739,228 (6%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>690,233 (7%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>AUDIO</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>29,045 (&gt;1%) </p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>7,019 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>VIDEO</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>5,031 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>1,489 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>ZIP</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>1,437 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>294 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>FLASH</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>0 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>0 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>XML</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>557 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>105 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>OTHER</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>7,268 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>1,960 (&gt;1%)</p>
			</td>
		  </tr>
		</table>
		<p class=MsoCaption>Chart 3: Election 2000 Web Archive file formats for 
		  HTTP Code 200.</p>
		<h2 class="SubHeaderSmall">Cataloging and Access</h2>
		<p class=normal>Election 2000 has a collection-level catalog record (Fig. 
		  2) Currently the record points to the Internet Archive copy of the Collection. 
		  Due to time constraints and higher priorities, there are no current 
		  plans to provide in-depth descriptive cataloging at the website level. 
		  Full Web site/URL lists will be provided by the Library to provide access 
		  to the archive. Additionally, the archive may be fully indexed by a 
		  search engine when it is available from the Library's Web site.<a name="fig2"></a></p>
		<p class=normal align="center"><a href="grotke.fig2.html"><img src="grotke.fig2.jpg" width="400" height="386" border="0"></a></p>
		<p class=normal>&nbsp;</p>
		<p class=MsoCaption>Fig 2. Snapshot of the Election 2000 catalog record 
		  (full record).&nbsp;</p>
		<h1 class="SubHeader">September 11th</h1>
		<p class=normal>&quot;It is the job of a library to collect and make available 
		  these materials so that future scholars, educators and researchers can 
		  not only know what the official organizations of the day were thinking 
		  and reporting about the attacks on America on Sept. 11, but can read 
		  the unofficial, 'online diaries' of those who lived through the experience 
		  and shared their points of view,&quot; said Winston Tabb, Associate 
		  Librarian for Library Services. &quot;Such sites are very powerful primary 
		  source materials.&quot; </p>
		<p class=normal>&quot;The Internet is as important as the print media 
		  for documenting these events,&quot; said Diane Kresh, the Library's 
		  Director of Public Service Collections. &quot;Why? Because the Internet 
		  is immediate, far-reaching, and reaches a variety of audiences. You 
		  have everything from self-styled experts to known experts commenting 
		  and giving their viewpoint.&quot; (http://www.loc.gov/today/pr/2001/01-150.html)</p>
		<h2 class="SubHeaderSmall">General Information</h2>
		<p class=normal>The MINERVA team had completed the Election 2000 Web Archive, 
		  and had begun discussions with WebArchivist.org and the Internet Archive 
		  about the potential for an Election 2002 collection. As preparations 
		  were underway, the tragic events of September 11, 2001, occurred, prompting 
		  Web creators around the world to respond by creating memorial sites, 
		  tribute pages and survivor registries. Corporations and non-profits 
		  solicited donations for charity. News sites from countless countries 
		  dedicated their resources to reporting the disaster and its aftermath, 
		  and government sites sought to inform and reassure the people. The Library 
		  of Congress and its partners scrambled to start collecting this content 
		  that sprang up immediately. Sites were selected by Recommending Officers 
		  at the Library of Congress, by the Internet Archive,by WebArchivist.org, 
		  and by the public. This archive consists of over 30,000 Web sites.</p>
		<h2 class="SubHeaderSmall">Access</h2>
		<p class=MsoNormal>On October 11, 2001, the September 11 Web Archive <span class="normal">was</span> 
		  released to the public. </p>
		<p class=MsoNormal>The September 11 Web Archive is currently hosted by 
		  the<a
href="http://www.archive.org/"> Internet Archive</a> at <a href="http://september11.archive.org/">http://september11.archive.org/</a>. 
		  <a href="http://www.webarchivist.org/">WebArchivist.org </a>developed 
		  and published fo<span class="normal">r</span> public access the user 
		  interface found on the <a href="http://september11.archive.org/">september11.archive.org</a> 
		  Web site (Fig. 3).</p>
		<p class=MsoNormal align="center"><img src="grotke.fig3.jpg" width="400" height="382"></p>
		<p class=MsoCaption>Fig. 3: Snapshot of the September 11 Web Archive, 
		  October 2001.</p>
		<p class=normal>The Library has received the archive and is processing 
		  it for long-term preservation and access. Once processing and production 
		  of the Library's interface for the archive is complete, the September 
		  11 Web Archive will be made available to the public from the Library's 
		  MINERVA Web site.</p>
		<h2 class="SubHeaderSmall">Collection Interface</h2>
		<p class=normal>While the collection is hosted by the Internet Archive, 
		  it is searchable by date, by URL, and by category via the Wayback Machine. 
		</p>
		<h2 class="SubHeaderSmall">Detailed Collection Information</h2>
		<p class=normal>Chart 4 provides a general statistical overview of the 
		  September 11<sup>th</sup> Collection HTTP return codes for all objects 
		  in the archive.</p>
		<table border=1 cellspacing=0 cellpadding=3  align="center" width="85%" bordercolor="#CCCCCC">
		  <tr> 
			<td width=221 valign=top class="SubHeaderSmall"> 
			  <p>URLS</p>
			</td>
			<td width=221 valign=top class="SubHeaderSmall"> 
			  <p>30,000+</p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>Crawl Dates</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>September 11, 2001- 6 December, 2001</p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>Crawler</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>Internet Archive/ALEXA crawler</p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>Crawl Periodicity</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>Daily</p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>HTTP Code 200</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>331,299,192 objects</p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>HTTP Code 400</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>15,925,789</p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>HTTP Code 300</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>18,762,095</p>
			</td>
		  </tr>
		  <tr> 
			<td width=221 valign=top class="normal"> 
			  <p>HTTP Code 500</p>
			</td>
			<td width=221 valign=top class="normal"> 
			  <p>1,634,926</p>
			</td>
		  </tr>
		</table>
		<p class=MsoCaption>Chart 4: HTTP return codes for objects in the September 
		  11 Web Archive. </p>
		<p class=normal>See Appendix A for a complete listing of the HTTP codes 
		  and a link to a description of codes.</p>
		<h2 class="SubHeaderSmall">Collection File Analysis</h2>
		<p class=normal>At the end of the three-month crawl, the September 11th 
		  Web Archive consisted of 331,299,187 (the HTTP Return Code 200) valid 
		  (good) objects. The Library's contractual requirement included a complete 
		  de-duping of the collection, because of the enormous size (5 terabytes 
		  of data). Using a checksum analysis of the Collection, after de-duping 
		  the Library's September 11th Collection consists of 55,224,374 valid 
		  unique objects, providing a reduction of size from 5 terabytes of data 
		  to 1 terabyte. </p>
		<p class=normal>Chart 5 provides a breakdown of the file formats for HTTP 
		  Code 200. The majority of formats are document type information files 
		  (HTML, Word, PDF, RTF); however, this archive has a greater percentage 
		  than the other Library Web archives of graphic formats. File formats 
		  areas follows:</p>
		<table border=1 cellspacing=0 cellpadding=3  align="center" width="85%">
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>File Format</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>Count (331,299,187 ) </p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>Unique (55,224,374)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>HTML/TEXT/RTF</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>192,565,878 (60%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>45,651,531 (82%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>JAVASCRIPT/CSS</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>3,238,926 (1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>617,426 (1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>MICROSOFT APPS</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>1,028,754 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>66,673 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>PDF</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>4,560,763 (1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>484,662 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>IMAGES</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>126,829,266 (38%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>7,883,425 (15%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>AUDIO</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>877,372 (&gt;1%) </p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>150,274 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>VIDEO</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>208,492 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>32,587 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>ZIP</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>217,659 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>29,616 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>FLASH</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>245,936 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>14,313 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>XML</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>61,173 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>5,901 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>OTHER</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>1,462,492 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>287,453 (&gt;1%)</p>
			</td>
		  </tr>
		</table>
		<p class=MsoCaption>Chart 5: September 11th Web Archive file formats for 
		  HTTP Code 200.</p>
		<h2 class="SubHeaderSmall">Cataloging</h2>
		<p class=normal>A collection-level bibliographic record (Fig. 4) currently 
		  points to the Internet Archive. </p>
		<p class=normal>WebArchivist.org is working with the Library to create 
		  catalog records for 2,500 of the 30,000 Web sites. The remaining sites 
		  will be searchable using the Wayback Machine.</p>
		<p class=normal><a name="fig4"></a></p>
		<p class=MsoNormal align="center"><a href="grotke.fig4.html"><img src="grotke.fig4.jpg" width="400" height="379" border="0"></a></p>
		<p class=MsoCaption>Fig. 4: Snapshot of the bibliographic record for the 
		  September 11 Web Archive.</p>
		<h1 class="SubHeader">Olympics 2002 Web Archive</h1>
		<h2 class="SubHeaderSmall">General Information</h2>
		<p class=normal>The Olympics 2002 Web Archive presents a daily snapshot 
		  of 70 Web sites selected by the Recommending Officer for sports at the 
		  Library of Congress, captured generally during 1-2 A.M. Pacific Time 
		  by the Internet Archive. The 2002 Olympics were selected because they 
		  were held in the United States.</p>
		<h2 class="SubHeaderSmall">Detailed Collection Information</h2>
		<p class=normal>Chart 6 provides a general overview of the Olympics 2002 
		  Web Archive. The sites in the collection consist of the Olympic 2002-related 
		  Web sites of the United States Olympic Committee, the official site 
		  for Salt Lake 2002, and the official Olympics Web site, plus 67 worldwide 
		  press Web sites.</p>
		<p class=normal>The Library's contractual requirement did not include 
		  a requirement for a de-duping of the collection due to its small size. 
		  The Olympics 2002 Web Archive is not currently available remotely or 
		  onsite at the Library of Congress. The Library has received the archive 
		  and is processing it for long-term preservation and access, and is working 
		  on interface and access issues.</p>
		<table border=1 cellspacing=0 cellpadding=3  align="center" width="85%">
		  <tr> 
			<td width=100 valign=top class="SubHeaderSmall"> 
			  <p>URLS</p>
			</td>
			<td width=250 valign=top class="SubHeaderSmall"> 
			  <p>70</p>
			</td>
		  </tr>
		  <tr> 
			<td width=100 valign=top class="normal"> 
			  <p>Crawl Dates</p>
			</td>
			<td width=250 valign=top class="normal"> 
			  <p>February 7, 2002 February 27, 2003</p>
			</td>
		  </tr>
		  <tr> 
			<td width=100 valign=top class="normal"> 
			  <p>Crawler</p>
			</td>
			<td width=250 valign=top class="normal"> 
			  <p>Internet Archive/ALEXA crawler</p>
			</td>
		  </tr>
		  <tr> 
			<td width=100 valign=top class="normal"> 
			  <p>Crawl Periodicity</p>
			</td>
			<td width=250 valign=top class="normal"> 
			  <p>Daily</p>
			</td>
		  </tr>
		  <tr> 
			<td width=100 valign=top class="normal"> 
			  <p>HTTP Code 200</p>
			</td>
			<td width=250 valign=top class="normal"> 
			  <p>18,445,502 objects</p>
			</td>
		  </tr>
		  <tr> 
			<td width=100 valign=top class="normal"> 
			  <p>HTTP Code 400</p>
			</td>
			<td width=250 valign=top class="normal"> 
			  <p>420,591</p>
			</td>
		  </tr>
		  <tr> 
			<td width=100 valign=top class="normal"> 
			  <p>HTTP Code 300</p>
			</td>
			<td width=250 valign=top class="normal"> 
			  <p>2,157,116</p>
			</td>
		  </tr>
		  <tr> 
			<td width=100 valign=top class="normal"> 
			  <p>HTTP Code 500</p>
			</td>
			<td width=250 valign=top class="normal"> 
			  <p>4,680</p>
			</td>
		  </tr>
		</table>
		<p class=MsoCaption>Chart 6: HTTP Olympics 2002 Web Archive return codes. 
		</p>
		<p class=normal>See Appendix A for a complete listing of the HTTP codes 
		  and a link to a description of codes.</p>
		<h2 class="SubHeaderSmall">Collection File Analysis</h2>
		<p class=normal>Of the 18,445,502 valid objects returned for this three-week 
		  collection, there were 6,696,026 valid unique objects. Approximately 
		  85% of the archive consists of docume<span class="normal">nt type information 
		  files (HTML, Word, PDF, RTF). File formats for this archive are as follows:</span></p>
		<table border=1 cellspacing=0 cellpadding=3  align="center" width="85%">
		  <tr> 
			<td width=148 valign=top class="SubHeaderSmall"> 
			  <p>File Format</p>
			</td>
			<td width=148 valign=top class="SubHeaderSmall"> 
			  <p>Count (18,445,502 ) </p>
			</td>
			<td width=148 valign=top class="SubHeaderSmall"> 
			  <p>Unique (6,696,026)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>HTML/TEXT/RTF</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>15,281,190 (83%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>5,679,313 (85%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>JAVASCRIPT/CSS</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>386,171 (2%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>279,792 (4%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>MICROSOFT APPS</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>2118 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>729 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>PDF</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>28,099 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>10,545 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>IMAGES</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>2,666,032 (15%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>690,233 (10%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>AUDIO</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>50,579 (&gt;1%) </p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>21,361 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>VIDEO</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>10,773 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>5,608 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>ZIP</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>1,512 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>759 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>FLASH</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>5046 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>1630 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>XML</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>55 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>52 (&gt;1%)</p>
			</td>
		  </tr>
		  <tr> 
			<td width=148 valign=top class="normal"> 
			  <p>OTHER</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>11,694 (&gt;1%)</p>
			</td>
			<td width=148 valign=top class="normal"> 
			  <p>4,579 (&gt;1%)</p>
			</td>
		  </tr>
		</table>
		<p class=MsoCaption>Chart 7: Olympics Archive file formats for HTTP Code 
		  200.</p>
		<p class=normal>Because the Olympics 2002 Web Archive consists primarily 
		  of worldwide news and newspaper Web sites, the sites tend to consist 
		  of online graphical advertisements which change at least daily and may 
		  explain why the duplicate count of images was low. </p>
		<h2 class="SubHeaderSmall">Cataloging</h2>
		<p class=normal>Cataloging is currently underway for the Olympics 2002 
		  Web Archive. The Library will provide a collection level record and 
		  is planning to assign more in-depth descriptive cataloging at the Web 
		  site level, based on the Library of Congress Metadata Object </p>
		<h4 class="SubHeaderSmall">Description Schema (MODS)<br>
		  (<a href="http://www.loc.gov/standards/mods/">http://www.loc.gov/standards/mods/</a>). 
		</h4>
		<p class=normal>Machine-generated administrative and preservation metadata 
		  for each base URL in the collection is also being generated.</p>
		<h1 class="SubHeader">Additional Collections In Production</h1>
		<p class=normal>During 2002, the Library commissioned the following crawls:</p>
	  </div>
	  <blockquote> 
		<div class=Section1> 
		  <p><b>Election 2002:</b> A Web archive of United States Senate and House, 
			state gubernatorial and city mayoral election contests. There are 
			approximately 4,000 Web sites in the collection, ranging from candidate, 
			newspaper, advocacy, party, government, and other sites. The crawl 
			began in August 2002 and ended on December 1, 2002. Cataloging, interface 
			design, quality review and finalizing the copyright notification process 
			are underway. The collection of candidate Web sites will be available 
			remotely in March 2003; remaining materials by September 2003. Partners 
			include WebArchivist.org, Internet Archive, and the Pew Internet &amp; 
			American Life Project.</p>
		</div>
		<div class=Section1> 
		  <p><b>September 11 Remembrance:</b> A Web archive of approximately 2,000 
			Web sites having content related to the September 11 anniversary, 
			crawled from 11 September 2002 to18 September 2002. Quality review 
			is currently being conducted. At this point, there is no timeframe 
			for making this archive available remotely or onsite at the Library 
			of Congress, although some integration with the existing September 
			11 Web Archive is anticipated. </p>
		</div>
		<div class=Section1><b>The 107<sup>th</sup> Congress:</b> A one-time crawl 
		  of the Web sites of the 107<sup>th</sup> Congress during the week of 
		  15 December 2002. A quality review is currently underway. The MINERVA 
		  team is investigating cataloging and access to these materials.</div>
	  </blockquote>
	  <div class=Section1> 
		<h1 class="SubHeader">Conclusions</h1>
		<p class=normal>This paper has provided an update of Web preservation 
		  projects at the Library of Congress to date. With over 35,000 sites 
		  archived since 2000, the Library of Congress has come along way -- much 
		  has been learned about the selection, harvesting, and cataloging of 
		  Web sites since William Arms and the MINERVA Web preservation team began 
		  their investigations. The future will bring new challenges and collaborations: 
		  a pilot with OCLC to test cataloging tools, testing of new standards 
		  (METS/MODS), partnerships with experts and others in the archival and 
		  library community, research and development, and long term preservation 
		  issues. The Library of Congress recognizes the urgency of the potential 
		  loss of at-risk material, while understanding the need to take a careful 
		  look at the challenges (technical and otherwise) that we face. </p>
		<p class=normal>Today, information technologies that are increasingly 
		  powerful and easy to use, especially like those that support the World 
		  Wide Web, have unleashed the production and distribution of digital 
		  information. Such information is penetrating and transforming nearly 
		  every aspect of our culture. If we are effectively to preserve for future 
		  generations the portion of this rapidly expanding corpus of information 
		  in digital form that represents our cultural record, we need to understand 
		  the costs of doing so and we need to commit ourselves technically, legally, 
		  economically and organizationally to the full dimensions of the task. 
		  Failure to look for trusted means and methods of digital preservation 
		  will certainly exact a stiff, long-term cultural penalty. (Task Force 
		  on Archiving of Digital Information, 1996)</p>
		<h1 class="SubHeader">References</h1>
		<p class=ReferencesText>Arms, W. Y. (2001) <i>Web Preservation Project 
		  Final Report</i>. Retrieved January 15 2003, from <a href="http://www.loc.gov/minerva/" target="_blank"><u>http://www.loc.gov/minerva/</u></a></p>
		<p class=ReferencesText>Arms, W. Y. (2001)<i> Web Preservation Project 
		  Interim Report</i>. Retrieved January 15, 2003, from <a
href="http://www.loc.gov/minerva/" target="_blank"><u>http://www.loc.gov/minerva/</u></a></p>
		<p class=ReferencesText>National Library of Australia.<i> PANDORA Archive</i>. 
		  Consulted January 10, 2003, from<u> </u><a href="http://pandora.nla.gov.au/index.html" target="_blank"><u>http://pandora.nla.gov.au/index.html</u></a></p>
		<p class=ReferencesText>National Research Council. ,Committee on an Information 
		  Technology Strategy for the Library of Congress, Computer Science and 
		  Telecommunications Board, Commission on Physical Sciences, Mathematics, 
		  and Applications, (2000). <i>LC21: A Digital Strategy for the Library 
		  of Congress</i>. National Academy Press. Washington, D. C. Consulted 
		  January 15, 2003, from <a
href="http://www.nap.edu/books/0309071445/html/" target="_blank"><u>http://www.nap.edu/books/0309071445/html/</u></a><u></u></p>
		<p class=ReferencesText>Sweden. Royal Library. <i>Kulturarw</i><sup>3</sup>. 
		  Consulted January 10, 2003, from <a href="http://www.kb.se/kw3/ENG/Default.htm" target="_blank"><u>http://www.kb.se/kw3/ENG/Default.htm</u></a><u></u></p>
		<p class=ReferencesText>Task Force on Archiving of Digital Information. 
		  (1996).<i> Preserving Digital Information: Report of the Task Force 
		  on Archiving of Digital Information / commissioned by the Commission 
		  on Preservation and Access and the Research Libraries Group, Inc</i>.. 
		  Consulted January 10, 2003. <u><a href="http://www.rlg.org/ArchTF/tfadi.index.htm" target="_blank">http://www.rlg.org/ArchTF/tfadi.index.htm</a></u></p>
		<p class=ReferencesText>United States. Library of Congress. (2001). <i>Library 
		  of Congress and Alexa Internet Announce Election 2000 Collection</i>. 
		  Consulted January 10, 2003, from <a
href="http://www.loc.gov/today/pr/2001/01-091.html" target="_blank"><u>http://www.loc.gov/today/pr/2001/01-091.html</u></a></p>
		<p class=ReferencesText>United States. Library of Congress.<i> </i>(2002). 
		  <i>Metadata Object Description Schema (MODS) Official Web Site</i>. 
		  Updated December 18, 2002. Consulted January 15, 2003, from <a href="http://www.loc.gov/standards/mods/" target="_blank">http://www.loc.gov/standards/mods/</a></p>
		<p class=ReferencesText>United States. Library of Congress. (2001). Library 
		  of Congress, Internet Archive, webarchivist.org and the Pew Internet 
		  &amp; American Life Project Announce Sept. 11 Web Archive. Consulted 
		  January 10, 2003, from <a
href="http://www.loc.gov/today/pr/2001/01-150.html" target="_blank"><u>http://www.loc.gov/today/pr/2001/01-150.html</u></a> 
		</p>
	  </div>
	  <p class="smallPurple">&nbsp;</p>
	  <!-- #EndEditable --></td>
  </tr>
</table>

<p class="smallPurple">&nbsp;</p>
<!--htdig_noindex-->

<!-- analytics scripts -->
<!-- tynt script -->
<script type="text/javascript">tyntVariables = {"ap":"Read more: "};</script> 
<script type="text/javascript" src="http://tcr.tynt.com/javascripts/Tracer.js?user=aTNeQ-tzOr36a6adbiUzgI&amp;s=130&amp;cc=6&amp;st=1"></script>
<noscript></noscript>

<!-- google analytics script -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26332456-1']);
  _gaq.push(['_setDomainName', '.archimuse.com']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!--chartbeat script -->
<script type="text/javascript">
var _sf_async_config={uid:3385,domain:"archimuse.com"};
(function(){
  function loadChartbeat() {
    window._sf_endpt=(new Date()).getTime();
    var e = document.createElement('script');
    e.setAttribute('language', 'javascript');
    e.setAttribute('type', 'text/javascript');
    e.setAttribute('src',
       (("https:" == document.location.protocol) ? "https://s3.amazonaws.com/" : "http://") +
       "static.chartbeat.com/js/chartbeat.js");
    document.body.appendChild(e);
  }
  var oldonload = window.onload;
  window.onload = (typeof window.onload != 'function') ?
     loadChartbeat : function() { oldonload(); loadChartbeat(); };
})();

</script>

<!--/htdig_noindex-->

</body>
<!-- #EndTemplate -->
<!-- Mirrored from www.museumsandtheweb.com/mw2003/papers/grotke/grotke.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 20:32:35 GMT -->
</html>
