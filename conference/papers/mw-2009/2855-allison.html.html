<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><!-- InstanceBegin template="/Templates/mw2009-papers.dwt" codeOutsideHTMLIsLocked="true" -->

<!-- Mirrored from www.museumsandtheweb.com/mw2009/papers/allison/allison.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 16:55:04 GMT -->
<head>
<!-- InstanceBeginEditable name="HeadPageTitle" -->
<title>Archives &amp; Museum Informatics: Museums and the Web 2009: Paper: Allison, J., and J. Fillwalk, Hybrid Realities: Visiting the Virtual Museum </title>
<!-- InstanceEndEditable --><!-- InstanceBeginEditable name="metaTitle" -->
<meta name="title" content="Archives  &amp; Museum Informatics: Museums and the Web 2009: Proceedings" />
<!-- InstanceEndEditable --><!-- InstanceBeginEditable name="Keywords" -->
<meta name="Keywords" content=", paper, research, MW2009, conference, museum, museums and the web, mw, matw, museums &amp; the web, archives &amp; museum informatics, archives, museums, informatics, digital museums, digital archives, digital art, museums online, archives online, libraries online, world wide web, www, web site, website, museum web site, museum website, howto,  conferences, professional papers, peer-reviewed, peer reviewed, peer review, digital libraries, online exhibits, online exhibitions, on-line" />
<!-- InstanceEndEditable --><!-- InstanceBeginEditable name="Description" -->
<meta name="Description" content="Museums and the Web 2009: the international conference for culture and heritage on-line" />
<!-- InstanceEndEditable --><!-- InstanceBeginEditable name="copyright" -->
<meta name="copyright" content="Archives &amp; Museum Informatics, 2009" />
<!-- InstanceEndEditable -->
<meta name="document-class" content="Published" />
<meta name="document-rating" content="General" />
<meta http-equiv="Content-Language" content="EN" />
<meta name="document-rights" content="Copyrighted Work" />
<!-- InstanceBeginEditable name="charset" -->
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<!-- InstanceEndEditable -->
<link rel="stylesheet" href="../../css/mw2009.css" type="text/css" media="screen" />
<link rel="stylesheet" href="../../css/papers.css" type="text/css" media="screen" />
<link rel="stylesheet" href="../../css/mw2009-noNews.css" type="text/css" media="screen" />
<link rel="stylesheet" href="../../css/print.css" type="text/css" media="print" />
<!--htdig_noindex-->
<!-- InstanceBeginEditable name="ImageRotateScript" --><!-- InstanceEndEditable -->
<!--/htdig_noindex-->
<!--htdig_noindex-->
<!-- InstanceBeginEditable name="PageScript" --><!-- InstanceEndEditable -->
<!--/htdig_noindex-->
</head>
<body>
<div id="container">
  <div id="header" onclick="location.href='../../index.html';" style="cursor:pointer;"> </div>
  <!--htdig_noindex-->
  <div id="top-nav">
    <ul id="top-nav-list">
      <li><a href="../../register/index.html">Register</a></li>
      <li><a href="../../dates/index.html">Key Dates</a></li>
      <li><a href="../../sescal/index.html">Schedule</a></li>
      <li><a href="../../local/index.html">Local Info</a></li>
    </ul>
    <!--/htdig_noindex-->
  </div>
  <div id="header-photo"> 
	 <!-- InstanceBeginEditable name="header-photo" --> <img src="../../images/rotate/header-1.jpg"  height="132" width="229" alt="MW-photo" />
	 <!-- InstanceEndEditable --></div>
<div id="print-title">
	<h1>Museums and the Web 2009: the international conference for culture and heritage on-line</h1>
	<h2>produced by Archives &amp; Museum Informatics</h2>
	<h3>site at http://www.archimuse.com/mw2009/</h3>	 
</div> 
 <div id="date"> <a href="../../sescal/index.html">April 15-18, 2009</a><br />
    <a href="../../local/index.html">Indianapolis, Indiana, USA</a> </div>
  <div id="title">
    <h1> 
		<!-- InstanceBeginEditable name="PageTitle" --> Hybrid Realities: Visiting the Virtual Museum

		<!-- InstanceEndEditable --> </h1>
  </div>
  <!--htdig_noindex-->
  <div id="main-content">
    <div id="news">
    </div>
    <!--/htdig_noindex-->
    <div id="intro-paragraph"> 
		<!-- InstanceBeginEditable name="IntroParagraph" --> 		
		<h2 class="Author"><a href="../../bios/au_445017089.html">Jesse Allison</a> and <a href="../../bios/au_445017094.html">John Fillwalk</a>, BSU Institute for Digital
	    Intermedia Arts, USA</h2>
		<p class="URL"><a href="../http://idiarts.org/">http://idiarts.org</a></p>
		<h3 class="AbstractTitle">Abstract</h3>
		<p class="AbstractText">Virtual worlds provide a platform in which to construct
		  compelling experiences not possible within the material and temporal
		  constraints of the physical world. The virtual realm has the potential to be
		  united and engaged by physicality &ndash; informing and transforming the audience&rsquo;s
		  experience of exhibition in a profoundly transformative nature. The Institute
		  for Digital Intermedia Arts at Ball State University has been incorporating
		  mixed-reality approaches into museum exhibitions, musical performances, installation
		  art, and interface over the last several years. This paper documents specific
		  explorations of the opportunities of the Second Life environment for
		  mixed-reality experiences &ndash; analyzing approaches to bridging the worlds; such
		  as, media streaming, client-side interaction, an external Web server communication
	    hub, as well as opportunities for human/computer interaction.</p>
		<p class="keywords">Keywords: Interactive exhibition, Second Life, Virtual
	    Worlds, mixed reality.</p>

		<!-- InstanceEndEditable --> 
	</div>
    <div id="body-text"> 
		<!-- InstanceBeginEditable name="BodyText" -->

		<h2>Betwixt And Between</h2>
		<h3>Overview</h3>
		<p>One of the most engaging features of virtual worlds is their
		  ability to represent our physicality in a three-dimensional spatialized
		  environment. Through the simulacrum of the avatar, we can negotiate spatial
		  environments through this represention of ourselves. This vicarious connection
		  to virtualized spaces provides experiences that can transcend more typical
		  screen-based digital phenomena. These are more compelling still when the plane
		  of the screen or fourth wall is expanded to incorporate physical reality in the
	    design of time-based and spatialized hybrid mixed-reality constructions.</p>
		<p>The participants become the mediators of these inputs,
		  negotiating the relations between imagery, sound and interactions. The
		  participants themselves are the conduits between the worlds, in providing rich
		  opportunities (relevant to experience) making physical and cognitive
		  connections that result in the fundamental link across the divide. Experiences
		  channeled vicariously through the avatar create a compelling association
		  between the participant and virtual space. As avenues are provided to the
		  participant&rsquo;s associated avatar to have<i> </i>a
		  new influence over the physical world, reflexively they also can affect the
		  course of the virtual. The bridge is thus strengthened and the experience
		  deepened &ndash; eventually creating a context of <i>parallel
	    reality</i> (Damer, 2008).</p>
		<p>To span between reality and a virtual world (Vasquez de la
		  Velasco, 2008) such as Second Life, three primary connections need to be made:
		  the visual, the aural, and the interactive. Ideally, these connections should
		  be integrated bilaterally, flowing in both directions. Imagery, data and sounds
	    from physical reality should inform the virtual realm, and vice versa.</p>
		<h2>Avatar-Based Experience</h2>
		<p>The conventional approach to accessing the virtual world is
		  by means of an avatar that can negotiate virtual space. An example is the
		  virtual collaborative space developed for the Las Americas Virtual Design
		  Studio collaboration (LAVDS), architecture studios between the United States
		  and Latin America united in a virtual world (Schroeder, 2008). Ball State University&rsquo;s
		  College of Architecture and Planning and nine Latin American universities
		  teamed up to work on a design studio which paralleled the design of a disaster
		  surge center created by a real life architectural firm. Collaboration is achieved
		  through the forms of avatar interactions: text, data, video, audio, and voice
		  chat using the keyboard and mouse paradigm. The virtual structure is a
		  deconstruction of the notion of a building itself. Once architecture is
		  unfettered from the physical constraints and needs such as gravity, nature, and
		  materiality, it is free to focus solely on the programming of space and
		  engagements by its users. The LAVDS structure is a configurable, collaborative
		  interface that responds to its users&rsquo; requirements via reactive data, media and
		  form. In this project the participants affect the virtual world through the
	    avatar&rsquo;s interactions. </p>
		<p class="caption"><img src="fillwalk_Allison_Fig1.jpg" alt="figure 1" width="500" height="298" /></p>
		<p class="caption">Fig. 1: LAVDS Collaborative Space (2008)</p>
		<p>The Second Life virtual realm is a potent platform for
		  delivering this mode of interaction. It is an engaging environment that has the
		  ability to transmit live images, geometry, data and audio to and from the
		  virtual realm. Vitally important is the expanding number of modalities of interacting
		  with content inside and out of the virtual world. The Institute for Digital
		  Intermedia Arts (IDIAA) has extensively engaged Second Life as a platform for
	    mixed-reality experiences, exhibitions and performances. </p>
		<h2>Experiences in Audio/Video Interactions</h2>
		<p>Convincing aural and visual experiences are an important
		  factor in transforming a virtual world into an immersive user experience. The
		  three-dimensional nature of the Second Life environment is retained both
		  visually and aurally, offering opportunities to spatialize traditionally one or
	    two-dimensional media. </p>
		<h3>Video streaming</h3>
		<p>Streaming video can be utilized to great effect in Second
		  Life. Interesting possibilities occur when exploring the ability to spatialize
		  traditional two-dimensional video applied as a texture on three-dimensional
		  geometry. IDIAA has explored various avenues of presentation in virtual video
		  installations, such as in <i>Survey v3</i> (Figure
	    2) and <i>Final Wisdom I v2</i> (Figure 3). </p>
		<p class="caption"><img src="fillwalk_Allison_Fig2.jpg" alt="figure 2" width="500" height="298" /></p>
		<p class="caption">Fig 2: Still from Survey v3 (2008)</p>
		<p class="caption"><img src="fillwalk_Allison_Fig3.jpg" alt="figure 3" width="500" height="298" /></p>
		<p class="caption">Fig 3: Still from Final Wisdom I v2 (2008)</p>
		<p>Although traditional media streaming in Second Life is
		  limited to one stream per parcel (or division of virtual land), developments
		  have been made in collaboration with Mitch McKenzie, IDIAA Research Fellow, to
		  allow multiple streams that are selectively delivered externally from Second
		  Life and applied to textures on 3D objects. When paired with proximity
		  detection, this allows for personal or group-experienced targeted media to be
	    triggered and disseminated on demand.</p>
		<p>Real-time video streaming is another video source wrought
		  with possibilities. In <i>Displaced Resonance </i>(Figure 4), Michael Pounds, John Fillwalk and Jesse Allison created a
		  physical sonic installation based on the resonant acoustical frequencies of
		  pipes. They later emulated, virtualized, and expanded the installation into a
		  Second Life version that referenced and enhanced the interactive model of the
		  physical work. When the installation was exhibited, the physical version incorporated
		  a display of the Second Life virtualization, and the Second Life version had a
		  stream of people interacting locally with the installation. In being manifested
		  and mirrored in the virtual, the installation had in essence gained its own
		  reflection presence or avatar. Participants on either side could view and
		  interact with the two installations side by side, creating a unique and engaging
	    event (Figure 5). </p>
		<p class="caption"><img src="fillwalk_Allison_Fig4.jpg" alt="figure 4" width="500" height="298" /></p>
		<p class="caption">Fig 4: Still from Displaced Resonance (2007)</p>
		<p class="caption"><img src="fillwalk_Allison_Fig5.jpg" alt="figure 5" width="500" height="326" /></p>
		<p class="caption">Fig 5: Still from a mixed-reality reception (2007)</p>
		<h3>Audio streaming</h3>
		<p>Streaming of audio is fairly similar to video streaming,
		  with one benefit: a negligible amount of delay allows for convincing
		  synchronized interactions between the physical and virtual environments. Users
		  can stream audio via Real Time Streaming Protocol (RTSP) to an individual
		  parcel of land in SL and broadcast it from there to the world. Alternatively,
		  they can stream audio directly from the client computer. This has the benefit
		  of being simple to set up; however, the audio stream is tied to the client&rsquo;s
	    avatar, while RTSP streaming can be emitted from any object. </p>
		<h3>Spatialized sound file playback</h3>
		<p>Audio experience in Virtual Worlds can be divided into three
		  categories: sample playback, synthesis, and spatialization (Kramer, 1995). Second
		  Life cannot synthesize sounds itself. Sound is restricted to audio files
		  uploaded to the Second Life server and played in a loop or triggered by stimuli
		  such as events, collisions, and proximity. This can be used to creatively
		  sonify the simulated world. When paired with other techniques for interaction
		  like HTTP requests and client-side influences, it can create convincing
	    physical-to-virtual interactions.</p>
		<p>In <i>Bob Box v4</i> (Figure
		  6), floating boxes use the physics engine to play composed sounds upon
		  collision, turning the physical nature of the objects into the score for the
		  work. <i>Flickr Gettr</i> rapidly creates
		  images pulled from the Web and with each image, triggers short audio clips to
		  create a cumulative sonic effect. In <i>Displaced
		    Resonance</i>, looped sound files increase in intensity based on proximity,
		  creating a gradually shifting timbre dependent on the avatar&rsquo;s spatial relationship
	    with the objects. </p>
		<p><img src="fillwalk_Allison_Fig6.jpg" alt="figure 6" width="500" height="298" /></p>
		<p class="caption">Fig 6: Still from Bob Box v4 (2008) showing streaming video
	    from a live Web cam.</p>
		<p>The primary limiting parameter for this approach is the
		  ten-second restriction per sound source. This becomes an effective solution for
		  event-based and cumulative audio effects, but is rather poor for creating
	    larger temporally directional audio experiences.</p>
		<h3>Web texturing</h3>
		<p>The ability to host texture images outside of the Second Life
		  grid is an important development. Web texturing is meant to provide the ability
		  to display Web pages and images on a primitive within Second Life. At the
		  moment, the imagery is static &ndash; no link or dynamic information is retained. Of
		  more immediate application is the ability for a Web texture to represent text
		  and image content that can be situationally dynamic, such as displaying
	    external information that automatically updates. </p>
		<p>The IDIAA is utilizing this ability to integrate the Ball
		  State University Museum of Art&rsquo;s Digital Images Delivered Online (DIDO) 11,000-piece
		  database where SL virtual museum attendees can search for artworks in the
		  collection based on direct in-world search queries parsing though each image&rsquo;s
		  metadata. This installation is found at the Virtual BSU Museum of Art on the
		  Ball State University SL Public Island 1. Viewers are presented with images of
		  matching artworks and can then choose a specific image to update the Web
		  texture and view the item, incorporating it into their own exhibit arrangement
		  in the gallery. The effect is a three-dimensional, spatialized search engine
		  that employs the gallery itself as the metaphor of browsing portal (Figure 7).
		  A similar effect was used in the <i>Flickr
	    Gettr</i> installation to collect and display queried Flickr images.</p>
		<p class="caption"><img src="fillwalk_Allison_Fig7.jpg" alt="figure 7" width="500" height="298" /></p>
		<p class="caption">Fig 7: View of Virtual Museum Gallery (2008)</p>
		<p>Limitations to this method are that the page must be created
		  and hosted somewhere else, necessitating the support of resources like Web
		  domains, Web applications, and media resources that are external to Second
		  Life. On a similar note, it may mean repurposing or reformatting the
		  information to display it in a way that is represented well in Second Life. The
		  resolution of the incoming page is limited to 1024x1024 pixels, adequate for
		  many textures, but fine details in high resolution images and text cannot be
		  displayed without preprocessing on the Web application side and only displaying
		  small portions of the entire image or text. Another current limitation is that just
		  one Web texture is available per parceled region. Because users can only see Web
		  textures from within the region that the avatar is standing, they are restricted
		  to using only 1024x1024 pixels as texture. Ideally, users would be able to
		  bring an unlimited number of textures in from the Web, allowing for dynamic
	    image content in the virtual world. </p>
		<h2>Interaction and Influence Experiences</h2>
		<p>The communication avenues that are available to transfer
		  information restrict making connections between the virtual world and the
		  physical world. Ideally, these communication avenues would be low latency,
		  flexibly routed messages that could be scripted to initiate a multitude of
		  actions. In practice, most avenues of communication have a specific task in
	    mind, but many can be coerced into other uses.</p>
		<h3>HTTP requests</h3>
		<p>HTTP Requests are typically used to request and post
		  information like Web pages to and from Web servers. With the expansion of Web
		  2.0 based Web services that give access to their internal information,
		  possibilities are expanding exponentially in ways to integrate pertinent information.
		  Scripts in Second Life are able to make requests and utilize the external
		  information within world. As a link, it can be used to pass complex state
		  information in to and out of the virtual world providing a potentially unifying
	    link. </p>
		<p>The authors used this technique in the performance piece <i>Traversal</i> to pass avatar location information
		  out of Second Life and into a live performance. The piece used interactions
		  with objects in a structure in Second Life to generatively perform on an actual
	    pipe organ in Sursa Hall on the Ball State University campus. </p>
		<h3>External Web server</h3>
		<p>To make these interactions more flexible, an intermediary Web
		  server can be employed to collate and prepare information for Second Life and
		  retain states that can be queried from external applications. The Web application
		  effectively serves as an intermediary between Second Life and outside
		  environments, providing the communications link and logic to assimilate the
		  information. Web 2.0 mash-ups (Web sites that integrate information gleaned
		  from multiple Web services such as images from Flickr, social networking from
		  Facebook, and text-messaging services, to name a few) can be easily
		  accomplished with highly developed code in Java, Ruby, and Perl, for example. Performing
		  a similar task through Second Life in-world scripting language of Linden
		  Scripting Language (LSL) would be difficult or impossible to accomplish. Separating
		  the task into an intermediate Web service takes the computational difficulties
		  out of Second Life and simply passes along Second Life-collated information for
	    easy integration. </p>
		<p>In <i>Flickr Gettr</i>, installed
		  at the New Media Consortium&rsquo;s Aho Museum in Second Life, the external Web
		  service was used as an intermediary to query Flickr, receive images and format
		  them for delivery as a second life texture. The Web service then transmitted
		  the images&rsquo; aspect ratios in a second query to allow the Second Life scripts to
	    map the textures properly. </p>
		<p class="caption"><img src="fillwalk_Allison_Fig8.jpg" alt="figure 8" width="500" height="298" /></p>
		<p class="caption">Fig 8: Still from Flickr Gettr (2008)</p>
		<h3>Blackboard</h3>
		<p>The IDIAA is currently developing a set of open source tools
		  uing HTTP requests to integrate SL with the Blackboard learning platform. IDIAA
		  was the inaugural recipient of the Blackboard Greenhouse Grant for Virtual
		  Worlds for the <i>Aesthetic Camera Project</i>,
		  an on-line distance education cinematography unit for virtual worlds developed
		  by John Fillwalk and recognized by the Campus Technology Innovators Award in
		  Virtual Learning. Blackboard is being used as the course-portal hosting the
		  assessments, discussions boards, and mirroring of instructional media assets,
		  while Second Life is engaged as a virtual &ldquo;hands-on&rdquo; studio and synchronous
		  spatialized learning environment. This hybrid model of the union of the two
		  environments allows for a richer distance learning community than can obtained
		  through just one method. The Building Block will securely and seamlessly
		  automate a number of course management processes to augment asynchronous hybrid
	    learning environments.</p>
		<h3>XML RPC</h3>
		<p>XML RPC is a protocol to pass information to and from a Web
		  service. The implementation in Second Life, although functional, has a drawback
		  in that it instantiates a three-second delay, doesn&rsquo;t keep track of queries and
		  results, and can have only one query open at a time (<a
href="../http://wiki.secondlife.com/wiki/Category:LSL_XML-RPC">http://wiki.secondlife.com/wiki/Category:LSL_XML-RPC</a>).
		  This means that under many circumstances, the possibility for lost data exists
		  and delayed data is inevitable. Due to these constraints, HTTP requests are
	    more widely used. </p>
		<h3>Client influence</h3>
		<p>Second Life is generated by two entities: a simulator that
		  holds all of the information about each primitive and what each one&rsquo;s current
		  state is, and the client which receives that information on the local computer
		  and renders the virtual world specific to the user that is logged in. The two
		  pass communications to sychronize events that are created locally, events
		  generated by other clients, and events that are generated through the simulation
	    engine on the server. </p>
		<h3>Keyboard and mouse commands</h3>
		<p>Keyboard and mouse inputs are generally used to interact
		  with Second Life objects. Using software like Max/MSP to generate and send
	    these commands allows us to hijack client-side control for automation purposes. </p>
		<h3>Audio cues</h3>
		<p>The <i>Traversal</i> organ performance required synchronized events to have SL play the physical organ
		  convincingly. Because all of the previous methods of obtaining this information
		  out of SL induce some amount of delay, a client-side approach was taken. Sine
		  waves at various frequencies were loaded into SL and triggered by specific
		  events and physical interactions. These were played locally by the client in
		  complete synchronization with the event. This audio was filtered and analyzed
		  by Max/MSP to track specific frequencies. When the specific sine wave frequency
		  occurred, the associated event was known to be triggered and the note, chord,
	    or parameter change was performed on the organ. </p>
		<p class="caption"><img src="fillwalk_Allison_Fig9.jpg" alt="figure 9" width="500" height="298" /></p>
		<p class="caption">Fig 9: Still from Traversal (2008)</p>
		<h2>Future Possibilities</h2>
		<p>As the exploration and integration of virtual worlds
		  continues to evolve and be adopted, methods for mixing reality and virtuality
		  will expand. Here are a few avenues that appear to be plausible in the near
	    future:</p>
		<ul>
		  <li>Adding the capacity for general messaging from external inputs to
		    the client. This would allow for user control from external software controls
		    such as innovative GUI elements and video tracking, and through them to
		    external hardware and sensors </li>
		  <li>Adding the capacity for general messaging from the client to
		    external software</li>
		  <li>Developing Web or locally hosted textures that would allow for
		    more dynamic delivery of static assets and relieve the expense of paying to
		    upload content to commercial servers</li>
		  <li>Using Web or locally hosted sound files </li>
		  <li>Allowing multiple video and audio streams per parcel</li>
		  <li>Resolving XML-RPC issues to make integrating with some external Web
		    services much simpler. </li>
	    </ul>
		<h2>References</h2>
		<h3>Articles</h3>
		<p class="ReferencesText">Damer, B. (2008). &ldquo;Meeting in the Ether: A brief
	    history of virtual worlds as a medium for user-created events&rdquo;. <i>Journal of Virtual Worlds Research</i> 1(1).</p>
		<p class="ReferencesText">Kramer, G. (1995). &ldquo;Sound and Communication in Virtual
		  Reality&rdquo;. In F. Biocca and M. Levy (Ed.) <i>Communication
	    in the Age of Virtuality</i>. New Jersey: Lawrence Erlbaum Publications, 293-4.</p>
		<p class="ReferencesText">Schroeder, R. (2008). &ldquo;Defining Virtual Worlds and
		  Virtual Environments&rdquo;. <i>Journal of Virtual
	    Worlds Research</i> 1(1).</p>
		<p class="ReferencesText">Category: LSL XML-RPC. Second Life Wiki. Consulted
	    December 10, 2008. <a
href="../http://wiki.secondlife.com/wiki/Category:LSL_XML-RPC">http://wiki.secondlife.com/wiki/Category:LSL_XML-RPC</a></p>
		<h3>Second Life Virtual Works</h3>
		<p class="ReferencesText">Allison, J., J. Fillwalk and M. Pounds (2008). <i>Displaced Resonance</i>. Sonic installation
	    and Virtual installation.</p>
		<p class="ReferencesText">Allison, J. and J. Fillwalk (2008). <i>Bob Box v4</i>. Virtual installation.</p>
		<p class="ReferencesText">Allison, J. and J. Fillwalk (2008). <i>Flickr Gettr</i>. Virtual installation.</p>
		<p class="ReferencesText">Allison, J. and J. Fillwalk (2008). <i>Traversal</i>. Virtual Installation with
	    Physical Organ Performance.</p>
		<p class="ReferencesText">Fillwalk, J. (2008). <i>Survey v3</i>. Virtual video installation.</p>
		<p class="ReferencesText">Fillwalk, J. (2008). <i>Final Wisdom I v2</i>. Virtual video installation.</p>
		<p class="ReferencesText">Vasquez de Velasco, G., A. Angulo, J. Fillwalk, B.
		  Hoopingarner, T. Danehy, and J. Baxter (2008). <i>LAVDS Collaborative Interface.</i> Second Life virtual architecture
	    studio.</p>
<!-- InstanceEndEditable --> </div>
  			<div id="citation">
            		
                <h4>Cite as:</h4>
				<p class="references"><!-- #BeginEditable "OnlineCitation" -->Allison, J., and J. Fillwalk, Hybrid Realities: Visiting the Virtual Museum<!-- #EndEditable -->. In J. Trant and D. Bearman (eds). <em>Museums and the Web 2009: Proceedings</em>.
				 Toronto: Archives &amp; Museum Informatics. Published March 31, 2009. Consulted  

                 <script language="JavaScript" type="text/javascript">
               <!-- <![CDATA[
// current date - based on http://rainbow.arch.scriptmania.com/scripts
// Array of day names
var dayNames = new Array("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday");

var monthNames = new Array("January","February","March","April","May","June","July",
                           "August","September","October","November","December");

var dt = new Date();
var y  = dt.getYear();

// Y2K compliant
if (y < 1000) y +=1900;

document.write(monthNames[dt.getMonth()] + " " + dt.getDate() + ", " + y + ". ");
	                // ]]> -->
				  </script>

http://www.archimuse.com/mw2009/papers/<!-- #BeginEditable "URL" -->allison/allison.html
				 <!-- #EndEditable --></p>
	</div>
</div>
  <!--htdig_noindex-->
  
  <div id="sidebar">
    <div id="side-nav">
      <ul id="side-nav-list">
        <li id="workshops"><a href="../../workshops/index.html" class="menu">Workshops</a></li><li id="sessions"><a href="../../sessions/index.html" class="menu">Sessions</a></li><li id="speakers"><a href="../../speakers/index.html" class="menu">Speakers</a></li><li id="interactions"><a href="../../interact/index.html" class="menu">Interactions</a></li><li id="demonstrations"><a href="../../demos/index.html" class="menu">Demonstrations</a></li><li id="events"><a href="../../events/index.html" class="menu">Events</a></li><li id="exhibits"><a href="../../exhibit/index.html" class="menu">Exhibits</a></li><li id="best"> <a href="../../best/index.html" class="menu">Best of the Web </a></li><li id="pc"><a href="../../thanks/index.html" class="menu">Committees</a></li><li  id="community"><a href="../http://conference.archimuse.com/" class="menu">Community On-line</a></li>
      </ul>
    </div>
    <div id="search-site">
<form method="get" id="searchform" action="http://wp.museumsandtheweb.com/">
<input type="text" class="field" name="s" id="s" placeholder="Search">
<input type="submit" class="submit" name="submit" id="searchsubmit" value="Search">
</form>
    </div>
        <div id="addthis">
    <!-- AddThis Button BEGIN -->
	<script type="text/javascript">var addthis_pub="archimuse";</script>
	<script type="text/javascript">var addthis_brand = "archimuse";</script>
	<script type="text/javascript">var addthis_options = 'twitter, facebook, linkedin, delicious, email, digg, favorites, more';</script>
	<a href="../http://www.addthis.com/bookmark.php?v=20" onmouseover="return addthis_open(this, '', '[URL]', '[TITLE]')" onmouseout="addthis_close()" onclick="return addthis_sendto()"><img src="../../../external.gif?link=http://s7.addthis.com/static/btn/lg-share-en.gif" width="125" height="16" alt="Share"/></a><script type="text/javascript" src="../http://s7.addthis.com/js/200/addthis_widget.js"></script><!-- AddThis Button END -->
</div>
    
    <div id="sidebar-links">
      <ul id="sidebar-links-list">
        <li><a href="../../../index.html" class="produced-by">produced by<br />
          <img src="../../images/sidelogo.png" width="144" height="37" alt="AMI logo" /></a></li>
        <li><a href="../../../index.html">Join our mailing list</a></li>
        <li><a href="../http://search.museumsandtheweb.com/search">Search A&amp;MI<br />
          <img src="../../images/search.gif" alt="search" width="24" height="25" border="0" /></a></li>
      </ul>
    </div>
    <div id="sidebar-acknowledge">

      <div id="sponsor">
</div>
    </div>
   <!--/htdig_noindex-->
  </div>
  <div id="footer">
    <div id="last-updated"> last updated: <!-- #BeginDate format:Am1a -->October 27, 2010 4:57 PM<!-- #EndDate -->
      <br />
[analytics code]<br />
<div id="cc">
        <!--htdig_noindex-->
        <a rel="license" href="../http://creativecommons.org/licenses/by-nc-nd/3.0/"><img src="../http://i.creativecommons.org/l/by-nc-nd/3.0/88x31.png" alt="Creative Commons Attribution-Noncommercial-No Derivative Works 3.0  License" width="88" height="31" style="border-width:0" /></a>
        <!--/htdig_noindex-->
      </div>
    </div>
    <!--htdig_noindex-->
    <div id="footer-content">
      <p>Archives &amp; Museum Informatics, 158 Lee Avenue, Toronto, Ontario, M4E
        2P3 Canada<br />
        Telephone: +1 416 691 2516 | Fax: +1 416 352 6025 | E-mail:
        <script language="JavaScript" type="text/javascript">
               <!-- <![CDATA[
	           user = "mw2009";
	           site = "archimuse.com";
	           position = "Page Footer";
	           document.write('<a href=\"mailto:' + user + '@' + site + '\?subject=Response from MW2008 Web Site: ' + position + '\">');
	           document.write( user  + ' @ ' + site + '<\/a>');
	                // ]]> -->
				  </script>
        <br />
        Copyright &copy; 2009 &ndash; Archives &amp; Museum Informatics &ndash; All
        rights reserved.<br />
      </p>
    </div>
    <div style="clear:both"></div>
  </div>
</div>
<!-- analytics scripts -->
<!-- tynt script -->
<script type="text/javascript">tyntVariables = {"ap":"Read more: "};</script> 
<script type="text/javascript" src="../http://tcr.tynt.com/javascripts/Tracer.js?user=aTNeQ-tzOr36a6adbiUzgI&amp;s=130&amp;cc=6&amp;st=1"></script>
<noscript></noscript>

<!-- google analytics script -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26332456-1']);
  _gaq.push(['_setDomainName', '.archimuse.com']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!--chartbeat script -->
<script type="text/javascript">
var _sf_async_config={uid:3385,domain:"archimuse.com"};
(function(){
  function loadChartbeat() {
    window._sf_endpt=(new Date()).getTime();
    var e = document.createElement('script');
    e.setAttribute('language', 'javascript');
    e.setAttribute('type', 'text/javascript');
    e.setAttribute('src',
       (("https:" == document.location.protocol) ? "https://s3.amazonaws.com/" : "http://") +
       "static.chartbeat.com/js/chartbeat.js");
    document.body.appendChild(e);
  }
  var oldonload = window.onload;
  window.onload = (typeof window.onload != 'function') ?
     loadChartbeat : function() { oldonload(); loadChartbeat(); };
})();

</script>
<!--/htdig_noindex-->
</body>
<!-- InstanceEnd -->
<!-- Mirrored from www.museumsandtheweb.com/mw2009/papers/allison/allison.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 16:55:04 GMT -->
</html>
