<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><!-- InstanceBegin template="/Templates/mw2008-papers.dwt" codeOutsideHTMLIsLocked="true" -->

<!-- Mirrored from www.museumsandtheweb.com/mw2008/papers/timpson/timpson.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 16:59:17 GMT -->
<head>

<!-- InstanceBeginEditable name="HeadPageTitle" -->
	<title>Archives &amp; Museum Informatics: Museums and the Web 2008: Paper: Timpson: C., et al., 3D Artefacts: Enriching User Interaction with Your Collections
</title>
<!-- InstanceEndEditable -->
<!-- InstanceBeginEditable name="metaTitle" -->
	<meta name="title" content="Archives  &amp; Museum Informatics: Museums and the Web 2008: Proceedings" />
<!-- InstanceEndEditable -->
<!-- InstanceBeginEditable name="Keywords" -->
<meta name="Keywords" content="3D, Demotride, Nefertiti, artefact, artifact, interaction, mw, mw2008, museums and the web, matw, 2008, archives &amp; museum informatics, archives, museums, informatics, digital museums, digital archives, digital art, museums online, archives online, libraries online. world wide web, www, conferences, professional papers, peer-reviewed, digital libraries, online exhibits, online exhibitions, on-line" />
<!-- InstanceEndEditable -->
<!-- InstanceBeginEditable name="Description" -->
<meta name="Description" content="Museums and the Web 2008: the international conference for culture and heritage on-line" />
<!-- InstanceEndEditable -->

<!-- InstanceBeginEditable name="copyright" -->
<meta name="copyright" content="Archives &amp; Museum Informatics, 2007" />
<!-- InstanceEndEditable -->
<meta name="document-class" content="Published" />
<meta name="document-rating" content="General" />
<meta http-equiv="Content-Language" content="EN" />
<meta name="document-rights" content="Copyrighted Work" />
<!-- InstanceBeginEditable name="charset" -->
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<!-- InstanceEndEditable -->
<link rel="stylesheet" href="../../css/mw2008.css" type="text/css" media="screen" />
<link rel="stylesheet" href="../../css/papers.css" type="text/css" media="screen" />
<link rel="stylesheet" href="../../css/mw2008-noNews.css" type="text/css" media="screen" />
<link rel="stylesheet" href="../../css/print.css" type="text/css" media="print" />
<!--htdig_noindex-->
<!-- InstanceBeginEditable name="ImageRotateScript" -->
<script language="JavaScript" type="text/javascript">

</script>
<!-- InstanceEndEditable -->
<!--/htdig_noindex-->
<!--htdig_noindex-->
<!-- InstanceBeginEditable name="PageScript" -->
<!-- InstanceEndEditable -->
<!--/htdig_noindex-->
</head>
<body  onload="initImgRotation()">
<div id="container">
  <div id="header" onclick="location.href='../../index.html';" style="cursor:pointer;"> </div>
  <!--htdig_noindex-->
  <div id="top-nav">
    <ul id="top-nav-list">
      <li><a href="../../register/index.html">Register</a></li>
      <li><a href="../../dates/index.html">Key Dates</a></li>
      <li><a href="../../sescal/index.html">Schedule</a></li>
      <li><a href="../../local/index.html">Local Info</a></li>
    </ul>
    <!--/htdig_noindex-->
  </div>
  <div id="header-photo"> 
	 <!-- InstanceBeginEditable name="header-photo" --> <img src="timpson.fig3-t.JPG"  height="132" width="229" alt="MW-photo" />	 <!-- InstanceEndEditable --></div>
<div id="print-title">
	<h1>Museums and the Web 2008: the international conference for culture and heritage on-line</h1>
	<h2>produced by Archives &amp; Museum Informatics</h2>
	<h3>site at http://www.archimuse.com/mw2008/</h3>	 
</div> 
 <div id="date"> <a href="../../sescal/index.html">April 9-12, 2008</a><br />
    <a href="../../local/index.html">Montr&eacute;al, Qu&eacute;bec, Canada</a> </div>
  <div id="title">
    <h1> 
		<!-- InstanceBeginEditable name="PageTitle" --> 
3D Artefacts: Enriching User Interaction with Your Collections
		<!-- InstanceEndEditable --> </h1>
  </div>
  <!--htdig_noindex-->
  <div id="main-content">
    <div id="news">
    </div>
    <!--/htdig_noindex-->
    <div id="intro-paragraph"> 
		<!-- InstanceBeginEditable name="IntroParagraph" --> 

    <h3 class="Author"><a href="../../bios/au_440015964.html">Corey Timpson</a>, Canadian Heritage Information Network; <a href="../../bios/au_440016182.html">Eric
      Paquet</a> and <a href="../../bios/au_440016162.html">Jean-Fran&ccedil;ois Lapointe</a>, National
      Research Council of Canada, Canada</h3>
    <h3 class="URL">Abstract</h3>
    <p class="AbstractText">Representatives from the National Research Council (NRC)
    and The Canadian Heritage Information Network (CHIN)&nbsp; present two innovative initiatives that address some of the
    current and future needs of museums and cultural institutions. CHIN undertook
    these pilot initiatives both to further advance its products and to encourage
    capacity building among its member institutions. The first initiative is the
    use of Nefertiti, software that classifies and retrieves three-dimensional
    images and models from databases. Unique to Nefertiti is its content-based
    algorithms which permit users to search by scale, shape, and/or color. The
    second initiative is a pilot project in collaboration with the McCord Museum
    and the Canadian Space Agency using the NRC's Demotride software. Demotride
    brings artefacts, objects and scenes vividly to life in three dimensions
    (3D);&nbsp; this project allows
    participative interaction with objects and artefacts, including the ability to
    rotate, zoom and manipulate them for highly-detailed examination.</p>
  <p class="keywords">Keywords: 3D, Demotride, Nefertiti, artefact, artifact,
    interaction</p>
	  <!-- InstanceEndEditable --> 
	</div>
    <div id="body-text"> 
		<!-- InstanceBeginEditable name="BodyText" -->


    <h1>1.&nbsp; Introduction</h1>
      <p>The Canadian Heritage Information Network (CHIN) is a
        special operating agency of the Federal Government&rsquo;s Department of Canadian
        Heritage. CHIN is a national centre of excellence that provides a visible face
        to Canada&rsquo;s heritage through the world of networked information. CHIN&rsquo;s mission
        is to promote the development, the preservation, and the presentation of
        Canadian digital cultural content. CHIN&rsquo;s network contains over 1,200 museum
      members across Canada.</p>
      <p>CHIN has two main public products through which cultural
        content and services are served. CHIN&rsquo;s Knowledge Exchange is an on-line
        participative space for museum professionals. It offers a variety of services
        and tools, including communities of practice, collaborative tools, courses,
        case studies, tip sheets, interviews, Web casts, on-line working groups, and
      more.</p>
      <p>The Virtual Museum of Canada (VMC) brings Canada&rsquo;s rich and
        diverse heritage into Canadian homes and schools. The VMC gives member museums
        the ability to reach Canadians and an international audience via the Internet
        by featuring a large image repository of over 600,000 digital artefacts, over
        200 virtual exhibits and games, access to learning resources and lesson plans,
        and a guide to Canadian museum services and events. With over 41 million visits
        from more than 170 countries since its launch in March 2001, the VMC is now
      established as one of the world&rsquo;s premier heritage gateways.</p>
      <p>While always looking to evolve and further advance our
        products for the public, CHIN also attempts to undertake initiatives which will
        benefit our membership. Many CHIN members are medium or small institutions
        which may not have the necessary resources to undertake certain activities. As
        such, capacity building, knowledge transfer and facilitation are key objectives
      of CHIN when undertaking any project.</p>
      <h2>1.1&nbsp; Working with Images</h2>
      <p>The Canadian Heritage Information Network&rsquo;s Virtual Museum
        of Canada (VMC) is currently being redesigned. Work on the evolution of the VMC
        began in late fall 2007 with a target to publicly launch the new product in
        fall 2008. One of the concept directions of the new VMC is to help users find
        the content they desire in as simple and quick a manner as possible. To address
        this goal, new and alternative browsing and searching technologies and
        methodologies were investigated for potential implementation within the new
        VMC. This led to a partnership between CHIN and the National Research Council
        of Canada (NRC), and the implementation of the NRC&rsquo;s Nefertiti technology
      within the VMC&rsquo;s Image Gallery.</p>
      <p>The VMC&rsquo;s Image Gallery provides users with access to over
        600,000 images. Users will be able to browse and search images through the
        VMC&rsquo;s navigation, search engine, and content featuring. With Nefertiti&rsquo;s
        inclusion, users will be able to visually search, and refine searches, for
      images based on colour and shape, as well.</p>
      <p>The use of this technology is relevant in a number of ways.
        The 600,000 images found within the VMC&rsquo;s Image Gallery are contributed to
        Artefacts Canada by heritage institutions across Canada. Having a number of
        institutions (over 1,200) contribute data results in some inconsistencies in
        metadata. This invariably affects the findability of images, as metadata is
        typically used by search engines to retrieve images. Nefertiti operates on the
        physical appearance of an image and, as such, the validity and quality of
        metadata is no longer an issue. This provides an excellent alternate method of
      accessing content for VMC users.</p>
      <p>Additionally, VMC user analysis has revealed a multitude of
        user types. Each user type has unique behaviour patterns. Providing the ability
        to visually retrieve content may appeal to certain specific user types. It also
      ensures that language is not a barrier.</p>
      <p>The collections of any museum or heritage institution can be
        vast. The ability to find images and return result sets through colour and
        shape can be very relevant as both an internal system for professionals, and a
        public system, on an institution&rsquo;s Web site. By incorporating Nefertiti within
        the VMC&rsquo;s Image Gallery, CHIN&rsquo;s members get a first-hand and in-depth look at
        how such a technology operates and is used. CHIN Members are also privy to
      research conclusions, statistics, reports and case studies.</p>
      <h2>1.2&nbsp; Working with 3D</h2>
      <p>While many struggle to get up to speed with Web 2.0, there
        has already been great discourse and discussion about &ldquo;Web 3D&rdquo;. Currently, the
        VMC has some 3D content in the Inuit 3D Exhibition created by the Canadian
        Museum of Civilization in March 2001. The 3D technology used within this
        exhibition was provided by the NRC and was considered very progressive six
      years ago.</p>
      <p>With the forthcoming launch of the new VMC, several
        technologies were investigated to&nbsp; enhance the way cultural content is presented to the public. Working
        with the NRC, the McCord Museum and the Canadian Space Agency (CSA), CHIN
      decided to undertake a 3D research project.</p>
      <p>Artefacts from the McCord and the CSA are digitized to
        create 3D models. These models are then presented in a context through a
        narrative called Explore: From Yesterday to Tomorrow. The project comprises
      complementary virtual and physical components.</p>
      <p class="caption"><a name="fig1" id="fig1"></a><a href="timpson-fig1.html"><img src="timpson.fig1a.jpg" alt="Figure 1" width="400" height="231" /></a></p>
      <p class="caption"><a href="timpson-fig1.html">Fig 1:&nbsp; a
      visual outline of the 3D project concept</a></p>
      <p>The physical component takes place at an installation within
        the McCord museum. 3D artefacts onscreen can be manipulated by users through
        gesture. Hand gestures are motion-captured and translate onscreen as movements
      of the 3D objects.</p>
      <p>The virtual component will be in the VMC Lab &ndash; a
        section of the new VMC which will present experimental research projects. Users
        will enjoy the same experience and content as in the physical space, and use
      the mouse for manipulating the scaled 3D objects.</p>
      <p>There are multiple objectives for this project. It is
        expected that in the future, visits to virtual museums will be richer
        experiences through the use of 3D technologies that can mimic natural,
        in-person experiences. The new VMC will have a modest sampling of 3D content for
      its launch; it will provide invaluable data for future projects. </p>
      <p>A case study will be conducted to document and analyze user
        interaction behaviour, technology performance, and the complementary use of the
        VMC on-line and in-house McCord components. The case study will be published on
      CHIN&rsquo;s Knowledge Exchange (KX) which is available to all CHIN members.</p>
      <p>The 3D artefacts will also be ready for inclusion as the
        first 3D content in Artefacts Canada &ndash; a repository of national cultural
        content containing over 3 million records and images from hundreds of museums
      across Canada.</p>
      <h1>2.&nbsp; General Considerations on
      Images</h1>
      <p>Pictures and images are of the utmost importance in virtual
        collections. They are (and will remain in the foreseeable future) the easiest,
        fastest and most economical means for creating virtual collections.
        Furthermore, most three-dimensional models are covered with textures. Textures
        constitute an important visual descriptor for viewers and convey essential
      historical, artistic and archaeological information. </p>
      <p>Images are difficult to describe: they convey vast amounts
        of complex and ambiguous information. Ambiguity results when the
        three-dimensional world is projected as a two-dimensional image and when the
        illumination of this world is arbitrary and cannot be controlled. Because of
        this ambiguity and complexity, it is difficult to segment images and to
        understand them. For these reasons, we propose a statistical approach in which
      the overall composition of the image is described in an abstract manner.</p>
      <h2>2.1&nbsp; Indexing and Retrieval of
      Images</h2>
      <p>We now depict our algorithm. The colour distribution of each
        image is described in terms of hue and saturation. This colour space imitates
        many characteristics of the human visual system. The hue corresponds to our
        intuition of colour (e.g. red, green or blue), while saturation corresponds to
      the colour strength (e.g. light red or deep red).</p>
      <p>Next, a set of points is sampled from the image. A
        quasi-random sequence generates the points. Each point of this sequence becomes
        the centre of a structuring element. For each centre position, the pixels
        inside the corresponding structuring element are extracted, and the associated
        hue and saturation images are calculated. The statistical distribution of the
        colours within the window is characterized by a bidimensional histogram. This
        bidimensional histogram is computed and accumulated for each point of the
        sequence &ndash; the current histogram is the sum of the histograms at the
        current and at the previous position. From this process, a compact descriptor
      or index is obtained. </p>
      <p>This index provides an abstract description of the image&rsquo;s
        composition; in other words, of the local distribution of colours throughout
        the image. This is very important. This index does not represent a global
        description of the image, nor is it based on a particular segmentation scheme.
        Instead, it characterizes the statistics of colour distribution within a small
        viewing area that is moved randomly over the image. Consequently, there are no
        formal relations between the different regions: the different components of a
        scene can be combined in various ways and still be identified as parts of the
        same scene. That is why that algorithm is robust against occlusion,
        composition, partial view and viewpoint. Nevertheless, this approach provides a
      good level of discrimination.</p>
      <p>The maxim &lsquo;an image is worth a thousand words&rsquo; illustrates
        the difficulty of describing an image by means of words alone. For that reason,
        our retrieval approach is based on the so-called &lsquo;query by example&rsquo; or &lsquo;query
        by prototype&rsquo; paradigm. To this end, we created a search engine that can handle
        such queries. In order to initiate a query, the user provides an image or
        prototype to the search engine. This prototype is described or indexed and the
        latter is compared with a metric from a database of pre-calculated indexes
        which correspond to the virtual collection&rsquo;s images. The search engine finds
        the most similar images with respect to the prototype and displays them to the
        user. Here, the user&rsquo;s own sense of recognition determines the preceding search
        results: he chooses the most meaningful image from the results provided by the
        search engine and reiterates the query process from the chosen image. The
      process is repeated until convergence is achieved. </p>
      <h2>2.2&nbsp; Application to the EROS
      Database</h2>
      <p>The C2RMF &ndash; Centre de recherche et restauration des
        mus&eacute;es de France &ndash; has been a pioneer in applying new technologies in the
        field of cultural heritage. The C2RMF&rsquo;s participation in the cultural heritage
        field began in 1989 and involved the high-quality digitization of images via a
        modified Thomson-Broadcast flatbed scanner developed for the NARCISSE project.
        There was subsequently direct digital imaging and panoramic viewing of objects,
        direct 3-D acquisition of the surface of paintings, and finally, multispectral
      colour reconstruction.</p>
      <p>All these techniques give us an enormous amount of data and
        information to organize and exploit. The information is focused on scientific
        and technical data. This includes indexing vocabularies, study reports,
        restoration reports, digital data from quantitative analysis, spectra, graphs,
        chemical formulae, UV, infrared, raking light photography, and scanning
        electron microscopy images. As computation capability continues to grow at a
        steady rate, user requests for new features and usability improvements are
        correspondingly advanced. The C2RMF has integrated these new advanced
      techniques and updated the EROS system.</p>
      <p>The EROS system is organized in several parts: the storage
        back-end, the relational database, the image server, the middleware and the Web
        server. The data is stored on 15TB HP RAID hard disk racks managed by a file
      server:</p>
      <ul>
        <li><span class="listwithbullets" style='font-family:Symbol'><span
style='font:7.0pt &quot;Times New Roman&quot;'></span></span>the
          metadata related to the works of art; the images; the reports; the analysis;
          the analytical reports; the restoration reports; the conservation surveys; the
          chemical, structural, isotopic and molecular quantitative and qualitative
        analytical results; and published papers;</li>
      <li><span class="listwithbullets" style='font-family:Symbol'><span
style='font:7.0pt &quot;Times New Roman&quot;'></span></span>high
        definition digital images (photographic films taken with different techniques
        such as infra-red, X-ray and ultra-violet light, detailed cross-sections,
        electron microscopy views, graphs, spectra, multispectral images, panoramic
        views and 3-D models);</li>
      <li><span class="listwithbullets" style='font-family:Symbol'><span
style='font:7.0pt &quot;Times New Roman&quot;'></span></span>feature
        vectors for 2-D and 3-D image content recognition for automatic classification
        and image category retrieval.</li>
    </ul>
      <p>The EROS system is an Open Source project available under
        the GNU Public License (GPL). It is based on powerful and industry-leading free
        software such as Linux, Apache, MySQL, PHP, and now Ruby and the framework
        RubyOnRails. Web access is via a W3C standard-compliant client such as Mozilla
      Firefox.</p>
      <p class="caption"><a name="fig2" id="fig2"></a><a href="timpson-fig2.html"><img src="timpson.fig2a.jpg" alt="Figure 2" width="400" height="250" /></a></p>
      <p class="caption"><a href="timpson-fig2.html">Fig 2: Query for a Chalcidian amphora in the EROS Database.
      All the views corresponding to the same amphora were retrieved.</a></p>
      <p>Figure 2 shows the retrieval of all the views related to a single
        Chalcidian amphora from a sole view. This amphora, hosted at the Mus&eacute;e du
        Louvre (Paris, France), was made during the Archaic Greek Period (620-480 B.C.)
        and was found in the South of Italy. This figure is an important example as the
        database user might be unaware that multiple views of the same amphora are
      stored in the database.</p>
      <p class="caption"><a name="fig3" id="fig3"></a><a href="timpson-fig3.html"><img src="timpson.fig3a.jpg" alt="Figure 3" width="400" height="250" /></a></p>
      <p class="caption"><a href="timpson-fig3.html">Fig 3: Query for a group of white figurines. All the
        pictures retrieved from the reference picture belong to the same group of
      figurines (Gallo-Roman Period). </a></p>
      <p>Our last example of pictorial interrogation is shown in
        Figure 3. This example is typical of situations in which one wants to retrieve
        a certain group of pictures that are very similar but that do not necessarily
        correspond to the same artefact. Such a group can be formed, for instance, from
        various figurines representative of a particular style and made from the same
      kind of material. Such a situation is illustrated in Figure 3. </p>
      <p>The reference image represents a broken Venus from which
        other sculptures of the same style are retrieved. The Venus belongs to the
        Gallo-Roman Period and was made between 40 B.C. and 300 A.D. All the figurines
        are made of ceramic and pottery. Currently, they can be found at the Mus&eacute;e du
        Chatillonnais (Chatillon-sur-Seine, France). Unless the database is very well
        documented, such a query is extremely difficult without a content-based system
        because the database user must have some knowledge both of the artefact per se
        and of the period. Once more, our results were validated with a textual query
      in the EROS Database.</p>
      <p>Our results have shown the efficiency of our algorithms. In
        many situations, content-based retrieval has proven itself to be not only a
        complement to text-based retrieval, but also a sine qua non condition for
        efficient retrieval. In any case, synergy between text-based and content-based
      data should be exploited to the maximum</p>
      <p>At this stage, about 600,000 paintings have been indexed at
        low resolution and 14,000 at high resolution. The low-resolution calculations
        have been performed on a high-end laptop while the indexes for the
        high-resolution paintings have been calculated in Paris on the C2RMF server.
        The fact that 600,000 paintings can be indexed on a laptop shows the
      optimisation of the algorithms.</p>
      <h1>3. Demotride 3D Viewer</h1>
      <p>Demotride is a 3D scene viewer that allows visualization of,
        and interaction with, 3D objects and scenes on the computer screen. Designed to
        be user-friendly, Demotride respects visualization parameters defined by content
        developers. It works with content files based on the VRML/X3D international
        standards (International Organization for Standards, 1997; Ibid, 2005). These
        standards for 3D scene description have been chosen because they are open;
        widely known and used; well documented; well supported by 3D content
        development tools; and freely available on the Web. Furthermore, these
        standards allow anyone to create 3D content by simply using a text editor such
      as Notepad.</p>
      <p>Demotride also allows interaction with multimedia content,
      including text, images, sounds and animations. </p>
      <p>Demotride's technology is used in research on human-computer
        interaction (HCI) for several projects. As an HCI testbed, it is used for rapid
      prototyping and evaluation of new 3D user interfaces.</p>
      <p>Although Demotride's technology is generic and can be
        adapted to many uses, it could be particularly useful for scientific
      visualization and virtual tours and presentations, such as virtual museums.</p>
      <p>Demotride is also freely available on the Web for personal,
        and academic, as well as research and development, purposes. Since its first
        public launch in 2004, several new versions have been released on a regular
        basis, each time adding functionality and improving its usability. The latest
        version offers unique features such as the ability to control key rendering and
      interaction parameters.</p>
      <p>Demotride&rsquo;s technology is used to conduct experiments in HCI
        (Lapointe et al, 2007; Savard and Lapointe, 2006) as well as to test 3D
        interaction techniques for specific content; for example, by combining the
        Inuit3D virtual museum (Corcoran et al, 2002) with a new joystick-based
        navigation interface, or by developing space-time interaction techniques for 3D
      content (El-Hakim et al, 2006).</p>
      <p>This viewer has been designed from the start for usability
        on the Web &ndash; to maximize&nbsp; effectiveness, efficiency and user satisfaction for Web users who are
        interested in visualizing and interacting with virtual environments on the Web
      in a simple and easy manner. </p>
      <p>In order to achieve these goals, we worked to maintain a
        minimum download size (currently under 1 MB), in order to reduce download time
        and make the technology&nbsp; accessible
        to all Internet users, including those using dial-up connections. Developed by
        the National Research Council of Canada, Demotride is currently available in
      French and English, the two official languages of Canada.</p>
      <p>Demotride is an evolving software: the aim of future
      releases will be to further increase its functionality and usability.</p>
      <h2>3.1&nbsp; Application for Museums</h2>
      <p>Apart from the applications mentioned before, we recently
        used Demotride&rsquo;s technology to demonstrate proof-of-concept gesture-based
        interaction with 3D content on a large display. Using interactive gesture-based
        kiosks to display 3D content to museum visitors has a lot of potential to
      attract their attention.</p>
      <p>From a Web perspective, virtual visitors can also benefit
        from 3D content through the use of interactive 3D visualization technologies.
        There is, however, a need to better assess the capability of these technologies
      to improve visitors&rsquo; experience and satisfaction.</p>
      <p>With that in mind, we are currently collaborating with the
        McCord Museum and the Canadian Space Agency to further improve the usability of
        interactive 3D visualization technologies on the Web. The idea is to develop a
        systematic evaluation method to measure the usability of these technologies for
      museum applications.</p>
      <p>Such a method will allow the objective measurement of the
        usability of 3D viewers and as such, will allow us to improve these tools.
        These improvements will benefit both users and the overall development of the
      field, with all the socio-economic impacts expected for this new form of media.</p>
      <p>Finally, CHIN is interested in using Demotride as a viewing
        technology for the creation of a 3D component within their VMC Lab on the new
        Virtual Museum of Canada site. In this way, we can offer a glimpse into the
        world of 2020, 2050, and beyond. The interactive capabilities of the viewer
        will allow visitors to see, experience, interact with and manipulate
      environments of the future.</p>
      <h1>4.&nbsp; Conclusion</h1>
      <p>Imagine a collections manager browsing through thousands of
        images, unconcerned with language or metadata, concerned only with the physical
        appearances of the images. Or&nbsp; imagine a 9-year-old browsing through images on a museum Web site,
        unconcerned with spelling and syntax. Imagine a museum visitor or research
        student, hundreds of kilometers away from a museum, rotating, zooming in, and
        playing with an ancient artefact. Both Nefertiti and Demotride (available on
        the Web at <a href="http://www.demotride.net/">http://www.demotride.net</a>) offer incredible potential to heritage
        institutions, both for&nbsp; professional operational purposes, and for greatly enriching the
      experience of their visitors. </p>
      <p>This paper has briefly presented some technologies that the
        Canadian Heritage Information Network (CHIN) is using in collaboration with the
        National Research Council of Canada (NRC), the McCord Museum, and the Canadian
        Space Agency (CSA). By incorporating these research projects on to their Web
        sites, CHIN allows its Web visitors to search and interact with digitized
        artefacts in new ways. At the same time, this provides CHIN with the ability to
        collect valuable research on new technology, user behaviours, and the
        relationship between complementary virtual and physical exhibitions, and to
      compile this and share it with its network of member museums.</p>
      <h1>Acknowledgements</h1>
      <p class="AcknowedgementsText">The authors wish to acknowledge the core teams of
        both the <i>VMC Nefertiti</i><span style='font-style:normal'> and the 3D </span><i>Explore:
          From Yesterday to Tomorrow</i><span style='font-style:normal'> projects for
            their great work and collaboration from concept through implementation, and
            study. Also, thanks to the McCord Museum and Nicole Valli&egrave;res; and the Canadian
            Space Agency and Marie-France Fortier for partnering with the 3D project. The
      authors also wish to thank Scott Cantin for his work in editing this paper.</span></p>
      <h1>References</h1>
      <p class="ReferencesText">Corcoran, F., J. Demaine,&nbsp; M. Picard,&nbsp; L.-G, Dicaire, J. Taylor.&nbsp; INUIT3D: An Interactive Virtual 3D Web Exhibition. <i>Museums and the
        Web 2002: Proceedings</i><span style='font-style:normal'>. Ed. J. Trant and D.
          Bearman. Boston, Massachusetts, USA. April 17-20, (2002). Available: <a href="http://www.archimuse.com/mw2002/papers/corcoran/corcoran.html">http://www.archimuse.com/mw2002/papers/corcoran/corcoran.html</a> The Interactive
          Virtual 3D Web Exhibition is also available on the Web:
      <a href="http://www.civilization.ca/aborig/inuit3d/inuit3d.html">http://www.civilization.ca/aborig/inuit3d/inuit3d.html</a></span></p>
      <p class="ReferencesText">El-Hakim, S. F., G. MacDonald, J.-F. Lapointe, L.
        Gonzo, M.&nbsp; Jemtrud. &quot;On the
        Digital Reconstruction and Interactive Presentation of Heritage Sites through
        Time&quot;. Proceedings of the 7th International Symposium on Virtual Reality,
        Archaeology and Intelligent Cultural Heritage (2006). October 30 &#8211;
      November 4, 2006, Hilton Nicosia, Cyprus, pp. 243-250.</p>
      <p class="ReferencesText">ISO: ISO/IEC14772-1:1997. Information technology -
        Computer graphics and image processing -- The Virtual Reality Modeling Language
        (VRML) - Part 1: Functional specification and UTF-8 encoding. International
      Organization for Standards (1997).</p>
      <p class="ReferencesText">ISO, ISO/IEC19776-2:2005(E). Information technology -
        Computer graphics, image processing and environmental data representation -
        Extensible 3D (X3D) encodings. Part 2: Classic VRML encoding. International
      Organization for Standards (2005).</p>
      <p class="ReferencesText">Lapointe, J.-F., and P. Savard. &quot;Comparison of
        Viewpoint Orientation Techniques for Desktop Virtual Walkthroughs&quot;,
        Proceedings of the IEEE International Workshop on Haptic Audio Visual
        Environments and their Applications (HAVE 2007). Ottawa, Ontario. October
      12-14, 2007. pp. 33-37.</p>
      <p class="ReferencesText"><span lang="fr" xml:lang="fr">Savard, P.,
        J.-F.Lapointe. &quot;Conception d&rsquo;un outil pour l&rsquo;&eacute;tude des techniques de
        d&eacute;placement en environnement virtuel&quot;. Actes de la 18e conf&eacute;rence francophone
        sur l&rsquo;interaction humain-machine. IHM 2006, 18 au 21 avril 2006, Montr&eacute;al,
      Qu&eacute;bec, Canada, pp. 269-272.</span></p>
  <!-- InstanceEndEditable --> </div>
  				<h4>Cite as:</h4>
				<p class="references"><!-- #BeginEditable "OnlineCitation" -->Timpson: C., et al., 3D Artefacts: Enriching User Interaction with Your Collections
<!-- #EndEditable -->, 
				in J. Trant and D. Bearman (eds.). <em>Museums and the Web 2008: Proceedings</em>,
				 Toronto: Archives &amp; Museum Informatics. Published March 31, 2008. Consulted  

                 <script language="JavaScript" type="text/javascript">
               <!-- <![CDATA[
// current date - based on http://rainbow.arch.scriptmania.com/scripts
// Array of day names
var dayNames = new Array("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday");

var monthNames = new Array("January","February","March","April","May","June","July",
                           "August","September","October","November","December");

var dt = new Date();
var y  = dt.getYear();

// Y2K compliant
if (y < 1000) y +=1900;

document.write(monthNames[dt.getMonth()] + " " + dt.getDate() + ", " + y + ". ");
	                // ]]> -->
				  </script>

http://www.archimuse.com/mw2008/papers/<!-- #BeginEditable "URL" -->timpson/timpson.html
				 <!-- #EndEditable --></p>
</div>
  <!--htdig_noindex-->
  
  <div id="sidebar">
    <div id="side-nav">
      <ul id="side-nav-list">
        <li id="workshops"> <a href="../../workshops/index.html" class="menu">Workshops</a> </li>
        <li id="sessions"> <a href="../../sessions/index.html" class="menu" >Sessions</a> </li>
        <li id="speakers"> <a href="../../speakers/index.html" class="menu" >Speakers</a> </li>
        <li id="interactions"> <a href="../../interact/index.html" class="menu">Interactions</a> </li>
        <li id="demonstrations"> <a href="../../demos/index.html" class="menu">Demonstrations</a> </li>
        <li id="events"> <a href="../../events/index.html" class="menu">Events</a> </li>
        <li id="exhibits"> <a href="../../exhibit/index.html" class="menu">Exhibits</a> </li>
        <li id="best"> <a href="../../best/index.html" class="menu">Best of the Web </a></li>
        <li id="pc"> <a href="../../thanks/index.html" class="menu">Committees</a></li>
      </ul>
    </div>
    <div id="search-site">
<form method="get" id="searchform" action="http://wp.museumsandtheweb.com/">
<input type="text" class="field" name="s" id="s" placeholder="Search">
<input type="submit" class="submit" name="submit" id="searchsubmit" value="Search">
</form>
    </div>
    <div id="sidebar-links">
      <ul id="sidebar-links-list">
        <li><a href="../../../index.html" class="produced-by">produced by<br />
          <img src="../../images/sidelogo.png" width="144" height="37" alt="AMI logo" /></a></li>
        <li><a href="../../../index.html">Join our mailing list</a></li>
        <li><a href="http://search.museumsandtheweb.com/search">Search A&amp;MI<br />
          <img src="../../images/search.gif" alt="search" width="24" height="25" border="0" /></a></li>
      </ul>
    </div>
    <div id="sidebar-acknowledge">
      <p><img src="../../images/PCH-logo.png" alt="PCH" width="160" height="22" /><br />
        Presented  in conjunction with the<br />
        Department of Canadian Heritage through the <a href="http://www.chin.gc.ca/" target="_blank">Canadian
      Heritage Information Network (CHIN)</a> and <a href="http://www.pch.gc.ca/progs/pcce-ccop/index_e.cfm" target="_blank">Canadian Culture Online (CCO)</a>.</p>
      <div id="sponsor">
 <p>Sponsored by<br />
   <a href="../../exhibit/ex_335001860.html">Interwoven</a> and <a href="../../exhibit/ex_335001863.html">Interflow</a></p>
</div>
    </div>
   <!--/htdig_noindex-->
  </div>
  <div id="footer">
   <div id="last-updated">published April 9, 2008<br />
	 last updated:
	   <!-- #BeginDate format:Am1a -->October 27, 2010 10:14 PM<!-- #EndDate --><br />
      <div id="cc">
        <!--htdig_noindex-->
        <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/3.0/"><img src="http://i.creativecommons.org/l/by-nc-nd/3.0/88x31.png" alt="Creative Commons Attribution-Noncommercial-No Derivative Works 3.0  License" width="88" height="31" style="border-width:0" /></a>
        <!--/htdig_noindex-->
      </div>
    </div>
    <!--htdig_noindex-->
    <div id="footer-content">
      <p>Archives &amp; Museum Informatics, 158 Lee Avenue, Toronto, Ontario, M4E
        2P3 Canada<br />
        Telephone: +1 416 691 2516 | Fax: +1 416 352 6025 | E-mail:
        <script language="JavaScript" type="text/javascript">
               <!-- <![CDATA[
	           user = "mw2008";
	           site = "archimuse.com";
	           position = "Page Footer";
	           document.write('<a href=\"mailto:' + user + '@' + site + '\?subject=Response from MW2008 Web Site: ' + position + '\">');
	           document.write( user  + ' @ ' + site + '<\/a>');
	                // ]]> -->
				  </script>
        <br />
        Copyright &copy; 2008 &ndash; Archives &amp; Museum Informatics &ndash; All
        rights reserved.<br />
      </p>
    </div>
    <div style="clear:both"></div>
  </div>
</div>
<!-- analytics scripts -->
<!-- tynt script -->
<script type="text/javascript">tyntVariables = {"ap":"Read more: "};</script> 
<script type="text/javascript" src="http://tcr.tynt.com/javascripts/Tracer.js?user=aTNeQ-tzOr36a6adbiUzgI&amp;s=130&amp;cc=6&amp;st=1"></script>
<noscript></noscript>

<!-- google analytics script -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26332456-1']);
  _gaq.push(['_setDomainName', '.archimuse.com']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!--chartbeat script -->
<script type="text/javascript">
var _sf_async_config={uid:3385,domain:"archimuse.com"};
(function(){
  function loadChartbeat() {
    window._sf_endpt=(new Date()).getTime();
    var e = document.createElement('script');
    e.setAttribute('language', 'javascript');
    e.setAttribute('type', 'text/javascript');
    e.setAttribute('src',
       (("https:" == document.location.protocol) ? "https://s3.amazonaws.com/" : "http://") +
       "static.chartbeat.com/js/chartbeat.js");
    document.body.appendChild(e);
  }
  var oldonload = window.onload;
  window.onload = (typeof window.onload != 'function') ?
     loadChartbeat : function() { oldonload(); loadChartbeat(); };
})();

</script>

<!--/htdig_noindex-->
</body>
<!-- InstanceEnd -->
<!-- Mirrored from www.museumsandtheweb.com/mw2008/papers/timpson/timpson.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 16:59:21 GMT -->
</html>
