<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">

<!-- Mirrored from www.museumsandtheweb.com/mw2011/papers/what_if_web_archiving_were_as_reliable_as_push by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 17:09:04 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>What If Web Archiving Were as Reliable As Pushing a Simple Button? | museumsandtheweb.com</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<script type="text/javascript">var _sf_startpt=(new Date()).getTime()</script>
<link rel="alternate" type="application/rss+xml" title="Comments for &quot;What If Web Archiving Were as Reliable As Pushing a Simple Button?&quot;" href="../../crss/node/14802html.html" />
<link rel="shortcut icon" href="../../sites/all/themes/at_mw2011/favicon.ico" type="image/x-icon" />
  <link type="text/css" rel="stylesheet" media="all" href="../../files/ctools/css/fc1c48c5ca33c8171b281d62bf027dd0e4da.css?5" />
<link type="text/css" rel="stylesheet" media="all" href="../../files/css/css_deaf8869d31a9684bd1d437eda500970.css" />
<link type="text/css" rel="stylesheet" media="print" href="../../files/css/css_7c2bf56cf58ae4752729cbcbd408ba47.css" />
  <style type="text/css">#container{width:960px;}.two-sidebars .content-inner{margin-left:240px; margin-right:240px;}.sidebar-first .content-inner{margin-left:240px; margin-right:0;}.sidebar-last .content-inner{margin-right:240px; margin-left:0;}#sidebar-first{width:240px;margin-left:-100%;}#sidebar-last{width:240px;margin-left:-240px;}</style>  <script type="text/javascript" src="../../files/js/js_cb84585e7a78c9c38296ab40c95667f0.js"></script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
jQuery.extend(Drupal.settings, {"basePath":"\/","block_edit":{"hover_links":1},"chartbeat":{"uid":3385,"domain":"museumsandtheweb.com"},"fivestar":{"titleUser":"Your rating: ","titleAverage":"Average: ","feedbackSavingVote":"Saving your vote...","feedbackVoteSaved":"Your vote has been saved.","feedbackDeletingVote":"Deleting your vote...","feedbackVoteDeleted":"Your vote has been deleted."},"googleanalytics":{"trackOutgoing":1,"trackMailto":1,"trackDownload":1,"trackDownloadExtensions":"7z|aac|arc|arj|asf|asx|avi|bin|csv|doc|exe|flv|gif|gz|gzip|hqx|jar|jpe?g|js|mp(2|3|4|e?g)|mov(ie)?|msi|msp|pdf|phps|png|ppt|qtm?|ra(m|r)?|sea|sit|tar|tgz|torrent|txt|wav|wma|wmv|wpd|xls|xml|z|zip"}});
//--><!]]>
</script>
</head>
<body class="not-front not-logged-in article-type-paper one-sidebar sidebar-first section-mw2011 page-node-14802">
  <div id="container">

    <div id="skip-nav" class="show-on-focus">
      <!-- To adjust the display of the skip link see the Advanced theme settings (General settings), and never use display:none! -->
      <a href="#main-content">Skip to main content</a>
    </div>

        
    
          <div id="leaderboard">  <div id="block-panels_mini-leader" class="block block-panels_mini odd block-region-leaderboard block-count-1">
  <div class="block-inner">

    
    <div class="content"><div class="panel-display panel-3col clear-block" id="mini-panel-leader">
  <div class="panel-panel panel-col-first">
    <div class="inside"></div>
  </div>

  <div class="panel-panel panel-col">
    <div class="inside"><div class="panel-pane pane-custom pane-1 " >
  
      <h2 class="pane-title"><a href="../../index.html">Museums and the Web </a></h2>
  
  
  <div class="pane-content">
    <font color="white">An annual conference exploring the social, cultural, design, technological, economic, and organizational issues of culture, science and heritage on-line.</font>  </div>

  
  </div> <!-- /panels-pane -->
</div>
  </div>

  <div class="panel-panel panel-col-last">
    <div class="inside"><div class="panel-pane pane-custom pane-2 " >
  
      <h2 class="pane-title"><a href="http://mw2013.museumsandtheweb.com/">Museums and the web 2013</a></h2>
  
  
  <div class="pane-content">
    <ul>
<li><a href="../../mw2012.html">2012</a></li>
<li><a href="../../mw2011.html">2011</a></li>
<li><a href="../../mw2010/index.html">2010</a></li>
<li><a href="../../mw2009/index.html">2009</a></li>
<li><a href="../../mw2008/index.html">2008</a></li>

<li><a href="../../mw/museums_and_the_web.html">...</a></li>
</ul>
  </div>

  
  </div> <!-- /panels-pane -->
</div>
  </div>
</div>
</div>

    
  </div>
</div> <!-- /block -->
</div> <!-- /leaderboard -->
    
    <div id="header" class="clearfix">

              <div id="branding">

                                    <div class="logo-site-name"><strong>
                <span id="logo"><a href="../../mw2011.html" title="Museums and the Web 2011: the international conference for culture and heritage on-line"><img src="../../sites/all/themes/at_mw2011/logo.png" alt="museumsandtheweb.com logo" title="Home page"/></a></span>                <span id="site-name"><a href="../../mw2011.html" title="Museums and the Web 2011: the international conference for culture and heritage on-line"><img src="../../sites/all/themes/at_mw2011/css/theme/images/mw2011-title.png" alt="Museums and the Web 2011: the international conference for culture and heritage on-line" /></a></span>              </strong></div> <!-- /logo/site name -->
                        <div id="site-slogan"><div class="when-where">April 5-9, 2011, Philadelphia, PA, USA</div><div class="by">produced by Archives &amp; Museum Informatics</div><div class="link">http://conference.archimuse.com/mw2011</div></div>                    
        </div> <!-- /branding -->
            
        <div id="social">
                    <div class="custom-user-menu"><ul class="item-list clear-block">
<li class="first"><a href="../../user/register.html">New Account</a></li>
<li class="last"><a href="../../user.html">Login</a></li>
</ul></div>          <div class="social-media clear-block"><ul>
<li><a class="linkedin" href="http://www.linkedin.com/shareArticle?url=http://museumsandtheweb.com/mw2011/papers/what_if_web_archiving_were_as_reliable_as_push&amp;source=Archimuse&amp;mini=true" rel="nofollow" target="_blank" title="Share on LinkedIn">LinkedIn</a></li>
<li><a class="facebook" href="http://www.facebook.com/share.php?u=http://museumsandtheweb.com/mw2011/papers/what_if_web_archiving_were_as_reliable_as_push" rel="nofollow" target="_blank" title="Share on Facebook">Facebook</a></li>
<li><a class="twitter" href="http://twitter.com/?status=http://museumsandtheweb.com/mw2011/papers/what_if_web_archiving_were_as_reliable_as_push" rel="nofollow" target="_blank" title="Share on Twitter">Twitter</a></li>
<li><a class="flickr" href="http://www.flickr.com/groups/mw2011-15th/" rel="nofollow" target="_blank" title="Join the Flickr group">Flickr</a></li>
</ul></div>
        </div> <!-- /social -->
        
              <div id="register"><a href="http://www2.archimuse.com/mw2011/mw2011.registrationForm.html" target="_blank">Register</a></div> <!-- /register -->
            
      
    </div> <!-- /header -->

        
      <div id="primary" class="nav">
      </div> <!-- /primary link menu -->


    


    
    <div id="columns"><div class="columns-inner clearfix">

      <div id="content-column"><div class="content-inner">
        
                
        
        <div id="main-content">
          
                      <div id="breadcrumb">
              <h2 class="element-invisible">You are here:</h2>
              <a href="../../mw2011.html">MW2011</a> &#187; <a href="../mini-workshops.html">Mini-Workshops</a> &#187; <a href="../programs/web_archiving_workshop.html">Web Archiving Workshop</a> &#187;             </div> <!-- /breadcrumb -->
              
                      <div id="main-content-header" class="clear-block">
              <h1 id="page-title">What If Web Archiving Were as Reliable As Pushing a Simple Button?</h1>                          </div>
          
          
          <div id="content"><div id="article-14802" class="article article-promoted paper-article clear-block">

    
    <div class="article-detail clear-block">
  <div class="node-edit-link" id="node-edit-link-14802"><ul class="links"><li class="0 first last active"><a href="what_if_web_archiving_were_as_reliable_as_push.html" class="active">[View]</a></li>
</ul>
</div><div id="intro-paragraph">
<h2 class="Author">Chloé Martin, France Lasfargues and Leïla Medjkoune, Internet Memory Foundation, France</h2>
<p class="URL"><a href="http://internetmemory.org/">http://internetmemory.org</a></p>
<h3 class="AbstractTitle">Abstract</h3>
<p class="AbstractText">Web content is, by nature, ephemeral: sites are constantly disappearing; others are frequently updated, involving the removal of online information. This medium continues to grow in our society: many museums and cultural heritage institutions are developing websites with a variety of content (videos, forums, blogs, online exhibitions, catalogues) creating a large media-centric Web sphere of unique value. As with any other medium before, it is becoming essential to preserve this Web sphere of cultural and historical value. From this point of view, Web archiving is becoming a key part of today's heritage conservation.</p>
<p class="keywords">Keywords: Web archiving, Preservation, Internet, Collection, State of the Art</p>
</div>
<p></p>
<div id="body-text">
<h2>Introduction</h2>
<h3>Why is it so important to archive websites?</h3>
<p>By nature, Web content is ephemeral: sites disappear continuously and are frequently updated, involving the disappearance of what is often very valuable online information.</p>
<p>This medium is pervasive in our society and certainly today one of its most important representations. From presidential elections to music festivals, every event is an opportunity to create, update or close a website, a Twitter, a Flickr or a Facebook profile; to communicate about it, to feed blogs, forums, social websites with opinion, points of view, issues… Concerning Museums and Galleries, Net'art involves a new perspective of archives and memory and new technological issues.</p>
<p>As with any other media, we believe this medium deserves a memory, and it is essential to preserve what has cultural, heritage and historical value.</p>
<p>Challenges come from the features and richness of the Web: dynamics, volatility, variety of formats and Internet users' contributions, all attributes increasingly used. Archiving the Web requires special attention in order to retain its value and ensure its fidelity to the original.</p>
<h3>The Internet Memory Foundation (IMF)</h3>
<p>The Internet Memory Foundation (formerly the European Archive Foundation) is a non-profit institution based in Amsterdam and Paris. Since 2004, it has actively supported the preservation of the Internet as a new medium. The Foundation has developed a wide range of collaboration all over the word, and especially in Europe, both with half-a-dozen cultural institutions and with about thirty research teams, to fulfill its mission.</p>
<p>Thus, the Foundation is archiving dozens of Terabytes of data per month, providing a shared Web archiving platform in order to help institutions to easily and quickly start collecting websites, including dynamic content and rich media, enabling navigation in past versions of a website, as if it were still live.</p>
<p>IMF is currently involved in various research projects with institutions such as the Max Planck Institute for Computer Science (Germany), Yahoo! Research or Leibniz University Hannover - L3S Research Center. It is developing several technologies to support the growth and use of Internet memory, such as a new crawler and architecture for Web scale crawling.</p>
<p>Our purpose in this paper is to present a large overview of Web archiving from IMF experience.</p>
<p>First, we present an overview of Web archiving, highlighting Europe. Then we continue with an outline of the State of the Art in this field. Finally, we raise the challenges we have to face, with a special focus on complex multimedia content, which is one of the main issues for Museums.</p>
<h2>1.    Inventory of Web archiving</h2>
<h3>International interest</h3>
<p>Since the beginning of the Internet Archive, the first notable Web archiving initiative and the most ambitious (<a href="http://www.archive.org/web/web.php">http://www.archive.org/web/web.php</a>) in 1996, a number of international, national and institutional Web archiving programs have been launched. From major national libraries or archives to consortia and university departments, one can find a wide diversity of Web archiving projects.</p>
<p>Our aim is not to give an exhaustive description of every such program but to summarize and highlight common facts and issues.</p>
<p>From 12 members in 2003, the International Internet Preservation Consortium (<a href="http://netpreserve.org/">http://netpreserve.org/</a>) has increased to 36 members all over the world (4 in Asia, 24 in Europe, 8 in North America and 2 in Oceania). At the beginning, membership was limited to charter institutions, but now, IPPC is open to all kinds of cultural institutions, such as libraries, archives and museums. Goals of this group are:</p>
<ul>
<li>To enable the collection of a rich body of Internet content from around the world to be preserved in a way that it can be archived, secured and accessed over time,</li>
<li>To foster the development and use of common tools, techniques and standards that enable the creation of international archives</li>
<li>To encourage and support heritage institutions everywhere to address Internet archiving and preservation.</li>
</ul>
<p>It is in the development of common tools and standards that IIPC has had its main achievements.</p>
<p>The growing interest in Web archiving is also noticeable through presentations and workshops in international conferences. Only last year, these conferences included:</p>
<ul>
<li>European Conference on Digital Archiving, ECA 2010: "Catching the Web - Mirroring information society through website archiving" by Austrian Parliamentary Administration (Günther Schefbeck, 2010)</li>
<li>European Conference on Digital Archiving, ECA 2010: "Intervening early to ensure links persistence: How the National Archives' Web Continuity project has helped to redefine What to keep?" (Amanda Spencer, 2010)</li>
<li>European Conference on Digital Archiving, ECA 2010: "Archivage du Web: perspective archivistique" by University of Montreal (Aïda Chebbi, 2010)</li>
<li>Association of European Research Libraries, LIBER 2010: "Introducing Web archives as a new library service: the experience of the National Library of France" (Sara Aubry, 2010)</li>
<li>International Conference of the Round Table on Archives, CITRA 2010: "Where have all the records gone? Challenges and Opportunities in Capturing websites" by Heritage Communications the Coca-Cola Company (Philip Mooney, 2010)</li>
<li>International Federation of Television Archives, FIAT/IFTA 2010: "Workshop on Web archiving" by the National Audiovisual Institute of France (Claude Mussou, 2010)</li>
</ul>
<h3>European overview</h3>
<p>Because the Internet Memory Foundation is established and more involved in Europe, we focus here on Web archiving projects in Europe.</p>
<p>In the framework of a research project named Living Web Archives, funded by the European Commission from 2008 to 2011 (<a href="http://liwa-project.eu/">http://liwa-project.eu/</a>), Internet Memory Foundation carried out a survey on Web archiving in December 2010, sent to European and International institutions. We summarize here its main findings.</p>
<h4>Which institutions do Web archiving?</h4>
<p>This survey has been sent to more than 360 institutions (most of them are European heritage institutions):</p>
<ul>
<li>National and Regional Libraries (19%)</li>
<li>University or specialized Libraries (22%)</li>
<li>National and Regional Archives (11%)</li>
<li>Audiovisual and/or Broadcasting Archives (20%)</li>
<li>Institutional Archives, as Parliament Archive, European Institutions and International Institutions (18%)</li>
<li>Documentation or Archive Department of Museum (10%)</li>
</ul>
<p>Most of the respondents (73 institutions completed the survey) are National Libraries (25%) and Audiovisual Archives (25%), following by National and Regional Archives (15%).</p>
<p>Thanks to this survey, we discovered that more institutions than expected have a Web archiving program: 41 active institutions have answered and many of them are not in IIPC (26); 17 institutions answered they do not have a current Web archiving program but they plan to have one in the next 3 years. Combined with the fact that 90.3% of survey participants answered they would like to be regularly informed about Web archiving, we can affirm that Web archiving is an expanding topic.</p>
<table>
<tbody>
<tr>
<th>Do you have a current <br>Web archiving program in your Institution?</th> <th>Response <br>Percent</th> <th>Response<br> Count</th>
</tr>
<tr>
<td>Yes, it is fully operational</td>
<td>29,7 %</td>
<td>22</td>
</tr>
<tr>
<td>Yes, it is operational but still experimenting</td>
<td>18,9 %</td>
<td>14</td>
</tr>
<tr>
<td>Yes, we are just starting a Web Archiving project</td>
<td>6,8 %</td>
<td>5</td>
</tr>
<tr>
<td>No, we do not but we plan to do it in a short-term (1 or 2 years)</td>
<td>12,2 %</td>
<td>9</td>
</tr>
<tr>
<td>No, we do not but we plan to do it in a mid-term (from 3 years)</td>
<td>10,8 %</td>
<td>8</td>
</tr>
<tr>
<td>No, we do not because we do not have funding for this project</td>
<td>5,4 %</td>
<td>4</td>
</tr>
<tr>
<td>No, we do not because it is not in our mandate</td>
<td>1,4 %</td>
<td>1</td>
</tr>
<tr>
<td>No, we do not because an other institution is already in charge</td>
<td>6,8 %</td>
<td>5</td>
</tr>
<tr>
<td>No, other reason</td>
<td>8,1 %</td>
<td>6</td>
</tr>
<tr>
<td valign="bottom">answered question</td>
<td valign="bottom">&nbsp;</td>
<td valign="bottom">74</td>
</tr>
</tbody>
</table>
<p class="caption">Table 1: Maturity of Web archiving program (IMF Survey, 2010)</p>
<p>It is also interesting to note that 42% of institutions which have no Web archives consider that it is or should be in the mandate of the National Library. It is also clear that these heritage institutions would like to be more involved. Only 15-20% of respondents are involved in the process, yet the interest goes up to 60% when asked if they would like to be more involved in the selection policy (preservation and access issues are coming just behind with 58% and 53%), even if the majority of institutions do not want to be involved in the whole process (around 80%). That is another sign that Web archiving can't be ignored any more.</p>
<p>Because we did not receive any answer from Museums, we are not able to say much about Museums' specificities or needs. Nevertheless, in the third part of this paper we highlight some specific issues we could expect for this field.</p>
<h4>What do they archive?</h4>
<p>A Web archiving selection policy may have to be formulated in the context of an existing organization-wide selection policy, or analogous selection policies for their types of resources. For example, in a country with a legal deposit on printed resources, the National Library would articulate its Web archiving policy in the same way.</p>
<p>One approach is to take the decision not to select, as Internet Archive (<a href="http://www.archive.org/web/web.php">http://www.archive.org/web/web.php</a>). The unselective approach is also possible within more limited contexts, as national domains (as in France or Sweden). So content of collections depends on the kind of institution and also legal limitations.</p>
<p>According to results of the survey, only national libraries (33% of them) operate global crawls on their national Top-Level Domain, but the large majority (93%) focuses on selective and thematic crawls.</p>
<p>On the other hand, we find audiovisual archives (75% of them), focus only on their websites (only 38% collect according to Thematic and Selective crawls). We can imagine that Museums would have the same selection policy: their own websites, with any associated social Web, and maybe some other selective websites as main galleries, specialized forums or blogs.</p>
<p>Concerning thematic selection, institutions can focus on Web domain (such as cern.ch), on subject (presidential elections), or creator (such as all governmental websites).</p>
<h4>How do they manage their Web archiving program?</h4>
<p>A number of different models have emerged for developing and implementing a Web archiving project. They can be categorized as follows:</p>
<ul>
<li>In-house: programs are entirely resourced and managed within the institution (about 70% of respondents are crawling in house). For example, the National Library of France, the Digital Archive of Chinese Studies, the British Library or the Library of Catalonia.</li>
<li>Outsourcing: programs have all or some aspects of the work operated by a contractor (most of these respondents declare that they choose or would choose to collaborate with non-profit Foundations (of 91% of outsourcing respondents, 30% of them collaborate with Internet Archive and 62% with Internet Memory).</li>
<li>Consortium: programs are implemented in a consortium of institutions, using some degree of shared infrastructure, research and development and management.</li>
</ul>
<p>Concerning the staff involved and the budget, numbers really depend on the current stage of the project. Thus, 38% of fully operation programs count more than 5 Full-Time Equivalent (FTE)s, 50% of experimenting and 67% of just started projects count to 2 to 5 FTE's, and around 60% of planned projects count 1 or fewer FTE.</p>
<p>Concerning the budget allocated to the project, curves follow the same evolution: 41% of fully operational institutions declare spending more than €200,000/year; 50.5% of experimental institutions declare from €10,000 to €200,000/year, and more than 70% of planned project institutions declare not to have any budget for this program yet.</p>
<h4>Which access to collections do they provide?</h4>
<p>It depends on legal aspects: all institutions do not provide the same access to their collections for the user.</p>
<table border="0" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<th>Answers</th> <th>Response <br>Percent</th>
</tr>
<tr>
<td>Access is online for anyone</td>
<td>41.0 %</td>
</tr>
<tr>
<td>Access is online with restrictions</td>
<td>27.9 %</td>
</tr>
<tr>
<td>Access is on site for anyone</td>
<td>18.0 %</td>
</tr>
<tr>
<td>Access is on site with restrictions</td>
<td>21.3 %</td>
</tr>
<tr>
<td>We do not have access: contents are in a completely dark archive</td>
<td>21.3 %</td>
</tr>
</tbody>
</table>
<p class="caption">Table 2: Access and Restriction to Web archives (IMF, 2010)</p>
<p>The other interesting aspect of access is the way chosen to navigate in collections.</p>
<h5>Search</h5>
<p>Searching is the most common method. The basic solution is to search for content on the basis of URL. Nevertheless this solution means that users need to know the exact URL. However, because users are more and more accustomed to Google, the most powerful and sophisticated option is provided by full-text searching across the entire collection or just a part of it, with the possibility to include, or not, type of content (.pdf,…).</p>
<h5>Browse</h5>
<p>Browsing Web archives means that the collection has been first categorized, classified, and that a hierarchy has been determined. These classifications can be helpful but offer a single view on the collection depending on decisions made by librarians and archivists. It is also possible to mix both solutions as Internet Memory did for the UK National Archives (<a href="http://collections.europarchive.org/tna/adv_search/">http://collections.europarchive.org/tna/adv_search/</a>).</p>
<p>After this overview of Web archiving, we now discuss the operational aspects of a Web archiving program.</p>
<h2>2.    Web archiving project planning</h2>
<p>Web archiving projects follow a generic production scheme which includes several phases, from the selection to the hosting and the quality review of archived content:</p>
<p class="caption c1"><span class="inline inline-center"><a href="../../image/martin_c_et_al_what_if_web_archiving_were_as_reliable_.html"><img class="image image-preview " src="http://museumsandtheweb.com/files/images/martin-fig1-print.preview.jpg" border="0" alt="Fig 1: Web Archiving production scheme" title="Fig 1: Web Archiving production scheme" width="520" height="520"></a><span class="caption"><strong>Fig 1: Web Archiving production scheme</strong></span></span></p>
<p>At the end of the scheme (quality review), some phases, such as capture, might start again, depending on the overall quality of captured content.</p>
<p>These practical phases of the workflow are presented below.</p>
<h3>Selection</h3>
<p>The selection phase can be divided in three distinct steps:</p>
<ol>
<li>Preparation</li>
<li>Discovery</li>
<li>Filtering</li>
</ol>
<h4>Preparation</h4>
<p>The preparation is an important phase of a Web archiving project as machines follow human orders. The archive quality will therefore depend on the collection definition and policy.</p>
<p>During the preparation phase, one needs to define as precisely as possible its target, its collection policy and any tools, which might be used.</p>
<p>As with building any collection, it is important to list what will be part of the collection and what will be excluded. In the context of Web archives, this can be done under several aspects:</p>
<ul>
<li>The defined collection policy of the institution, its scope: What needs to be captured and preserved?<br> <br> The scope will define the target content to be crawled: broad or focused collection, totally or partially for a website. In some cases, this will avoid duplication between institutions or Departments and will guarantee as much as possible the consistency of the collection.</li>
</ul>
<ul>
<li>Frequency of capture.<br> <br> The team should decide if a selected website or part of a website should be captured daily (for example, because of a political or social event), weekly, monthly, or even six-monthly or yearly (because the content of the website is not updated very often).</li>
</ul>
<ul>
<li>Technical limitations:<br> <br> These can be related to the tools used to capture content. Problems can, for instance, be expected when trying to use a crawler that is best suited for very focused crawls for a large snapshot of a whole national domain. They can also be related to the number of resources available for the project and/or these resources' profile, etc.</li>
</ul>
<p>The preparation phase is therefore crucial as the project plan should meet all defined needs and take into account any predictable limitation.</p>
<h4>Discovery</h4>
<p>Once the targeted content is identified, it is important to find out how to discover and "extract" it from the Web.</p>
<p>Relevant entry points to the content you wish to capture can be discovered before the crawling phase (heterogeneous discovery) or while crawling (endogenous discovery).</p>
<p>By entry point, we mean a URL used as a starting point by the crawler tool to discover resources from the Web. To define the crawler behavior, a scope (as well as a number of technical settings) needs to be associated to the entry point. This will, for instance, force the crawler to follow only URLs that are part of the defined domain name. (e.g.: 123.com is the entry point, the scope states that everything discovered under 123.com should be captured.)</p>
<p>The heterogeneous discovery is very close to any collection building approach. The entry points are discovered manually through hubs, search engines or any relevant sources listing interesting references. If this process is well known and easier to handle, it is also time consuming and only useful for selective crawls. Still, the quality of the collection built will be easier to monitor.</p>
<p>The endogenous discovery relies on the crawler "tool" chosen for the project. It consists in providing a number of relevant entry points to the crawler and letting it discover related URLs. This method is based on the assumption that 1/3 of links are cross-sites links. Obviously, the URLs provided to start the discovery should cover as many aspects of the collection as possible. If not, some URLs might not be discovered because of the way sites link to each other on the Web. For instance, two competitors will not link to each other's website on the web.</p>
<h4>Filtering</h4>
<p>Entry points selected through the previous phases are provided to the crawler "tool" to start a new crawling job.</p>
<p>From there, two types of collections can be created, indexed and hosted, based on the crawling parameters:</p>
<p><strong>Extensive collections</strong> start from the entry points provided and focus on horizontal completion. This means that the crawler is set to go to a limited level of depth. On the way, links to other domains found are used as new entry points. This method will allow the discovery of many URLs but will ensure deep coverage by domain.</p>
<p><strong>Intensive collections</strong> start from the entry point provided and capture any URL which belongs to the related domain (or part of a domain, depending on crawling parameters). With this strategy, the crawler goes as deep as possible to capture a maximum of discovered resources within a domain.</p>
<h3>Management tools and SaaS solutions</h3>
<p>Once the crawler and collection policy are defined, Web archiving teams need to use a management tool.</p>
<p>Management tools can fulfill different purposes, from the management of entry points, collections (name, description, etc), to the management of crawling parameters and even to the automatic launch and monitoring of the crawl themselves. If technical parameters can be set from the management tool, the crawl can either be realized in-house, or be out-sourced with the help of an SaaS (Software as a Service) solution, for example.</p>
<p>This obviously impacts the project's resources. If crawls and technical aspects need to be monitored in-house, an engineering team will be necessary.</p>
<p>Hosting and access to collections are also subject to the choice of running a Web archiving project in-house or out-sourcing it. As for the management tools, access tools such as the Wayback Machine are open source, and maintaining servers to host content is feasible.</p>
<p>Again, at the project level, the choice has to be made to decide if all or some part of the workflow should be outsourced for economical or technical reasons.</p>
<h3>Quality assurance</h3>
<p>Most of the SaaS solutions do not offer any quality review of collections.</p>
<p>Once content is captured, it is archived and either hosted to allow access to content, or delivered to the institution in the standard archiving format (ISO 28500:WARC).</p>
<p>The quality review is obviously based on the institution's needs and its collection policy. It can be manual or "automated".</p>
<p>Quality control is a time-consuming task when done manually. It requires operators to be trained on what is a Web archive is, as well as tools used to collect content and their limits.</p>
<p>Based on their knowledge of the crawler behavior, operators test links methodically to discover missing resources which can then be added to the archive if decided by the project team. Indeed, adding resources to the archive after the crawl can be considered as an improvement of the archive quality, but also as an alteration of the archive. In the latter case, temporal incoherence can be experienced; for instance, when adding some content to an archived version of a page which was already updated on the live version.</p>
<p>Some tools can facilitate manual checking: tools such as browsers' plug-ins or proxies, for instance, by listing 404's when loading a page.</p>
<p>Some basic bug-tracking tool can also be used to compile information about collections at the entry point level. This may allow assessors to define areas of difficulties or technical limitations that might require development.</p>
<p>Automated quality assurance requires the use of tools such as URL testers, which can be coupled with other tools to facilitate missing resources recovery and archiving. Such tools are usually developed internally and based on users' experience and needs.</p>
<h2>3.    State of the Art</h2>
<p>Web archiving requires tools to collect, preserve and access archived Web content. The International Internet Preservation Consortium has developed tools and methods to process Web archiving at each step of the process. Furthermore, other institutions such as the Internet Memory Foundation, but also companies and universities, develop their own tools.</p>
<p>This next part proposes an inventory of the tools useful for the Web archiving process: for selection, crawler, access, and preservation.</p>
<h3>Selection</h3>
<p>Most of the institutions which are involved in Web archiving create some focus collection based on specific contents: event, thematic… Management tools are developed to help curators or archivists to follow the process.</p>
<ul>
<li>Netarchivesuite (<a href="http://netarchive.dk/suite/">http://netarchive.dk/suite/</a>) developed by the two national deposit libraries in Denmark, The Royal Library and The State and University Library, is an open source tool that allows planning, scheduling and operation of Web harvests for selective and broad crawl with a built-in bit preservation functionality (replication).</li>
<li>The Web curator tool (<a href="http://webcurator.sourceforge.net/">http://webcurator.sourceforge.net</a>) is an open-source workflow management application for selective Web archiving developed by the National Library of New Zealand and the British Library, initiated by the International Internet Preservation Consortium.</li>
<li>Archive-it (<a href="http://www.archive-it.org/">http://www.archive-it.org/</a>) is a subscription service by Internet Archive to build and preserve collections. It allows harvesting, cataloguing, managing and browsing archived collections.</li>
<li>Archivethe.net, AtN (<a href="http://archivethe.net/">http://archivethe.net</a>) is a shared Web archiving platform operated by the Internet Memory Foundation. AtN helps institutions to easily and quickly start collecting websites including dynamic content and rich media, enabling navigation in past versions of a website as if it were still live. By using a shared platform, institutions retain full control of their collection policy (sites selection, depth, gathering frequency, etc.), while benefiting from a dedicated and optimized crawling infrastructure. They also retain custody of collected material, with regular delivery of complete copies of collected material in the ISO 28500:2009 WARC format.</li>
</ul>
<h3>Crawls strategy</h3>
<p>The collects are made with robots named crawlers. Collecting the Web is not an easy thing to do. Robots function in a similar way to crawlers for search engines. They must fit all the heterogeneity of architectures, (dynamic, social Web…), languages and formats (video, text, audio files…) and also interpret links. Links are the center of crawling problems as they are the key to discovery of content.</p>
<p>Several types of links can be found:</p>
<ul>
<li>Explicit links: source code is available and full path is explicitly stated</li>
<li>Variable link: source code is available but uses variables to encode the path</li>
<li>Opaque links: source code is not available.</li>
<li>Different strategies are developed:</li>
<li>Httrack or Heritrix (<a href="http://crawler.archive.org/">http://crawler.archive.org</a>) is the Internet Archive's open-source, extensible, Web scale, archival-quality Web crawler project. It works as a parser, extracts links and archives the content on the fly.</li>
<li>The other method consists in downloading the page as a browser, replaying the page, and downloading the pages and repeating the operation for all the pages of the website. <span>This technology has been developed by Hanzo (<a href="http://www.hanzoarchives.com/">http://www.hanzoarchives.com/</a>)</span></li>
</ul>
<p>To improve the crawl process, modules have been developed. In the context of the LiWA (Living Web Archives) European Project, new technologies have been developed to extend <span>the current state of the art for capture, preservation, analysis, and enrichment services altogether, to improve fidelity, coherence, and interpretability of Web archives.</span></p>
<ul>
<li>SPAM Module: Web Spam (automatically generated Web content to cheat search engines) has become a real industry estimated to represent up to 20% of all Web. In the context of Web archiving, we can easily understand that archiving Spam is a big challenge in terms of costs (saving time during crawl process and hosting) and content compliance.<br> <br> The SPAM module enables assessment of the crawled Web hosts. For each host, the module defines a "spamcity" of the host and decides whether or not the host has to be archived.</li>
</ul>
<ul>
<li>Rich media capture: The Rich Media Capture module (RMC), developed in LiWA, is designed to enhance the capturing capabilities of the crawler, with regards to different multimedia content types. The current version of Heritrix is mainly based on the HTTP/HTTPS protocols, and it cannot treat other content transfer protocols widely used for the multimedia content, such as streaming.</li>
<li>Temporal coherence: website may take hours to be crawled, during which changes can be made or pages can become unavailable. The module includes methods for proper dating of Web pages and provides coherent crawls with complete and correct temporal metadata, including time-aware reference sources such as the Wikipedia history.</li>
</ul>
<h3>Access</h3>
<p>A Web archive is a copy of a website recorded by a crawler at a specific date and time. Each institution involved in Web archiving develops its own strategy. The main large public archive is available through the Internet Archive and Internet Memory Foundation. Some archives have only restricted access. This is the case for the French National Library, where archives are available on site only for accredited researchers, or in Austria. To browse the archive, users can research by URL or by full text.</p>
<p>Most institutions use the open source Wayback Machine developed by Internet Archive with the support of IIPC. Through a form a user submits an URL. The tool provides a table with all the archive dates for a given URL. By clicking on a date, the user can browse the archive. The URL archived is rewritten on the fly by the Wayback to ensure that navigation is really done on the archive and not on the live Web. Other access tools use a server-side rewriting method.</p>
<p>Currently, most implementation of full text research is based on Lucene (<a href="http://lucene.apache.org/">http://lucene.apache.org/</a>).</p>
<p>As Web archiving has become more popular, user requirements have been taken into account in order to develop smart access. Thus, several user interfaces have been developed. The UI framework developed by LIWA provides a new timetable browser and an organizer. Other institutions like UKWAC (UK Web Archive) provide access to the archive by collection and using a time frame.</p>
<p>Another interesting development is initiatives to embed Web archives as part of the user experience. The Internet Memory Foundation has implemented with its partner The UK National Archives a redirection service that enables a user to be automatically redirected to the archive when the content is no longer available online.</p>
<h3>Preservation</h3>
<p>The issue of the preservation is linked to the issue of format and metadata. Web archives are recorded in a specific ISO format: WARC.</p>
<p>ISO 28500:2009 specifies the WARC file format. The WARC (Web ARChive) format specifies a method for combining multiple digital resources into an aggregate archival file together with related information. Resources are dated, identified by URIs, and preceded by simple text headers, using MIME entities. By convention, files of this format are named with the extension ".warc" and have the MIME type application/warc. The WARC file format is a revision and generalization of the ARC originally developed by the Internet Archive to store information blocks harvested by Web crawlers.</p>
<h3 class="c2">4.    Metadata</h3>
<p>In terms of preservation, Web collection consists of collected documents and their metadata and form together a network of content and description of content. Technical dependency is key for Web material as well as for digital objects in general.</p>
<p>Several levels of metadata have to be collected and preserved to ensure the reliability of the archive. Metadata from the selection process give information about the context of the crawl, which policy content was chosen, its original place, and its evaluation. Metadata about documents (size, format, checksum…) can be leveraged for preservation policy (migration, emulation and bit-level preservation). In addition to this, Metadata about the process gathers information about the communication with the server during the archiving process (giving important context to the documents preserved).</p>
<h2>5.    Challenges</h2>
<p>Challenges come from the richness and variety of Internet content and its increasing dependency on new publishing technologies. We will focus here on the most relevant issues for institutions such as Museums and Galleries.</p>
<h3>Video</h3>
<p>Internet is a perfect media to offer good visibility to videos: from videos such as interviews of artists, or visitors' experiences, to videos as full-fledged artistic work, videos of performances and happenings etc. These videos are stored on museum websites and/or hosted on external platforms like YouTube. Thus, you will find the same video of "TateShots: Ai Weiwei, one-to-one" on the Tate Gallery website and also on their YouTube channel.</p>
<p>But capturing Web video is quite complicated because the technology used aims at avoiding direct access to the files by the users. Two main categories of issues have been highlighted.</p>
<ol>
<li>For websites that use standard HTTP protocol to deliver video content, the difficulty consists in the various techniques used to obfuscate links to video files (2 or 3 hops and redirects): YouTube is a representative example.</li>
<li>Some websites use transport protocols other than HTTP, such as RTMP streaming protocol (<a href="http://www.swr.de/">http://www.swr.de</a>).</li>
</ol>
<p>The Internet Memory Foundation has developed some tools to overcome these problems, but it seems difficult to design general solutions for dealing with all the websites hosting video content. Moreover, the State of the Art for delivering Web video is changing fast, and Web archiving technologies will have to adapt to each particular case.</p>
<h3>Social Web</h3>
<p>The Social Web is also becoming a new challenge for preservation. Our information society is characterized by radical changes in information creation, communication and citizen involvement (e.g., there are now more social network items created than Google searches). Social media are becoming more and more pervasive in all areas of life. For example, Museums and Galleries are using Twitter and Facebook to inform their communities of new events.</p>
<p>On the one hand, this material is both ephemeral and highly contextualized, making it increasingly difficult for an archivist to decide what to preserve.</p>
<p>On the other hand, the social Web is based on dynamic websites and uses some specific technologies to publish content. New preservation strategies have to be created to enable the capture of this content in terms of selection and crawls. These issues are addressed on the research level by the European Commission-funded ARCOMEM project (Collect-All ARchives to COmmunity MEMories - <a href="http://internetmemory.org/en/index.php/projects/arcomem1">http://internetmemory.org/en/index.php/projects/arcomem1</a>).</p>
<h3>Net'art</h3>
<p>In the context of the Museum, Net'art preservation represents a challenge. Net'art covers a wide range of practices. In a global definition, Net'art gathers all creations based on the Internet as the medium when they cannot be experienced in any other way. In this framework, the artwork is as much the design of interactive devices that produce life forms online as interaction with the social Web. The Internet is just as invested as a workshop. How does one preserve such an immaterial artwork in the state of the art of the technology?</p>
<p>The work of Albertine Meunier, a French artist, questions in a critical or amusing way web<span class="BodyTextChar">sites such as Google, Facebook or freebase. In 2006, she began "My Google Search History": the artist is publishing month after month, on a website, a comprehensive inventory of Google searches, questioning the retention of personal data by search engines. The artwork includes applications and results. Both aspects have to be considered for preservation. How to collect such materials?</span></p>
<p>An interesting experience designed by the British Library in 2009 illustrated this. "One &amp; Other" is a live artwork by sculptor Antony Gormley. Over 100 days and nights, each of 2,400 participants representing every region of the UK spent an hour alone on an empty plinth in Trafalgar Square. All participants, or plinthers, were filmed, and the videos were brought together on the project website (<a href="http://www.oneandother.co.uk/">http://www.oneandother.co.uk</a>). The website received over 7 million visits during the project. Overly complex URL structures include numerous variables, marked by ampersands, equal signs, session or user IDs, as well as referral tracking.</p>
<p>The question of the preservation of this website was at the center of the project. In this context, the British Library has implemented a new solution to cover this event, dealing with archiving rich media and replaying it.</p>
<h2>6.    Conclusion</h2>
<p>Web archiving has a great future ahead, but huge challenges. Since the Web was born, it has evolved in many ways, and the continuous development of the Web will require Web archiving actors to think and adapt at a fast pace and to develop scaling technologies.</p>
<p>The Internet Memory Foundation has, for many years, and thanks to collaboration with many partners and in several research projects, put its best effort into meeting these challenges. Its research areas are mainly the scalability and automation of process and the development of tools to use Web archives in a relevant way. Indeed, the final purpose is not only to be able to capture Web content, but also to preserve and share it.</p>
<h2>7.    References</h2>
<p class="ReferencesText">Brown, A. (2006). Archiving websites. London: Facet Publishing.</p>
<p class="ReferencesText">Hockx-Yu Helen, L. Crawford, R. Coram &amp; S. Johnson (2010). "Capturing and replaying streaming media in web archive - A British Library Case Study". International Conference on Preservation of Digital Objects (iPRES2010, Vienna). Consulted January 31, 2011. <a href="http://www.ifs.tuwien.ac.at/dp/ipres2010/index.html%20&amp;%20http://www.ifs.tuwien.ac.at/dp/ipres2010/papers/hockxyu-44.pdf">http://www.ifs.tuwien.ac.at/dp/ipres2010/index.html &amp; http://www.ifs.tuwien.ac.at/dp/ipres2010/papers/hockxyu-44.pdf</a></p>
<p class="ReferencesText">Masanès, J., R. Pop &amp; G. Vasile (2010). Archiving Web video. Vienna 2010: International Web Archiving Workshop. Consulted January 31, 2011. <a href="http://iwaw.europarchive.org/10/IWAW2010.pdf">http://iwaw.europarchive.org/10/IWAW2010.pdf</a></p>
<p class="ReferencesText">Masanès, J. (2006). Web Archiving. Springer-Verlag Berlin Heidelberg.</p>
<p class="ReferencesText">Meunier, A. (2006). My Google Search History. Publication November 11, 2006. Consulted January 31, 2011. <a href="http://www.albertinemeunier.net/google_search_history/google_search_history.htm">http://www.albertinemeunier.net/google_search_history/google_search_history.htm</a></p>
<p class="ReferencesText">Tate Gallery, TateShots: Ai Weiwei, one-to-one. Publication January 27, 2011. Consulted January 31, 2011. <a href="http://channel.tate.org.uk/#media:/media/766906069001&amp;list:/channel">http://channel.tate.org.uk/#media:/media/766906069001&amp;list:/channel/playlists/45927933001&amp;context:/channel/playlists</a></p>
<p class="ReferencesText">Tate Gallery, YouTube channel. TateShots: Ai Weiwei, one-to-one. Publication January 28, 2011. Consulted January 31, 2011. <a href="http://www.youtube.com/watch?v=4sy1AFYxDmo">http://www.youtube.com/watch?v=4sy1AFYxDmo</a></p>
</div>
<div id="citation">
<h4>Cite as:</h4>
<p class="references">Martin, C., et al., What If Web Archiving Were as Reliable As Pushing a Simple Button? In J. Trant and D. Bearman (eds). <em>Museums and the Web 2011: Proceedings</em>. Toronto: Archives &amp; Museum Informatics. Published March 31, 2011. Consulted
<script type="text/javascript">// <![CDATA[
 <![CDATA[
      // current date - based on http://rainbow.arch.scriptmania.com/scripts
      // Array of day names
      var dayNames = new Array("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday");

      var monthNames = new Array("January","February","March","April","May","June","July",
                           "August","September","October","November","December");

      var dt = new Date();
      var y  = dt.getYear();

      // Y2K compliant
      if (y < 1000) y +=1900;

      document.write(monthNames[dt.getMonth()] + " " + dt.getDate() + ", " + y + ". ");
                       // 
// ]]></script>
http://conference.archimuse.com/mw2011/papers/what_if_web_archiving</p>
</div>
<div id="copyright"><a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/3.0/"><img class="c3" src="../../files/images/cc-88x31.png" border="0" alt="Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 License" width="88" height="31"></a>
<p>Copyright © 2011 - Archives &amp; Museum Informatics.</p>
</div><div class="field nodereference field-paper-program-ref">
                                <h3 class="label inline">Program Item Reference:&nbsp;</h3>
          <div class="item inline odd"><a href="../programs/web_archiving_workshop.html">Web Archiving Workshop</a></div>
              </div>
 <!-- /content-field -->
  </div>
  
  <div class="article-meta">
      <p class="submitted">Posted <em class="time">March 27, 2011 - 9:24pm</em> by <em class="author"><a href="../../user/chlo_martin.html" class="username" title="View Chloé&#039;s profile.">Chloé Martin</a></em></p>
  
    
  <ul class="taxonomy"><li><a href="../../conferences/mw/mw2011.html" rel="tag" title="Museums and the Web 2011">MW2011</a></li><li><a href="../../paper_tags/collection.html" rel="tag" title="">collection</a></li><li><a href="../../paper_keywords/internet_0.html" rel="tag" title="">internet</a></li><li><a href="../../paper_keywords/preservation_0.html" rel="tag" title="">preservation</a></li><li><a href="../../paper_keywords/state_of_the_art_0.html" rel="tag" title="">State of the Art</a></li><li><a href="../../paper_tags/web_archiving.html" rel="tag" title="">Web archiving</a></li></ul>  </div>
  
  
</div> <!-- /article --></div>

        </div> <!-- /main-content -->

        
      </div></div> <!-- /content-column -->

              <div id="sidebar-first" class="sidebar">  <div id="block-menu-menu-mw2011-menu" class="block block-menu odd block-region-sidebar-first block-count-2">
  <div class="block-inner">

          <h2 class="block-title">MW2011 Main Menu</h2>
    
    <div class="content"><ul class="menu">
 <li class="leaf first about-mw2011"><a href="../about.html" title="Museums and the Web - the international conference for culture and heritage online">About MW2011</a></li>
<li class="leaf workshops"><a href="../workshops.html" title="Explore topics in-depth in full or half-day pre-conference workshops">Workshops</a></li>
<li class="leaf sessions"><a href="../sessions.html" title="Presentations including Mini-Workshops and Professional Forums">Sessions</a></li>
<li class="collapsed speakers"><a href="../speakers.html" title="People from around the world present their latest work">Speakers</a></li>
<li class="leaf demonstrations"><a href="../demonstrations.html" title="See new museum Web sites up-close">Demonstrations</a></li>
<li class="leaf exhibits"><a href="../exhibits.html" title="Software and services for museums, libraries and archives online">Exhibits</a></li>
<li class="collapsed best-of-the-web"><a href="../best.html" title="Recognizing the best work on the cultural Web">Best of the Web</a></li>
<li class="leaf program-committee"><a href="../program_committee.html" title="Proposals for MW are peer-reviewed by this group">Program Committee</a></li>
<li class="leaf collaborators"><a href="../thanks.html" title="Thanks everyone! We couldn&#039;t do it without you.">Collaborators</a></li>
<li class="leaf mw-online"><a href="../mw2011_online_the_permanent_backchannel.html" title="Find MW2011 online and in social media">MW Online</a></li>
<li class="collapsed registration"><a href="../register.html" title="Join us in Philadelphia">Registration</a></li>
<li class="leaf scholarships"><a href="../scholarships.html" title="Need some help getting to MW2011?">Scholarships</a></li>
<li class="leaf local-information"><a href="../local.html" title="Details about Philadelphia + the Conference Hotel">Local Information</a></li>
<li class="leaf events"><a href="../events.html" title="Social events throughout MW2011">Events</a></li>
<li class="leaf key-dates"><a href="../dates.html" title="Watch these dates leading up to MW2011">Key Dates</a></li>
<li class="leaf suggestions-"><a href="../../forum/suggestions_for_the_mw2011_program.html" title="Got ideas for MW2011? Leave us a note in the online community">Suggestions?</a></li>
<li class="leaf last questions-"><a href="../../forum/heads_museums_and_web_2011_mw2011.html" title="See the Frequently Asked Questions in the online community">Questions?</a></li>
 </ul>
</div>

    
  </div>
</div> <!-- /block -->
</div> <!-- /sidebar-first -->
      
      
    </div></div> <!-- /columns -->

    
          <div id="footer">

                  <div id="footer-region">  <div id="block-panels_mini-footer" class="block block-panels_mini odd block-region-footer block-count-3">
  <div class="block-inner">

    
    <div class="content"><div class="panel-flexible panels-flexible-4 clear-block" id="mini-panel-footer">
<div class="panel-flexible-inside panels-flexible-4-inside">
<div class="panels-flexible-region panels-flexible-region-4-left panels-flexible-region-first left">
  <div class="inside panels-flexible-region-inside panels-flexible-region-4-left-inside panels-flexible-region-inside-first">
  </div>
</div>
<div class="panels-flexible-region panels-flexible-region-4-center center">
  <div class="inside panels-flexible-region-inside panels-flexible-region-4-center-inside">
<div class="panel-pane pane-custom pane-3 " >
  
      <h2 class="pane-title">Founded by Archives &amp; Museum Informatics</h2>
  
  
  <div class="pane-content">
    <p><a href="http://www.archimuse.com/" title="www.archimuse.com">www.archimuse.com</a></p>
  </div>

  
  </div> <!-- /panels-pane -->
  </div>
</div>
<div class="panels-flexible-region panels-flexible-region-4-right panels-flexible-region-last right">
  <div class="inside panels-flexible-region-inside panels-flexible-region-4-right-inside panels-flexible-region-inside-last">
<div class="panel-pane pane-custom pane-4 " >
  
      <h2 class="pane-title">Managed by Museums and the Web LLC</h2>
  
  
  <div class="pane-content">
    <p>703 Dale Drive<br />
Silver Spring MD 20910 USA<br />
info @ museumsandtheweb.com<br />
<a href="../../terms.html">Terms and Conditions</a> </p>
  </div>

  
  </div> <!-- /panels-pane -->
  </div>
</div>
</div>
</div>
</div>

    
  </div>
</div> <!-- /block -->
</div> <!-- /footer-region -->
        
        
      </div> <!-- /footer -->
    
  </div> <!-- /container -->

  <script type="text/javascript">
  var _sf_async_config=Drupal.settings.chartbeat;
  (function(){
    function loadChartbeat() {
      window._sf_endpt=(new Date()).getTime();
      var e = document.createElement('script');
      e.setAttribute('language', 'javascript');
      e.setAttribute('type', 'text/javascript');
      e.setAttribute('src',
         (("https:" == document.location.protocol) ? "http://s3.amazonaws.com/" : "http://") +
         "static.chartbeat.com/js/chartbeat.js");
      document.body.appendChild(e);
    }
    var oldonload = window.onload;
    window.onload = (typeof window.onload != 'function') ?
       loadChartbeat : function() { oldonload(); loadChartbeat(); };
  })();
</script><script type="text/javascript">
<!--//--><![CDATA[//><!--
var _gaq = _gaq || [];_gaq.push(["_setAccount", "UA-26332456-1"]);_gaq.push(['_setAllowLinker', true]);
_gaq.push(['_setAllowHash', false]);_gaq.push(["_trackPageview"]);(function() {var ga = document.createElement("script");ga.type = "text/javascript";ga.async = true;ga.src = ("https:" == document.location.protocol ? "http://ssl" : "http://www") + ".google-analytics.com/ga.js";var s = document.getElementsByTagName("script")[0];s.parentNode.insertBefore(ga, s);})();
//--><!]]>
</script>

</body>

<!-- Mirrored from www.museumsandtheweb.com/mw2011/papers/what_if_web_archiving_were_as_reliable_as_push by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 17:09:04 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
</html>
