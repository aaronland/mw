<!DOCTYPE html>
<html lang="en-US" class="no-js">

<!-- Mirrored from mw17.mwconf.org/paper/a-case-study-on-using-voice-technology-to-assist-the-museum-visitor/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 23 Apr 2022 22:00:26 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,400i,600,700" rel="stylesheet">
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0"/>
	<link rel="profile" href="http://gmpg.org/xfn/11">
		<script>(function(html){html.className = html.className.replace(/\bno-js\b/,'js')})(document.documentElement);</script>
<title>A case study on using voice technology to assist the museum visitor &#8211; MW17: Museums and the Web 2017</title>
<link rel='dns-prefetch' href='../../index.html' />
<link rel='dns-prefetch' href='http://fonts.googleapis.com/' />
<link rel='dns-prefetch' href='http://s.w.org/' />
<link href='https://fonts.gstatic.com/' crossorigin rel='preconnect' />
<link rel="alternate" type="application/rss+xml" title="MW17: Museums and the Web 2017 &raquo; Feed" href="../../feed/index.html" />
<link rel="alternate" type="application/rss+xml" title="MW17: Museums and the Web 2017 &raquo; Comments Feed" href="../../comments/feed/index.html" />
<link rel="alternate" type="application/rss+xml" title="MW17: Museums and the Web 2017 &raquo; A case study on using voice technology to assist the museum visitor Comments Feed" href="feed/index.html" />
		<script>
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/mw17.mwconf.org\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.6"}};
			!function(e,a,t){var r,n,o,i,p=a.createElement("canvas"),s=p.getContext&&p.getContext("2d");function c(e,t){var a=String.fromCharCode;s.clearRect(0,0,p.width,p.height),s.fillText(a.apply(this,e),0,0);var r=p.toDataURL();return s.clearRect(0,0,p.width,p.height),s.fillText(a.apply(this,t),0,0),r===p.toDataURL()}function l(e){if(!s||!s.fillText)return!1;switch(s.textBaseline="top",s.font="600 32px Arial",e){case"flag":return!c([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])&&(!c([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!c([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]));case"emoji":return!c([55357,56424,8205,55356,57212],[55357,56424,8203,55356,57212])}return!1}function d(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(i=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},o=0;o<i.length;o++)t.supports[i[o]]=l(i[o]),t.supports.everything=t.supports.everything&&t.supports[i[o]],"flag"!==i[o]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[i[o]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(r=t.source||{}).concatemoji?d(r.concatemoji):r.wpemoji&&r.twemoji&&(d(r.twemoji),d(r.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style>
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='wp-block-library-css'  href='../../wp-includes/css/dist/block-library/style.min40df.css?ver=5.6' media='all' />
<link rel='stylesheet' id='wp-block-library-theme-css'  href='../../wp-includes/css/dist/block-library/theme.min40df.css?ver=5.6' media='all' />
<link rel='stylesheet' id='sidebar-login-css'  href='../../wp-content/plugins/sidebar-login/build/sidebar-login3822.css?ver=1604077128' media='all' />
<link rel='stylesheet' id='parent-style-css'  href='../../wp-content/themes/twentysixteen/style40df.css?ver=5.6' media='all' />
<link rel='stylesheet' id='child-style-css'  href='../../wp-content/themes/mw-twentysixteen/style40df.css?ver=5.6' media='all' />
<link rel='stylesheet' id='twentysixteen-fonts-css'  href='https://fonts.googleapis.com/css?family=Merriweather%3A400%2C700%2C900%2C400italic%2C700italic%2C900italic%7CMontserrat%3A400%2C700%7CInconsolata%3A400&amp;subset=latin%2Clatin-ext&amp;display=fallback' media='all' />
<link rel='stylesheet' id='genericons-css'  href='../../wp-content/themes/twentysixteen/genericons/genericons3ce7.css?ver=20201208' media='all' />
<link rel='stylesheet' id='twentysixteen-style-css'  href='../../wp-content/themes/mw-twentysixteen/style3ce7.css?ver=20201208' media='all' />
<style id='twentysixteen-style-inline-css'>

		/* Custom Link Color */
		.menu-toggle:hover,
		.menu-toggle:focus,
		a,
		.main-navigation a:hover,
		.main-navigation a:focus,
		.dropdown-toggle:hover,
		.dropdown-toggle:focus,
		.social-navigation a:hover:before,
		.social-navigation a:focus:before,
		.post-navigation a:hover .post-title,
		.post-navigation a:focus .post-title,
		.tagcloud a:hover,
		.tagcloud a:focus,
		.site-branding .site-title a:hover,
		.site-branding .site-title a:focus,
		.entry-title a:hover,
		.entry-title a:focus,
		.entry-footer a:hover,
		.entry-footer a:focus,
		.comment-metadata a:hover,
		.comment-metadata a:focus,
		.pingback .comment-edit-link:hover,
		.pingback .comment-edit-link:focus,
		.comment-reply-link,
		.comment-reply-link:hover,
		.comment-reply-link:focus,
		.required,
		.site-info a:hover,
		.site-info a:focus {
			color: #e55747;
		}

		mark,
		ins,
		button:hover,
		button:focus,
		input[type="button"]:hover,
		input[type="button"]:focus,
		input[type="reset"]:hover,
		input[type="reset"]:focus,
		input[type="submit"]:hover,
		input[type="submit"]:focus,
		.pagination .prev:hover,
		.pagination .prev:focus,
		.pagination .next:hover,
		.pagination .next:focus,
		.widget_calendar tbody a,
		.page-links a:hover,
		.page-links a:focus {
			background-color: #e55747;
		}

		input[type="date"]:focus,
		input[type="time"]:focus,
		input[type="datetime-local"]:focus,
		input[type="week"]:focus,
		input[type="month"]:focus,
		input[type="text"]:focus,
		input[type="email"]:focus,
		input[type="url"]:focus,
		input[type="password"]:focus,
		input[type="search"]:focus,
		input[type="tel"]:focus,
		input[type="number"]:focus,
		textarea:focus,
		.tagcloud a:hover,
		.tagcloud a:focus,
		.menu-toggle:hover,
		.menu-toggle:focus {
			border-color: #e55747;
		}

		@media screen and (min-width: 56.875em) {
			.main-navigation li:hover > a,
			.main-navigation li.focus > a {
				color: #e55747;
			}
		}
	
</style>
<link rel='stylesheet' id='twentysixteen-block-style-css'  href='../../wp-content/themes/twentysixteen/css/blockscb8b.css?ver=20190102' media='all' />
<!--[if lt IE 10]>
<link rel='stylesheet' id='twentysixteen-ie-css'  href='https://mw17.mwconf.org/wp-content/themes/twentysixteen/css/ie.css?ver=20170530' media='all' />
<![endif]-->
<!--[if lt IE 9]>
<link rel='stylesheet' id='twentysixteen-ie8-css'  href='https://mw17.mwconf.org/wp-content/themes/twentysixteen/css/ie8.css?ver=20170530' media='all' />
<![endif]-->
<!--[if lt IE 8]>
<link rel='stylesheet' id='twentysixteen-ie7-css'  href='https://mw17.mwconf.org/wp-content/themes/twentysixteen/css/ie7.css?ver=20170530' media='all' />
<![endif]-->
<!--[if lt IE 9]>
<script src='https://mw17.mwconf.org/wp-content/themes/twentysixteen/js/html5.js?ver=3.7.3' id='twentysixteen-html5-js'></script>
<![endif]-->
<script src='../../wp-includes/js/jquery/jquery.min9d52.js?ver=3.5.1' id='jquery-core-js'></script>
<script src='../../wp-includes/js/jquery/jquery-migrate.mind617.js?ver=3.3.2' id='jquery-migrate-js'></script>
<link rel="https://api.w.org/" href="../../wp-json/index.html" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="../../xmlrpc0db0.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="../../wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 5.6" />
<link rel="canonical" href="index.html" />
<link rel='shortlink' href='../../index8ae4.html?p=798' />
<link rel="alternate" type="application/json+oembed" href="../../wp-json/oembed/1.0/embed322f.json?url=https%3A%2F%2Fmw17.mwconf.org%2Fpaper%2Fa-case-study-on-using-voice-technology-to-assist-the-museum-visitor%2F" />
<link rel="alternate" type="text/xml+oembed" href="../../wp-json/oembed/1.0/embed5b0d?url=https%3A%2F%2Fmw17.mwconf.org%2Fpaper%2Fa-case-study-on-using-voice-technology-to-assist-the-museum-visitor%2F&amp;format=xml" />
	<script src="https://use.typekit.net/cfh1uqy.js"></script>
	<script>try{Typekit.load({ async: true });}catch(e){}</script>
	<script type="text/javascript" src="../../wp-content/themes/mw-twentysixteen/flexibility.js"></script>
</head>

<body class="paper-template-default single single-paper postid-798 wp-custom-logo wp-embed-responsive">
<div id="page" class="site"> <!-- TAG CLOSES IN FOOTER.PHP (.site) -->
	<div class="site-inner"> <!-- TAG CLOSES IN FOOTER.PHP (.site-inner) -->
		<a class="skip-link screen-reader-text" href="#content">Skip to content</a>
		<header id="masthead" class="site-header" role="banner">
		<div class="site-header-main">
					<div class="site-branding">
						<a href="../../index.html" class="custom-logo-link" rel="home"><img width="240" height="240" src="../../wp-content/uploads/2017/02/cropped-mw-final.png" class="custom-logo" alt="MW17: Museums and the Web 2017" /></a>					</div>

											<button id="menu-toggle" class="menu-toggle">Menu</button>

						<div id="site-header-menu" class="site-header-menu">
							<div class="top-nav-desc">
								<p> MW17: Museums and the Web 2017 <span>Cleveland Ohio - April 19-22</span></p>
								<form class="search-form" role="search" method="get" action="#">
									<label>
										<span class="screen-reader-text">Search for:</span>
										<input class="search-field" placeholder="Search …" value="" name="s" type="search">
									</label>
									<button class="search-submit" type="submit">
										<span class="screen-reader-text">Search</span>
									</button>
								</form>
							</div>
															<nav id="site-navigation" class="main-navigation" role="navigation" aria-label="Primary Menu">
									<div class="menu-menu-1-container"><ul id="menu-menu-1" class="primary-menu"><li id="menu-item-3074" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-3074"><a href="https://museumsandtheweb.com/">MW Home</a></li>
<li id="menu-item-88" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-has-children menu-item-88"><a href="../../index.html">About</a>
<ul class="sub-menu">
	<li id="menu-item-90" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-90"><a href="../../key-dates/index.html">Key Dates</a></li>
	<li id="menu-item-580" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-580"><a href="../../local-information-and-accommodation/index.html">Local Information and Accommodation</a></li>
	<li id="menu-item-1917" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1917"><a href="../../faqs/index.html">FAQs</a></li>
</ul>
</li>
<li id="menu-item-172" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-172"><a href="../../attending/index.html">Attending</a>
<ul class="sub-menu">
	<li id="menu-item-552" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-552"><a href="../../registration/index.html">Registration</a></li>
	<li id="menu-item-475" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-475"><a href="../../scholarships-volunteering/index.html">Scholarships &#038; Volunteering</a></li>
</ul>
</li>
<li id="menu-item-108" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-108"><a href="../../call-for-proposals/index.html">Presenting</a>
<ul class="sub-menu">
	<li id="menu-item-490" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-490"><a href="../../call-for-proposals/index.html">Call for Proposals</a></li>
	<li id="menu-item-494" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-494"><a href="../../presentation-guidelines/index.html">Presentation Guidelines</a></li>
	<li id="menu-item-489" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-489"><a href="../../paper-guidelines/index.html">Paper Guidelines</a></li>
</ul>
</li>
<li id="menu-item-135" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-135"><a href="../../exhibiting/index.html">Exhibiting</a>
<ul class="sub-menu">
	<li id="menu-item-479" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-479"><a href="../../exhibitor-registration/index.html">Exhibitor Registration</a></li>
	<li id="menu-item-173" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-173"><a href="../../sponsorship-opportunities/index.html">Sponsorship Opportunities</a></li>
	<li id="menu-item-1689" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1689"><a href="../../advertising/index.html">Advertising</a></li>
</ul>
</li>
<li id="menu-item-573" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-573"><a href="../../program/index.html">Conference</a>
<ul class="sub-menu">
	<li id="menu-item-2972" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2972"><a href="../../program/index.html">Program</a></li>
	<li id="menu-item-483" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-483"><a href="../../exhibits/index.html">Exhibits</a></li>
	<li id="menu-item-3023" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3023"><a href="../../select-session-slides/index.html">Presentations</a></li>
	<li id="menu-item-1760" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1760"><a href="../../glami-awards/index.html">GLAMi Awards</a>
	<ul class="sub-menu">
		<li id="menu-item-2968" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2968"><a href="../../glami-winners/index.html">GLAMi Winners</a></li>
		<li id="menu-item-2963" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2963"><a href="../../glami-nominees/index.html">GLAMi Nominees</a></li>
	</ul>
</li>
	<li id="menu-item-2894" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2894"><a href="../../mwx/index.html">MWX 2017</a></li>
	<li id="menu-item-1252" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1252"><a href="../../attendees/index.html">Attendees</a></li>
	<li id="menu-item-460" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-460"><a href="../../committees/index.html">Committees</a></li>
</ul>
</li>
<li>
    <form role='search' method='get' class='search-form' action='http://mw17.mwconf.org/'>
	<label>
	<span class='screen-reader-text'>Search for:</span>
	<input type='search' class='search-field' placeholder='Search &hellip;' value='' name='s' />
	</label>
	<button type='submit' class='search-submit'>
	<span class='screen-reader-text'>Search</span></button>
	</form>    
	</li></ul></div>								</nav><!-- .main-navigation -->
							
													</div><!-- .site-header-menu -->
									</div><!-- .site-header-main -->

			</header><!-- .site-header -->


	
<section id="page-hero">
	<div class="background"> </div>
</section>
<script>
    var images = ['page-hero1.jpg', 'page-hero2.html', 'page-hero3.html', 'page-hero4.html', 'page-hero5.html','page-hero6.html', 'page-hero7.html', 'page-hero8.jpg' ];
    jQuery('#page-hero .background').css("background", "rgba(0, 0, 0, 0) url('https://mw17.mwconf.org/wp-content/themes/mw-twentysixteen/images/" +images[Math.floor(Math.random() * images.length)]+ "') no-repeat scroll center top / cover") 
	</script>

	<div id="content" class="site-content"> <!-- TAG CLOSES IN FOOTER.PHP (.site-header) -->

<div id="primary" class="content-area">
<main id="main" class="mw-main75" role="main">


<article id="post-798" class="post-798 paper type-paper status-publish hentry">

<style type="text/css">
h2 { font-weight: bold; font-size: 18px; }
h3, h4, h5, h6 { font-weight: bold; font-size: 16px; }

td, th { padding: 5px; }
th { background-color: #ccc; font-weight: bold; }
tr:nth-child(odd) { background-color: #eee }
</style>


<h1 class="entry-title">A case study on using voice technology to assist the museum visitor</h1>

<p><a target="_blank" href="http://www.museumsandtheweb.com/member/steven_moore@moma.org/">Steven Moore</a>, The Museum of Modern Art (MoMA), USA, <a target="_blank" href="http://www.museumsandtheweb.com/member/diana_pan@moma.org/">Diana Pan</a>, The Museum of Modern Art, USA, <a target="_blank" href="http://www.museumsandtheweb.com/member/Manish/">Manish Engineer</a>, Seattle Art Museum, USA</p>
<h2>Abstract</h2>
In 1952, Bell Laboratories developed what is considered the first speech recognition system: Audrey (Pinola, 2011).  It could only understand numbers and it required the speaker to pause between words. Since then, other systems followed, each with a growing vocabulary set but each with different limitations on usage. It was only in the 2000s that speech recognition made a significant leap forward, first with the Google Voice Search application and Google Now, and then very closely followed by Apple's Siri. Mobile devices offered an ideal platform for practical uses of hands-free speech recognition tools. Both Google tools and Siri also relied heavily on the power of cloud-based computing, the ability to draw upon a massive amount of data pertaining to speech search queries, and an ever evolving and constantly learning analysis of one's own unique speech patterns, all of which helped these tools to produce the best possible response to a user’s query. While not mainstream yet, the improved accuracy, as well as the quirkiness of these tools helped increase overall awareness of voice activated technologies in solving basic user questions.

As voice activated smart devices become more mainstream with consumers, we at The Museum of Modern Art (MoMA) in New York City, have taken steps towards analyzing its potential uses on both a consumer and an enterprise level to assist our Museum community. In order to do this, we focused on the Amazon Echo. In this How-To session we will cover how we integrated the Amazon Echo with the MoMA Collections database and built it a new "skill" for answering queries related to modern and contemporary art at MoMA. The purpose of this session is to introduce voice activated technologies with a concrete and functioning prototype. We will walk through the technical implementation details of our prototype and discuss what MoMA considers the potential use cases at our Museum.</p>
<p><b>Keywords:</b> voice technology siri amazon echo</p>
<h2>Introduction</h2>
<p>In late 2014, the Amazon Echo was introduced as a consumer oriented smart speaker and in-home assistant. A year later, on Black Friday 2015, the Echo was the top selling item over $100 on Amazon (Amazon, 2015), and by April 2016, sales of the product reached 3 million units. The steadily increasing popularity of the Echo, with its constantly growing set of “skills,” is a result of very smart marketing by Amazon, and also reflects a growing awareness by consumers and businesses alike of voice activated technologies not dissimilar to Siri. In early October 2016, Google announced their own smart speaker assistant, the Google Home, and two months later, opened its platform up through its Actions on Google functionality for third party software applications integration.</p>
<p>As voice activated smart devices become more mainstream with consumers, we at The Museum of Modern Art (MoMA) in New York City have taken steps towards analyzing its potential uses on both a consumer and an enterprise level to assist our museum community. In order to do this, we focused on the Amazon Echo. In this How-To session we will cover how we integrated the Amazon Echo with the MoMA Collections database and built it a new &#8220;skill&#8221; for answering queries related to modern and contemporary art at MoMA. Specifically, we will cover:</p>
<ul>
<li>Basics: Amazon Alexa’s skills, intents, utterances, and slots</li>
<li>How voice user design differs from Web design</li>
<li>How to work with the Amazon Alexa API</li>
<li>A general look at smart assistants and what we learned</li>
<li>Museum use cases and what’s next for MoMA</li>
</ul>
<p>The purpose of this session is to introduce voice activated technologies with a concrete and functioning prototype. We will walk through the technical implementation details of our prototype with Amazon’s Echo and discuss generally what MoMA considers as potential use cases at our museum.</p>
<h2><b>Basics: Amazon Alexa Skills, Intents, Utterances, and Slots</b></h2>
<p>It is helpful to understand specific vocabulary before talking about Alexa’s technical capabilities and limitations.  It mainly comes down to four things: <em>Skills</em>, <em>Intents</em>, <em>Utterances,</em> and <em>Slots</em>.</p>
<ol>
<li><b>Skill</b>:  A <i>Skill </i>is something that Alexa is capable of doing, like “Alexa, play Adele,” or answering a question like “Alexa, what is the weather?”</li>
<li><b>Intent</b>:  An <i>Intent </i>is a something that your Skill does or answers.  For example, “Alexa, ask MoMA how do I get there?” is the <em>Directions Intent.</em>  “Ask MoMA about Picasso” is the <i>Artist Intent.</i>  The end user is not concerned with Intents, but it is part of the vocabulary when we talk about building an Alexa Skill.</li>
<li><b>Utterances</b>:  <em>Utterances</em> are what the person says to Alexa.  You classify each Utterance as an Intent type, for example:
<ul>
<li>BathroomsIntent <i>Where are the bathrooms</i></li>
<li>BathroomsIntent <i>Where are the restrooms</i></li>
<li>HoursIntent <i>When are you open</i></li>
<li>HoursIntent <i>When can I go for free</i></li>
<li>DirectionsIntent <i>Where is MoMA</i></li>
<li>DirectionsIntent <i>Which subway do I take to get to MoMA<br />
</i></li>
</ul>
</li>
<li><b>Slots</b>: <em>Slots</em> is the Alexa word for a variable in an Utterance. So part of the Utterance is fixed and the Slot fills in for the part that changes, specifically artist and title in MoMA’s case, for example:
<ul>
<li>ArtistsIntent <i>How many works do you have by {Artist}</i></li>
<li>ArtIntent <i>Where is the art work {Title} </i></li>
</ul>
</li>
</ol>
<p>In the examples, you substitute the {Artist} Slot with the artist’s name, same for {Title} in the art work title.  Slots are optional.</p>
<h2><b>How to work with the Amazon Alexa API</b></h2>
<p>A skill has two parts: the<em> Skill Service</em> and the <em>Skill Interface</em> (Figure 1).  The Skill Service is implemented by a developer.  The Skill Interface is a set of options that you configure in the Alexa Skills developer portal (<a href="https://developer.amazon.com/alexa">https://developer.amazon.com/alexa)</a>.  Together, they make up a working Skill.</p>
<p><img loading="lazy" class="alignnone size-full wp-image-793" src="../../wp-content/uploads/2017/01/moore.fig1_.jpg" alt="" width="698" height="655" /></p>
<p>Figure 1: Skill Service and the Skill Interface</p>
<h3><b>Skill interface</b></h3>
<p>The Skill Interface is the easier part, but one of the inputs is the HTTPS endpoint where the Skill Service is located.  We will cover that later.</p>
<p>After logging into the Alexa Skills developer portal and adding a new Skill, all of which is self-explanatory, you will see a set of seven steps as shown in Figure 2 (<a href="https://developer.amazon.com/">https://developer.amazon.com</a>).</p>
<p><img loading="lazy" class="alignnone wp-image-794" src="../../wp-content/uploads/2017/01/moore.fig2_.jpg" width="800" height="433" /></p>
<p>Figure 2: Skill Interface</p>
<p>Rather than explain every detail, below you will find the notable parts that you may need to consider for each section:</p>
<ul>
<li><b>Skill Information:</b> Skill Type is Custom</li>
<li><b>Interaction Model:</b> The most important part of the Skill Interface.  This is where you put in the <em>Intent Schema</em> and <em>Sample Utterances</em>.  It will look like Figure 3.</li>
</ul>
<p><img loading="lazy" class="alignnone wp-image-795" src="../../wp-content/uploads/2017/01/moore.fig3_.jpg" width="800" height="685" /></p>
<p>Figure 3: Interaction Model</p>
<ul>
<li><b>Configuration: </b>Where you define the service endpoint.  Most museums will leave &#8220;Account Linking&#8221; as &#8220;No.&#8221;  &#8220;Account Linking&#8221; allows your Skill to link to users’ Amazon accounts, for purchasing or ordering services, for example.  It also means the Skill certification process will be much more detailed.</li>
<li><b>SSL Certificate: </b>You can use a self-signed certificate for testing, but a public Skill requires an SSL certificate from a trusted certificate authority that is approved by Amazon.  This covers the standard certificate authorities, but check the developer portal if you purchase from a lesser-known vendor.</li>
<li><b>Test:</b>  Essential for testing and debugging.  The <em>Service Simulator</em> allows you to test Alexa by typing in Utterances and seeing what kind of response comes back.  It also has a <em>Voice Simulator</em> so you can hear what it sounds like with Alexa.</li>
<li><b>Publishing Information:</b>  Small and large icons in specific sizes are needed for the Skill, otherwise self-explanatory.</li>
<li><b>Privacy &amp; Compliance: </b> Self-explanatory.  Privacy and Terms of Use policies are optional unless you use Account Linking; then it is mandatory to pass certification.</li>
</ul>
<h3><b>Skill Service</b></h3>
<p>This is the code part.  A Skill can be written in any programming language that can run on an HTTPS web server and return JSON as the response.  In these examples, we are using .NET and C#.</p>
<p>Many of the introductory examples suggest using AWS Lambda and Node.js.  This is a great way to start, but it does not really apply to most museums and database-driven content because the database servers are often in-house.  AWS Lambda is cloud-based so integrating your internal database would be fairly complicated.  It is possible to implement Alexa in a museum setting without database-driven content.  If all the questions have fixed responses, then AWS Lambda is a good choice and the whole process is much easier.  It is also possible to hard-code curatorial responses for specific works or artists, but it means that you create a specific Intent for each artwork/artist.  This would apply at say, The Dali Museum, where you would create an Intent that retrieves information for Salvador Dali; or, a museum has a renowned work like Vincent van Gogh&#8217;s <em>The Starry Night</em> (MoMA) and you anticipate many questions for just that work.  In our examples, we anticipate any artwork on view (because location in the museum is part of the response) and any artist.</p>
<p>At MoMA, we implemented ten Intents.  Most intents have hard-coded responses.  This paper is concerned with showing steps for the database-driven responses (bold below):</p>
<ol>
<li><b>Exhibitions</b></li>
<li>Events*</li>
<li>Films*</li>
<li><b>Artists</b></li>
<li><b>Art</b></li>
<li>Bathrooms</li>
<li>Hours</li>
<li>Directions</li>
<li>Food</li>
<li>Stores</li>
</ol>
<p>*can be database driven but are not for now</p>
<p>There are also built-in Intents such as <em>Stop,</em> <em>Cancel,</em> <em>Help</em>, and <em>Launch</em>, but that is covered in most introductory examples so we will not look at that.</p>
<p>Let’s look at the <em>Exhibitions Intent</em>.</p>
<p>The first step is to imagine the kinds of things users will ask Alexa about exhibitions at MoMA. They will also ask the same question in a number of different ways (ask about, tell me about, what are, etc.). In these examples we use just one form; but certifying your Skill requires adding all the variations you can think of.  Below are two examples.</p>
<blockquote><p>&#8220;Alexa, ask MoMA about exhibitions.&#8221;</p>
<p>&#8220;Alexa, ask MoMA about exhibitions {Date}&#8221;</p></blockquote>
<p>What is<em> {Date}</em>?  This is a built-in Slot that allows the user to say things like “tomorrow,” “next week,” or “in March.”  When we looked at the Interaction Model above, you can see these phrases in the Sample Utterances section (Figure 3).</p>
<p>Amazon’s technology takes the voice input and matches it to the Skill name (in this case MoMA) and the Sample Utterance.  The Skill Service’s main responsibility is to provide the response, in a standard JSON format, back to Amazon.</p>
<p>For MoMA, that all starts with SQL.</p>
<p>The exhibitions example is a good place to start because the slot/variable for Date is almost always understood by Alexa.  The Date returned by Alexa needs to be parsed, which is not an insignificant task (see GitHub repository <a href="https://github.com/smoore4moma/tms-api">https://github.com/smoore4moma/tms-api</a> for details), but the SQL is straightforward:</p>
<pre>SELECT DISTINCT E.ExhTitle, E.DisplayDate
FROM   Exhibitions E INNER JOIN
      ExhVenuesXrefs EX ON E.ExhibitionID = EX.ExhibitionID
WHERE  (EX.ConstituentID = 1234)
AND (EX.BeginISODate &lt;= @p_start_date)
AND (EX.EndISODate &gt;= @p_end_date)</pre>
<p>The exhibition title and date are then used in the Alexa response, which looks like this:</p>
<blockquote><p>{Alexa says} &#8220;Here are the exhibitions you asked for.  Bouchra Khalili: The Mapping Journey Project.  Bruce Connor: It’s All True&#8230;&#8221;</p></blockquote>
<p>And the visual “card” you see on the mobile Alexa app or at alexa.amazon.com shows the following (Figure 4):</p>
<p><img loading="lazy" class="alignnone wp-image-796" src="../../wp-content/uploads/2017/01/moore.fig4_.png" width="360" height="640" /></p>
<p>Figure 4: visual &#8220;card&#8221; in Alexa mobile application</p>
<p>So&#8230;how do you do that?</p>
<p>First understand that the following is really intended for developers and technical people, but it is easy to follow along.  At a conceptual level, here are the steps:</p>
<ol>
<li>The user says something to Alexa.</li>
<li>Alexa identifies the Utterance and associates it with a Skill name (MoMA) and a Skill intent (I want to know about exhibitions).</li>
<li>Alexa creates a POST request to your Skill service.  The POST lets the service know the intent type and variables, if any.</li>
<li>The Skill service pulls data from the database for the specific intent and creates a JSON response which it sends back to Alexa.</li>
<li>Alexa reads the response aloud.</li>
</ol>
<h3><b>The Code</b></h3>
<p>All of the code discussed in this section is available on GitHub:</p>
<p><a href="https://github.com/smoore4moma/tms-api">https://github.com/smoore4moma/tms-api</a></p>
<p>The GitHub repository is neither owned nor endorsed by The Museum of Modern Art (MoMA), and MoMA takes no responsibility for its contents.</p>
<p>On a code level, the Alexa Request and Response follows a fixed JSON format, specifically:</p>
<h3><b>Alexa Request</b></h3>
<p><a href="https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit/docs/alexa-skills-kit-interface-reference#request-format">https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit/docs/alexa-skills-kit-interface-reference#request-format</a></p>
<p>Alexa will POST something like the JSON below to your skill service.  Alexa provides this, but you must be able to consume the JSON.  See GitHub repository for object definition under Models, AlexaRequest.cs:</p>
<pre>{
 "session": {
    "sessionId": "SessionId.2e634962-101c-49df-b84c-a654de74b75f",
    "application": {
     "applicationId": "amzn1.ask.skill.15a86908-4360-49aa-adb7-foobar"
    },
    "attributes": {},
    "user": {
     "userId": "amzn1.ask.account.alsofoobar"
    },
    "new": true
 },
 "request": {
    "type": "<b>IntentRequest</b>",
    "requestId": "EdwRequestId.8d213991-4a28-4a5a-a776-a64e3483f02a",
    "locale": "en-US",
    "timestamp": "2016-12-15T18:43:09Z",
    "intent": {
     "name": "<b>ExhibitionsIntent</b>",
     "slots": {
       "Date": {
         "name": "Date"
       }
     }
    }
 },
 "version": "1.0"
}</pre>
<p>Again, the code’s responsibility is to consume the POST data from Alexa and handle the kind of question appropriately, then provide a response.  It does this with code called the Intent Handler.  As mentioned previously, MoMA has ten different Intents.  If the request name is <i>ExhibitionsIntent, </i>which it is above, then we will call <i>ExhibitionsIntentHandler</i>.  The handler is the part that goes to the database and runs the SQL.  It looks like this:</p>
<pre>// Exhibitions
private AlexaResponse ExhibitionsIntentHandler(Request request)
{
   string dateValue = "";
 
   if (request.SlotsList.FirstOrDefault(s =&gt; s.Key == "Date").Value != null)
      dateValue = request.SlotsList.FirstOrDefault(s =&gt; s.Key == "Date").Value.ToString();

   string conn_data = ConfigurationManager.ConnectionStrings["MyConnectionString"].ConnectionString;

   SqlConnection sql_conn_data = new SqlConnection(conn_data);
   sql_conn_data.Open();

   // Get exhibitions
   SqlCommand getAlexaExhibitions = new SqlCommand("procMomaAlexaExhibitions", sql_conn_data);
   getAlexaExhibitions.CommandType = CommandType.StoredProcedure;
   getAlexaExhibitions.Parameters.Clear();
   getAlexaExhibitions.Parameters.Add(new SqlParameter(@"@p_alexa_date", SqlDbType.VarChar, 50) { Value = dateValue.ToString() });

   SqlDataAdapter sda = new SqlDataAdapter(getAlexaExhibitions);
   DataSet ds = new DataSet();
   sda.Fill(ds);
   sda.Dispose();

   DataTable dt_exhs = ds.Tables[0];

   int m_dt_exhs_ct = dt_exhs.Rows.Count;

   var output = new StringBuilder("Here are the exhibitions you asked for. ");

   var outputCard = new StringBuilder("Here are the exhibitions you asked for.\n");

   foreach (DataRow dr_exh in dt_exhs.Rows)
   {
     output.Append(dr_exh["ExhTitle"].ToString() + ". ");   
     outputCard.Append(dr_exh["ExhTitle"].ToString() + ", " + dr_exh["DisplayDate"].ToString() + "\n");
   }

   sql_conn_data.Close();

   var response = new AlexaResponse(output.ToString());
   response.Response.Card.Title = "Exhibitions";
   response.Response.Card.Type = "Standard";
   response.Response.Card.Text = outputCard.ToString();

   return response;
}</pre>
<h3><b>Alexa Response</b></h3>
<p>The<em> Response</em> is a class with all of the variables defined in the Alexa standard:</p>
<p><a href="https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit/docs/alexa-skills-kit-interface-reference#response-format">https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit/docs/alexa-skills-kit-interface-reference#response-format</a></p>
<p>For MoMA it looks like the JSON below, which is returned to Alexa.  Alexa reads the Response text aloud and shows the card text on a device.  See GitHub repository for object definition under Models, AlexaResponse.cs:</p>
<pre>{
 "version": "1.0",
 "response": {
    "outputSpeech": {
     "type": "PlainText",
     "text": "Here are the exhibitions you asked for.  How Should We Live? Propositions for the Modern Interior. A Revolutionary Impulse: The Rise of the Russian Avant-Garde. Francis Picabia: Our Heads Are Round so Our Thoughts Can Change Direction."
    },
    "card": {
     "text": "Here are the exhibitions you asked for.\n How Should We Live? Propositions for the Modern Interior, October 01, 2016 - April 23, 2017\nA Revolutionary Impulse: The Rise of the Russian Avant-Garde, Saturday, December 03, 2016 - Sunday, March 12, 2017\nFrancis Picabia: Our Heads Are Round so Our Thoughts Can Change Direction, November 21, 2016 - March 19, 2017",
     "title": "Exhibitions",
     "image": {},
     "type": "Standard"
    },
    "reprompt": {
     "outputSpeech": {
       "type": "PlainText"
     }
    },
    "shouldEndSession": true
 },
 "sessionAttributes": {
    "memberId": 0
 }
}</pre>
<h2><b>The next step: art and artists</b></h2>
<p>Once you can do one database-driven response, then you can do just about anything in a database.  For art and artists, there are two caveats that are particular to Alexa.  The first is Alexa is still learning how to pronounce non-English names and words, and many museums have non-English artist names and artwork.  Even with common examples, Alexa can have issues.  For example, the renowned sculptor Richard Serra is more likely to be interpreted as Richard Sarah.  And you will get no response, or an incorrect one.</p>
<p>The other caveat is the need to have a search index as part of your SQL or use a NoSQL option like Elasticsearch or Solr.  At MoMA, we use SQL Server Full-Text Index to query the data needed for the response.  For example, if I say this:</p>
<blockquote><p>&#8220;Alexa, ask MoMA about the artwork The Starry Night&#8221;</p></blockquote>
<p>Alexa will include this in the Request:</p>
<p>&#8220;intent&#8221;: {<br />
&#8220;name&#8221;: &#8220;ArtIntent&#8221;,<br />
&#8220;slots&#8221;: {<br />
&#8220;Title&#8221;: {<br />
&#8220;name&#8221;: &#8220;Title&#8221;,<br />
<b>&#8220;value&#8221;: &#8220;starry night&#8221;</b><br />
}<br />
}</p>
<p>The <i>ArtIntentHandler </i>will then take the “value” part of the Alexa request &#8211; “starry night” &#8211; and use it in a SQL statement to get the data:</p>
<p><i>Note: @p_searchterm is ‘starry AND night’</i></p>
<pre><i>SELECT {24 fields} </i>
<i>FROM {11 tables} </i>
<i>WHERE CONTAINS(OT.Title, @p_searchterm)</i></pre>
<p>CONTAINS is a SQL Server convention used with Full-Text Index.  The SQL is filtering the data where the title contains &#8220;starry&#8221; and &#8220;night&#8221;.</p>
<p>As long as Alexa understands “starry” (not story, starfleet, starting, etc.) and “night” (not knife), then you get a valid response that looks like Figure 5:</p>
<p><img loading="lazy" class="alignnone wp-image-797" src="../../wp-content/uploads/2017/01/moore.fig5_.png" width="360" height="640" /></p>
<p>Figure 5: Alexa &#8220;card&#8221; response for object</p>
<h3><b>Technology</b></h3>
<p>MoMA uses The Museum System by Gallery Systems, specifically TMS 2016 R2.  The database platform is SQL Server 2014.  Snapshot replication is used to create a daily copy of the production database, with just selected tables.  The Alexa service uses the copy, not production.  The compiled .NET code is hosted on Windows Server 2008 R2 running IIS.</p>
<h3><b>A look at smart assistants and what we learned</b></h3>
<p>In the few short months since Google Home became generally available, many comparisons between it and Amazon’s Echo have already been made.  While most focused on consumer oriented features such as smart home partnerships, speaker quality, personal assistant capabilities, and music streaming options, to name a few, we looked at the Echo, the Home, and also Siri based on their ability to integrate with and present museum-specific content to enhance MoMA’s visitor experience. Here is what we learned:</p>
<p>1. Equal amongst these devices, and as mentioned earlier, one major limitation is simply the devices’ availability in English only. All of these devices could not comprehend non-English names or titles posed within a question (see previous Richard Serra example), nor respond properly with such. In the case of Amazon’s Echo, MoMA is actively working with Amazon on a project that will help teach Alexa the names and titles of non-English artists and artwork.</p>
<p>2. Domains, actions, skills, oh my. These are all the different ways to integrate data sources or applications with the various smart assistants. We’ve already examined up close Alexa’s skills and intents and how we integrated Alexa with MoMA’s collection database. Apple’s Siri allows for a higher level of categorization in “domains” (e.g., ride booking, photos, messaging) with the “intents” as supported functions within a domain (e.g., “send message,” “search photos,” “book a ride”). “Extensions” allow apps in those domains to integrate to Siri to support the intents (e.g., extensions are built into the Uber or Lyft apps so Siri can book a ride on one of those services). The list of supported domains and their intents is still evolving.  In the Google Home, one can build “conversation actions” which would hand a user off, for example, to an Uber conversation agent who can have a seemingly natural, contextually aware, though still limited, conversation to search for and book a ride.</p>
<p>While none of these products are anywhere near mature yet, each integration option shows tremendous promise for a future where a true &#8220;natural&#8221; conversation can occur. Also of importance, the Google Home and Amazon Echo already have simplistic contextual awareness. Proper responses are made for questions such as “tell me about Jackson Pollock,” followed by “when was he born?” without having to repeat the name Jackson Pollock. One can envision a day where there is an arts “domain,” or when the home becomes an “art curator” and the “intents” or “skills” cut across multiple museum data sources to answer a question such as “tell me about abstract expressionist artists” followed by “where can I view such artworks?” and other related questions. At present though, the conversation with each of these devices is still awkward and exposes their technical limitations.</p>
<h3><b>Museum use cases and what’s next for MoMA</b></h3>
<p>Having walked through an implementation with the Echo and MoMA’s collections database, it is clear that the such voice activated smart assistants are not ready yet for mainstream consumption, without at least some amount of guidance and limitation. Introducing such tools into a public space offers new audiences participatory opportunities while also posing new social interaction questions, as demonstrated recently at the Barnes Foundation (Bernstein, 2016). Nevertheless, these are some potential uses that may be worth exploring in a museum and arts context:</p>
<ul>
<li>An internal tool to help museum staff more quickly learn and find information about an artwork, including information that is not available to the public. This would be an alternative to a browser based tool and at best would shave minutes off what would otherwise be a browser search.</li>
<li>An external tool for exhibition and art information. As we work with Amazon to solve the non-English name pronunciation issue, we hope to eventually release our integration as a new Skill for Alexa. Observing how this Skill is then used by any owner of an Echo may be informative not just to MoMA, but to the arts sector.</li>
<li>A public-facing tool in the museum placed in common areas such as a museum’s charging stations or cafes to be used to serve general information, and also to help us gather information and learn about visitor interests. Since Amazon saves all queries, this could be useful information to review and help us provide better messaging to visitors based on what is being asked. A public-facing tool, however, introduces some practical challenges, such as physically locking down the device or restricting use of the tool to specific Skills, to name a few.</li>
<li>A public-facing in-gallery assistant to provide information about very specific exhibitions, artists, and artworks. Since we know the Echo has some limitations in non-English responses, we can work around this and experiment with it in a limited and controlled fashion to see if this is a viable in-gallery tool.</li>
<li>A public-facing alternative tool to aid in accessibility options.</li>
</ul>
<h2><b>Acknowledgements</b></h2>
<p>This paper acknowledges the contributions and collaborative work between individuals in the MoMA Information Technology department and also Amazon Echo’s product development teams.</p>
<h2><b>References</b></h2>
<p>Amazon. (2015).  Press Release: <span class="ccbnTtl">Record Weekend for Amazon Devices—Up 3x Over Last Year, with Millions of Devices Sold, 2015.  Consulted February 8, 2017. Availble </span><a href="http://phoenix.corporate-ir.net/phoenix.zhtml?c=176060&amp;p=irol-newsArticle&amp;ID=211902">http://phoenix.corporate-ir.net/phoenix.zhtml?c=176060&amp;p=irol-newsArticle&amp;ID=211902</a>5</p>
<p>Apple. (2016). &#8220;Siri’s Domains and Intents.&#8221; Consulted December 12, 2016. Available <a href="https://developer.apple.com/library/content/documentation/Intents/Conceptual/SiriIntegrationGuide/SiriDomains.html">https://developer.apple.com/library/content/documentation/Intents/Conceptual/SiriIntegrationGuide/SiriDomains.html</a></p>
<p>Apple. (2017). &#8220;Conversation Actions for Google Home.&#8221; Consulted January 27, 2017. Avaialble <a href="https://developers.google.com/actions/develop/conversation">https://developers.google.com/actions/develop/conversation</a></p>
<p>Bernstein, S. (2016). “What Can Alexa Teach Us About the Barnes?” <em>Medium. </em>Consulted December 6, 2016. Available <a href="https://medium.com/barnes-foundation/what-can-alexa-teach-us-about-the-barnes-21154d68700c#.v08qjcf4k">https://medium.com/barnes-foundation/what-can-alexa-teach-us-about-the-barnes-21154d68700c#.v08qjcf4k</a></p>
<p>Pinola, M. (2011). &#8220;Speech Recognition Through the Decades: How We Ended Up With Siri.&#8221; Consulted February 8, 2017. Available <a href="http://www.pcworld.com/article/243060/speech_recognition_through_the_decades_how_we_ended_up_with_siri.html">http://www.pcworld.com/article/243060/speech_recognition_through_the_decades_how_we_ended_up_with_siri.html</a></p>
<p>&nbsp;</p>
<hr>

<script type="text/javascript">
var d=new Date();
var month=new Array();
month[0]="January";
month[1]="February";
month[2]="March";
month[3]="April";
month[4]="May";
month[5]="June";
month[6]="July";
month[7]="August";
month[8]="September";
month[9]="October";
month[10]="November";
month[11]="December";

var day_number=d.getDate();
var month_name=month[d.getMonth()];
var year=d.getFullYear();
var full_date = month_name+" "+day_number+", "+year;
</script>

Cite as:<br /> 

Moore, Steven, Diana Pan and Manish Engineer. "A case study on using voice technology to assist the museum visitor." <i>MW17: MW 2017</i>. Published January 26, 2017. Consulted <script type="text/javascript">document.write(full_date);</script>.<br />
https://mw17.mwconf.org/paper/a-case-study-on-using-voice-technology-to-assist-the-museum-visitor/<br /><br /><hr>

<div id="comments" class="comments-area">

	
	
		<div id="respond" class="comment-respond">
		<h2 id="reply-title" class="comment-reply-title">Leave a Reply <small><a rel="nofollow" id="cancel-comment-reply-link" href="index.html#respond" style="display:none;">Cancel reply</a></small></h2><p class="must-log-in">You must be <a href="../../wp-login9fb5.html?redirect_to=https%3A%2F%2Fmw17.mwconf.org%2Fpaper%2Fa-case-study-on-using-voice-technology-to-assist-the-museum-visitor%2F">logged in</a> to post a comment.</p>	</div><!-- #respond -->
	
</div><!-- .comments-area -->
</article>
</main>
<div id="mw-sidebar" class="mw-sidebar25">

	<aside id="secondary" class="sidebar widget-area" role="complementary">
		<section id="text-7" class="widget widget_text">			<div class="textwidget"><h2 class="widget-title">Community Conveners</h2>
<p><a title="Wezit" href="https://wezit.io/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="https://www.museumsandtheweb.com/wp-content/themes/mw-theme/wezit-250-75.jpg" alt="Wezit" /></a><br />
<a title="Axiell" href="http://www.axiell-alm.com/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" style="border: 0px;" src="https://www.museumsandtheweb.com/wp-content/themes/mw-theme/axiell-250-75.jpg" alt="Axiell" /></a></p>
<h2 id="gold-sponsor" class="widget-title">Platinum Sponsor</h2>
<p><a title="Microsoft" href="http://aka.ms/museweb" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="https://www.museumsandtheweb.com/wp-content/themes/mw-theme/Microsoft-250-75.jpg" alt="Microsoft" /></a><br />
<!-- <a title="Izi Travel" href="http://www.izi.travel" target="_blank" rel="noopener"><img src="https://www.museumsandtheweb.com/wp-content/themes/mw-theme/izi-250-75.jpg" alt="Izi Travel" class="sponsor-img sponsor-top" /></a> --></p>
<h2 id="gold-sponsor" class="widget-title">Gold Sponsor</h2>
<p><a title="Piction" href="http://www.piction.com/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="https://www.museumsandtheweb.com/wp-content/themes/mw-theme/piction-250-75.jpg" alt="Piction" /></a></p>
<h2 id="bronze-sponsor" class="widget-title">Bronze Sponsors</h2>
<p><a title="MailChimp" href="https://mailchimp.com/resources/guides/mailchimp-for-nonprofits/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="https://mw2015.museumsandtheweb.com/wp-content/themes/mw-theme/mailchimp-250-75.jpg" alt="mailchimp" /></a><br />
<a title="Netx" href="http://netx.net/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="https://www.museumsandtheweb.com/wp-content/themes/mw-theme/netx-250-75.gif" alt="Netx" /></a><br />
<a title="PatronTech" href="http://patrontechnology.com/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="https://www.museumsandtheweb.com/wp-content/themes/mw-theme/patron-250-75.jpg" alt="PatronTech" /></a></p>
<h2 id="conference-sponsor" class="widget-title">Conference Sponsors</h2>
<p><a title="CMA" href="http://clevelandart.org/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="https://www.museumsandtheweb.com/wp-content/themes/mw-theme/cma-250-75.jpg" alt="CMA" /></a><br />
<a title="Rock &amp; Roll" href="http://www.rockhall.com/" target="_blank" rel="noopener"><img class="sponsor-img sponsor-top" src="https://www.museumsandtheweb.com/wp-content/themes/mw-theme/rrhf-250-75.jpg" alt="Rock &amp; Roll" /></a></p>
</div>
		</section>	</aside><!-- .sidebar .widget-area -->
</div>
</div>

		</div><!-- TAG OPENS IN HEADER.PHP (.site-content) -->

		<footer id="colophon" class="site-footer" role="contentinfo">

			<div class="site-info">
				<div class="site-title">Founded by Archives &amp; Museum Informatics<br><a href="http://www.archimuse.com/" target="_blank">www.archimuse.com</a></div>
				<div class="site-title right">Managed by <a href="http://www.mwconf.org/">Museums and the Web LLC</a><br> 703 Dale Drive Silver Spring MD 20910 USA<br><a href="mailto:info@mwconf.org">info@mwconf.org</a></div>
				
				
			</div><!-- .site-info -->
		</footer><!-- .site-footer -->

	</div><!-- TAG OPENS IN HEADER.PHP (.site-inner) -->
</div><!-- TAG OPENS IN HEADER.PHP (.site) -->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-26332456-1"></script>
<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'UA-26332456-1', {
  		'linker': {
    	'domains': ['museweb.net', 'mwconf.org', 'museumsandtheweb.com']
  }
});
</script>

<script src='../../wp-content/themes/twentysixteen/js/skip-link-focus-fixfd15.js?ver=20170530' id='twentysixteen-skip-link-focus-fix-js'></script>
<script src='../../wp-includes/js/comment-reply.min40df.js?ver=5.6' id='comment-reply-js'></script>
<script id='twentysixteen-script-js-extra'>
var screenReaderText = {"expand":"expand child menu","collapse":"collapse child menu"};
</script>
<script src='../../wp-content/themes/twentysixteen/js/functionsb889.js?ver=20181217' id='twentysixteen-script-js'></script>
<script src='../../wp-includes/js/wp-embed.min40df.js?ver=5.6' id='wp-embed-js'></script>
</body>

<!-- Mirrored from mw17.mwconf.org/paper/a-case-study-on-using-voice-technology-to-assist-the-museum-visitor/ by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 23 Apr 2022 22:00:47 GMT -->
</html>
