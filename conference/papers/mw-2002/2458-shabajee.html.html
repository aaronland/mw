<html><!-- #BeginTemplate "/Templates/mw2002-papers.dwt" --><!-- DW6 -->

<!-- Mirrored from www.museumsandtheweb.com/mw2002/papers/shabajee/shabajee.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 17:47:33 GMT -->
<head>
<!-- #BeginEditable "doctitle" -->

	<title>MW2002: Papers: Adding value to large multimedia collections through annotation technologies and tools: Serving communities of interest.</title>

	<meta http-equiv="Content-Type" content="text/html; charset=en">

	<meta name="DC.Format" content="text/html">

	<meta name="DC.language" content="ISO 8859-1">

	<meta name="DC.Title" content="Adding value to large multimedia collections through annotation technologies and tools: Serving communities of interest.">

	<meta name="htDig.keywords" content="community annotation, flexible publishing, semantic web,

ontologies, collaboration">

	<meta name="keywords" content="community annotation, flexible publishing, semantic web,

ontologies, collaboration">

	<meta name="DC.Subject" content="community annotation, flexible publishing, semantic web,

ontologies, collaboration">

	<meta name="description" content="A group of research projects based at HP-Labs Bristol, the University of Bristol and ARKive (a new large multimedia database project focused on the worlds biodiversity based in the UK) are working to develop a flexible model for the indexing of multimedia collections that allows users to 'annotate' content utilising extensible controlled vocabularies. As part of the educationally focused ARKive-ERA project a series of models for user annotation have been developed. 



The need for these types of user support and tools was identified while conducting pre-design stage user studies with specialist user groups. The needs centre around the limitations of current on-line museum and library systems that do not provide support for users to annotate or 'tag' multimedia objects of relevance to their particular community of interest or with specialised indexing terms. This would enable specialised resource discovery and knowledge sharing  with other members of their communities. 



One example is that of University Lecturers and Researchers studying a particular type of animal behaviour. They may wish to identify all relevant images or video of that particular behaviour and annotate them as good illustrations of aspects of that behaviour. However significant issues arise over for example, the validation of information, access control and the use of such annotations by the resource discovery tools. The paper explores these and other issues and problems involved and how the various models can help provide solutions to the key problems and thus meet the needs of a diverse range of 'communities of interest' and adding significant value to on-line multimedia collections.

">

	<meta name="DC.Description" content="A group of research projects based at HP-Labs Bristol, the University of Bristol and ARKive (a new large multimedia database project focused on the worlds biodiversity based in the UK) are working to develop a flexible model for the indexing of multimedia collections that allows users to 'annotate' content utilising extensible controlled vocabularies. As part of the educationally focused ARKive-ERA project a series of models for user annotation have been developed. 



The need for these types of user support and tools was identified while conducting pre-design stage user studies with specialist user groups. The needs centre around the limitations of current on-line museum and library systems that do not provide support for users to annotate or 'tag' multimedia objects of relevance to their particular community of interest or with specialised indexing terms. This would enable specialised resource discovery and knowledge sharing  with other members of their communities. 



One example is that of University Lecturers and Researchers studying a particular type of animal behaviour. They may wish to identify all relevant images or video of that particular behaviour and annotate them as good illustrations of aspects of that behaviour. However significant issues arise over for example, the validation of information, access control and the use of such annotations by the resource discovery tools. The paper explores these and other issues and problems involved and how the various models can help provide solutions to the key problems and thus meet the needs of a diverse range of 'communities of interest' and adding significant value to on-line multimedia collections.

">

	<meta name="DC.Publisher" content="Archives & Museum Informatics">

	<meta name="DC.Creator" content="Miller, Libby">

	<meta name="DC.Creator" content="Shabajee, Paul"><!-- #EndEditable --> 
<meta http-equiv="Content-Type" content="text/html; charset="><!-- #BeginEditable "script" --><!-- #EndEditable -->
<script language="JavaScript">
<!--
function MM_swapImgRestore() { //v3.0
  var i,x,a=document.MM_sr; for(i=0;a&&i<a.length&&(x=a[i])&&x.oSrc;i++) x.src=x.oSrc;
}

function MM_preloadImages() { //v3.0
  var d=document; if(d.images){ if(!d.MM_p) d.MM_p=new Array();
    var i,j=d.MM_p.length,a=MM_preloadImages.arguments; for(i=0; i<a.length; i++)
    if (a[i].indexOf("#")!=0){ d.MM_p[j]=new Image; d.MM_p[j++].src=a[i];}}
}

function MM_findObj(n, d) { //v4.01
  var p,i,x;  if(!d) d=document; if((p=n.indexOf("?"))>0&&parent.frames.length) {
    d=parent.frames[n.substring(p+1)].document; n=n.substring(0,p);}
  if(!(x=d[n])&&d.all) x=d.all[n]; for (i=0;!x&&i<d.forms.length;i++) x=d.forms[i][n];
  for(i=0;!x&&d.layers&&i<d.layers.length;i++) x=MM_findObj(n,d.layers[i].document);
  if(!x && d.getElementById) x=d.getElementById(n); return x;
}

function MM_swapImage() { //v3.0
  var i,j=0,x,a=MM_swapImage.arguments; document.MM_sr=new Array; for(i=0;i<(a.length-2);i+=3)
   if ((x=MM_findObj(a[i]))!=null){document.MM_sr[j++]=x; if(!x.oSrc) x.oSrc=x.src; x.src=a[i+2];}
}
//-->
</script>
<link rel="stylesheet" href="../../Library/mw2002-paper.css" type="text/css">
</head>

<body bgcolor="#FFFFFF" background="../../images/mw2002.bg.gif" text="#000000" link="#003399" vlink="#660000" onLoad="MM_preloadImages('../../images/register_on.gif','../../images/workshops_on.gif','../../images/sessions_on.gif','../../images/speakers_on.gif','../../images/interact_on.gif','../../images/demos_on.gif','../../images/exhibit_on.gif','../../images/events_on.gif','../../images/best_on.gif','../../images/dates_on.gif','../../images/boston_on.gif','../../images/sponsors_on.gif')">
<table width="600" border="0" cellspacing="2" cellpadding="5">
  <tr> 
    <td width="145" align="LEFT" valign="TOP"> 
      <p><a href="../../index.html"><img src="../../images/mw.gif" width="112" height="155" border="0" alt="/mw/"></a></p>
      <p> <a href="../../register/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('register','','../../images/register_on.gif',1)"><img name="register" border="0" src="../../images/register_off.gif" width="114" height="18" alt="Register"></a><a href="../../workshops/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('workshops','','../../images/workshops_on.gif',1)"><img name="workshops" border="0" src="../../images/workshops_off.gif" width="114" height="18" alt="Workshops"></a><a href="../../sessions/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('sessions','','../../images/sessions_on.gif',1)"><img name="sessions" border="0" src="../../images/sessions_off.gif" width="114" height="18" alt="Sessions"></a><a href="../../speakers/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('speakers','','../../images/speakers_on.gif',1)"><img name="speakers" border="0" src="../../images/speakers_off.gif" width="114" height="18" alt="Speakers"></a><a href="../../interact/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('interactions','','../../images/interact_on.gif',1)"><img name="interactions" border="0" src="../../images/interact_off.gif" width="114" height="18" alt="Interactions"></a><a href="../../demos/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('demonstrations','','../../images/demos_on.gif',1)"><img name="demonstrations" border="0" src="../../images/demos_off.gif" width="114" height="18" alt="Demonstrations"></a><a href="../../exhibit/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('exhibits','','../../images/exhibit_on.gif',1)"><img name="exhibits" border="0" src="../../images/exhibit_off.gif" width="114" height="18" alt="Exhibits"></a><a href="../../events/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('events','','../../images/events_on.gif',1)"><img name="events" border="0" src="../../images/events_off.gif" width="114" height="18" alt="Events"></a><a href="../../best/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('best','','../../images/best_on.gif',1)"><img name="best" border="0" src="../../images/best_off.gif" width="114" height="18" alt="Best of the Web"></a><a href="../../dates/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('dates','','../../images/dates_on.gif',1)"><img name="dates" border="0" src="../../images/dates_off.gif" width="114" height="18" alt="Key Dates"></a><a href="../../boston/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('boston','','../../images/boston_on.gif',1)"><img name="boston" border="0" src="../../images/boston_off.gif" width="114" height="18" alt="Boston"></a><a href="../../sponsor/index.html" onMouseOut="MM_swapImgRestore()" onMouseOver="MM_swapImage('sponsors','','../../images/sponsors_on.gif',1)"><img name="sponsors" border="0" src="../../images/sponsors_off.gif" width="114" height="18" alt="Sponsors"></a><br>
        <br>
        <a href="../http://www.archimuse.com/" target="_top"><img src="../../images/nav_ami.gif" width="135" height="25" border="0" alt="A&amp;MI home"></a> 
        <br>
        <span class="small">Archives &amp; Museum Informatics<br>
        158 Lee Avenue<br>
        Toronto, Ontario<br>
        M4E 2P3 Canada</span></p>
      <p class="small">info @ archimuse.com<br>
        <a href="../http://www.archimuse.com/" style="text-decoration: underline">www.archimuse.com</a></p>
      <table width="74">
        <tr> 
          <td> <a href="../http://search.museumsandtheweb.com/search" target="_top"> <img src="../../images/search.gif" width="24" height="25" alt="Search" border="0" name="Search"></a> 
          </td>
          <td valign="MIDDLE"> <a href="../http://search.museumsandtheweb.com/search" style="text-decoration: underline"> 
            <span class="verysmall">Search<br></span></a> </td>
        </tr>
      </table>
      <p><font face="Arial, Helvetica, sans-serif" class="verysmall"><span class="small">Join 
        our <a href="../http://search.museumsandtheweb.com/mailinglist/" style="text-decoration: underline"> 
        Mailing List</a>. <br>
        <a href="../http://search.museumsandtheweb.com/terms-of-use-privacy/" style="text-decoration: underline"> 
        Privacy</a>.</span></font> </p>
       <p><font SIZE='-2' class='verysmall'>published: April, 2002 </font>
        <!--

document.write("<FONT SIZE='-2' class='verysmall'>"+"analytics scripts updated:&nbsp;"+document.lastModified);

// -->
      </p>
   <p><font face="Arial, Helvetica, sans-serif" class="small">© Archives & Museum Informatics, 2002.</font><br>
  <a rel="license" href="../http://creativecommons.org/licenses/by-nc-nd/3.0/"><img src="../http://i.creativecommons.org/l/by-nc-nd/3.0/88x31.png" alt="Creative Commons Att
   ribution-Noncommercial-No Derivative Works 3.0  License" width="88" height="31" style="border-width:0" /></a>      </p>
    </td>
    <td width="455" align="LEFT" valign="TOP" class="normal">
      <p><a href="../../speakers/index.html"><img src="../../images/papers.gif" width="390" height="55" border="0" alt="MW2002: Papers"></a></p>
     <!-- #BeginEditable "Body of Page" --> 

      <p class=PaperTitle>Adding Value to Large Multimedia Collections Through 

        Annotation Technologies and Tools: Serving Communities of Interest</p>

      <p class=Author>Paul Shabajee, Libby Miller, Institute for Learning and 

        Research Technology (ILRT), University of Bristol, UK, Andy Dingley, Codesmiths, 

        UK</p>

      <p class=AbstractTitle>Abstract</p>

      <p class=AbstractText>A group of research projects based at HP-Labs Bristol, 

        the University of Bristol and ARKive (a new large multimedia database 

        project focused on the world&#146;s biodiversity based in the UK) are 

        working to develop a flexible model for the indexing of multimedia collections 

        that allows users to &#145;annotate&#146; content utilizing extensible 

        controlled vocabularies. As part of the educationally focused ARKive-ERA 

        project, a series of models for user &#145;annotation&#146; have been 

        developed. </p>

      <p class=AbstractText>The need for these types of user support and tools 

        was identified while conducting pre-design user studies with specialist 

        user groups. The needs center around the limitations of current on-line 

        museum and library systems that do not provide support for users to annotate 

        or &#145;tag&#146; multimedia objects of relevance to their particular 

        &#145;community of interest&#146; or with specialized indexing terms. 

        Tagging would enable specialized resource discovery and knowledge sharing  

        with other members of their communities. </p>

      <p class=AbstractText>One example is that of University Lecturers and Researchers 

        studying a particular type of animal behavior. They may wish to identify 

        all relevant images or video of that particular behavior and annotate 

        them as good illustrations of aspects of that behavior. However, significant 

        issues arise over, for example, the validation of information, access 

        control and the use of such annotations by the resource discovery tools. 

        The paper explores these and other issues and problems involved, and explains 

        how the various models can help provide solutions to key problems and 

        thus meet the needs of a diverse range of &#145;communities of interest&#146;, 

        thereby adding significant value to on-line multimedia collections.</p>

      <p class=AbstractText>Key Words: community annotation, flexible publishing, 

        semantic web, ontologies, collaboration</p>

      <h1>Introduction </h1>

      <p>The ARKive-ERA project is focused on investigating how best to design 

        the underlying technological infrastructures to enable large multimedia 

        database systems to maximize the educational potential of their multimedia 

        assets, for users from very diverse range of backgrounds and in a wide 

        variety of contexts. The focus for the research has been the ARKive project 

        (<a href="../http://www.wildscreen.org.uk/arkive/" target="_blank">http://www.wildscreen.org.uk/arkive/</a>), 

        a large multimedia Web-based database system under development, containing 

        diverse data related to endangered animal, plant and fungi species and 

        their habitats as well as more common UK species. </p>

      <p>ARKive is characteristic of many large digitization projects; during 

        its <i>initial phase</i> of development it will contain data profiling 

        some 2000 species and their habitats. This will take the form of approximately 

        9,000 minutes of digitized video and 30,000 still images along with hours 

        of audio, maps, textual information and other supporting media and educational 

        materials. These assets are donated by aa diverse range of commercial 

        and non-profit organizations as well as by individuals. </p>

      <p>Essentially ARKive is a &#145;community project&#146; insofar as it is 

        part of and relies on a community of organizations and individuals who 

        have an interest in sharing access to rich multimedia resources focused 

        on biodiversity.</p>

      <p>ARKive type projects are designed to serve the needs of their diverse 

        potential users by providing tools for individuals and communities of 

        users to &#145;annotate&#146; the content of the database so as to make 

        the content more valuable to others with similar interests. </p>

      <p>It is important to note that we define <i>annotation</i> as metadata 

        (see below) created after the creation of the content. It is this post 

        hoc nature (&#147;a note added to anything written&#148;, Oxford English 

        Dictionary, 1998) that represents a considerable expansion of its usefulness, 

        as a means of adding value to content, because it now allows people other 

        than the original content author to add metadata descriptions.</p>

      <h1>The Challenge</h1>

      <p>As part of early work to identify the key requirements of ARKive and 

        similar projects, it became clear that the diverse range of potential 

        users includes school children and their teachers, media researchers, 

        conservation scientists, customs officers, university lecturers and students 

        and the very many people with personal rather than professional or educational 

        interests in wildlife, to name but a few. </p>

      <p>Each of the groups listed above is itself diverse with respect to the 

        particular needs or desires of ARKive or similar systems. </p>

      <p>We conducted a small-scale interview survey with University Lecturers 

        about their likely uses and needs of ARKive with respect to supporting 

        their teaching activities. As a result we identified that a key need of 

        this &#145;group of users&#146; was to be able to search for multimedia 

        resources to &#145;illustrate&#146; concepts when presenting to and supporting 

        their students. Specific examples included infanticide, drug induced behavior, 

        life strategies of plants, inter-specific competition, identifying and 

        classifying organisms, tropic levels, echolocation, binocular vision, 

        and harvesting theory. Lecturers from different sub-domains (e.g. behavioral 

        biology and ecology) suggested different terms. </p>

      <p>This small example shows that even within sub-groups of one relatively 

        well-defined group of users the &#145;resource discovery needs&#146; alone 

        were complex. Indeed it quickly became clear that all of these sub-groups 

        or &#145;communities of interest&#146; have their own specialized vocabularies 

        and concepts that they would like the resources indexed under so as to 

        support their resource discovery needs. </p>

      <p>Not only did they want to be able to search for assets using specialist 

        vocabularies, but they also wanted ideally be able to find &#145;good&#146; 

        examples of assets that illustrated a particular aspect of a particular 

        concept. </p>

      <p>These are not unreasonable requests as clearly it is not practical to 

        browse 9,000 minutes of video, or even a small sub-set, in the hope of 

        finding a good example to illustrate aspects of, for example, &#145;harvesting 

        theory&#146;. However for ARKive it is simply not feasible to index every 

        asset with the terms relevant to all possible communities of interest. 

      </p>

      <p class=MsoHeader>The problems can be expressed more clearly by using basic 

        concepts from Information Retrieval (IR) literature (e.g. Chowdhury 1999). 

      </p>

      <ul>

        <li class="normal"><span class="normal"> <b>Precision </b>(number of relevant 

          documents in results divided by the number of retrieved objects)</span></li>

        <li class="normal"><span class="normal"> <b>Recall </b>(number of retrieved 

          documents divided by the number of relevant objects in the collection)</span></li>

        <li class="normal"><span class="normal"> <b>Specificity </b>(level of 

          detail of indexing of an object i.e. how fine grained is the indexing)</span></li>

        <li class="normal"><span class="normal"> <b>Exhaustivity</b> (completeness 

          of indexing of object using available vocabulary)</span></li>

      </ul>

      <p>If we use the example above, the University lectures (not unreasonably) 

        want to use their specialist vocabularies to search ARKive's multimedia 

        archive and have high precision and recall from the system based on those 

        terms and queries constructed from them.</p>

      <p>When actually doing the indexing, ARKive has to balance the levels of 

        specificity and exhaustiveness of their indexing to make the task tractable 

        within the limits of available resources and time. </p>

      <p>It is useful here to refer to some well-defined 'specialist vocabularies' 

        to get some insight into the scale of the challenge. </p>

      <ul>

        <li class="normal"><span class="normal">The Biosys, Zoological Record 

          (<a

href="../http://www.biosis.org.uk/products_services/zoorecord.html" target="_blank">http://www.biosis.org.uk/products_services/zoorecord.html</a>) 

          is indexed using an extensive thesaurus of around 10,000 terms developed 

          over more than 20 years. </span></li>

        <li class="normal"><span class="normal"> The General Multilingual Environmental 

          Thesaurus (GEMET) was developed by the European Environment Agency (EEA) 

          together with a co-operation of international experts to serve the needs 

          of environmental information systems. Analysis and evaluation work produced 

          a core terminology of 5,400 generalized environmental terms and their 

          definitions. (European Environment Agency, 2002)</span></li>

        <li class="normal"><span class="normal">Medical Subject Headings (MeSH) 

          (<a

href="../http://www.nlm.nih.gov/mesh/meshhome.html" target="_blank">http://www.nlm.nih.gov/mesh/meshhome.html</a>)contain 

          more than 19,000 main headings.  There are also 103,500 headings called 

          Supplementary Concept Records within a separate chemical thesaurus. 

          </span></li>

        <li class="normal"><span class="normal"> The Art &amp; Architecture Thesaurus 

          (AAT - <a

href="../http://www.getty.edu/research/tools/vocabulary/aat/" target="_blank">http://www.getty.edu/research/tools/vocabulary/aat/</a>) 

          is maintained by the Getty Research Institute (see <a

href="../http://www.getty.edu/gri/" target="_blank">http://www.getty.edu/gri/</a>) 

          and the thesaurus keeps growing. The AAT contains about 120,000 terms 

          covering objects, textual materials, images, architecture and material 

          culture from antiquity to the present. (J. Paul Getty Trust, 2002)</span></li>

        <li class="normal"><span class="normal">UK National Curriculum (for schools) 

          Metadata Schema contains some 2000 'subject keywords' (Qualifications 

          and Curriculum Authority, 2002)</span></li>

      </ul>

      <p>While any particular collection of multimedia will not necessarily contain 

        objects which are appropriately indexed under many of the terms from each 

        and every available specialist vocabulary, it is none-the-less possible 

        that some terms from all of these will be applicable to some objects. 

      </p>

      <p>These issues are relevant to many other types of projects, not least 

        those involved in the development of cross-searching of multiple databases 

        which have been indexed using different indexing schemas (e.g. Clark, 

        2001).  Much work is going on with respect to providing ways of robustly 

        mapping between different schemas. These issues are discussed again below.</p>

      <h1>Indexing, Metadata, Interoperability and Ontologies </h1>

      <p>It is beyond the scope of this paper to review the extensive literature 

        on the indexing and applications of 'metadata' (see below) to multimedia 

        objects, the issues of interoperability and related technologies. See 

        Gill and Miller (2002) for an overview of the key issues with regard to 

        &#145;digital cultural content&#146;, and below for some examples of relevant 

        projects. However a brief overview is necessary and useful in providing 

        additional background to the remainder of the paper.</p>

      <p>Metadata is broadly defined as &#145;data about data ' (Gilliland-Swetland, 

        1998).   The  traditional library catalogue index card is a classic example 

        of metadata. The publication date, author, title, publisher, dewey decimal 

        code&#133; are <i>'metadata elements'</i> within a clearly defined <i>metadata 

        schema</i> and <i>scheme </i>(list of metadata elements, allowed states 

        of those and relationships between them).</p>

      <p>As can be seen from this example, there are different types of metadata. 

        Gilliland-Swetland (1998) distinguishes between 5 types:</p>

      <ul>

        <li class="normal"><span class="normal"> <b>Administrative:</b> Metadata 

          used in managing and administering information resources</span></li>

        <li class="normal"><span class="normal"> <b>Descriptive:</b> Metadata 

          used to describe or identify information resources</span></li>

        <li class="normal"><span class="normal"> <b>Preservation:</b> Metadata 

          related to the preservation management of information resources</span></li>

        <li class="normal"><span class="normal"><b>Technical:</b> Metadata related 

          to how a system functions or metadata behave</span></li>

        <li class="normal"><span class="normal"> <b>Use:</b> Metadata related 

          to the level and type of use of information resources<br>

          </span></li>

      </ul>

      <p>Descriptive metadata is of most relevance to the challenges outlined 

        above, but in principle the issues apply to all the types. </p>

      <p>The interoperability of metadata i.e. the ability of different information 

        systems to inter-operate or be compatible with each other&#146;s vocabularies 

        is seen as a fundamentally important issue in the development of Web-based 

        information systems (Gill and Miller, 2002). This is because it is valuable 

        if two (or more) systems holding data on similar things can be reliably 

        cross searched and/or share data. Many standards, initiatives and projects 

        are in place to develop systems that will be able to interoperate at a 

        vocabulary and semantic (meaning) level (e.g. W3C 2002b, Miller 2001, 

        see also below). </p>

      <p>Part of the development of interoperable Web-based systems includes the 

        creation of systems that utilize semantically interoperable ways of describing 

        things, characteristics of things, and the relationships between them. 

        These 'ontologies' (e.g. Ontologies W3C initiative, W3C 2002b) take the 

        form of structured machine readable representation of the knowledge. </p>

      <p class=BlockQuote>Just like people need to have agreement on the meanings 

        of the words they employ in their communication, computers need mechanisms 

        for agreeing on the meanings of terms in order to communicate effectively. 

        Formal descriptions of terms in a certain area (shopping or manufacturing, 

        for example) are called ontologies and are a necessary part of the Semantic 

        Web. RDF [Resource Description Framework], ontologies, and the representation 

        of meaning so that computers can help people do work are all topics of 

        the Semantic Web Activity<i>.<br>

        <span class="BlockQuoteAuthor">(W3C 2001b)</span></i></p>

      <p>These developments form what can be seen as part of a larger movement 

        in Web technology development towards a more semantically interoperable 

        Web (W3C 2001a, Berners-Lee et al 2001) in which information is globally 

        interoperable. </p>

      <p>There are significant difficulties with building ontologies and applying 

        them to bodies of information. Ontology creation and application is a 

        very specialized and time-consuming activity. Even more difficult is mapping 

        between ontologies, especially those written by different communities 

        of interest. An ontology provides a machine processable hierarchy of terms, 

        but not all of the intentions of the ontology creator are encoded into 

        the description of the ontology. Therefore mapping between them is prone 

        to errors of interpretation.</p>

      <h1>Part of a Solution: Community of Interest/Expertise Annotation</h1>

      <p>The development of more semantically interoperable Web-based technologies 

        seems to promise the ability to solve part of the challenge outlined above; 

        namely, that of enabling machines (computers) to relate terms from different 

        specialist vocabularies about what are essentially the same thing or concept 

        and thus being able to map existing terms to the specialist vocabularies 

        (including other languages). </p>

      <p>However they do not provide a solution to the problem that members of 

        specialist interest groups will want to describe (apply metadata to) data 

        in ways relating to totally different concepts. </p>

      <p>A simple example makes the issue clearer: </p>

      <p class=normal>Imagine that there is a database of 100,000 images of people 

        in a wide variety of different settings, say developed for a news agency. 

        The database may be indexed using terms relating to identification of 

        people (name, age,&#133;) and event (time, place&#133;) as well as administrative, 

        preservation and technical metadata. This is because those are the important 

        characteristics to those who originally setup the database. </p>

      <p class=MsoBodyTextIndent3><span class="normal">Now milliners might see 

        great potential for studying how people use hats. The database is likely 

        to be a very useful resource:, they could search to see how the style 

        of hats has changed over time, or what types of hats are most popular; 

        they could answer  many more specific questions, e.g. what percentage 

        of women have bows on their hats? or wear a particular type hat at a particular 

        time of year?&#133; however the database is not indexed using the concept 

        of 'hat' and so it is not possible to interrogate it to find the answers 

        to these questions.</span></p>

      <p class=normal>Imagine now that someone else, a landscape architect, comes 

        across the database and sees that it could be used to study how public 

        seating is used in urban settings&#133;</p>

      <p>In each of these examples the collection <i>could be</i> of very great 

        value to the user, but the existing indexing was not originally designed 

        with these uses in mind and so it is not. It is in these cases that <i>community 

        annotation</i> of a collection, could offer the key to meeting these needs 

        and thus greatly extend the scope and value of an on-line collection. 

      </p>

      <p>In the example above the individuals are from communities of 'milliners' 

        and 'landscape architects'. They could annotate the images with specialist 

        indexing terms used by their communities, ideally from ontologies developed 

        to facilitate a semantically consistent representation. However it might 

        be that they simply want to add 'notes' to particular images for others 

        from their communities to find or make a hyper-link to a page of more 

        detailed complementary information or case studies of that kind of example.</p>

      <h1>Models of Community Annotation</h1>

      <p>This section outlines a number of models of community annotation that 

        we have identified, and that we believe help meet the diverse needs of 

        different &#145;user communities&#146; and the database system developers 

        such as ARKive.</p>

      <p>Figure 1 shows via a much simplified Venn diagram some of the communities 

        of interest of an ARKive type project. There are the more traditional 

        &#145;target users&#146;, in ARKive&#146;s case, those with interests 

        in biodiversity and wildlife media and their sub-communities A1, A2, A3&#133; 

        (e.g. different sub-disciplines, phases of education&#133;), and ARKive&#146;s 

        own staff. However there are other &#145;communities of interest&#146; 

        (B, C, D and E) that lie outside or may have some degree of overlap with 

        the original target community or communities.</p>

      <p class=MsoCaption><img src="shabajee.figure1.gif" width="400" height="289"><br>

        Figure 1 &#150; Communities of Interest</p>

      <p>Whilst the discussion here is focused on the use of community annotation 

        to apply &#145;specialist&#146; indexing to objects, the majority of the 

        issues discussed are the same for other kinds of annotation. Examples 

        include case studies in the use of a particular image or media type, or 

        notes relating to the object (e.g. what it shows, interesting facts, controversies). 

      </p>

      <p>Possibly the most critical issues related to &#145;community annotation&#146; 

        for the organizations behind ARKive-type Web sites are related to the 

        quality, accuracy and relevance of any annotation. One of ARKive&#146;s 

        fundamental values is ensuring that it provides scientifically accurate 

        and up-to-date information.</p>

      <p>If users are given tools that enable them to add/link &#145;metadata&#146; 

        to multimedia assets, many issues arise about how that annotation can, 

        or should be, made available to other users of the system. Below we have 

        outlined four models of annotation that we have developed to illustrate 

        the issues.</p>

      <ol>

        <li class="normal"><span class="normal"><b>Trusted members of trusted communities</b>: ARKive already has 

          a group of &#145;trusted&#146; experts and organizations that provide 

          and validate information which ARKive collates and publishes on its 

          Web site. This approach would expand this single group to wider communities; 

          for example, a &#145;trusted organization&#146; could provide a list 

          of potential members that it states are competent to annotate ARKive 

          resources. Likely the resources and &#145;metadata terms&#146; that 

          they are permitted (by ARKive) to annotate and use, would be limited 

          to a specific set  within their area of competency and that the types 

          of annotation or vocabulary of concepts would also be limited (see consistency 

          below).<br>

          <br>

          These &#145;trusted members&#146; could be given usernames and passwords 

          and on-line tools to annotate ARKive resources. These annotations would 

          thus in principle be &#145;ARKive approved annotations&#146; and thus 

          in effect integral to the ARKive cataloguing and indexing system. However, 

          it may be that only particular communities of users get access to particular 

          sets of annotations.<br>

          <br>

        </span></li>

        <li class="normal"><span class="normal"><b>Self-selecting communities</b>: Much as there are self-selecting, 

          open and closed discussion groups on academic mail lists such as JISCMail 

          (<a href="../http://www.jiscmail.ac.uk/" target="_blank">http://www.jiscmail.ac.uk</a>), 

          it would be possible to provide annotation tools for a self-selecting 

          and administering community of users.<br>

          <br>

          Such communitties normally have &#145;community leaders&#146; who administer 

          them on a day-to-day basis. They vary greatly in nature from highly 

          structured and constituted  to loose with similar interests.<br>

          <br>

          It could be that only members of a &#145;closed&#146; community get 

          access to the annotations added by their group, or that these are made 

          available to generic ARKive users but with a &#145;disclaimer&#146;. 

          <br>

          <br>

        </span></li>

        <li class="normal"><span class="normal"><b>Open annotation:</b> in this model any ARKive user could annotate 

          an object. This is similar to ratings systems which exist on e-commerce 

          sites such as Amazon.com (<a

href="../http://www.amazon.com/" target="_blank">www.amazon.com</a>). The degree 

          of &#145;openness&#146; may range from totally &#145;open&#146; to a 

          more &#145;mediated&#146; approach in which some validation or quality 

          criteria are applied (see &#145;Consistency and Quality Control&#146; 

          below).<br>

          <br>

          In this case, all annotation would have to have some form of &#145;disclaimer&#146; 

          as ARKive would have relatively little control over the quality, accuracy 

          or relevance of any annotation. <br>

          <br>

        </span></li>

        <li class="normal"><span class="normal"><b>Third Party Annotation:</b>  ARKive users might want to produce 

          &#145;third party&#146; sites to <b>draw </b>together resources from 

          ARKive and other sites; the simplest example of this would be a list 

          of links to other Web sites. However,  these third parties might also 

          produce their own &#145;annotations&#146; for ARKive resources; e.g. 

          they might use a very subject-specific vocabulary. &#145;Annotating&#146; 

          resources from diverse sources has the advantage of enabling resource 

          discovery across multiple information sources but with a particularspecialist 

          vocabulary and personal control.<br>

          <br>

          ARKive would not have control over this form of annotation but might 

          want to provide infrastructures and tools to support such annotation. 

        </span></li>

      </ol>

      <h1>Existing Projects</h1>

      <p>Many Web-based projects and sites use some form of annotation to 'add 

        value' to their data.  Each example below utilizes one of the approaches 

        above:  </p>

      <ul>

        <li class="normal"><span class="normal"> Amazon.co.uk (<a href="../http://www.amazon.co.uk/" target="_blank">http://www.amazon.co.uk/</a>) 

          provides customers with the ability to add comments about a product 

          and give it a star rating. This gives future users the 'added value' 

          of hearing the views of others who had read, listened to, watched etc&#133; 

          the product. All users can see all annotations once they have been vetted 

          for compliance with Amazon's guidelines. For guidelines see (<a

href="../http://www.amazon.co.uk/exec/obidos/subst/misc/author-review-guidelines.html/026-1836225-8318031" target="_blank">http://www.amazon.co.uk/exec/obidos/subst/misc/author-review-guidelines.html/026-1836225-8318031</a>) 

          <br>

          <br>

          </span></li>

        <li class="normal"><span class="normal"> PseudoCAP: : Pseudomonas aeruginosa 

          Community Annotation Project (<a href="../http://www.cmdr.ubc.ca/bobh/PAAP.htm" target="_blank">http://www.cmdr.ubc.ca/bobh/PAAP.htm</a>) 

          allows  Web-based annotation tools a to be used by members of a closed 

          community.  Since they aim toto:<br>

          <br>

          </span></li>

        <li class="normal"><span class="normal"> &quot;&#133; improve the quality 

          of analysis of the <i>Pseudomonas aeruginosa</i> PAO1 genomic sequence, 

          and to ensure the development and widespread availability of genetic 

          tools to analyze Pseudomonas gene function, this <i>Pseudomonas aeruginosa</i> 

          community annotation project (PseudoCAP) was initiated to enlist the 

          expertise of volunteer Pseudomonas scientists in annotating the genome 

          sequence. Annotations provided by the Pseudomonas scientists were subjected 

          to peer review and used to aid the final genome annotation that was 

          published. All participants in this project for the publication of the 

          genome sequence have been acknowledged in the genome paper&#133;&quot;   

          <br>

          <br>

          </span></li>

        <li class="normal"><span class="normal"> Slashdot (<a href="../http://slashdot.org/" target="_blank">http://slashdot.org/</a>) 

          is an example of a &#145;community news portal.&#146;  It allows users 

          to up-load news and then others can take part in a (threaded) discussion 

          based on the original submission. <br>

          <br>

          </span></li>

        <li class="normal"><span class="normal"> Gimp-Savvy.com (<a href="../http://www.gimp-savvy.com/" target="_blank">http://www.gimp-savvy.com/</a>) 

          is a Community-Indexed Photo Archive which provides simple tools for 

          users to add indexing terms to images in an on-line image database (<a href="../http://gimp-savvy.com/PHOTO-ARCHIVE/" target="_blank">http://gimp-savvy.com/PHOTO-ARCHIVE/</a>)<br>

          <br>

          </span></li>

        <li class="normal"><span class="normal"> Berkman Center for Internet and 

          Society (<a

href="../http://eon.law.harvard.edu/cite/annotate.cgi" target="_blank">http://eon.law.harvard.edu/cite/annotate.cgi</a>.) 

          has developed an on-line tool (Annotation Engine) for users to annotate 

          on-line documents by placing a link in the text at the point that the 

          user wishes to annotate  <br>

          <br>

          </span></li>

        <li class="normal"><span class="normal"> FishBase (<a href="../http://www.fishbase.org/" target="_blank">http://www.fishbase.org/</a>) 

          is an interesting example of a specialist site which is run and managed 

          as a community. FishBase contributors have passworded access to edit 

          and add data to the very extensive underlying database of scientific 

          data and multimedia resources.</span></li>

      </ul>

      <p>More generally the W3C are looking to develop &#145;annotation standards&#146; 

        under the Annotea project (W3C, 2002a) to allow users to collaboratively 

        annotate Web pages. In <span class=MsoHyperlinkFollowed>parallel</span> 

        with these developments, the standards which support the use of metadata 

        descriptions are expanding; e.g. the MPEG-7 standard (Martínez, 2001) 

        for the &#145;content description&#146; of multimedia includes a comprehensive 

        &#145;Description Definition Language&#146; which allows complex description 

        of multimedia objects.</p>

      <p>These projects all provide tools that enable users of different types 

        to add value to the 'collections' by adding annotation.</p>

      <h1>Implementation of Community Annotation &#150; Issues </h1>

      <h2>Use of and Access to Annotation data </h2>

      <p>As can be seen above, the use of and access to any annotation is an issue 

        inseparable from that of the under lying model of annotation. Probably 

        the most fundamental issues are deciding who has access to any annotations 

        and how any annotations (explicit, e.g. case studies, or implicit,e.g. 

        search terms) are used and their use signaled. Some approaches follow.</p>

      <ol>

        <li class="normal"><span class="normal"> &#145;<b>Trusted community annotation&#146;</b> might effectively 

          be transparent to any users and simply be utilized as core ARKive tagging 

          or alternatively might be provided via a specialist search engine option 

          or provided with a disclaimer.<br>

          <br>

        </span></li>

        <li class="normal"><span class="normal">&#145;<b>Self-selecting community annotation&#146;</b> might be available 

          to all users via a disclaimer or only available to &#145;subscribers&#146; 

          to that annotation (i.e. they explicitly request access) or only to 

          members of the community.<br>

          <br>

        </span></li>

        <li class="normal"><span class="normal">&#145;<b>Open annotation&#146;</b> could be &#145;transparent&#146; 

          or have access controlled as in the previous two cases.<br>

          <br>

        </span></li>

        <li class="normal"><span class="normal">&#145;<b>Third party annotation&#146;</b> would mean ARKive would 

          have no control over access to or use of this type of annotation. For 

          user groups this might be seen as an advantage as the system is &#145;independent&#146;.</span></li>

      </ol>

      <h2>Consistency and &#145;Quality Control&#146;</h2>

      <p>Another fundamental issue with respect to using community annotation 

        to assist with &#145;indexing&#146; metadata is ensuring that there is 

        consistency in both the terms used and the application of those terms, 

        which relate back to precision and recall (see above).</p>

      <p>The main solution to the issue of consistency has historically been to 

        utilize a &#145;controlled vocabulary&#146; with clear instructions about 

        what those terms relate to; e.g. library catalogue systems. In particular, 

        controlled vocabularies appear to improve consistency where indexing is 

        being conducted by a number of &#145;indexers&#146; (Markey,1984).  In 

        the case of ARKive there is already a controlled (bespoke) vocabulary 

        for a number of aspects of the data and metadata used to describe the 

        multimedia objects. </p>

      <p>In order to annotate objects with relevant terms/concepts, it seems necessary 

        to provide not only a controlled vocabulary but also a highly structured 

        conceptual framework on which the vocabulary is based. This is because 

        of the very large range of concepts that are covered by ARKive content, 

        including bio- and bio-geographic sciences, wildlife film making, conservation 

        and sustainable development, and educational uses. </p>

      <p>These are broadly quality control issues; key questions for any system 

        will relate to the degree of &#145;quality control&#146; required for 

        any annotations. This may extend from a check that annotations are not 

        obscene or contravene legal requirements (e.g. libel laws) all the way 

        to full multilevel verification by appropriate experts with formal &#145;sign 

        off&#146; of any new annotations. </p>

      <p>The degree to which this is appropriate must depend on the nature of 

        the system; e.g. a &#145;closed community&#146; in which members of the 

        community are the <i>only </i>users who can access the annotation may 

        require no formal quality control (other than legal issues) from the collection/Web 

        site owners. However &#145;trusted community&#146; annotation that is 

        accessible to all users may require significant quality control.</p>

      <h2>Tracking Annotation &amp; Access Control &#150; Annotation Metadata</h2>

      <p>If community annotation is used, there must be systems in place to manage 

        the new data. That is the ability to track and maintain the annotations; 

        it is necessary to have metadata about the annotations. Cross et al (2001) 

        show how this kind of data can be created and maintained. The potential 

        value of this data is significant, as it potentially enables users (internal 

        to the organization or external) to query the system to say &#147;show 

        me all the annotation to the collection (or subset) made by person &#145;x&#146; 

        or members of community &#145;y&#146;&#148;. This forms the basis of providing 

        controlled access to the annotation data.</p>

      <h2>Extensibility</h2>

      <p>A further requirement of any system of annotation focused on adding value 

        to a collection by  &#145;indexing&#146; is that it be extensible; i.e. 

        that new terms can be added in a coherent and meaningful way. </p>

      <p>For example when a new &#145;term&#146; is added it must be done in such 

        a way that concepts of which it is a sub-element (e.g. pecking might be 

        a sub-set of feeding or defensive behaviors) retain conceptual integrity, 

        e.g. the term &#145;pecking&#146; should not be applied to an object that 

        does not have a related parent concept (e.g. feeding) or that existing 

        parent concept must (henceforth) be made to apply to the object as well. 

        Hence there may be a need to create new non-overlapping sub-categories 

        of pecking; e.g. feeding:pecking and defensive-behavior:pecking. </p>

      <p>This simple example shows that the creation of any conceptual representation 

        will be very problematic. However the current authors believe that without 

        such a framework, effective use of annotation would be very problematic 

        if not impossible to manage and monitor. Heflin and Hendler (2000) explore 

        the complexities of making changes to formal ontologies and some the many 

        associated problems. </p>

      <p>Other issues include how to deal with and represent 'controversial knowledge', 

        'fallacies', 'old knowledge' and other forms of 'inconstancies' in any 

        knowledge base. There are no simple answers to these problems. Once again 

        the most appropriate solution will depend on the particular situation; 

        e.g. in the case of relatively open annotation such as gimp-savvy.com 

        (<a href="../http://www.gimp-savvy.com/" target="_blank">http://www.gimp-savvy.com/</a>) 

        it may be appropriate for any user to be able to add indexing terms (given 

        legal considerations are dealt with, see above) whilst in the case of 

        &#145;trusted community&#146; annotation, changes to the ontology or vocabulary 

        used might require a formal meeting of some form of &#145;expert panel&#146;.</p>

      <p>However whatever form it takes, we argue that there must be some system(s) 

        to facilitate such extension of the available terms and concepts if the 

        overall systems are to be effective and sustainable.</p>

      <p>A further fundamental problem is that community annotation using extensible 

        annotation vocabularies and schemes is post-hoc and thus, unless every 

        object is systematically annotated, it is very likely that the some objects 

        will not be tagged with a new type of annotation e.g. a particular indexing 

        term, when it 'should' be. Thus the annotation or indexing becomes inconsistent 

        across the collection. There seems to be no simple solution to this problem 

        other than systematic annotation. However as outlined in the next section, 

        the use of 'semantically aware' tools may provide a means of optimizing 

        the completeness of annotations across a collection where (as in most 

        cases) there are time and resource constraints.</p>

      <h2>Semantic Bootstrapping </h2>

      <p>One very interesting requirement that we have identified for all of the 

        models described above is  &#145;semantic bootstrapping&#146;; that is, 

        when a collection has been &#145;indexed&#146; from one perspective (i.e. 

        for its primary target use or user group) using one set of vocabularies, 

        it is necessary to have or create some kind of &#145;semantic hook(s)' 

        in the data to allow users to begin the process of indexing the collection 

        from the new perspective, using the new vocabulary. </p>

      <p>This is a form of &#145;semantic bootstrapping&#146;, conceptually related 

        to the idea developed by Pinker (1984) to refer to his postulated process 

        by which children &#145;semantically bootstrap&#146; or learn syntax from 

        some form(s) of built in &#145;semantic categories&#146; and contexts. 

      </p>

      <p>Ontology-based tools (see above) could allow existing ontologies to be 

        linked to the already-present vocabularies or ontologies via concepts 

        common to both existing and new domains.</p>

      <p>Concept extraction tools such as the &#145;Non Zero Match&#146; tool 

        were developed at the University of Bristol (<a href="../http://nzm.dig.bris.ac.uk/index.html" target="_blank">http://nzm.dig.bris.ac.uk/index.html</a>). 

        The tool allows users to auto-index text-based documents using concepts 

        defined by a list of words/phrases with positive and negative weights. 

        E.g. say a &#145;car&#146; by defining the concept via the occurrence 

        of a set of words or phrases &#145;registration number&#146;, &#145;steering 

        wheel&#146;, &#145;make&#146;, &#145;model&#146; etc&#133; the parser 

        then processes the whole corpus of documents indexing the documents under 

        the appropriate concepts. Thus by using existing text or indexing/markup 

        it would be possible to create new concepts to help &#145;bootstrap&#146; 

        the new indexing.</p>

      <p>Another example is described by Bobrovnikoff (2000) using the DIPRE (Dual 

        Interative Pattern Relation Extraction) algorithm, to recognize pattern 

        in existing data.  Auto-indexing of still and moving images also provides 

        the potential to extract and index new concepts; e.g. in the example above 

        of looking for &#145;hats&#146; in the database of images of people.  

        See Campbell et al (1997) and Lew (2000) for examples of this approach.</p>

      <p>There are various forms that semantic bootstrapping could take, with 

        various levels of automation. It could be a time-consuming and highly 

        skilled manual task, effectively re-indexing the database manually by 

        re-cataloguing by placing the images within an ontology used by a community 

        of interest, or by using a controlled vocabulary. At the opposite end 

        of the spectrum, the images could be auto-classified using specialist 

        tools for pattern recognition.</p>

      <p>Somewhere in between is a stored search by a subject expert. For example, 

        when people search Google for a particular topic, they use their knowledge 

        of their subject area and their common sense coupled with their experience 

        of the content of the Google database itself to choose search terms that 

        will accurately retrieve the information they require. For example someone 

        looking for 'flying things' would use more specific search terms like 

        'bird', 'helicopter' 'parrot'.</p>

      <p>An annotated stored query of a database by someone with knowledge of 

        the indexing terms used in the database and the specialist subject knowledge 

        of the community of interest would enhance the value of the database to 

        that community. Such an annotation would provide fast approximate information 

        for that community. An example might be a search of a database for photos 

        of people dressed for a 'formal event' to get pictures of hats.</p>

      <p>If there were time, the user could go through the images found in this 

        way to check if the retrieved pictures were in fact pictures with hats, 

        discarding those that were not. However, even a quick annotated search 

        could provide added value.</p>

      <p>Some form of &#145;semantic bootstrapping&#146; will be essential in 

        making annotation work effectively for communities. Different types of 

        &#145;semantic bootstrapping&#146; tools are likely to assist with different 

        types of problem, and hence it is likely that what is needed is a suite 

        of tools rather than one single tool or approach.</p>

      <h1>Moving Forward</h1>

      <p>We are working to formalize the models outlined above and are developing 

        more detailed technical requirements for the implementation of the models. 

        The ideal is that we design an approach that can allow ARKive type organizations 

        to implement any and all of the models of annotation outlined above.</p>

      <p>In parallel we are investigating the advantages and disadvantages of 

        the different models in different contexts in order to help developers 

        make decisions about which ones are the most appropriate for their particular 

        needs and contexts. Parallel investigation into different approaches to 

        &#145;semantic bootstrapping&#146; and development of appropriate tool 

        sets will continue.</p>

      <h1>Conclusions </h1>

      <p>Community annotation offers the developers of large multimedia database 

        systems the ability to support specialist &#145;communities of Interest&#146; 

        and thus enhance the value of their data. There are many technologies 

        available and under development that would support this approach; some 

        projects are already utilizing them.</p>

      <p>This paper has dealt primarily with the annotation of multimedia objects 

        with specialist indexing/resource discovery terms and the associated technologies; 

        however, the issues are similar for more generic types of annotation.</p>

      <p>The four models of community annotation outlined in the paper provide 

        a framework for the development of community-based approaches to enhance 

        the value of Web-based museum and multimedia collections for specialist 

        communities of interest.</p>

      <p>There are many implementation issues that remain highly problematic, 

        in particular the coherent and consistent extensibility of vocabularies 

        and the development of &#145;semantic bootstrapping&#146; tools. </p>

      <p>However, it will likely be possible, in the short to medium term, to 

        find solutions by assessing needs and matching solutions in each specific 

        case. In the longer term, we hope that the on-going development of a more 

        &#145;semantically interoperable&#146; Web and associated technologies 

        will lead to the creation of sets of approaches and tools to make the 

        implementation of community-based annotation relatively simple and effective.</p>

      <h1>Acknowledgements </h1>

      <p class=AcknowedgementsText>The ARKive-ERA project is funded by HP-Labs, 

        Bristol. The authors wish to thank Dave Reynolds of HP Labs, for discussing, 

        exploring and expanding the ideas related in this paper.</p>

      <h1>References</h1>

      <p class=ReferencesText>Berners-Lee, T., Hendler, J. and Lassila, O. (2001) 

        The Semantic Web, Scientific American, May 2001.</p>

      <p class=ReferencesText>Buckingham Shum, S., E. Motta, et al. (2000). <u>International 

        Journal on Digital Libraries</u> <b>3</b>(3): 237-248.</p>

      <p class=ReferencesText>Chowdhury, G. G. (1999) Introduction to Modern Information 

        Retrieval, Library Association Publishing, London.</p>

      <p class=ReferencesText>Clark, J. (2001). &quot;Subject portals.&quot; Ariadne(29). 

        Available on-line: <a href="../http://www.ariadne.ac.uk/issue29/clark/" target="_blank">http://www.ariadne.ac.uk/issue29/clark/</a></p>

      <p class=ReferencesText>Cross, P., Miller, L., and Palmer, S.  (2001). Using 

        RDF to Annotate the (Semantic) Web. K-CAP Workshop Knowledge Markup &amp; 

        Semantic Annotation, Victoria B.C., Canada.</p>

      <p class=ReferencesText>DELESE (2001). Digital Library for Earth System 

        Education (DELESE) Web site. <a href="../http://www.dlese.org/" target="_blank">http://www.dlese.org/</a></p>

      <p class=ReferencesText>Eakins, J. and M. Graham (1999). Content-based Image 

        Retrieval, JTAP (Joint Technology Applications Programme). </p>

      <p class=ReferencesText>European Environment Agency (2002). GEneral Multilingual 

        Environmental Thesaurus (GEMET): The GEMET 2.0 Approach. Available on-line:<a href="../http://www.mu.niedersachsen.de/cds/etc-cds_neu/library/Gemet.pdf" target="_blank"> 

        http://www.mu.niedersachsen.de/cds/etc-cds_neu/library/Gemet.pdf</a></p>

      <p class=ReferencesText>Gill, T. and P. Miller (2002). &quot;Re-inventing 

        the Wheel? Standards, Interoperability and Digital Cultural Content.&quot; 

        D-Lib Magazine 8(1).</p>

      <p class=ReferencesText>Gilliland-Swetland, Anne J. &quot;Setting the Stage: 

        Defining Metadata&quot; in Introduction to Metadata: Pathways to Digital 

        Information, Murtha Baca, ed. (Los Angeles: Getty Information Institute, 

        1998) Available on-line: <a href="../http://www.getty.edu/research/institute/standards/intrometadata/2_articles/index.html" target="_blank">http://www.getty.edu/research/institute/standards/intrometadata/2_articles/index.html</a></p>

      <p class=ReferencesText>Heflin, J. and J. Hendler (2000). Dynamic ontologies 

        on the Web. Seventeenth National Conference on Artificial Intelligence 

        (AAAI-2000).</p>

      <p class=ReferencesText>Lew, Michael (2000) Next-Generation Web Searches 

        for Visual Content, IEEE Computer, 33(11) p46-53, November, 2000 </p>

      <p class=ReferencesText>Markey, K. (1984) &quot;Interindexer Consistency 

        Tests: A Literature Review and Report of a Test of Consistency in Indexing 

        Visual Materials.&quot;, Library and Information Science Research, 6, 

        155-177.</p>

      <p class=ReferencesText>Martínez, J. M. (2001). Overview of the MPEG-7 Standard 

        (version 6.0), MPEG (Moving Picture Experts Group). Available on-line 

        <a href="../http://mpeg.telecomitalialab.com/standards/mpeg-7/mpeg-7.htm" target="_blank">http://mpeg.telecomitalialab.com/standards/mpeg-7/mpeg-7.htm</a></p>

      <p class=ReferencesText>Miller, P. (2001) Interoperability Focus homepage. 

        Available on-line <a href="../http://www.ukoln.ac.uk/interop-focus/" target="_blank">http://www.ukoln.ac.uk/interop-focus/</a>. 

      </p>

      <p class=ReferencesText>Campbell, N. W. Mackeown, W. P. J., Thomas, B. T, 

        and Troscianko, T. Interpreting Image Databases by Region Classification, 

        Pattern Recognition (Special Edition on Image Databases), 30(4):555-563, 

        April 1997. </p>

      <p class=ReferencesText>Qualifications and Curriculum Authority (2002). 

        National Curriculum Online Metadata Standard Overview, Available on-line 

        <a

href="../http://www.nc.uk.net/metadata/" target="_blank">http://www.nc.uk.net/metadata/</a> 

      </p>

      <p class=ReferencesText>Schreiber, A. T., B. Dubbeldam, et al. (2001). &quot;Ontology-Based 

        Photo Annotation.&quot; IEEE Inteligent Systems May/June 2001: 2-10.</p>

      <p class=ReferencesText>W3C. (2001a) Semantic Web. Available online: <a

href="../http://www.w3.org/2001/sw/" target="_blank">http://www.w3.org/2001/sw/</a>.</p>

      <p class=ReferencesText>W3C (2001b), XML-in-10-points, Available online: 

        <a

href="../http://www.w3.org/XML/1999/XML-in-10-points/" target="_blank">http://www.w3.org/XML/1999/XML-in-10-points/</a> 

      </p>

      <p class=ReferencesText>W3C. (2002a) Annotea Project Homepage. W3C. Available: 

        <a href="../http://www.w3.org/2001/Annotea/" target="_blank">http://www.w3.org/2001/Annotea/</a>. 

      </p>

      <p class=ReferencesText>W3C. (2002b) Web-Ontology (WebOnt) Working Group 

        Homepage. W3C. Available: <a href="../http://www.w3.org/2001/sw/WebOnt/" target="_blank">http://www.w3.org/2001/sw/WebOnt/</a>. 

      </p>

      <!-- #EndEditable --></td>
  </tr>
</table>
<!--htdig_noindex-->

<!-- analytics scripts -->
<!-- tynt script -->
<script type="text/javascript">tyntVariables = {"ap":"Read more: "};</script> 
<script type="text/javascript" src="../http://tcr.tynt.com/javascripts/Tracer.js?user=aTNeQ-tzOr36a6adbiUzgI&amp;s=130&amp;cc=6&amp;st=1"></script>
<noscript></noscript>

<!-- google analytics script -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26332456-1']);
  _gaq.push(['_setDomainName', '.archimuse.com']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!--chartbeat script -->
<script type="text/javascript">
var _sf_async_config={uid:3385,domain:"archimuse.com"};
(function(){
  function loadChartbeat() {
    window._sf_endpt=(new Date()).getTime();
    var e = document.createElement('script');
    e.setAttribute('language', 'javascript');
    e.setAttribute('type', 'text/javascript');
    e.setAttribute('src',
       (("https:" == document.location.protocol) ? "https://s3.amazonaws.com/" : "http://") +
       "static.chartbeat.com/js/chartbeat.js");
    document.body.appendChild(e);
  }
  var oldonload = window.onload;
  window.onload = (typeof window.onload != 'function') ?
     loadChartbeat : function() { oldonload(); loadChartbeat(); };
})();

</script>

<!--/htdig_noindex-->

</body>
<!-- #EndTemplate -->
<!-- Mirrored from www.museumsandtheweb.com/mw2002/papers/shabajee/shabajee.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 17:47:36 GMT -->
</html>
