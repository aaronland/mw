<!DOCTYPE html>
<!--[if IE 6]>
<html id="ie6" lang="en-US">
<![endif]-->
<!--[if IE 7]>
<html id="ie7" lang="en-US">
<![endif]-->
<!--[if IE 8]>
<html id="ie8" lang="en-US">
<![endif]-->
<!--[if !(IE 6) & !(IE 7) & !(IE 8)]><!-->
<html lang="en-US">
<!--<![endif]-->

<!-- Mirrored from mwa2013.museumsandtheweb.com/paper/where-are-the-pictures-linking-photographic-records-across-collections-using-fuzzy-logic-2/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 24 Apr 2022 19:30:32 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width" />
<title>
Where Are the Pictures? Linking Photographic Records across Collections Using Fuzzy Logic | MWA2013: Museums and the Web ASIA 2013	</title>
<link rel="profile" href="https://gmpg.org/xfn/11" />
<link rel="stylesheet" type="text/css" media="all" href="../../wp-content/themes/twentyeleven-child/style8d89.css?ver=20190507" />
<link rel="pingback" href="../../xmlrpc.php">
<!--[if lt IE 9]>
<script src="https://mwa2013.museumsandtheweb.com/wp-content/themes/twentyeleven/js/html5.js?ver=3.7.0" type="text/javascript"></script>
<![endif]-->
<link rel='dns-prefetch' href='../../index.html' />
<link rel='dns-prefetch' href='http://s.w.org/' />
<link rel="alternate" type="application/rss+xml" title="MWA2013: Museums and the Web ASIA 2013 &raquo; Feed" href="../../feed/index.html" />
<link rel="alternate" type="application/rss+xml" title="MWA2013: Museums and the Web ASIA 2013 &raquo; Comments Feed" href="../../comments/feed/index.html" />
<link rel="alternate" type="application/rss+xml" title="MWA2013: Museums and the Web ASIA 2013 &raquo; Where Are the Pictures? Linking Photographic Records across Collections Using Fuzzy Logic Comments Feed" href="feed/index.html" />
		<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/mwa2013.museumsandtheweb.com\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.6"}};
			!function(e,a,t){var r,n,o,i,p=a.createElement("canvas"),s=p.getContext&&p.getContext("2d");function c(e,t){var a=String.fromCharCode;s.clearRect(0,0,p.width,p.height),s.fillText(a.apply(this,e),0,0);var r=p.toDataURL();return s.clearRect(0,0,p.width,p.height),s.fillText(a.apply(this,t),0,0),r===p.toDataURL()}function l(e){if(!s||!s.fillText)return!1;switch(s.textBaseline="top",s.font="600 32px Arial",e){case"flag":return!c([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])&&(!c([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!c([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]));case"emoji":return!c([55357,56424,8205,55356,57212],[55357,56424,8203,55356,57212])}return!1}function d(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(i=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},o=0;o<i.length;o++)t.supports[i[o]]=l(i[o]),t.supports.everything=t.supports.everything&&t.supports[i[o]],"flag"!==i[o]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[i[o]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(r=t.source||{}).concatemoji?d(r.concatemoji):r.wpemoji&&r.twemoji&&(d(r.twemoji),d(r.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='wp-block-library-css'  href='../../wp-includes/css/dist/block-library/style.min40df.css?ver=5.6' type='text/css' media='all' />
<link rel='stylesheet' id='wp-block-library-theme-css'  href='../../wp-includes/css/dist/block-library/theme.min40df.css?ver=5.6' type='text/css' media='all' />
<link rel='stylesheet' id='twentyeleven-block-style-css'  href='../../wp-content/themes/twentyeleven/blockscb8b.css?ver=20190102' type='text/css' media='all' />
<link rel="https://api.w.org/" href="../../wp-json/index.html" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="../../xmlrpc0db0.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="../../wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 5.6" />
<link rel="canonical" href="index.html" />
<link rel='shortlink' href='../../indexcfab.html?p=1337' />
<link rel="alternate" type="application/json+oembed" href="../../wp-json/oembed/1.0/embedee2c.json?url=https%3A%2F%2Fmwa2013.museumsandtheweb.com%2Fpaper%2Fwhere-are-the-pictures-linking-photographic-records-across-collections-using-fuzzy-logic-2%2F" />
<link rel="alternate" type="text/xml+oembed" href="../../wp-json/oembed/1.0/embedd51a?url=https%3A%2F%2Fmwa2013.museumsandtheweb.com%2Fpaper%2Fwhere-are-the-pictures-linking-photographic-records-across-collections-using-fuzzy-logic-2%2F&amp;format=xml" />
<style type="text/css" id="custom-background-css">
body.custom-background { background-color: #850000; }
</style>
	</head>

<body class="paper-template-default single single-paper postid-1337 custom-background wp-embed-responsive single-author two-column right-sidebar">
<div class="skip-link"><a class="assistive-text" href="#content">Skip to primary content</a></div><div id="page" class="hfeed">
	<header id="branding" role="banner">
			<hgroup>
				<h1 id="site-title"><span><a href="../../index.html" rel="home">MWA2013: Museums and the Web ASIA 2013</a></span></h1>
				<h2 id="site-description">The conference of Museums and the Web in Asia | December 8-12 | Hong Kong | December 14-15 | Beijing</h2>
			</hgroup>

						<a href="../../index.html">
									<img src="../../wp-content/uploads/2013/07/cropped-HK-16000x400.jpg" width="1000" height="250" alt="MWA2013: Museums and the Web ASIA 2013" />
								</a>
			
									<form method="get" id="searchform" action="https://mwa2013.museumsandtheweb.com/">
		<label for="s" class="assistive-text">Search</label>
		<input type="text" class="field" name="s" id="s" placeholder="Search" />
		<input type="submit" class="submit" name="submit" id="searchsubmit" value="Search" />
	</form>
			
			<nav id="access" role="navigation">
				<h3 class="assistive-text">Main menu</h3>
				<div class="menu-mwa-container"><ul id="menu-mwa" class="menu"><li id="menu-item-258" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-has-children menu-item-258"><a href="../../index.html">About</a>
<ul class="sub-menu">
	<li id="menu-item-420" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-420"><a href="http://www.museumsandtheweb.com/">MW Community</a></li>
	<li id="menu-item-1303" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-1303"><a href="http://www.museumsandtheweb.com/conferences/">Conferences</a></li>
</ul>
</li>
<li id="menu-item-544" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-544"><a href="../../news/index.html">News</a></li>
<li id="menu-item-444" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-444"><a href="../../attending/index.html">Attending</a>
<ul class="sub-menu">
	<li id="menu-item-423" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-423"><a href="../../call-for-proposals/index.html">Call for Proposals</a>
	<ul class="sub-menu">
		<li id="menu-item-422" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-422"><a href="../../guidelines-for-proposals/index.html">Guidelines for Proposals</a></li>
		<li id="menu-item-421" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-421"><a href="../../terms-and-conditions/index.html">Terms and Conditions</a></li>
		<li id="menu-item-424" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-424"><a href="../../submit-proposal/index.html">Submit Proposal</a></li>
		<li id="menu-item-609" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-609"><a href="../../paper-guidelines/index.html">Paper Guidelines</a></li>
		<li id="menu-item-612" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-612"><a href="../../presentation-guidelines/index.html">Presentation Guidelines</a></li>
	</ul>
</li>
	<li id="menu-item-916" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-916"><a href="../../local-information/index.html">Local Information</a></li>
	<li id="menu-item-504" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-504"><a href="../../key-dates/index.html">Key Dates</a></li>
	<li id="menu-item-503" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-503"><a href="../../scholarships-volunteering/index.html">Scholarships &#038; Volunteering</a>
	<ul class="sub-menu">
		<li id="menu-item-1195" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1195"><a href="../../volunteer-application/index.html">Volunteer Application</a></li>
		<li id="menu-item-1194" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1194"><a href="../../scholarship-application/index.html">Scholarship Application</a></li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-523" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-523"><a title="Exhibiting" href="../../exhibiting-and-sponsorship/index.html">Exhibiting</a>
<ul class="sub-menu">
	<li id="menu-item-563" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-563"><a href="../../exhibitor-rates/index.html">Exhibitor Rates</a></li>
	<li id="menu-item-567" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-567"><a href="../../exhibition-terms/index.html">Exhibition Terms</a></li>
	<li id="menu-item-521" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-521"><a href="../../sponsorship-opportunities/index.html">Sponsorship</a></li>
	<li id="menu-item-536" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-536"><a href="../../advertising/index.html">Advertising</a></li>
</ul>
</li>
<li id="menu-item-1267" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1267"><a href="../../conference/index.html">Conference</a>
<ul class="sub-menu">
	<li id="menu-item-1268" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1268"><a href="../../program/index.html">Hong Kong Program</a></li>
	<li id="menu-item-2418" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2418"><a href="../../program-beijing/index.html">Beijing Program</a></li>
	<li id="menu-item-1291" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1291"><a href="../../exhibits/index.html">Exhibits</a></li>
</ul>
</li>
<li id="menu-item-568" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-568"><a href="../../people/index.html">People</a>
<ul class="sub-menu">
	<li id="menu-item-2447" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-2447"><a href="../../people/index.html">Planning Committee</a></li>
	<li id="menu-item-2405" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2405"><a href="../../attendees/index.html">Attendees</a></li>
</ul>
</li>
</ul></div>			</nav><!-- #access -->
	</header><!-- #branding -->


	<div id="main">

<style type="text/css">
#full_width_content {
	margin-left: 76px;
	margin-right: 76px;
}

h2, h3, h4 {
	font-weight: bold;
}
</style>

<div id="primary">
<div id="full_width_content">
			

<h1 class="entry-title">Where Are the Pictures? Linking Photographic Records across Collections Using Fuzzy Logic</h1>
<b></b><br />

<a href="http://www.museumsandtheweb.com/member/sbrown1951">Stephen Brown</a>, UK, <a href="http://www.museumsandtheweb.com/member/simonc@dmu.ac.uk">Simon Coupland</a>, UK, <a href="http://www.museumsandtheweb.com/member/dcroft">David Croft</a>, UK, <a href="http://www.museumsandtheweb.com/member/jethros">Jethro Shell</a>, UK, <a href="http://www.museumsandtheweb.com/member/avlunen">Alexander von Lünen</a>, UK<br /><br /><b>Abstract</b><br />
<p>This paper describes a novel approach to interrogating different online collections to identify potential matches between them, using fuzzy logic-based data-mining algorithms. Potentially, information about objects from one collection could be used to enrich records in another where there are overlaps. But although there is a considerable amount of bibliographic and other kinds of data on the Web that share similar information, a standardized way of structuring such data in a way that makes it easy to identify significant relationships does not yet exist. In the case of historical photographs, the challenge is further exacerbated by the enormous range of subjects depicted, and the fact that surviving records are not always complete, accurate, or consistent and the amount of text available per record is very small. Fuzzy-matching algorithms combined with semantic similarity techniques offer a way of finding potential matches between such items when standard ontology and corpus-based approaches are inadequate, in this case helping researchers for the first time match photographs held in different archives to historical exhibition catalogue records.</p>
<p><b>Keywords: </b>linked data, semantic, ontology, metadata, fuzzy logic, co-reference</p>
<h2>1. Introduction</h2>
<p>The volume of online resources has grown exponentially and is forecast to continue to expand similarly into the foreseeable future (Figure 1). This growth creates enormous potential for cross-linkage between records, where there are overlaps, with the possibility of using information about objects from one data set to enrich records in another, thus enhancing their value.</p>
<p><a href="../../wp-content/uploads/2013/09/Brownfig1png.png"><img loading="lazy" alt="Brownfig1png" src="../../wp-content/uploads/2013/09/Brownfig1png-300x190.png" width="300" height="190" /></a></p>
<p>Figure 1: Information availability online from 2005 to 2015 (estimated). Source: IDC VIEW report ‘Extracting value from chaos,’ June 2011 (Fullan &amp; Donnelly, 2013, p. 9). 1 zettabyte = 1 trillion (1018) gigabytes.</p>
<p align="left">Galleries, libraries, archives, and museums (GLAMs) are adding to this content by digitizing their collections. In the United States, an analysis of 18,142 museums and libraries by the Institute of Museums and Library Services (IMLS, 2006) revealed that the majority of museums and larger public libraries make digital records available to the public via the Internet, and the same was true for a smaller proportion of public and smaller academic libraries. Individual institutional postings can run to hundreds of thousands of objects. As of January 2013, the Museum of Modern Art had posted more than 540,000 images, the British Museum offers images of more than 730,000 works, and the Victoria and Albert museum (V&amp;A) website offers access to more than 300,000 images of works in its collection (Kelly, 2013). Collectively, these resources amount to a vast quantity of data. The Europeana aggregator website offers access to 21.3 million objects from thirty-three countries (Europeana, 2012).</p>
<p>However, finding, evaluating, and gaining access to this content is challenging. GLAMs&#8217; object data typically resides in databases, which, while they may have Web-facing search interfaces, are not well integrated with other data sources on the Web. Although considerable amounts of bibliographic and other kinds of data exist on the Web that share information that could be linked, “Without tools and methods for filtering, categorizing, clustering, weighting, and disambiguating our expanding datasets, museums will face increasing difficulty in managing and organizing their online resources, while their visitors will struggle to locate and make use of them” (Klavans et al., 2011). Most of the information in GLAM records is encoded as natural-language text, which is not readily machine processable, and the GLAM and semantic Web communities have different terminology for similar metadata concepts, making implementation of semantic approaches difficult. Considerable interest has been expressed in the concept of linked data (Bizer et al., 2009; Heath &amp; Bizer, 2011; Oommen &amp; Baltussen, 2012), and some progress has been made in the form of REpresentational State Transfer (REST) and RDF Query Language (SPARQL) interfaces (ACRL Research Planning and Review Committee, 2012). But building a data pipeline to convert heterogeneous data from various source collections into common RDF in order to create linked open data that can facilitate searching across multiple collections requires considerable technical expertise (Henry &amp; Brown, 2012). While the onus is on GLAMs to standardize and convert their collections metadata, the prospect of universally linked data remains remote.</p>
<p align="left">This paper describes an alternative approach for helping researchers to find potential matches between such items based on similarity identification, in this case helping researchers to match photographs held in different archives to historical exhibition catalogue records for the first time.</p>
<h2>2. Exhibitions of the Royal Photographic Society</h2>
<p align="left">From its foundation in 1853, the Photographic Society in London always considered itself as the &#8216;parent society&#8217; and, after suffering several setbacks during the late 1860s, reemerged to establish itself as the preeminent photographic society of Britain. During the years that followed, the Photographic Society changed its name: first to the Photographic Society of Great Britain in 1874, and then in 1894 to the Royal Photographic Society, the name it retains today.</p>
<p align="left">Although other photographic societies flourished elsewhere in Britain and held their own annual exhibitions, catalogues from these societies have not survived in any significant number. In contrast, the forty-six surviving catalogues from the Photographic Society&#8217;s annual exhibitions from 1870 to 1915 contain 34,917 individual exhibit records. Collectively, these exhibition records are a highly significant research resource, offering a unique insight into the evolution of aesthetic trends and photographic technologies; the response of a burgeoning group of photographic manufacturers to business opportunities; and the activities and fortunes of individuals concerned with the technical, artistic, and commercial development of photography. The society&#8217;s exhibitions attracted a wide constituency of photographers from Britain, Europe, and America, and many individuals launched their photographic careers by exhibiting at the Royal Photographic Society.</p>
<p align="left"><em>Exhibitions of the Royal Photographic Society 1870–1915</em> (ERPS; <a href="http://erps.dmu.ac.uk/">http://erps.dmu.ac.uk</a>) is one of a number of photographic research resources hosted by De Montfort University (<a href="http://kmd.dmu.ac.uk/kmd_photohistory_page">http://kmd.dmu.ac.uk/kmd_photohistory_page</a>). These resources have enormous potential to enrich and contextualise records of historical photographs in GLAMs&#8217; collections, if co-referent photographs exist. Equally, matching surviving pictures to the exhibition catalogue records would enhance their value to researchers, particularly since although the ERPS exhibition catalogues contain information about many different aspects of the exhibits, they contain very few reproductions of the photographic exhibits themselves. There are only 1,040 images, most of which are merely artists’ sketches of the originals because, at the time of the exhibitions, mechanical reproduction of photographic images was technically impossible. While many researchers have commended the ERPS database for its usefulness, a common criticism is that most of the pictures are missing. The “FuzzyPhoto” project described here is developing and testing computer-based finding aids aimed at answering the questions:</p>
<ul>
<li>Where are the surviving pictures referred to in the exhibition catalogues?</li>
</ul>
<ul>
<li>What do those pictures look like?</li>
</ul>
<h2>3. Research challenges and methods</h2>
<p align="left">GLAMs&#8217; collection records generally, and the ERPS records in particular, present a number of challenges. In the case of the ERPS exhibition records, a new exhibition committee each year structured the exhibition into sections that seemed appropriate and labeled exhibits in particular ways. Thus some records have extensive metadata within a large number of fields, while others have only minimal entries under just a few headings. For example, sometimes a complete address is listed for an exhibitor, while for others there is only a neighborhood or a town name. It is unsurprising that address information should change, and equally unsurprising that in some cases exhibitor names changed as well, either through marriage or through promotion. For example, one can trace through the records the career of Lieutenant, later Captain and finally Sir, C.E. Abney. Less expected was that sometimes the same photograph was exhibited in different years by different people and sometimes under a different title.</p>
<p>GLAM records have their own issues. Record management systems and cataloguing conventions tend to vary between institutions, which tends to create structural differences between their respective data sets. Clustering algorithms can be used to identify similarities between different data sets (Dhillon et al., 2003), but when we ran a clustering algorithm on a sample of data from a range of institutions, we found that data clustered most strongly within the originating collections and that clusters of data between collections were very much less evident. In other words, the institutional cataloguing style was so strong that it masked any other similarities that might exist between records in different collections.</p>
<p>The quality of records is also highly variable. In some cases, records are kept as simple spreadsheets, with little or no structure, while other institutions keep meticulous records clearly differentiated into multiple fields. The problem of lack of clear structure is exacerbated when data are entered inconsistently, making it difficult to develop rules for separating out different data elements. For example, examination of the records for one collection revealed that twenty different ways of formatting date information had been used.</p>
<p>In order to compare records across ERPS and GLAMs&#8217; collections, an approach was required that could cope with incompleteness, uncertainty, and inconsistency. The methodology we use comprises four steps:</p>
<ol start="1">
<li>Data preparation (correcting typographical errors, standardizing data such as dates, removing duplicate entries and mapping data to a common metadata schema)</li>
<li>Data aggregation (combining standardized records in a single XML database where they can be mined for similarities)</li>
<li>Query expansion (extending the range of keywords that are searched for)</li>
<li>Field comparison (comparing the contents of individual fields and combining these to produce an overall similarity metric)</li>
</ol>
<p>Figure 2 outlines the overall workflow of the project, showing schematically how collection records are ingested, aggregated, and mined for links that can then be output to partners’ own Web sites, where they can be accessed by visitors to those sites.</p>
<p><a href="../../wp-content/uploads/2013/09/Brownfig2.png"><img loading="lazy" alt="Brownfig2" src="../../wp-content/uploads/2013/09/Brownfig2-300x157.png" width="300" height="157" /></a></p>
<p>Figure 2: Overall project workflow</p>
<h3>Data preparation and aggregation</h3>
<p align="left">Thus far, the FuzzyPhoto project has acquired circa 1.5 million historical photographic records from GLAMs, including the V&amp;A, British Library, New York Metropolitan Museum of Art, National Media Museum, National Museums Scotland, Birmingham City Library, St Andrews University, the National Archives, the Musée d’Orsay in Paris, and open sources such as Culture Grid. The first step is to convert all the data to a common MySQL table format. CSV files can be imported directly into MySQL, but for XML data, an XML data store (BaseX) and XQuery queries have to be used to convert data to MySQL tables, and an intermediate Microsoft SQL database was necessary to convert British Library (BL) data (Figure 3). After the data are imported, “cleaning up” such as eliminating duplicates or spelling variants is done, chiefly with SQL queries. Some operations, however, are too complex to be handled in SQL, so Java and Python scripts are used externally.</p>
<p align="left"> <a href="../../wp-content/uploads/2013/09/Brownfig2png1.png"><img loading="lazy" class="alignnone size-medium wp-image-1347" alt="Brownfig2png" src="../../wp-content/uploads/2013/09/Brownfig2png1-300x246.png" width="300" height="246" srcset="https://mwa2013.museumsandtheweb.com/wp-content/uploads/2013/09/Brownfig2png1-300x246.png 300w, https://mwa2013.museumsandtheweb.com/wp-content/uploads/2013/09/Brownfig2png1-364x300.png 364w, https://mwa2013.museumsandtheweb.com/wp-content/uploads/2013/09/Brownfig2png1.png 579w" sizes="(max-width: 300px) 100vw, 300px" /></a></p>
<p>Figure 3: Workflow for mapping different metadata sources to LIDO</p>
<p align="left">The next step is to map the records in the temporary MySQL tables to a common metadata schema. This is necessary because the original collections were catalogued using different schemas, which makes it difficult to compare records between them. We chose the ICOM LIDO metadata schema (<a href="http://network.icom.museum/cidoc/working-groups/data-harvesting-and-interchange/what-is-lido/">http://network.icom.museum/cidoc/working-groups/data-harvesting-and-interchange/what-is-lido/</a>). LIDO is an XML harvesting schema developed for exposing, connecting, and aggregating information about museum objects on the Web. It is ideally suited to the task of standardizing the metadata provided by each of the contributors.</p>
<h3>Query expansion</h3>
<p align="left">The endpoint of the first stage therefore is a MySQL database of records in LIDO format. The aim is to compare these records in order to identify similarities. Similarity identification, known variously as co-reference identification, record linkage, and entity resolution, is a common problem in many fields, and a correspondingly wide range of approaches have been developed to deal with it (Elmagarmid et al., 2007). Effective techniques have been developed for contexts where there are sufficiently large volumes of text to allow matching of key words (e.g., Luo &amp; Xie, 2009), or where very strong identifiers such as book titles, post codes, or telephone numbers link different items. However, such approaches are of only limited use in the context of GLAMs&#8217; collections, which typically have only limited metadata—often just a title, date and name, and sometimes not even that—and records are not always complete, accurate, or consistent (Tzompanaki, 2012).</p>
<p align="left">In addition to these general problems, most ERPS exhibit titles are just a few words, even though some extend to several lines. The average title length is just 8.1 words, of which only 5.4 are useful, making it very difficult to apply document classification or corpus-linguistics based approaches that rely on matching clusters of similar words in different documents. There are just not enough words in the titles as they stand to find such clusters. Furthermore, the range of subject matter depicted is enormous, including landscapes, events, scientific experiments, medicine, architecture, fashion, museums, folk customs, celebrities, photographic equipment, etc., against which ontology-based matching approaches are ineffective. The requisite ontology would have to cover just about every subject imaginable in the mid- to late nineteenth century.</p>
<p>One way of tackling the problem of limited amounts of text is query expansion. Query expansion uses semantically similar terms to those in a query to increase the chances of locating matching words (Xu &amp; Croft, 1996). Query expansion is relevant in the case of ERPS records because the titles contain so few words and because we know that variants of some photographs appear under similar but not identical titles. By searching for similar words, we increase our chances of finding the same photograph, even though its title may be different.</p>
<p>Before a term can be semantically expanded, its meaning has to be unambiguously defined (Stevenson &amp; Wilks, 2003). Many English-language words have multiple meanings: for example, “fair” can mean “blonde,, “attractive,” “festival,” or “equitable.” Therefore, when matching an exhibit title such as “Fair Daffodils,” the term “fair” has to be disambiguated first. Many semantic disambiguation techniques employ a corpus taken from a specific subject area with text structures that encompass long sentences, or even whole paragraphs, to derive a deep understanding of the context. Since the subject matter of the ERPS exhibits is so diverse, and the exhibit titles are so short, an alternative approach is required. We use the WordNet Lexical database (<a href="http://wordnet.princeton.edu/">http://wordnet.princeton.edu/</a>) to identify synsets of keywords, each of which represents a different meaning for that term, and supplementing this with Part-of-Speech Tagging (POST). POST applies descriptors to each element in a sentence (i.e., noun, verb, participle, article, pronoun, preposition, adverb, and conjunction) to help disambiguate the words (Voutilainen, 2003). A comparison of alternative software part-of-speech taggers indicated that the Stanford POST software (<a href="http://nlp.stanford.edu/software/tagger.shtml">http://nlp.stanford.edu/software/tagger.shtml</a>) is the most accurate when used against a test dataset of ERPS records.</p>
<h3 align="left">Field comparison</h3>
<p align="left">Field comparison entails comparing the expanded set of keywords relating to each individual record from the ERPS database (defined as a “seed record”) with the expanded query terms generated for other records in the data warehouse to assess their similarity. Similarity between terms in different records is assessed firstly by comparison between individual fields, and individual field similarity metrics are then combined to produce an overall similarity metric for each pair of records. Overall metrics are then ranked in order of most to least similar.</p>
<p align="left">Thus far, the research has concentrated on just four fields: title, date, creator, and process. Of these, date, creator and process are the most straightforward. The key factor in relation to date is the amount of time between the dates described in the fields. The greater the amount of time between them, the less similar they are. Some of the dates given describe a span of time rather than a specific year (e.g., &#8220;1890s,&#8221; &#8220;the 19th century&#8221;). Greater differences between time spans indicate less similarity between fields. For example &#8220;19th century&#8221; and &#8220;1900&#8221; are less similar than &#8220;1900s&#8221; and &#8220;1900.&#8221;</p>
<p align="left">In the case of the creator field, name comparison is a well-established problem in many areas, and a large number of algorithms exist to compare names which can handle typographical errors, alternative spellings, etc. We use established edit-distance techniques that measure similarity in terms of the number of changes (edits) required to convert one string into another (Winkler, 2006). The technique we use to assess the similarity of process field data matches the stated process with a list of preset keywords describing various known processes. This allows for typographical errors and spelling variations. The various photographic processes are organised into a branched dendrogram structure in which processes sharing specific traits appear on the same branch. Once a field has been matched to a specific locus, it is compared to other fields by finding the shortest path between the processes in the dendrogram. The shorter the distance between the approaches, the more similar they are considered to be.</p>
<h3>The title field</h3>
<p align="left">The extreme brevity of most ERPS exhibit titles rules out standard statistical text similarity metrics based on analysis of long text strings. Short-text semantic similarity tools such as Latent Semantic Analysis (LSA) and Sentence Similarity (STASIS) overcome this problem, but they are most effective with small volumes of text (O’Shea et al., 2008). As the volume of text increases, the time taken to process it becomes prohibitive. Although the titles of ERPS records are short, there are 35,000, and in total we have 1.5 million records to process. To deal with this volume, we have developed a simplified semantic similarity measure called Lightweight Semantic Similarity (LSS), which significantly lowers the computational overhead without significantly reducing the accuracy of results (Croft et al., 2013). LSS is based on standard statistical similarity metrics known as “cosine similarity” (Manning &amp; Schütze, 1999), but additionally takes into account the semantic similarity between words, with aid of WordNet and POST.</p>
<h3>Combined similarity metric</h3>
<p align="left">The final step in our workflow is to combine the individual field metrics into an overall record similarity metric. A series of rules was created that describes how to combine and weight the individual metrics. As an expert knowledge approach, it relies on the programmed knowledge of domain experts (Winkler, 2006), in our case derived from a survey of members of the GLAM community to establish the relative importance of the different variables. The result is a series of “if, then” statements (i.e., <b>IF </b><i>x, </i><b>THEN </b><i>y</i>), which represent the rules that a person would use to solve the same task. Rule-based systems are popular for commercial applications, but they often function poorly when faced with imprecise information, where the identity of <i>x</i> may be uncertain. In our case, uncertainty arises from factors such as imprecise dates (e.g., “circa 1890”); lack of definitive information about historical photographic processes, especially since the production of a photograph could entail more than one process; and the potential existence of variants resulting from different prints from the same negative.</p>
<p align="left">The solution to this difficulty is to use a fuzzy rule-based approach. Fuzzy logic allows an object to belong to more than one category, but to various degrees. For example, consider a number of people of different heights. While some are taller than others, the distinction between tall and not tall is not clear cut, and in different contexts a person of average height might be considered both tall and short. Fuzzy logic can accommodate this relativity by assigning a value to such a person that quantifies the extent to which they belong to the group “tall,” giving it greater resilience regarding imprecision compared with crisp logic. Fuzzy logic has been applied previously to resource discovery challenges (Feng, 2012; Lai et al., 2011; Li et al., 2009). However, these approaches were based on analysis of large volumes of text and thus are not applicable in our context. Our approach is tailored to the challenge of comparing records of titles, person names, dates, and processes, in which most fields contain only small amounts of text. The full set of fuzzy rules we use draws on the individual field-similarity metrics to ascertain if the match between a pair of fields is good, and then combines that comparison with other field comparisons as follows:</p>
<p><b>IF </b><i>title </i>is good <b>AND </b><i>person </i>is good, <b>THEN </b>match is good</p>
<p><b>IF </b><i>title </i>is good <b>AND </b>(<i>date </i>is good <b>OR </b><i>process </i>is good), <b>THEN </b>match is ok</p>
<p><b>IF </b><i>person </i>is good <b>AND </b><i>title </i>is bad, <b>THEN </b>match is ok</p>
<p><b>IF </b><i>title </i>is bad <b>AND </b><i>person </i>is bad, <b>THEN </b>match is bad</p>
<h2>4. Results</h2>
<p>Figure 4 illustrates how the overall similarity values are used to create connections between the records. Starting with a seed record at the root node, the combined rules identify the record with the highest similarity to that seed record and adds it as a child node. The record with the highest similarity to either of those two nodes is then added, creating a branching tree-like structure, and so on until all the records are added to the tree and the process ends. The connections shown in Figure 4 are just the topmost level of the complete dendrogram.</p>
<p><a href="../../wp-content/uploads/2013/09/Brownfig4web.png.png"><img loading="lazy" class="alignnone size-medium wp-image-2177" alt="Brownfig4web.png" src="../../wp-content/uploads/2013/09/Brownfig4web.png-300x144.png" width="300" height="144" srcset="https://mwa2013.museumsandtheweb.com/wp-content/uploads/2013/09/Brownfig4web.png-300x144.png 300w, https://mwa2013.museumsandtheweb.com/wp-content/uploads/2013/09/Brownfig4web.png-1024x491.png 1024w, https://mwa2013.museumsandtheweb.com/wp-content/uploads/2013/09/Brownfig4web.png-500x240.png 500w" sizes="(max-width: 300px) 100vw, 300px" /></a></p>
<p>Figure 4: Top-level dendrogram of search results for a single ERPS seed record</p>
<p>The result is that those records with the greatest similarity to the seed record appear in the highest layers of the tree. Of course, a similar effect could be achieved by simply selecting the<i> </i>records with the highest similarity to the seed record. However, this approach does more than just select the records with the greatest similarity to the seed record; it also groups similar records together within the hierarchy. For example, records with the same/similar person fields will be grouped together, which allows for easy exploration of all the records by a single photographer.</p>
<p>Figure 5 shows the results of one such search relating to ERPS record erps28409, a portrait of George Meredith, exhibited by Fred Hollyer in 1909. Examining the metadata for the records, it appears that erps28409 was not the original study. In fact, V&amp;A exhibit vaO75248 was created first by Frederick Hollyer in 1886, then later erps28409 was created for exhibition in 1909 by enlarging of a portion of vaO75248. An etching was also produced by Frederick&#8217;s brother Samuel in 1900, which resulted in the Library of Congress record loc92512466.</p>
<p align="left"> <a href="../../wp-content/uploads/2013/09/Brownfig4png.png"><img loading="lazy" alt="Brownfig4png" src="../../wp-content/uploads/2013/09/Brownfig4png-300x239.png" width="300" height="239" /></a></p>
<p align="left">Figure 5: Comparison of results of search for seed record erps28409</p>
<p align="left">What is remarkable about these results is that while the images are patently similar, from a computational perspective the metadata for each is quite different. For example, as human beings we can see that the creator names “Fred. Hollyer,” “Hollyer, Samuel,” and “Hollyer, Frederick” are similar, but as they are not identical in the way they have been expressed, a simple word-by-word comparison would not work. However, it should be noted that these are preliminary results, and confirmation of the efficacy of the proposed approach must await full-scale implementation. Thus far, we have tested a sample of the outcomes on a panel of subject experts, to compare speed and accuracy of co-reference identification between expert human beings and our computer algorithms. The results indicate our new approach is at least as accurate as techniques employed by experienced researchers, historians, and curators, and considerably faster if the offline processing time needed to create the links database is discounted.</p>
<h2>5. Conclusions</h2>
<p align="left">Cultural heritage institutions are beginning to explore the added value of sharing and connecting data. Recent moves towards making GLAMs&#8217; records available in computer readable formats such as XML and JSON and making the collections searchable using REST and SPARQL interfaces go some way towards improving access to collections records, but a major barrier to effective sharing across multiple platforms is the absence of machine-readable text standards that make it easy to automate the process of identifying significant relationships between records. Most of the information in GLAM records is encoded as human-readable text, which is not readily machine-processable, and GLAM semantic Web communities have different terminologies for similar metadata concepts, making implementation of semantic approaches difficult. While linked open data offers a tantalizing glimpse of what the future could contain, the reality is that universally applied and adopted standards are a remote possibility for the foreseeable future. Alternative approaches are needed that can work with the messy characteristics of existing collection records.</p>
<p align="left">This research shows that low-cost, lightweight approaches to co-reference identification may be possible, although further work is required to prove the results beyond a pilot study so far, and refinements would be needed to reduce processing time and extend the approach to other domains. A further problem is variation in the structure and quality of GLAM records. Each contributing institution has its own records management system and distinctive cataloguing style. This has necessitated manual data cleansing and mapping to an appropriate common metadata schema. In order to open this approach more widely to other institutions, ways need to be found to automate these labour-intensive data preparation stages.</p>
<h2>Acknowledgements</h2>
<p>This research is funded by the UK Arts and Humanities Research Council AHRC Research Grant AH/J004367/1. Thanks are due to Birmingham City Library, the British Library, the Louvre, the Metropolitan Museum of Art, Musée d’Orsay, the National Archives, the National Media Museum, National Museums Scotland, St Andrews University, the V&amp;A, and Professor Roger Taylor for their generous support.</p>
<h2>References</h2>
<p align="left">ACRL Research Planning and Review Committee. (2012). “2012 top ten trends in academic libraries.” <i>College &amp; Research Libraries News</i> 73 (6), 311–320. Consulted October 28, 2013. <a href="http://crln.acrl.org/content/73/6/311.full.pdf+html">http://crln.acrl.org/content/73/6/311.full.pdf+html</a></p>
<p align="left">Bizer, C., T. Heath, &amp; T. Berners-Lee, T. (2009). “Linked data &#8211; The story so far.” <i>International Journal on Semantic Web and Information Systems</i> 5 (3), 1-22.</p>
<p align="left">Croft, D., S. Coupland, J. Shell, &amp; S. Brown. (2013) “A fast and efficient semantic short text similarity metric.” In Y. Jin and S. A. Thomas (eds.), <i>Proceedings of the 2013 UK Workshop on </i><i>Computational Intelligence (UKCI 2013</i>). Surrey: University of Surrey. (In press.)</p>
<p align="left">Dhillon, I., J. Kogan, &amp; C. Nicholas. (2003). “Feature selection and document clustering.” In M. Berry (ed.), <i>A Comprehensive Survey of Text Mining</i>. Berlin/Heidelberg: Springer-Verlag, 73-100.</p>
<p align="left">Elmagarmid, A., P. Ipeirotis, &amp; V. Verykios. (2007). “Duplicate record detection: A survey.” <i>IEEE Transactions on Knowledge and Data Engineering</i> 19 (1), 1–16.</p>
<p align="left">Europeana. (2012). <i>Breaking new ground: Europeana annual report and accounts 2011.</i> The Hague: Europeana Foundation. Consulted October 28, 2013. <a href="http://pro.europeana.eu/documents/858566/ade92d1f-e15e-4906-97db-16216f82c8a6">http://pro.europeana.eu/documents/858566/ade92d1f-e15e-4906-97db-16216f82c8a6</a></p>
<p align="left">Feng, J. (2012). “Efficient fuzzy type-ahead search in XML data.” <i>IEEE Transactions on Knowledge and Data Engineering </i>24 (5), 882-895.</p>
<p align="left">Fullan, M., &amp; K. Donnelly. (2013). <i>Alive in the swamp: Assessing digital innovations in education. </i>London: Nesta. Consulted September 5, 2013. <a href="http://www.nesta.org.uk/areas_of_work/public_services_lab/digital_education/assets/features/alive_in_the_swamp_assessing_digital_innovations_in_education">http://www.nesta.org.uk/areas_of_work/public_services_lab/digital_education/assets/features/alive_in_the_swamp_assessing_digital_innovations_in_education</a></p>
<p align="left">Heath, T., &amp; C. Bizer. (2011). “Linked data: Evolving the Web into a global data space.” <i>Synthesis Lectures on the Semantic Web: Theory and Technology</i> 1 (1), 1–136.</p>
<p align="left">Henry, D., &amp; E. Brown, E. (2012). &#8220;Using an RDF data pipeline to implement cross-collection search.&#8221; In D. Bearman and J. Trant (eds.). <i>Museums and the Web 2011: Proceedings</i>. Toronto: Archives &amp; Museum Informatics, 2011. Last updated March 25, 2012. Consulted September 5, 2013. <a href="http://www.museumsandtheweb.com/mw2012/papers/using_an_rdf_data_pipeline_to_implement_cross_.html">http://www.museumsandtheweb.com/mw2012/papers/using_an_rdf_data_pipeline_to_implement_cross_.html</a></p>
<p align="left">IMLS (2006). <i>State of technology and digitization in the nation’s museums and libraries. </i>Washington, DC: The Institute of Museums and Library Services. Consulted October 25, 2013. <a href="http://web.archive.org/web/20060926090433/http:/www.imls.gov/resources/TechDig05/Technology+Digitization.pdf">http://web.archive.org/web/20060926090433/http://www.imls.gov/resources/TechDig05/Technology%2BDigitization.pdf</a></p>
<p align="left">Kelly, K. (2013). <i>Images of works of art in museum collections: The experience of open access &#8211; A study of 11 museums</i>. Washington, DC: The Council on Library and Information Resources. Consulted October 28, 2013. <a href="http://www.clir.org/pubs/reports/pub157/pub157.pdf">http://www.clir.org/pubs/reports/pub157/pub157.pdf</a></p>
<p align="left">Klavans, J., R. Stein, S. Chun, &amp; R. D. Guerra. (2011). &#8220;Computational linguistics in museums: Applications for cultural datasets.&#8221; In J. Trant and D. Bearman (eds.), <i>Museums and the Web 2011: Proceedings</i>. Toronto: Archives &amp; Museum Informatics, 2011. Last updated March 27 2011. Consulted September 5, 2013. <a href="http://conference.archimuse.com/mw2011/papers/computational_linguistics_in_museums">http://conference.archimuse.com/mw2011/papers/computational_linguistics_in_museums</a></p>
<p align="left">Lai, L. F., C. C. Wu, P. Y. Lin, &amp; L. T. Huang. (2011). &#8220;Developing a fuzzy search engine based on fuzzy ontology and semantic search.&#8221; In <i>Proceedings of IEEE International Conference on Fuzzy Systems. </i>Taipei: IEEE, 2684-2689.</p>
<p align="left">Li, F. Z., D. Y. Luo, &amp; D. Xie. (2009). &#8220;Fuzzy search on non-numeric attributes of keyboard query over relational databases.&#8221; In <i>Proceedings of ICCSE ’09. 4th International Conference on Computer Science and Education. </i>Nanning, China: IEEE, 811-814.</p>
<p align="left">Manning, C. D., &amp; H. Schütze. (1999). <i>Foundations of statistical natural language processing</i>. Cambridge, MA: MIT Press.</p>
<p align="left">Oommen, J., L. Baltussen, &amp; M. van Erp. (2012). &#8220;Sharing cultural heritage the linked open data way: Why you should sign up.&#8221; In J. Trant and D. Bearman (eds.), <i>Museums and the Web 2011: Proceedings</i>. Toronto: Archives &amp; Museum Informatics, 2012. Last updated March 25, 2012. Consulted September 5, 2013. <a href="http://www.museumsandtheweb.com/mw2012/papers/sharing_cultural_heritage_the_linked_open_data">http://www.museumsandtheweb.com/mw2012/papers/sharing_cultural_heritage_the_linked_open_data</a></p>
<p>O’Shea, J., Z. Bandar, K. Crockett, &amp; D. Mclean. (2008). “A comparative study of two short text semantic similarity measures.” <i>Lecture Notes in Computer Science,</i> 4953, 172-181.</p>
<p>Stevenson, M., &amp; Y. Wilks. (2003). “Word sense disambiguation.” In R. Mitkov (ed.), <i>The Oxford Handbook of Computational Linguistics. </i>Oxford: Oxford University Press, 249-265.</p>
<p align="left">Tzompanaki, K. (2012). &#8220;A new framework for querying semantic networks.&#8221; In J. Trant and D. Bearman (eds.), <i>Museums and the Web 2011: Proceedings</i>. Toronto: Archives &amp; Museum Informatics, 2012. Last updated March 25, 2012. Consulted September 5, 2013. <a href="http://www.museumsandtheweb.com/mw2012/papers/a_new_framework_for_querying_semantic_networks">http://www.museumsandtheweb.com/mw2012/papers/a_new_framework_for_querying_semantic_networks</a></p>
<p>Voutilainen, A. (2003). “Part-of-speech tagging.” In R. Mitkov (ed.), <i>The Oxford Handbook of Computational Linguistics. </i>Oxford: Oxford University Press, 219-232.</p>
<p align="left">Winkler, W. E. (2006). &#8220;Overview of record linkage and current research directions.&#8221; <i>Research Report Series (Statistics #2006-). </i>Washington, DC: U.S. Census Bureau. Consulted October 28, 2013. <a href="http://www.census.gov/srd/papers/pdf/rrs2006-02.pdf">http://www.census.gov/srd/papers/pdf/rrs2006-02.pdf</a></p>
<p align="left">Xu, J., &amp; W.B. Croft. (1996). “Query expansion using local and global document analysis.” In H.P. Frei, D. Harman, P. Schaubie, and R. Wilkinson (eds.), <i>Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.</i> ACM, 4-11.</p>
<hr>

<script type="text/javascript">
var d=new Date();
var month=new Array();
month[0]="January";
month[1]="February";
month[2]="March";
month[3]="April";
month[4]="May";
month[5]="June";
month[6]="July";
month[7]="August";
month[8]="September";
month[9]="October";
month[10]="November";
month[11]="December";

var day_number=d.getDate();
var month_name=month[d.getMonth()];
var year=d.getFullYear();
var full_date = month_name+" "+day_number+", "+year;
</script>

Cite as:<br /> 

S. Brown, S. Coupland, D. Croft, J. Shell and A. von Lünen, Where Are the Pictures? Linking Photographic Records across Collections Using Fuzzy Logic. In <i></i>, N. Proctor & R. Cherry (eds). Silver Spring, MD: Museums and the Web. Published September 9, 2013. Consulted <script type="text/javascript">document.write(full_date);</script> <!-- April 24, 2022 -->.<br />
https://mwa2013.museumsandtheweb.com/paper/where-are-the-pictures-linking-photographic-records-across-collections-using-fuzzy-logic-2/<br /><br /><hr>
	<div id="comments">
	
	
	
		<div id="respond" class="comment-respond">
		<h3 id="reply-title" class="comment-reply-title">Leave a Reply <small><a rel="nofollow" id="cancel-comment-reply-link" href="index.html#respond" style="display:none;">Cancel reply</a></small></h3><p class="must-log-in">You must be <a href="../../wp-login4edd.html?redirect_to=https%3A%2F%2Fmwa2013.museumsandtheweb.com%2Fpaper%2Fwhere-are-the-pictures-linking-photographic-records-across-collections-using-fuzzy-logic-2%2F">logged in</a> to post a comment.</p>	</div><!-- #respond -->
	
</div><!-- #comments -->
						

</div><!-- #content -->
</div><!-- #primary -->



	</div><!-- #main -->

	<footer id="colophon" role="contentinfo">

			

			<div id="site-generator">
												<a href="https://wordpress.org/" class="imprint" title="Semantic Personal Publishing Platform">
					Proudly powered by WordPress				</a>
			</div>
	</footer><!-- #colophon -->
</div><!-- #page -->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-26332456-1"></script>
<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'UA-26332456-1', {
  		'linker': {
    	'domains': ['museweb.net', 'mwconf.org', 'museumsandtheweb.com']
  }
});
</script>

<script type='text/javascript' src='../../wp-includes/js/comment-reply.min40df.js?ver=5.6' id='comment-reply-js'></script>
<script type='text/javascript' src='../../wp-includes/js/wp-embed.min40df.js?ver=5.6' id='wp-embed-js'></script>

</body>

<!-- Mirrored from mwa2013.museumsandtheweb.com/paper/where-are-the-pictures-linking-photographic-records-across-collections-using-fuzzy-logic-2/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 24 Apr 2022 19:30:56 GMT -->
</html>
