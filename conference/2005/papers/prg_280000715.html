<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><!-- InstanceBegin template="/Templates/mw2005-papers.dwt" codeOutsideHTMLIsLocked="false" --><!-- Mirrored from www.museumsandtheweb.com/mw2005/papers/addis/addis.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 17:39:58 GMT --><head>
<!-- #BeginEditable "HeadPageTitle" -->
    <title>Archives &amp; Museum Informatics: Museums and the Web 2005: Papers: Addis, Martinez, Lewis, Stevenson, Giorgini...Collections over the Web</title><!-- #EndEditable --><!-- #BeginEditable "metaTitle" -->
    <meta name="title" content="Archives &amp; Museum Informatics: Museums and the Web 2005"/><!-- #EndEditable --><!-- #BeginEditable "Keywords" -->
    <meta name="Keywords" content="Semantic Web, 3D models, CIDOC CRM, Search and Retrieval, e-learning, archives &amp; museum informatics, archives, museums, informatics, digital museums, digital archives, digital art, museums online, archives online, libraries online, technology, network, world wide web, www, conferences, professional papers, peer-reviewed, digital libraries, online exhibits, online exhibitions, on-line"/><!-- #EndEditable --><!-- #BeginEditable "Description" -->
    <meta name="Description" content="Museums and the Web 2005: the international conference for culture and heritage on-line"/><!-- #EndEditable --><!-- #BeginEditable "copyright" -->
    <meta name="copyright" content="Archives &amp; Museum Informatics, 2005"/><!-- #EndEditable -->
<meta name="document-class" content="Published"/>
<meta name="document-rating" content="General"/>
<meta http-equiv="Content-Language" content="EN"/>
<meta name="document-rights" content="Copyrighted Work"/>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/>
<link rel="stylesheet" href="../../Library/mw2005.css" type="text/css"/>

</head>

<body onload="initImgRotation()">
<table width="720" border="0" align="center" cellspacing="0">
  <tbody><tr> 
    <td width="126" rowspan="3" class="menuLogo"><div align="center"><a href="../../index.html"><img src="../../images/mw.no.date.jpg" alt="MW2005 Logo" width="112" height="155" border="0" align="middle"/></a>
    </div>
    </td>
    <td width="114" class="menuTop"><a href="../../register/index.html" class="menu">Register</a></td>
    <td width="117" class="menuTop"><a href="../../dates/index.html" class="menu">Key Dates</a></td>
    <td width="114" class="menuTop"><a href="../../sescal/index.html" class="menu">Schedule</a></td>
    <td width="113" class="menuTop"><a href="../../events/index.html" class="menu">Events</a></td>
    <td width="90" class="menuTop"><a href="../../local/index.html" class="menu">Local Info</a></td>
    <td class="menuTop" width="32"> </td>
  </tr>
<tr>
    <td colspan="3" class="pageTitle"><a href="../../../index.html" class="pageTitle">Museums and the Web 2005</a><br/>
      <!-- InstanceBeginEditable name="PageTitle" -->
             <a href="../../speakers/index.html">Papers</a> <!-- InstanceEndEditable -->
	</td>
    <td colspan="3" rowspan="2" align="center" class="imageRotate"> 
	<!-- InstanceBeginEditable name="imageRotate-100x136-nam=img1" --> 
      <a href="#Fig23"><img src="addis.fig23.t.gif" width="136" height="98" border="0" alt="Screen Shot: museum objects"/></a><!-- InstanceEndEditable --></td>
</tr>
  <tr>
    <td colspan="3" class="introParagraph">
	<!-- #BeginEditable "IntroParagraph" -->
                <p class="introParagraph">Reports and analyses from around the world are presented at MW2005.</p><!-- #EndEditable --></td>
  </tr>
  <tr>
	<td align="left" valign="top" class="menuSideStretch">
	<table border="0" align="left" cellpadding="0" cellspacing="0">
<tbody><tr>
<td class="menuSide"> </td>
</tr>
 <tr> 
    <td class="menuSide"> <a href="../../workshops/index.html" class="menu">Workshops</a> </td>
  </tr>
  <tr> 
    <td class="menuSide"> <a href="../../sessions/index.html" class="menu">Sessions</a> </td>
  </tr>
  <tr>
    <td class="menuSide"> <a href="../../speakers/index.html" class="menu">Speakers</a> </td>
  </tr>
  <tr> 
    <td class="menuSide"> <a href="../../interact/index.html" class="menu">Interactions</a> </td>
  </tr>
  <tr> 
    <td class="menuSide"> <a href="../../demos/index.html" class="menu">Demonstrations</a> </td>
  </tr>
  <tr> 
    <td class="menuSide"> <a href="../../exhibit/index.html" class="menu">Exhibits</a> </td>
  </tr>
  <tr>
    <td class="menuSide"><a href="../../best/index.html" class="menu">Best of the Web </a></td>
  </tr>
    <tr>
    <td class="menuSide"> </td>
  </tr>
  <tr>
    <td class="menuSide"> </td>
  </tr>
  <tr>
    <td class="menuSideAMI">produced by
    <a href="../../../index.html"><img src="../../images/nav_ami.gif" alt="Archives &amp; Museum Informatics Wordmark" width="116" height="35" border="0"/></a></td>
  </tr>
  <tr>
    <td class="menuSideAMI"><form method="get" id="searchform" action="http://wp.museumsandtheweb.com/">
<input type="text" class="field" name="s" id="s" placeholder="Search"/>
<input type="submit" class="submit" name="submit" id="searchsubmit" value="Search"/>
</form></td>
  </tr>
  <tr>
    <td class="menuSideAMI"><a href="../../../index.html" class="menuAMI">Join our Mailing List</a><br/>
      <a href="../../../privacy.html" class="menuAMI">Privacy Policy</a> </td> 
  </tr>
    </tbody></table>
    </td>
	<td id="body" rowspan="2" colspan="6">
	<!-- #BeginEditable "BodyText" --> 
      <h1>New Ways to Search, Navigate and Use Multimedia Museum Collections over 
        the Web</h1>
      <h2>Matthew Addis, IT Innovation Centre, Kirk Martinez, Paul Lewis, University 
        of Southampton, James Stevenson, Victoria &amp; Albert Museum, United Kingdom, and Fabrizio 
        Giorgini, Giunti Interactive Labs, Italy</h2>
      <p><a href="http://www.sculpteurweb.org/" target="_blank">http://www.sculpteurweb.org</a></p>
      <h3>Abstract</h3>
      <p id="abstract">Museums and galleries are becoming increasing rich in digital 
        information. This is often created for internal activities such as cataloguing, 
        curation, conservation and restoration, but also has many additional uses 
        including gallery terminals, Web access, educational, scientific, and 
        commercial licensing. New forms of multimedia content such as 3D models 
        and virtual spaces have huge potential for enhancing the way people interact 
        with museum collections; for example, in structured eLearning environments. 
        Despite drivers for increased integration of information sources within 
        the museum or gallery, and for improved Web accessibility for external 
        users, this content is often hard to access and is held in multiple internal 
        systems with non-standard schemas and descriptions. Providing information 
        to external users or applications in a structured and machine-readable 
        form is particularly difficult due to a lack of tools and standards. This 
        makes it difficult to expose this rich source of information so it can 
        be used over the Web in external applications. Over the past three years, 
        the European Commission IST supported SCULPTEUR project has been addressing 
        these problems by developing new ways to create, search, navigate, access, 
        share, repurpose and use multimedia content over the Web for professional 
        users. This paper describes the tools and techniques developed in the 
        project.</p>
      <p id="keywords">Keywords: Semantic Web, 3D models, CIDOC CRM, Search and 
        Retrieval, eLearning.</p>
      <h1>Introduction</h1>
      <p>Museums and galleries are becoming increasingly rich in multimedia representations 
        of works of art such as 2D images or 3D models. It is not uncommon for 
        large museums and galleries to have tens or hundreds of thousands of digital 
        images of works of art in their possession.</p>
      <p>The use of digital photography to create high resolution and colour accurate 
        representations is now well established and is within the reach of even 
        modestly sized organizations. A similar effect will follow for new forms 
        of multimedia content, for example 3D models and interactive virtual environment, 
        which in turn swell and diversify museum multimedia collections.</p>
      <p>Applications include collection management, cataloguing, conservation 
        and restoration, commercial picture sales, public access material for 
        gallery terminals and Web sites, promotion and marketing, and sales and 
        acquisitions, to name but a few. Each application has its own requirements 
        for content type and quality, and often this gives rise to multiple systems 
        and processes within an organization. When there is a need to source content 
        from across these systems, then typically the approach is ad hoc and requires 
        &#39;cut and paste&#39; between the user interfaces of the multiple software systems 
        involved.</p>
      <p>This problem is not restricted to internal use of digital content. The 
        recent drive towards increased Web accessibility and openness for cultural 
        heritage organizations now means that there are high-value uses for digital 
        content in public access, education and research.</p>
      <p>As a result, it can be frustrating that this content is &#39;locked away&#39; 
        in internal legacy systems with non-standard schemas and descriptions, 
        and also requires aggregation and repurposing to transform it into the 
        right form for external consumption.</p>
      <p>Even for digital content that is created directly for use by third parties, 
        there is still a lack of standards and infrastructure to make it available 
        in a uniform way that allows the content to be easily used and understood, 
        especially in conjunction with other information sources.</p>
      <p>In summary, museums and galleries are faced with a wealth of new opportunities 
        to create and deliver exciting new forms of digital content, both for 
        internal use and for remote use over the Web. However, this is a double-edged 
        sword. Significant technological barriers exist due to immaturity of the 
        technology, lack of standards and best practice, and difficulties in combining 
        information from multiple sources, whether they be within a single museum 
        or distributed across the Web.</p>
      <p>Over the past three years, the European Commission IST Sculpteur project 
        (<a href="http://www.sculpteurweb.org/" target="_blank">http://www.sculpteurweb.org</a>) 
        has been addressing these problems by developing new ways to create, search, 
        navigate, access, share, repurpose and use multimedia content from multiple 
        sources over the Web.</p>
      <p>In particular, the project has four focus areas:</p>
      <ul>
        <li>Creating new 3D digital content based on photographic image capture 
          techniques that don&#39;t require expensive equipment and specialist skills.</li>
        <li>Developing new modes of information retrieval and collection exploration 
          by combining Semantic Web and content-analysis techniques (Addis, 2003) 
          to allow searching by concept, metadata and content.</li>
        <li>Designing automatic aids to cluster and classify 3D content to enhance 
          search and retrieval, help the labeling of new items added to a collection, 
          and explore what objects have similar 3D properties.</li>
        <li>Developing software and tools for accessing and repurposing digital 
          content over the Web.</li>
      </ul>
      <p>This paper focuses on the aspects related to the search and navigation 
        of multimedia museum collections over the Web.</p>
      <p>Sculpteur involves five major museums and galleries: the Uffizi in Florence; 
        the National Gallery and the Victoria and Albert Museum in London; the 
        Musee de Cherbourg and the Centre de Recherche et de Restauration des 
        Musees de France (C2RMF).</p>
      <p>These galleries have substantial digital archives comprising images, 
        3D models and videos together with textual information and metadata.</p>
      <p>Figure 1 shows our overall approach in terms of the system we have built 
        to allow their internal staff and external professional users to gain 
        access to the multimedia museum information they possess.</p>
      <p class="caption"><a name="Fig1" id="Fig1"></a><a href="addis.fig1.html"><img src="addis.fig1.400.gif" width="400" height="246" border="0" alt="Screen Shot: Sculpteur architecture"/></a></p>
      <p class="caption">Figure 1: Sculpteur architecture</p>
      <p>The main input is content extracted from existing museum and gallery 
        systems; for example collection management databases, photo catalogues, 
        document repositories and stores of 3D models.</p>
      <p>We index this collection according to the multimedia content (for example, 
        the colour of 2D images and the shape of 3D models) as well as the textual 
        descriptions extracted from the museum and gallery legacy systems. At 
        this stage the classification techniques are used to automatically associate 
        3D models with different classifications of art objects.</p>
      <p>We structure the textual descriptions, 3D models, 2D images, content 
        indexes and the classified models using an ontology, in particular an 
        ontology based on the CIDOC Conceptual Reference Model (<a href="http://cidoc.ics.forth.gr/" target="_blank">http://cidoc.ics.forth.gr/</a>).</p>
      <p>Next, the ontology is published on the Web in an XML form to describe 
        the collection, which, along with a search and retrieval service based 
        on Z39.50 SRW (<a href="http://www.loc.gov/z3950/agency/zing/srw/" target="_blank">http://www.loc.gov/z3950/agency/zing/srw/</a>), 
        allows remote applications to access the multimedia content.</p>
      <p>A range of Web interfaces for navigation and search and retrieval are 
        built on top of this interface. These include a graphical ontology browser 
        so that users unfamiliar with museum collections can understand and explore 
        the rich cultural heritage information space.</p>
      <p>Giunti Interactive Labs have used the SRW to integrate their Learning 
        Content Management System, Learn eXact (<a href="http://www.learnexact.com/" target="_blank">http://www.learnexact.com/</a>). 
        Motivated by the recent increased interest by cultural institutions in 
        reusable multimedia components for learning (called Cultural Learning 
        Objects, CLO) and on-line learning contents delivery and management, the 
        result is a content authoring tool able to remotely create and manage 
        3D virtual learning environments.</p>
      <p>The rest of this paper covers the themes of Sculpteur in more detail, 
        in particular focusing on the challenges we have faced and the solutions 
        we have developed.</p>
      <h1>Searching and Navigating Multimedia Collections</h1>
      <h2>Modes of Searching</h2>
      <p>Text based searching using Web forms and &#39;google&#39; type interfaces is 
        a familiar way for many to search large digital collections. Simple substring 
        searching works well when significant amounts of free text are present, 
        often the case with descriptive metadata for museum and gallery objects.</p>
      <p>Sculpteur supports text-based searching by allowing the user to search 
        against one or more text attributes in the collection. The user can look 
        for strings within free text fields, choose from items in controlled vocabularies, 
        and combine several search attributes together using logical operators. 
        In this way it is easy to specify queries such as &#34;find all works 
        of art painted by Van Gogh using oil where the title contains the word 
        &#39;sunflowers&#39;&#34; (although the query isn&#39;t physically entered in this 
        free text form). This is of course fairly standard stuff when it comes 
        to museum information systems and Web sites.</p>
      <p>However, there are cases where new search modalities can greatly improve 
        the results of searching, especially for large collections.</p>
      <p>In Sculpteur, we provide two additional ways of searching and exploring 
        a collection: by <strong>concept</strong> and by <strong>content.</strong></p>
      <h3>Concept Based Searching And Navigation</h3>
      <p>Searching by concept provides the user with a high-level way to explore 
        a collection by abstracting the relatively low-level text attributes found 
        in many legacy systems. The use of an ontology allows text attributes 
        can be grouped together according to common semantics; for example according 
        to the concepts of people (e.g. artist, curator, owner, restorer), art 
        objects and representations (e.g. painting, sculptures, films, digital 
        representations), events and activities (e.g. creation, acquisition, restoration, 
        loan, birth, death, period), places (e.g. gallery, conservation centre, 
        country, city, town, studio), and methods and techniques (e.g. oil, watercolour, 
        carving, x-ray, restoration technique). These concepts are linked together 
        by relationships specified in the ontology, and in our case we adopt the 
        CIDOC Conceptual Reference Model (CRM). For example, the ontology specifies 
        that objects are created during production events in which various people 
        participate in different roles.</p>
      <p class="caption"><a name="Fig2" id="Fig2"></a><a href="addis.fig2.html"><img src="addis.fig2.400.gif" width="400" height="277" border="0" alt="Screen Shot: General structure of the CRM"/></a></p>
      <p class="caption">Figure 2: General structure of the CRM showing the high 
        level relationships between people and groups (actors), object (physical 
        stuff), places and events (temporal activities).</p>
      <p>The ability to search and navigate by concept provides several benefits. 
        For example, a user can make complex queries such as &#39;find me works of 
        art that were painted by, depict, or were owned by Van Gogh&#39; instead of 
        having to manually combine the results of several separate queries against 
        &#39;author&#39;, &#39;subject&#39; and &#39;owner&#39; fields. If a search provides too few (or 
        too many) results, then the user can generalize (or specialize) their 
        query to get a better match. For example, if searching for something specific 
        like a &#39;teapot&#39; does not yield enough results, then the query can be generalized 
        to &#39;vessels&#39;, which will retrieve &#39;pots&#39;, &#39;vases&#39;, &#39;urns&#39; etc. as well. 
        The use of an ontology that makes the relationships between concepts explicit 
        also allows different explorative paths to be taken through the collection. 
        For example, the user might be interested in the relationship between 
        &#39;style&#39;, &#39;artist&#39; and &#39;materials&#39; for a set of paintings and would want 
        to explore which artists adopted which styles and what materials they 
        used to do so. This &#39;slice and dice&#39; approach to exploring information 
        is not easily supported using legacy systems. </p>
      <p>In Sculpteur, the ontology can be graphically visualized using a Concept 
        Browser that implements a graph-based approach. Due to the complexity 
        of the full CRM, this view is generally hidden from the user. Instead, 
        a simplification of the ontology is displayed that will show only the 
        concepts and relations that are present in the museum metadata structure. 
        These concepts and relations are further refined and simplified, in some 
        cases using terms from the original metadata schema to increase familiarity 
        of the users with the interface.</p>
      <p>The choice not to display the CRM was a result of several trials involving 
        the museum and gallery partners in the project that evaluated several 
        user interface approaches. The terminology and complexity of the CRM proved 
        to be too challenging to visualize in an intuitive way; hence we adopted 
        a simplification strategy with much better results.</p>
      <p>The ability to overlay a simplified and personalized view on top of the 
        CRM is also a potentially powerful way to enable cross-collection searching 
        since it allows the user of one collection to visualize the contents of 
        someone else&#39;s collection in their own context by using the CRM as an 
        underlying (and hidden) interlingua.</p>
      <p class="caption"><a name="Fig3" id="Fig3"></a><a href="addis.fig3.html"><img src="addis.fig3.400.gif" width="400" height="212" border="0" alt="Screen Shot: Graphical visualisation of the ontology"/></a></p>
      <p class="caption">Figure 3: Graphical visualisation of the ontology</p>
      <p>An important aspect of ontological visualization tools is querying for 
        instances of concepts. Although the visualization of instance information 
        within a graph based interface has been investigated before, for example 
        Fenfire (<a href="http://www.nongnu.org/fenfire/" target="_blank">http://www.nongnu.org/fenfire/</a>) 
        and IsaViz (<a href="http://www.w3.org/2001/11/IsaViz" target="_blank">http://www.w3.org/2001/11/IsaViz</a>), 
        trying to display even a subset of large museum collections in a graph-based 
        visualization results in a confusing and messy display for the user.</p>
      <p>Instead, we base instance visualization and querying on mSpace interfaces 
        (<a href="http://mspace.ecs.soton.ac.uk/" target="_blank">http://mspace.ecs.soton.ac.uk</a>, 
        McGuffin 2004). mSpace is an interaction model designed to allow a user 
        to navigate in a meaningful manner the multi-dimensional space that an 
        ontology can provide.</p>
      <p>Our mSpace interface uses a multipanel display, where &#39;slices&#39; through 
        the ontology are presented as columns arranged from left to right. Selection 
        in a slice will update the display so that the values displayed in the 
        next slice (i.e. to the right of the current slice) are related to that 
        value. For example, if there is a slice of artists and the next slice 
        is painting titles, then selecting an artist will display only that artist&#39;s 
        paintings in the titles slice. When an item is chosen in a slice, details 
        about that item are displayed in a detail panel. Slices can be freely 
        interchanged or removed, and new slices can be added to the mSpace.</p>
      <p>The ontology simplification interface, based on TouchGraph (<a href="http://www.touchgraph.com/" target="_blank">http://www.touchgraph.com</a>), 
        allows users to browse and add the slices in which they are interested 
        into the mSpace browser, where they can be arranged to suit the user&#39;s 
        preference. A preview panel displays the current slice arrangement. Predefined 
        groups of slices can be selected, and users are able to save and load 
        their own arrangements.</p>
      <p class="caption"><a name="Fig4" id="Fig4"></a><a href="addis.fig4.html"><img src="addis.fig4.400.gif" width="400" height="162" border="0" alt="Screen Shot: Example use of the mSpaces browser"/></a></p>
      <p class="caption">Figure 4: Example use of the mSpaces browser showing 
        the places in which works of art were created for particular materials 
        and technique.</p>
      <h3>Content Based Searching</h3>
      <p>Searching by content allows the user to query and compare different aspects 
        of 2D images and 3D models. For example, a user can find images that have 
        a pattern or colour similar to an image that they supply, or they can 
        find other objects in a collection that have a similar shape to a 3D model 
        that they have already found.</p>
      <p>More specialized search capabilities are also available; for example, 
        allowing users to search for paintings with a particular type of craquellure 
        identified according to image-based analysis of the pattern of cracks 
        in the painting surface. Another example is finding high quality colour 
        images based on low quality black and white images, in particular photocopies 
        and faxes, useful for museums that provide identification or picture services. 
        Further details of our image-based searching can be found in (Addis, 2002; 
        Lewis, 2004).</p>
      <p>For a 3D content-based retrieval, in addition to simple searches according 
        to various 3D shape descriptors (for example, Zhang, 2001), we are developing 
        some specific 3D searching applications. These include a way to compare 
        figurines with the moulds from which they were produced. This is an interesting 
        problem that highlights some of the benefits and challenges of content 
        based searching. When clay figurines are created from a mould (which is 
        often in several pieces itself) and are then fired in a kiln, the figurine 
        will often shrink and distort. Second generation moulds are sometimes 
        made from such figurines, and these moulds used to make further figurines. 
        Over time, the moulds and figurines are dispersed and often find their 
        way into different museums. The challenge is to match them again, an ideal 
        application for 3D content analysis.</p>
      <p>Whilst content, concept and text based queries each have their individual 
        merits, querying by any one aspect in isolation can still result in too 
        many hits when large collections are being searched.</p>
      <p>However, when these search modalities are combined, new user search scenarios 
        can be supported and much better results are achieved. For example, a 
        user might search for items of furniture that have upholstery of a particular 
        colour or texture, or search for religious oil paintings that used a pigment 
        of a particular shade of blue; for example, to study the transition from 
        lapis to artificial aquamarine pigment.</p>
      <p>See the example in Figure 5, where a user selects a colour with a picker 
        tool and also enters a keyword in a text form. The results of the search 
        are shown in Figure 6 which present thumbnails of the matching objects 
        in the collection (the V&amp;A in this case).</p>
      <p class="caption"><a name="Fig5" id="Fig5"></a><a href="addis.fig5.html"><img src="addis.fig5.400.gif" width="400" height="313" border="0" alt="Screen Shot: Specifying a combined content and text query"/></a></p>
      <p class="caption">Figure 5: Specifying a combined content and text query 
        using the colour picker and text form</p>
      <p class="Para c2">Specification of a combined content and text based query 
        to find &#39;red chairs&#39; in the Victoria and Albert Museum.</p>
      <p class="caption"><a name="Fig6" id="Fig6"></a><a href="addis.fig6.html"><img src="addis.fig6.400.gif" width="400" height="279" border="0" alt="Screen Shot: Results of the combined content and text query"/></a></p>
      <p class="caption">Figure 6: Results of the combined content and text query 
        as specified in Figure 5</p>
      <p>An example of a 3D query is shown in Figure 7. The user uploads a VRML 
        model of an object to be used as the basis of finding other objects in 
        the collection with a similar shape. The first three results of the query 
        are shown in Figure 8. The objects found clearly have a similar 3D shape, 
        but also note that they have different textual descriptions (sugar shaker, 
        ceramic object etc.). Text based searching in isolation would have proved 
        difficult since a large variety of objects would need to be included in 
        order to cover all the items likely to have a similar shape. The user 
        would then have to manually sort through a large number of results.</p>
      <p class="caption"><a name="Fig7" id="Fig7"></a><a href="addis.fig7.html"><img src="addis.fig7.400.gif" width="400" height="263" border="0" alt="Screen Shot: 3D content-based query"/></a></p>
      <p class="caption">Figure 7: Specification of a 3D content-based query whereby 
        the user supplies a 3D model that they want to use to find similar objects 
        in the collection.</p>
      <p class="caption"><a name="Fig8" id="Fig8"></a><a href="addis.fig8.html"><img src="addis.fig8.400.gif" width="400" height="344" border="0" alt="Screen Shot: Results of 3D content-based query"/></a></p>
      <p class="caption">Figure 8: Results of 3D content-based query as specified 
        in Figure 7. Results are in order of similarity to the query 3D model.</p>
      <h1>Clustering and Classification of Museum Objects Using Shape</h1>
      <p>In Sculpteur, the combination of content semantics (colour, pattern, 
        shape) and application semantics (who, what, where, when etc.) also forms 
        the basis of a classifier whereby multimedia can be analyzed to classify 
        the art object represented according to art domain semantics.</p>
      <p>For example, flat round objects which are gold/silver/bronze in colour 
        might be automatically classified as coins, medals or metal plates. Likewise, 
        an oil painting with surface relief of a spider web type pattern might 
        be classified in terms of severity of craquellure and need for restoration.</p>
      <p>In Sculpteur we use a classifier agent that has both k-Means and k-NN 
        classifiers available. The classifier agent is supplied with a dataset 
        based on 3D models held by the museum partner. The user is able to choose 
        the parameters for the classifier and train it against the data set supplied. 
        The classifier is then used to label new objects supplied by the user, 
        and graphically inspect the clusters containing the other models with 
        the same label.</p>
      <p>The ability of the classifier to cluster objects of a similar shape can 
        also be used to inspect groups of objects that share a similar trait. 
        This is useful when the user wants to explore how a particular style (e.g. 
        amphora style of Grecian urn) has been implemented across a range of periods, 
        geographical locations, materials and artists.</p>
      <p class="caption"><a name="Fig9" id="Fig9"></a><a href="addis.fig9.html"><img src="addis.fig9.400.gif" width="400" height="348" border="0" alt="Screen Shot: Classification of objects"/></a></p>
      <p class="caption">Figure 9: Classification of objects in a collection</p>
      <h1>Web Interface</h1>
      <p>The Concept Browser, mSpaces values explorer, and content-based searching 
        interfaces described above are part of an integrated Web interface. A 
        series of interlinked pages allow the user to move back and forth between 
        these different aspects of searching. For example, the results of content-based 
        searches can be transferred to the Concept Browser interface, allowing 
        users to perform mSpace queries with the content query results.</p>
      <p>The target users are museum professionals or similar &#39;power users&#39; who 
        require advanced searching and exploration tools. The user interface is 
        not intended for general-purpose public access, e.g. on a Museum Web site 
        or inside a gallery terminal.</p>
      <p>In addition to integrated and multimodal searching, several supporting 
        tools are available to help the professional user in using the system. 
        These include:</p>
	  <p class="list"></p>
      <ul>
        <li>Attribute Map for graphically showing the metadata attributes their 
          interrelationships.</li>
        <li>Colour Picker for selecting one or more colours and using these for 
          a 2D content-based search.</li>
        <li>Lightbox for storing individual search results and then using these 
          in new queries.</li>
        <li>Image cropper for cropping 2D images if necessary before executing 
          a content query.</li>
        <li>Query Basket to summarize all the current components of a query.</li>
        <li>Results overview page of each matching result to a query, including 
          a thumbnail, can be viewed on a results page.</li>
        <li>Query History to allow previous queries to be examined and the results 
          inspected again at a later date.</li>
        <li>The user login, personal history/lightbox and preferences.</li>
      </ul>
	  
	  <p>The rest of this section presents a series of screen shots of a typical 
        exploration and querying activity by a user (based on a collection of 
        objects from the V&amp;A).</p>
      <p class="caption"><a name="Fig10" id="Fig10"></a><a href="addis.fig10.html"><img src="addis.fig10.400.gif" width="400" height="259" border="0" alt="Screen Shot: CRM ontology"/></a></p>
      <p class="caption">Figure 10: The user graphically inspects the CRM ontology</p>
      <p class="caption"><a name="Fig11" id="Fig11"></a><a href="addis.fig11.html"><img src="addis.fig11.400.gif" width="400" height="254" border="0" alt="Screen Shot: museum schema"/></a></p>
      <p class="caption">Figure 11: The user graphical inspects the museum schema</p>
      <p class="caption"><a name="Fig12" id="Fig12"></a><a href="addis.fig12.html"><img src="addis.fig12.400.gif" width="400" height="138" border="0" alt="Screen Shot: mSpaces viewer"/></a></p>
      <p class="caption">Figure 12: The user uses the mSpaces viewer to explore 
        the instances for art object types, their techniques, and the materials 
        used in their construction.</p>
      <p class="caption"><a name="Fig13" id="Fig13"></a><a href="addis.fig13.html"><img src="addis.fig13.400.gif" width="400" height="407" border="0" alt="Screen Shot: alternative visualization"/></a></p>
      <p class="caption">Figure 13: The user switches to the attribute map showing 
        alternative visualization of museum schema. They select &#39;short caption 
        = vase&#39; as basis of a search.</p>
      <p class="caption"><a name="Fig14" id="Fig14"></a><a href="addis.fig14.html"><img src="addis.fig14.400.gif" width="400" height="355" border="0" alt="Screen Shot: text-based search for vases"/></a></p>
      <p class="caption">Figure 14: Overview page of the results of a text-based 
        search for vases as specified in Figure 13</p>
      <p class="caption"><a name="Fig15" id="Fig15"></a><a href="addis.fig15.html"><img src="addis.fig15.400.gif" width="400" height="299" border="0" alt="Screen Shot: Lightbox"/></a></p>
      <p class="caption">Figure 15: Lightbox showing objects of interest stored 
        by the user from several queries. Objects can be used as the basis of 
        new queries. Note yellow vase from results in Figure 14.</p>
      <p class="caption"><a name="Fig16" id="Fig16"></a><a href="addis.fig16.html"><img src="addis.fig16.400.gif" width="400" height="325" border="0" alt="Screen Shot: results of serach for vase"/></a></p>
      <p class="caption">Figure 16: Overview of the results of a search for vases 
        of a similar colour to the selected vase (inset).</p>
      <p class="caption"><a name="Fig17" id="Fig17"></a><a href="addis.fig17.html"><img src="addis.fig17.400.gif" width="400" height="372" border="0" alt="Screen Shot: results for &#39;three graces&#39;"/></a></p>
      <p class="caption">Figure 17: Results of another query for the &#39;three graces&#39; 
        showing different views available for the art object along with the detailed 
        textual description and a full resolution image of one of the views (inset).</p>
      <h1>CRM Mapping</h1>
      <p>Each museum and gallery has mapped the information in their legacy systems 
        to the CRM in order to fully benefit from Sculpteur (the system can be 
        used without any mappings, or with other mappings such as Dublin Core).</p>
      <p>A graphical representation of this mapping process is shown in Figure 
        18 along with the resultant text mappings in Figure 19.</p>
      <p class="caption"><a name="Fig18" id="Fig18"></a><a href="addis.fig18.html"><img src="addis.fig18.400.gif" width="400" height="234" border="0" alt="Screen Shot: CRM mapping process"/></a></p>
      <p class="caption">Figure 18: Graphical representation of the CRM mapping 
        process. The attributes in a record held in a legacy system that describes 
        an art object are mapped to the corresponding entities in the CRM.</p>
      <p class="caption"><a name="Fig19" id="Fig19"></a><a href="addis.fig19.html"><img src="addis.fig19.400.gif" width="400" height="176" border="0" alt="Screen Shot: Detailed mappings"/></a></p>
      <p class="caption">Figure 19: Detailed mappings that show how each attribute 
        in the legacy data corresponds to a &#39;path&#39; through the CRM.</p>
      <p>In Sculpteur, we found that ontology mapping requires close collaboration 
        between computer scientists who understand ontologies and knowledge engineering 
        in the context of the Sculpteur software system, museum professionals 
        who understand the legacy data and the cultural heritage domain, and external 
        experts who understand the CRM, its origins and how to use it. Collaboration 
        among these parties is time and effort consuming, but is also essential 
        to achieve accurate and meaningful mapping of each user&#39;s legacy data 
        to the CRM framework.</p>
      <p>Once the mapping has been completed and the corresponding legacy dataset 
        identified, work still needs to be done to export the data from museum 
        and gallery legacy systems so it can be imported into Sculpteur. This 
        in itself presents issues due to the different staff involved at the user 
        site or service provider and the need for suitable formats and transfer 
        mechanisms.</p>
      <p>Population of Sculpteur with this metadata from legacy systems is heavily 
        dependent on the structure and semantics of the user&#39;s metadata, which 
        are not always explicit in the legacy data structure. As a result, further 
        manual steps ensure the data imported into Sculpteur matches the semantics 
        of the mappings.</p>
      <p>We found that there is a balance between level of interoperability desired 
        and the effort needed to use the CRM. Currently, due to lack of CRM tool 
        support and examples and processes to follow, the effort is significant.</p>
      <p>On the other hand, the benefits of using the CRM are clear, and the level 
        of interoperability and cross-collection searching that can be achieved 
        both &#39;in house&#39; and with external systems goes far beyond what can be 
        done with simpler approaches such as Dublin Core.</p>
      <p>We also anticipate the CRM gaining adoption, especially now that it has 
        been submitted as an ISO standard and real examples of its use start to 
        appear. Therefore, methodologies, tools and examples become more prevalent, 
        and the barriers will come down.</p>
      <p class="MsoBodyText">In effect, Sculpteur has been one of several &#39;frontier&#39; 
        efforts that we believe will help ease the life of the &#39;settlers&#39; that 
        follow.</p>
      <h1>Interoperability and Remote Access over the Web</h1>
      <p>One of the main benefits of mapping to a common ontology is to achieve 
        interoperability and cross-collection searching, both within a set of 
        legacy systems installed at a museum or gallery site, and between separate 
        museums over the Web.</p>
      <p>However, there is more to interoperability than mapping to a shared ontology, 
        especially if the objective is to provide remote access to museum information.</p>
      <p>Sculpteur takes a layered approach to interoperability based on a series 
        of Web and cultural heritage domain standards.</p>
      <p>The &#39;nuts and bolts&#39; of interoperability are provided by XML as a syntax 
        to structure information, Web Service standards to physically allow exchange 
        of this information over the Internet, SRW (<a href="http://www.loc.gov/z3950/agency/zing/srw/" target="_blank">http://www.loc.gov/z3950/agency/zing/srw/</a>) 
        to provide a protocol that allows one party to request information from 
        another party, and CQL (<a href="http://www.loc.gov/z3950/agency/zing/cql/">http://www.loc.gov/z3950/agency/zing/cql/</a>) 
        to act as a query language to express what information is desired.</p>
      <p>These &#39;nuts and bolts&#39; allow the syntactic exchange of information and 
        do not say anything about the meaning of this information, i.e. the semantics. 
        This is fine if the only use of the information is &#39;one collection at 
        a time&#39; by people who can read additional user manuals and descriptions 
        of the semantics of the specific service and data they are using.</p>
      <p>However, this does not work if software systems need to communicate with 
        each other to use the information; for example, an eLearning tool that 
        sources content from a remote museum, or a search engine that can search 
        across and combine content from more than one source. These applications 
        need the semantics to be made explicit.</p>
      <p>This is the next level up. The data semantics need to be made explicit 
        both in terms of structure (what each field or attribute means) and content 
        (what controlled vocabularies and languages are involved). Finally, the 
        supported search capabilities need to be described so that a remote system 
        knows what parts of the collection can be queried and in what way.</p>
      <p>The interoperability &#39;stack&#39; that we adopt is shown in Figure 20.</p>
      <p class="caption"><a name="Fig20" id="Fig20"></a><a href="addis.fig20.html"><img src="addis.fig20.gif" width="400" height="323" border="0" alt="Screen Shot: Sculpteur interoperability stack"/></a></p>
      <p class="caption">Figure 20: Sculpteur interoperability stack</p>
      <p>In Sculpteur we have implement this stack based around an extended version 
        of the SRW 1.1 standard (Addis, 2004).</p>
      <p>The CRM domain ontology is expressed in a standard ontology language, 
        RDF (<a href="http://www.w3.org/RDF/" target="_blank">http://www.w3.org/RDF/</a>), 
        and is made available for download. The mappings of the legacy systems 
        to the CRM are published as an XML structure, available through the SRW 
        &#39;explain&#39; operation. The SRW is able to dynamically map CQL queries expressed 
        in terms of these CRM mappings to the relevant legacy database fields, 
        execute a combined metadata and content search, and then return the results 
        as XML structured according to the CRM mappings. The user can explore 
        the CRM ontology and then use the SRW to retrieve corresponding instances. 
        These instances can then be displayed to the user, for example as slices 
        in the mSpace viewer.</p>
      <p>By using the CRM mappings and the common CRM ontology, a common result 
        schema is achieved and cross-collection searching can be done across multiple 
        art object collections.</p>
      <p>In this way we leverage Semantic Web (<a href="http://www.semanticweb.org/" target="_blank">http://www.semanticweb.org</a>) 
        techniques to describe and visualize the complex space of cultural heritage 
        information, whilst using XML and Web Service standards to provide an 
        easy to use search and retrieval service to access this information.</p>
      <h1>eLearning</h1>
      <p>Giunti Interactive Labs have used the SRW interface to integrate their 
        Learning Content Management System, Learn eXact. The e-learning system 
        can search and import 2D and 3D images and related metadata from remote 
        collections and use them to build new cultural learning objects.</p>
      <p>These learning objects include virtual museums and galleries which offer 
        an interactive learning experience following e-learning standards like 
        IEEE LOM, IMS Content Package and ADL SCORM. Functionality includes evaluation 
        of sessions (based on the IMS QTI specifications) and tracking of end-user 
        actions based on the ADL SCORM specification.</p>
      <p class="caption"><a name="Fig21" id="Fig21"></a><a href="addis.fig21.html"><img src="addis.fig21.400.gif" width="400" height="260" border="0" alt="Screen Shot: The Learn eXact tool"/></a></p>
      <p class="caption">Figure 21: The Learn eXact tool can be used to access 
        the Sculpteur SRW and display the results of query.</p>
      <p class="caption"><a name="Fig22" id="Fig22"></a><a href="addis.fig22.html"><img src="addis.fig22.400.gif" width="400" height="336" border="0" alt="Screen Shot: Full details"/></a></p>
      <p class="caption">Figure 22: Full details are available on each museum 
        object retrieved from Sculpteur.</p>
      <p class="caption"><a name="Fig23" id="Fig23"></a><a href="addis.fig23.html"><img src="addis.fig23.400.gif" width="400" height="289" border="0" alt="Screen Shot: museum objects"/></a></p>
      <p class="caption">Figure 23: Museum objects are then placed in a virtual 
        environment and associated with other learning resources such as documents 
        to provide a structured learning experience.</p>
      <h1>Conclusions</h1>
      <p>This paper has presented our approach to search, retrieval, navigation 
        and interoperability of multimedia museum collections over the Web.</p>
      <p>Mapping of museum legacy information to the CRM ontology is our bedrock, 
        and around this are built advanced search modalities, innovative navigation 
        and exploration tools, and the ability to provide access to this functionality 
        to remote applications over the Web.</p>
      <p>Sculpteur has needed to overcome significant technological barriers to 
        make this possible, and the investment needed by museums and galleries 
        to fully benefit from our approach should not be underestimated.</p>
      <p>The benefits are significant and include integrated and powerful access 
        to multimedia museum information as well as the ability to deliver this 
        capability to remote users and collaborating organizations.</p>
      <h1>References</h1>
      <p class="references">Zhang, C. and T. Chen, T. (2001). &#34;Efficient 
        Feature Extraction for 2D/3D Objects in Mesh Representation&#34;, ICIP 
        2001, 935-938, 2001, Thessaloniki, Greece.</p>
      <p class="references">Addis, M., M. Boniface, S. Goodall, P. Grimwood, 
        S. Kim, P. Lewis, K. Martinez,. and A. Stevenson (2003). SCULPTEUR: Towards 
        a New Paradigm for Multimedia Museum Information Handling. In Proceedings 
        of Semantic Web ISWC 2870, pages 582 -596.</p>
      <p class="references">Addis, M., P. Lewis, and K. Martinez (2002). ARTISTE 
        image retrieval system puts European galleries in the picture. Cultivate 
        Interactive.</p>
      <p class="references">Lewis, P. H., K. Martinez, F.S. Abas, , M.F. Ahmad 
        Fauzi, , M. Addis, C. Lahanier,, J. Stevenson, S.C.Y. Chan, J.B. Mike, 
        and G. Paul (2004). An Integrated Content and Metadata based Retrieval 
        System for Art. <em>IEEE Transactions on Image Processing</em> 13(3):pp. 
        302-313.</p>
      <p class="references">McGuffin, M. J. and M.C. Schraefel (2004). A Comparison 
        of Hyperstructures: Zzstructures, mSpaces, and Polyarchies. In Proceedings 
        of ACM Conference on Hypertext and Hypermedia, 2004 (in press), pages 
        pp. 153-162, Santa Cruz, California, USA.</p>
      <h4>Acknowledgements</h4>
      <p class="AcknowedgementsText">The authors wish to thank the European Commission 
        for support through the SCULPTEUR project under grant IST-2001-35372. 
        We would also like to thank our collaborators on the project, including 
        Francis Schmitt and Tony Tung of ENST, Paris, Christian Lahanier of C2RMF, 
        James Stevenson and Rachel Coates of the V&amp;A museum, Joseph Padfield 
        of the National Gallery, Raffaela Rimaboschi of the Uffizi and Jean-Pierre 
        of the Musee de Cherbourg for many useful discussions, use of data and 
        valuable help and advice; Patrick Sinclair and Simon Goodall from IAM 
        and Adrian Pillinger and Dan Prideaux from IT Innovation for their intellectual 
        contributions and development of the Sculpteur system. M. Chapman, P. Dibdin, 
        A. Pillinger, R. Sadotra, S. Samangooei, A. Smithson and T. Wirdyanto who, 
        as Master of Engineering students, contributed to the development of SCULPTEUR 
        prototypes; Patrick Le Boeuf of the Biblioteheque Nationale de France 
        for assistance with mapping to the CRM; TouchGraph (<a href="http://www.touchgraph.com/" target="_blank">http://www.touchgraph.com</a>) 
        for software used in the concept browser; and Hewlett Packard&#39;s Art &amp; 
        Science programme for the donation of server equipment.</p>
      <!-- #EndEditable -->
	<h4>Cite as:</h4>
	<p class="references"><!-- InstanceBeginEditable name="OnlineCitation" -->Addis et al., New Ways to Search, Navigate and Use Multimedia Museum Collections over 
        the Web<!-- InstanceEndEditable -->, 
	in J. Trant and D. Bearman (eds.).<em> Museums and the Web 2005: Proceedings</em>, Toronto: Archives &amp; Museum Informatics, published March 31, 2005 at http://www.archimuse.com/mw2005/papers/<!-- InstanceBeginEditable name="URL" -->addis/addis.html<!-- InstanceEndEditable --></p>
	<br/></td>
  </tr>
 
  <tr>
   <td align="left" valign="top" class="menuSideStretch"> </td>
  </tr>
  <tr> 
    <td rowspan="2" class="menuUpdateInfo">last updated:<br/>
      April 2005<br/>
analytic scripts updated:<br/>
October 2010<br/><a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/3.0/"><img src="http://i.creativecommons.org/l/by-nc-nd/3.0/88x31.png" alt="Creative Commons Attribution-Noncommercial-No Derivative Works 3.0  License" width="88" height="31" style="border-width:0"/></a></td>
    <td colspan="6" class="menuContactInfo" id="contactInfo"> Archives &amp; Museum Informatics, 158 Lee Avenue, Toronto, Ontario, M4E 2P3 Canada <br/>
      Telephone: +1 416 691 2516 | Fax: +1 416 352 6025 | E-mail: 
        <script language="JavaScript" type="text/javascript">
		<!-- <![CDATA[

				user = "mw2005";
				site = "archimuse.com";
				position = "Page Footer";
				document.write('<a href=\"mailto:' + user + '@' + site + '\?subject=Response from MW2005 Web Site: ' + position + '\">');
				document.write( user  + ' @ ' + site + '</a>');
		 // ]]> -->
		</script>
    </td>
  </tr>
  <tr> 
    <td colspan="6" class="menuCopyright">Copyright © 2005 - Archives &amp; Museum Informatics.</td>
  </tr>
</tbody></table>
<br/>
<!--htdig_noindex-->

<!-- analytics scripts -->
<!-- tynt script -->
<script type="text/javascript">tyntVariables = {"ap":"Read more: "};</script> 
<script type="text/javascript" src="http://tcr.tynt.com/javascripts/Tracer.js?user=aTNeQ-tzOr36a6adbiUzgI&amp;s=130&amp;cc=6&amp;st=1"></script>
<noscript></noscript>

<!-- google analytics script -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26332456-1']);
  _gaq.push(['_setDomainName', '.archimuse.com']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!--chartbeat script -->
<script type="text/javascript">
var _sf_async_config={uid:3385,domain:"archimuse.com"};
(function(){
  function loadChartbeat() {
    window._sf_endpt=(new Date()).getTime();
    var e = document.createElement('script');
    e.setAttribute('language', 'javascript');
    e.setAttribute('type', 'text/javascript');
    e.setAttribute('src',
       (("https:" == document.location.protocol) ? "https://s3.amazonaws.com/" : "http://") +
       "static.chartbeat.com/js/chartbeat.js");
    document.body.appendChild(e);
  }
  var oldonload = window.onload;
  window.onload = (typeof window.onload != 'function') ?
     loadChartbeat : function() { oldonload(); loadChartbeat(); };
})();

</script>

<!--/htdig_noindex-->





</body><!-- InstanceEnd --><!-- Mirrored from www.museumsandtheweb.com/mw2005/papers/addis/addis.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 17:40:00 GMT --></html>