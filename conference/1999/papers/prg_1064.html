<html><!-- Mirrored from www.museumsandtheweb.com/mw99/papers/milekic/milekic.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 19:32:31 GMT --><head>

        <title>Archives &amp; Museum Informatics: MW99 - Papers</title>

        <script language="JavaScript">



<!--



// Detect if browser is Netscape 3 + or IE 4 +.

bName = navigator.appName;

bVer = parseInt(navigator.appVersion);

    if ((bName == "Netscape" && bVer >= 3) || 

        (bName == "Microsoft Internet Explorer" && bVer >= 4)) br = "n3"; 

    else br = "n2";



// Create image objects, preload all active and inactive images.

    if (br== "n3") { 

     

    img2on = new Image();

    img2on.src = "../../nav/mw99_nav_registeron.gif";

    img3on = new Image();

    img3on.src = "../../nav/mw99_nav_workshopson.gif";

    img4on = new Image();

    img4on.src = "../../nav/mw99_nav_demonstrationson.gif";

    img5on = new Image();

    img5on.src = "../../nav/mw99_nav_sessionson.gif";

    img6on = new Image();

    img6on.src = "../../nav/mw99_nav_speakerson.gif";

    img7on = new Image();

    img7on.src = "../../nav/mw99_nav_exhibiton.gif";

    img8on = new Image();

    img8on.src = "../../nav/mw99_nav_sponsoron.gif";

    img9on = new Image();

    img9on.src = "../../nav/mw99_nav_beston.gif";

    img10on = new Image();

    img10on.src = "../../nav/mw99_nav_eventson.gif";

    img11on = new Image();

    img11on.src = "../../nav/mw99_nav_keydateson.gif";

        img12on = new Image();

    img12on.src = "../../nav/mw99_nav_neworleanson.gif";



     

        img2off = new Image();

    img2off.src = "../../nav/mw99_nav_registeroff.gif";

    img3off = new Image();

    img3off.src = "../../nav/mw99_nav_workshopsoff.gif";

    img4off = new Image();

    img4off.src = "../../nav/mw99_nav_demonstrationsoff.gif";

    img5off = new Image();

    img5off.src = "../../nav/mw99_nav_sessionsoff.gif";

    img6off = new Image();

    img6off.src = "../../nav/mw99_nav_speakersoff.gif";

    img7off = new Image();

    img7off.src = "../../nav/mw99_nav_exhibitoff.gif";

    img8off = new Image();

    img8off.src = "../../nav/mw99_nav_sponsoroff.gif";

    img9off = new Image();

    img9off.src = "../../nav/mw99_nav_bestoff.gif";

    img10off = new Image();

    img10off.src = "../../nav/mw99_nav_eventsoff.gif";

    img11off = new Image();

    img11off.src = "../../nav/mw99_nav_keydatesoff.gif";

    img12off = new Image();

    img12off.src = "../../nav/mw99_nav_neworleansoff.gif";

    }



// Function to "activate" images.

function imgAct(imgName) {

    if (br == "n3") {

    document[imgName].src = eval(imgName + "on.src");

    }

}



// Function to "deactivate" images.

function imgInact(imgName) {

    if (br == "n3") {

    document[imgName].src = eval(imgName + "off.src");

    }

}



// -->



</script>

</head>







<body bgcolor="#FFFFFF" background="../../../conferences/conferences_bg.html">

<table border="0" cellpadding="5">



<tbody><tr>

<td valign="TOP" width="135">





<a href="../../index.html"><center><img src="../../mw99.gif" width="112" height="155" alt="Museums and the Web 1999" border="0"/></center></a><p>







<a href="../../workshops/index.html" onmouseover="imgAct(&#39;img3&#39;)" onmouseout="imgInact(&#39;img3&#39;)" target="_top">

<img name="img3" src="../../nav/mw99_nav_workshopsoff.gif" width="125" height="15" border="0" alt="Workshops"/></a><br/>



<a href="../../sessions/index.html" onmouseover="imgAct(&#39;img5&#39;)" onmouseout="imgInact(&#39;img5&#39;)" target="_top">

<img name="img5" src="../../nav/mw99_nav_sessionsoff.gif" width="125" height="15" border="0" alt="Sessions"/></a><br/>



<a href="../../speakers/index.html" onmouseover="imgAct(&#39;img6&#39;)" onmouseout="imgInact(&#39;img6&#39;)" target="_top">

<img name="img6" src="../../nav/mw99_nav_speakersoff.gif" width="125" height="15" border="0" alt="Speakers"/></a><br/>



<a href="../../demos/index.html" onmouseover="imgAct(&#39;img4&#39;)" onmouseout="imgInact(&#39;img4&#39;)" target="_top">

<img name="img4" src="../../nav/mw99_nav_demonstrationsoff.gif" width="125" height="15" border="0" alt="Demonstrations"/></a><br/>



<a href="../../exhibit/index.html" onmouseover="imgAct(&#39;img7&#39;)" onmouseout="imgInact(&#39;img7&#39;)" target="_top">

<img name="img7" src="../../nav/mw99_nav_exhibitoff.gif" width="125" height="15" border="0" alt="Exhibit"/></a><br/>







<a href="../../events/index.html" onmouseover="imgAct(&#39;img10&#39;)" onmouseout="imgInact(&#39;img10&#39;)" target="_top">

<img name="img10" src="../../nav/mw99_nav_eventsoff.gif" width="125" height="15" border="0" alt="Events"/></a><br/>



<a href="../../best/index.html" onmouseover="imgAct(&#39;img9&#39;)" onmouseout="imgInact(&#39;img9&#39;)" target="_top">

<img name="img9" src="../../nav/mw99_nav_bestoff.gif" width="125" height="15" border="0" alt="Best of the Web"/></a><br/>







<br/> <br/>



<a href="http://www.archimuse.com/"><img src="../../../nav/nav_ami.html" width="135" height="25" alt="Home" border="0"/></a><br/>



<font size="-2">Archives &amp; Museum Informatics<br/>





2008 Murray Ave.,<br/>

Suite D<br/>

Pittsburgh, PA<br/>

15217 USA</font></p><p><font size="-2">

</font></p><p><font size="-2">

<a href="../../../mw98/index.html">info@museumsandtheweb.com</a><br/>

<a href="http://www.archimuse.com/">www.archimuse.com</a></font></p><p>

</p><p>

<font size="-2">Join our <a href="../../../index.html">Mailing List</a>.</font></p><p>

<font size="-2">
Published: March 1999.<br/></font>

<script language="JavaScript">

<!--

document.write("<FONT SIZE='-2'>"+"Updated:&nbsp;"+document.lastModified);

// -->

</script>
</p></td>



<td width="450" valign="TOP">

<img src="../papers.gif" width="325" height="66" alt="Papers" border="0"/><p>



</p><h3>Collaborative Digital Environments for Art Education / Exploration</h3>



<b><a href="../../bios/au_3850.html">Slavko Milekic</a></b>, Hampshire College, USA<p>



</p><h3>Introduction</h3>



The goal of this paper is to examine the role of digital technology in the context of Art Education / Exploration, although the presented analysis could be generalized to almost any interaction which involves humans and the digital medium.  I will argue that the present state of affairs in the development of digital devices is technology focused, which makes the development of human-centered applications harder, and in some cases, impossible.  For this reason I will also argue that there is a need for a conceptual change in the way we design and view digital devices.  To facilitate this I will suggest the use of term &#34;digital environment&#34; to denote digital devices which go beyond the traditional characteristics of a personal computer.  



<h3>Why are computers not built for humans?</h3>



To make a claim that computers are not built for humans may seem a paradox today, when an office or a school is unimaginable without computers, but this just reflects how well we have been trained.  The personal computer has been around for twenty years and in these two decades the basic design has practically not changed.  The basic computer is still a keyboard with some kind of display which is meant to reside on one&#39;s desk (or lap) regardless of the fact that it can be (and is) used for such diverse tasks as voice recognition, painting or finding one&#39;s exact position in a remote area.  Donald Norman (Norman, 1998) describes this situation as the first cycle of any new technology where, in its early stages, the emphasis is on functionality.  At this stage the technology is driven by, so called, early adopters -- enthusiasts who are willing to invest enormous amounts of time and energy into learning to use the technology, as long as they perceive that it meets some of their needs.   Once they have mastered the use of new technology, the focus of these users is on increasing its functionality.  To meet this desire (and to increase their profit margins) the companies invest in technological features.  This is nowhere more evident than in the computer industry -- there is a frenzied race for ever faster processors, more memory, larger hard drives, bigger monitors.  Often these features do not address any of the user&#39;s real needs but in the world of well-trained technology consumers they are the most common reasons affecting computer purchases.   The development of software mirrors the hardware trends -- the applications are getting larger and larger in order to utilize greater processor speeds and larger amounts of memory.  The number of &#34;features&#34; of software packages is dramatically growing exceeding the user&#39;s capacity to even remember all of them.  For example, the word processor I am currently using has well over 1000 commands, of which I probably use only a dozen or so!<p>



For certain subpopulations of potential computer users, the situation is even harder.   These include the technologically naïve (those millions who don&#39;t make a distinction between Windows and Mac OS), preliterate children and the growing population of elderly.  Analyzing the problems these populations have in using the computers often clearly demonstrates the areas that need to be addressed in a human-centered design.   For the purposes of this paper I will often use examples of the relationship of digital technologies with children as consumers.  This relationship most clearly depicts the general trends in the development of digital devices for two reasons: 



</p><ul>

	<li>in targeting children as a consumer population one has to address obvious limitations this population has in terms of physical size, cognitive ability, literacy level, attention span, hand-eye coordination, etc.<p>



	</p></li><li>children are also the most adaptable and fast learning consumer population which can be easily &#39;trained&#39; to accommodate for different shortcomings of the offered technology.

</li></ul>

  

It is illustrative to see how the industry has responded to the characteristics of this population.   It is evident that the least effort was made to change the physical characteristics of the hardware, although it is obvious how inadequate they are for this population.  Following the analogy with toys as miniaturized adult tools and appliances, the most consistent effort in adapting computers to the needs of children was in changing their size.  As reported by Goodman (1998) the next logical step was to shrink the desks computers are on and miniaturized wood-and-steel computer workstations can already be purchased for your 4-year old&#39;s &#39;office&#39; (<a href="http://www.tuffyland.com/tuffy_comp.htm">http://www.tuffyland.com/tuffy_comp.htm</a>).   To reduce the cognitive complexity and allow more efficient use of the computer keyboard for preschoolers the keyboard is color coded (keys that should be pressed with the left hand are one color, the ones for the right hand a different one).  The keyboard is advertised not only as child-friendly but also as parent-friendly presumably because nothing on the keyboard was really changed, so there is no need for parents to switch to the &#39;adult&#39; keyboard when they want to use the computer (see below).<p>



</p></td>

</tr>

</tbody></table>



<table border="0" cellpadding="5">



<tbody><tr>

<td valign="TOP" width="135"> 

</td>



<td width="450" valign="TOP">



<center><img src="milekic.Figures/milekic.Fig1.jpg" width="200" height="108" alt="KidBoard" border="0"/><p>



<table><tbody><tr><td><font size="-1"><i>Figure 1</i>.  KidBoard, a color-coded computer keyboard for children.  Keys that should be pressed with left hand are colored differently than the right-hand ones.  Moreover, each key has also a tiny picture of an object whose name begins with that letter (a - apple, etc.).  Reproduced with permission from <a href="http://www.webchild.com/kidboard.htm">http://www.webchild.com/kidboard.htm</a></font></td></tr></tbody></table></p></center>

<p>



Changes in size in order to make things child-friendly can also go into the opposite direction.  Microsoft has put out a giant trackball which should be easier to manipulate by young children compared to the average-sized one.  All these &#39;solutions&#39; are not inherently bad -- if one thinks that a child needs to sit at a desk while using a computer then it is definitely better if the chair and the desk are appropriately sized.  The problem is that all these solutions are solutions for the wrong kind of question -- they are trying to make the <i>existing</i> technology more palatable to different users, rather than <i>changing</i> the technology to meet diverse needs.   This view is so entrenched that the idea that it is necessary to <i>train</i> the users so they can use the technology is becoming widely accepted as a universal solution.</p><p>

  

Although software designed for children made giant progress in recent years most of the children&#39;s software still tends to be &#39;adapted&#39; for children in a similar way.  It is often oversimplified, with an abundance of animated objects and cartoonish characters.  Computer games tend to promote &#39;blind action&#39; of the type &#39;shoot anything that moves&#39; or &#39;click on everything&#39;.  They have a true addictive quality similar to psychological conditioning experiments.  What is amazing is that these &#39;adaptations&#39; seem to work!  Children are happy to have access to computers and are willing to compensate for numerous shortcomings of the technology.  Actually, they are capable of &#39;adapting&#39; to the existing technology much faster than adults. This fact is then used by the industry as a proof that the technology really does not need to be changed -- even a child can use it!</p><p>

     

The problem is that, even among children, it is a certain self-selected group that is willing to adapt to the technology as it is presented to them.  And once this group has mastered the ways of communicating with this technology they will no longer be interested in modifying these aspects of it -- their main desire will be to get better technology:  faster processors (for smoother animation), larger amounts of RAM (for full screen video), bigger hard drives (for storing video and audio clips).  Which leaves the rest of the population behind…</p><p>



However, in the maturation cycle of any technology a time comes when further technological improvements become irrelevant.  For example, one seldom buys a car today for the ultimate speed it can develop, but rather because of the comfort it offers, gas/mileage ratio, color, status, etc.  It seems that the computer industry is rapidly reaching the point where the existing processor speeds will be able to handle most complex tasks like continuous speech recognition and full screen digital video.  Increasing processor speed beyond this point will have little visible effect so the focus of consumers (and the industry) is bound to shift to other factors like ease and versatility of use.  It is also at this point in time that one may leave the traditional idea of a computer and make conjectures about the future.  





</p><h3>Towards digital environments</h3>



Here I would like to leave behind the traditional notion of a computer because of the conceptual baggage it carries -- a square box on a desk used for data storage and manipulation.   I suggest the introduction of another general concept, the one of a <i>digital environment</i>. What are digital environments? The <i>digital</i> in digital environments should be self-explanatory -- they are digital because information in them is digitally stored and represented. They are environments because they should be able to offer experiences which come close to real-world experiences in terms of richness of stimulation, manipulability and possibility of creative expression.  The main purpose of digital environments is not to simulate the real world (although simulations play an important role in digital environments) but to create a medium which will afford different kinds of unique interactions.  For example, in this environment one would be able to create, but also to un-create, that is, go back in time, or try out different outcomes before choosing one.<p>

  

	Three years ago (Milekic, 1997) I argued that for the transition from computers to digital environments to happen it has to be followed by changes in:



</p><ul>

	<li>location and shape of digital devices;<p>

	</p></li><li>input/interaction devices, and<p>

	</p></li><li>content structure.<p>

</p></li></ul>

 

In the dynamic computer market one can see some of this changes, although they tend to occur in isolated fashion and most often are not followed by changes in other domains which would make them truly functional.   The most common changes are visible in portable computers which, by definition, should allow easy changes in location.  So far, the change in location seems to be focused on the human body -- thus the proliferation of laptops, palmtops, hand-helds.   Some models also provide support for a number of input devices (see illustration below).<p>



</p><center><img src="milekic.Figures/milekic.Fig2.jpg" width="330" height="78" alt="The Clio PC companion" border="0"/>



<table><tbody><tr><td><font size="-1"><i>Figure 2</i>.  The Clio PC companion from Vadem illustrates the movement towards flexible digital environments, both in terms of support for a variety of interaction devices (keyboard, pen, finger, voice) but also in allowing quick transformations in physical shape and orientation -- from traditional notebook style to writing pad or presentation easel. (reproduced with permission from <a href="http://www.vadem.com/">http://www.vadem.com</a>)</font></td></tr></tbody></table></center>

<p>



However, although these changes are definitely going in the right direction, they are not accompanied by other adaptations which are necessary to make them really useable.  For example, the units which boast a touch-sensitive screen as an alternative input channel still have the same graphical user interface (GUI) which was adequate for a mouse-driven cursor.  Trying to use the same interface with one&#39;s finger is in the best case uncomfortable, and in the worst case impossible.</p><p>



<table border="1" cellpadding="5">

<tbody><tr><td valign="TOP" colspan="3" height="34">

<b><p><i>Table 1</i>.  Comparison of characteristics between traditional PCs, digital environments and information appliances</p></b></td>

</tr>

<tr><td width="33%" valign="TOP" height="34">

<b></b><p align="CENTER"><b>traditional<br/>PCs</b></p></td>

<td width="33%" valign="TOP" height="34">

<b></b><p align="CENTER"><b>digital environments</b></p></td>

<td width="33%" valign="TOP" height="34">

<b></b><p align="CENTER"><b>information appliances</b></p></td>

</tr>

<tr><td width="33%" valign="TOP" height="40">

<p>personally-oriented general use</p></td>

<td width="33%" valign="TOP" height="40">

<p>socially-oriented general use</p></td>

<td width="33%" valign="TOP" height="40">

<p>specialized, task specific</p></td>

</tr>

<tr><td width="33%" valign="TOP" height="40">

<p>tend to be very complex to operate</p></td>

<td width="33%" valign="TOP" height="40">

<p>easy to use</p></td>

<td width="33%" valign="TOP" height="40">

<p>simple to operate</p></td>

</tr>

<tr><td width="33%" valign="TOP" height="40">

<p>traditional input devices: keyboard, mouse</p></td>

<td width="33%" valign="TOP" height="40">

<p>support variety of <i>interaction</i> devices</p></td>

<td width="33%" valign="TOP" height="40">

<p>specialized input channel &amp; device</p></td>

</tr>

<tr><td width="33%" valign="TOP" height="40">

<p>tend to be physically larger, hard to move </p></td>

<td width="33%" valign="TOP" height="40">

<p>smaller than computers and portable</p></td>

<td width="33%" valign="TOP" height="40">

<p>tend to be small and portable</p></td>

</tr>

<tr><td width="33%" valign="TOP" height="40">

<p>traditional shape</p></td>

<td width="33%" valign="TOP" height="40">

<p>free shape</p></td>

<td width="33%" valign="TOP" height="40">

<p>task customized shape &amp;  size</p></td>

</tr>

<tr><td width="33%" valign="TOP" height="40">

<p>larger processing &amp; storage capacity</p></td>

<td width="33%" valign="TOP" height="40">

<p>larger processing &amp; storage capacity</p></td>

<td width="33%" valign="TOP" height="40">

<p>smaller processing &amp; storage capacity</p></td>

</tr>

<tr><td width="33%" valign="TOP" height="40">

<p>single user input</p></td>

<td width="33%" valign="TOP" height="40">

<p>support simultaneous multi-user interactions</p></td>

<td width="33%" valign="TOP" height="40">

<p>primary single input &amp; user/operator</p></td>

</tr>

<tr><td width="33%" valign="TOP" height="40">

<p>user unaware </p></td>

<td width="33%" valign="TOP" height="40">

<p>user aware - presence, intent, emotion </p></td>

<td width="33%" valign="TOP" height="40">

<p>user unaware, unless this is a part of the task</p></td>

</tr>

<tr><td width="33%" valign="TOP" height="40">

<p>user interface consistent over applications </p></td>

<td width="33%" valign="TOP" height="40">

<p>user interface adapts to interaction device, user, and application </p></td>

<td width="33%" valign="TOP" height="40">

<p>single, task specific user interface</p></td>

</tr>

</tbody></table>

</p><p>



	Here I would like to draw a distinction between other trends in the development of digital devices and the concept of digital environment.  The most common name to describe modern digital devices which include PDAs like Palm Pilot, electronic organizers, digital cameras and MIDI music instruments is &#39;information-appliances&#39; (Norman, 1998).  The most important characteristic of these appliances is their ability to share information.  With their specialization for certain tasks, portability and simplicity of use, the information appliances radically departed from the traditional concept of a personal computer.   However, I still think that there is a need for a digital device which would serve as a general purpose medium for social interactions and knowledge building and exchange - the digital environment.  To clarify the differences between the traditional PCs, digital environments and information appliances I have provided a comparative table of their characteristics (see above).</p><p>



	The main characteristic of digital environments is that they are capable of simultaneous multi-user input which allows them to support a variety of social interactions, and to add the social dimension to digitally-supported education.  Also note the change of term &#39;input devices&#39; to &#39;interaction devices&#39;.  The term &#39;input devices&#39; is a misleading residual from the times when humans were only inputting data into computers.  In the prehistory of computers the action of data inputting (using &#39;punch cards&#39;) was both physically and chronologically separated from data processing.  However, in modern computers the gap between inputting the data and interacting with it does not exist anymore.  Most of the interactions with computers today are performed in &#39;real-time&#39; which has a profound impact on interface design.  For this reason, I will take Baber&#39;s suggestion (Baber, 1997) and adopt the term &#39;interaction devices&#39; instead of &#39;input devices&#39;.  As Baber points out, the change in the term calls for a change in how these devices are viewed in the field of human-computer interaction.  The best level of description for interaction devices is in terms of goal-directed and contextual human action where these devices are mediators of human behavior.  In the next section I will provide examples and suggestions for the use of digital environments in art education and exploration.



</p><h3>Digital environments for art exploration</h3>



Digital environments are much better suited for activity- and inquiry-based pedagogical activities than traditional computers.  Some of these advantages are simply the consequence of the changes in shape and location.<p>



</p><center><img src="milekic.Figures/milekic.Fig3.jpg" width="200" height="152" alt="different display orientation" border="0" hspace="5"/><img src="milekic.Figures/milekic.Fig4.jpg" width="200" height="152" alt="different display orientation" border="0" hspace="5"/><p>



<table><tbody><tr><td><font size="-1"><i>Figure 3 &amp; 4</i>.  Examples of different display orientation.</font></td></tr></tbody></table></p></center>

<p>



If the display is positioned vertically or <i>in front</i> of the user it impairs direct communication between several users.   Flipping the orientation of the display into the horizontal plane, it becomes a part of the <i>common space</i> and can support a variety of interactions between the users.  In the photograph on the right (above), a student project exploring the applications of KiddyFace technology (Milekic, 1997) consisted of a touch-sensitive display embedded in a child-sized table (Milekic,S., Goodman, B., Benjamin, Z.A., Sullivan, K., Newman, J., Irons, N., 1998).  The setup promoted collaborative activities not only through its orientation but also with specially designed software which allowed the users to accomplish certain tasks much easier if they collaborated, that is, carried out together certain actions on the screen with a common goal in mind.</p><p>



	One of the problems which is becoming apparent with the increased use of the Internet is the vastness of &#39;digital spaces&#39;.  This is nowhere more evident than in the area of art education -- the number of available digitized reproductions of works of art is approaching a million.  Current &#39;browsing&#39; applications are ill-suited for meaningful navigation of these spaces.  Their navigational mechanisms are abstract and they offer little or no possibility of interacting with the works of art.  In the section below I will provide examples of how a touchscreen-based digital environment can be used to explore both conceptually and experientially complex spaces.</p><p>

  

	Touchscreens offer the most direct and intuitive way of interacting with digital devices.  However, they never gained popularity with personal computers presumably because they were never accompanied by the software specifically designed support this kind of interaction.  The throwing action occurs when a selected (touched) object is dragged rapidly across the screen and then released (finger is lifted from the screen).  For throwing to occur a certain threshold value of the movement speed needs to be reached.  The threshold is expressed as a linear distance (number of pixels) covered per unit of time (milliseconds).   This value can be fine tuned so that the throwing occurs only when the user really intends to throw away the objects and does not interfere with the selection and movement of objects at a &#39;normal&#39; pace.  

It seems that there is no need to explain the action of throwing to young children.  Observations of young children interacting with the KiddyFace environment at the Hampshire College Children&#39;s Center indicate that even children younger than 3 years of age discover the throwing action while exploring the environment on their own.  Very soon they discover an efficient way of throwing, using a short and quick &#39;flicking&#39; motion.  Interestingly enough, even after very short exposure to this way of interaction (it was available in only two out of ten modules), children generalized the expectations of this kind of behavior to other objects and tried to elicit it even in modules that did not support it.  It is possible that the attractiveness of this kind of interaction comes from the fact that a very small investment yields a substantial result, similar to the delight which very young children find in repeatedly throwing various objects from their crib.</p><p>



</p><center><img src="milekic.Figures/milekic.Fig5.jpg" width="220" height="199" alt="the " veggie="" face"="" module"="" border="0"/><p>



<table><tbody><tr><td><font size="-1"><i>Figure 5</i>. Illustration of throwing action in the &#34;Veggie Face&#34; module from the KiddyFace installation at the Speed Art Museum, Louisville, Kentucky (Milekic, 1997).</font> </td></tr></tbody></table></p></center>

<p>



Object &#34;throwing&#34; can be used to achieve a variety of exploratory and navigational goals without marked  increases in cognitive complexity of visual interface design.  In the module depicted above, different abstract face parts (vegetables) when &#34;thrown away&#34; from the screen would be replaced by a randomly chosen element from a database containing objects of the same kind.  Even with a relatively small number of objects in individual databases the number of distinctly different patterns (faces) which can be created is very large.  Using this approach in another project (build-a-face) the children were free to manipulate face parts with characteristics belonging to different age, gender, race and culture groups.</p><p>

 

An example of an interface design which uses the throwing action both for exploration of objects and navigation in digital space is the &#34;Throwing Gallery&#34;, also a part of the KiddyFace installation (see Figure 4.).  The goal of this module was to make parts of the collection of the Speed Art Museum in Louisville, Kentucky accessible even to the youngest audiences.</p><p>

  

Physically, the installation consisted of a (hidden) computer with a large touch-sensitive monitor.  The monitor was encased in such a way that the children were presented with an interactive touch-sensitive surface facing upward at a 60 degree angle.  The display was at a comfortable height for a standing child or a sitting adult.  A support for leaning on or sitting was provided through a large, movable, &#34;bean-bag&#34; arm which could be positioned at various distances from the display.</p><p>



The challenge for interface design was to provide a way to allow the children to browse the &#34;virtual gallery&#34; which contained a large number of digitized representations of the works of art.  The pedagogical goal was not just to expose the children to the reproductions of artworks  but also to convey some educational information, both at the level of individual works and at the level of art as an inherently human activity.  The goal on the level of interface design was to provide an environment with minimal demands in terms of cognitive complexity and eye-hand co-ordination requirements necessary for navigation.  To allow a child to focus undistracted on a single work of art, at any given time there was only one image on the screen, represented in the largest format possible.</p><p> 



</p><center><img src="milekic.Figures/milekic.fig6.jpg" width="400" height="272" alt="The " throwing="" gallery"="" module"="" border="0"/><p>



<table><tbody><tr><td><font size="-1"><i>Figure 6</i>.  The &#34;Throwing Gallery&#34; module from the KiddyFace installation at the Speed Art Museum, Louisville, Kentucky (Milekic, 1997)</font></td></tr></tbody></table></p></center>

<p>



The main mode of exploring this digital gallery was by using the throwing action (although it was also possible to move and reposition an image on the screen without throwing it away).  The child could &#34;throw&#34; an image in any direction -- left, right, up or down.  The &#34;thrown&#34; image would continue moving in the direction of the throw, eventually leaving the screen.   At the moment at which the &#34;thrown&#34; image disappeared from the screen, a new image would appear moving from the opposite edge of the screen towards its center, where it would settle.  With the new image in the center of the display a short voiceover (in a child&#39;s voice) would draw the attention to different aspects of the represented work of art. This interface was especially advantageous for use with children because:



</p><ul>

	<li>it uses a simple, natural gesture for exploration &amp; navigation;<p>

	</p></li><li>it allowed experiential mapping of the &#39;digital space&#39; to the child&#39;s own activity;<p>

	</p></li><li>it makes it possible for the educators to convey additional (meta)information by mapping different categories of the presented material onto the four &#39;throwing&#39; directions.

</li></ul>



Throwing action, which in the case of touchscreen-mediated action may be better described as &#39;pushing away&#39;, is a symbolic (semantic) gesture. Although very young children perform it with less precision and using a whole-arm movement they are capable of performing this action.  Moreover, in the touchscreen-mediated throwing the differences in throwing styles between immature and mature &#34;throwers&#34; are ironed out.  A wide, clumsy movement or the elegant wrist &#39;fling&#39; will produce the same effect on the screen.

The fact that the throwing action has a definite direction (as opposed to clicking on a button) allows creation of sequences which are meaningfully related to the child&#39;s activity.  Thus, by throwing the images from the virtual gallery in one direction, the child will be able to explore this part of digital space in a sequential fashion, comparable to exploring real space by walking in one direction.  Consequently, reversing the direction would allow the child to &#34;go back&#34;, that is, explore the objects which he/she manipulated before.<p>



By making objects (paintings) also &#39;throwable&#39; in up/down directions, it is possible to create a navigational space which will reflect the categories signified by the objects.  In the above illustration (Figure 6), the objects are the paintings in the museum gallery classified into child-friendly categories, like &#34;faces&#34;, &#34;flowers&#34;, &#34;outdoors&#34;.  &#34;Throwing&#34; an object to the right or left lets the child explore objects belonging to one category while throwing it up or down brings about a new category.  In the example depicted above, throwing an object left or right explores the category of &#34;flowers&#34;; throwing it up switches the category to &#34;faces&#34; (portraits) and throwing it down brings the category &#34;animals&#34; (not depicted in the illustration).  The possibility of mapping &#39;categorical&#39; spaces onto the experiential  &#39;navigational&#39; space of a child allows educators to expose the children to different kinds of meta-knowledge; for example, classification of paintings based on technique (oil, aquarelle, gouache), style (cubist, impressionist, baroque), etc.</p><p>

  

Directional mapping also can be used for other purposes; for example, for switching between different levels of complexity.  In this case &#39;horizontal&#39; navigation would correspond to a certain complexity level which could be increased by going &#39;up&#39; or decreased by going &#39;down&#39;.</p><p>

   

Interestingly enough, interactions via object throwing can be easily ported over even to the traditional systems which use the computer mouse as an interaction device.  Although there is an increase in complexity because of the necessity to map the mouse movements onto the cursor movement, it is still an easy, intuitive way of navigating through digital spaces.  With the increased use of the World Wide Web this kind of interface may prove to be significantly easier to use even for adults.</p><p>



	There is a growing consensus among human/computer interaction (HCI) researchers that the description of interaction between humans and computers in terms of action is more adequate than the description in terms of information processing.   Touchscreen-based environments offer the most direct interaction with digital representations through users&#39; actions.</p><p>

  

	Long before they are capable of understanding it, children are capable of acting within and upon their environment.  In his recent monograph on action as a integral component of cognition Andy Clark writes:



</p><blockquote>Cognitive development, it is concluded, cannot be usefully treated in isolation from issues concerning the child&#39;s physical embedding in, and interactions with, the world.  A better image of child cognition (indeed of <i>all</i> cognition) depicts perception, action, and thought as bound together in a variety of complex and interpenetrating ways. (Clark, 1997, pp 37, italics in original)</blockquote>



Clark uses the example of a puzzle assembly task.  A possible approach would be to look at each piece and figure out where its place would be.  However, both children and adults often use the strategy of &#39;trying out&#39; the fit of various pieces, and rotating the pieces themselves rather than trying to perform the same operation mentally.   Note that the touch-enabled computer display allows for this kind of interaction to occur in a natural way (one could do the same by using the mouse but the necessary mapping of mouse-to-cursor actions makes it harder for young children).<p>



</p><center><img src="milekic.Figures/milekic.fig7.jpg" width="320" height="240" alt="Module " from="" parts="" to="" whole""="" border="0"/><p>



<table><tbody><tr><td><font size="-1"><i>Figure 7</i>.  Module &#34;From parts to whole&#34; from the KiddyFace installation at the Speed Art Museum, Louisville, Kentucky.</font></td></tr></tbody></table></p></center>

<p>



However, assembling a complex puzzle (like the Henry Moore sculpture from the Speed Art Museum, depicted above) would be still extremely hard to solve for a 2.5 year-old even with extensive manipulation and will often lead to frustration and abandonment of the task.  This is a situation where digital environments can provide &#39;environmental&#39; clues which would bring about the ability to solve this task even in the population of young children.   An example would be the &#39;receptive target&#39; feature as implemented in the KiddyFace environment:  the final position of each puzzle piece corresponds to an invisible &#39;target area&#39;.   When a child tries to find the correct place for a puzzle piece using a finger (or the whole hand!) to drag the piece across the screen, if it happens to reach the target area it will automatically snap into the proper place, as if pulled by an invisible magnet.  Note that by increasing the size of the target area (&#39;tolerance level&#39;) the task can be made accessible even to very young children, or children with problems in eye-hand coordination.  Currently, a prototype of an environment which would be able to adapt itself dynamically to the registered ability of the user is developed for use in rehabilitation of children with different cognitive and motor disabilities (Milekic et al. 1997, Lukic, Milekic, Cordic, Milacic, Sazdanovic 1999).</p><p>

 

	The described procedure may not seem that different from similar applications played on traditional PCs, but the ability to react to simultaneous input of multiple users is what makes these environments truly social and allows support for collaborative relationships such as mentoring group knowledge building.</p><p>



</p><center><img src="milekic.Figures/milekic.Fig8.jpg" width="200" height="150" alt="Peer mentoring" border="0" hspace="5"/><img src="milekic.Figures/milekic.Fig9.jpg" width="200" height="150" alt="Peer mentoring" border="0" hspace="5"/><p>



<table><tbody><tr><td><font size="-1"><i>Figures 8 &amp; 9</i>.  Peer mentoring is a common way of transferring information among children and

group discovery is possible only if the environment allows simultaneous actions of group members.</font></td></tr></tbody></table></p></center>

<p>



	The flexibility of digital representations and the hands-on quality of digital environments allows exploration of works of art to an extent which was never possible before. The process of art creation can also be described as a process of selection.  The artist is making choices all along the path of creation.  Using the example of an oil painting we can say that an artist starts by choosing the topic, choosing the medium (oil pigments), and making a decision about the style of the execution.  Finer grained choices follow -- the choice of the relationship of depicted entities (composition), the choice of individual pigments (colors), their use, juxtaposition, etc.  Describing art in these terms may seem like an irrelevant exercise in logic because it is precisely the uniqueness of artist&#39;s choices which makes his/her art art.  However, because of the ease with which these representations can be transferred, modified and cloned in the digital medium, emphasizing the selection aspects of the art creation process can provide us with a more practical level of description of art-related educational activities in this medium. Not only can one zoom in on the finest details of a digital representation, but it is also possible to manipulate some of the very parameters the artist played with while creating the work.  In digital environments it is possible to allow the user to play with the composition of a painting, with light and even execution style.  A possibility of recording the stages of creation of a modern work of art offers yet another unique exploratory technique specific to the digital medium.   A suggestion of a possible museum setup which would allow both adults and children to explore art in an age-appropriate manner is depicted below.</p><p>



</p><center><img src="milekic.Figures/milekic.Fig10.jpg" width="400" height="296" alt="a possible museum setting" border="0"/><p>



<table><tbody><tr><td><font size="-1"><i>Figure 10</i>.  An example of a possible museum setting which would allow simultaneous exploration

of  the same work of art on two different levels.</font></td></tr></tbody></table></p></center>

<p>



</p><h3>Conclusion</h3>



The development of digital environments is seen as the next step in the evolution of traditional computers.  In contrast to information appliances, digital environments are general-purpose devices.  Their main characteristic is support for simultaneous multiple-user interactions.  This makes them an invaluable tool for social and collaborative activities.  The ease with which a user can manipulate visually represented information in these environments makes them particularly suitable for art education/exploration. 



<h3>References</h3>



<p>Baber, C. (1997) <i>Beyond the Desktop: Designing and Using Interaction Devices</i>, Academic Press</p>



<p>DataWeb, Inc. (1999) kidBoard: computer keyboard for children, consulted January 25, 1999.<br/> <a href="http://www.webchild.com/kidboard.htm">http://www.webchild.com/kidboard.htm</a></p>



<p>Goodman, B. (1998) Child-friendly collaborative digital environments, unpublished BA thesis, Hampshire College</p>



<p>H. Wilson Company (1999) Tuffy Plastic Computer Workstations, consulted January 25, 1999. <br/><a href="http://www.tuffyland.com/tuffy_comp.htm">http://www.tuffyland.com/tuffy_comp.htm</a></p>



<p>Lukic, D., Milekic, S., Cordic, A., Selakovic, M., Milacic, I. (1999-2000) Using touchscreen-based computer applications in rehabilitation of autistic children, Soros Foundation / Foundation for an Open Society grant research</p>



<p>Milekic,S. (1997) Virtual Museums: How to make digital information child-friendly?, in Bearman, D., Trant, J. (eds.) <i>Museums and the Web: Selected papers from Museums and the Web&#39;97</i>, (pp. 271-276). Pittsburgh: Archives and Museum Informatics</p>



<p>Milekic, S. (1997) KiddyFace, an installation at the Speed Art Museum, Louisville, Kentucky</p>



<p>Milekic,S., Goodman, B., Benjamin, Z.A., Sullivan, K., Newman, J., Irons, N. (1998) Innovative Interfaces: KiddyFace, project presentations at the Smithsonian Institution, 2n Annual NCIIA National Conference, March 13-15, Washington DC</p>



<p>Milekic, S. (PI), Ispanovic-Radojkovic, V., Krstic, N., Car, M.(1997-99) Neuropsychological diagnosis, assessment and rehabilitation of young children with Traumatic Brain Injury (TBI) using touchscreen-based computer applications, Soros Foundation / Foundation for an Open Society grant research</p>



<p>Norman, D. (1998) <i>The Invisible Computer</i>, Cambridge, MIT Press</p>



<p>Vadem, Inc. (1999) Clio, PC Companion, consulted January 24, 1999. <a href="http://www.vadem.com/">http://www.vadem.com</a></p>





</td>

</tr>

</tbody></table>

<!--htdig_noindex-->

<!-- analytics scripts -->
<!-- tynt script -->
<script type="text/javascript">tyntVariables = {"ap":"Read more: "};</script> 
<script type="text/javascript" src="http://tcr.tynt.com/javascripts/Tracer.js?user=aTNeQ-tzOr36a6adbiUzgI&amp;s=130&amp;cc=6&amp;st=1"></script>
<noscript></noscript>

<!-- google analytics script -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26332456-1']);
  _gaq.push(['_setDomainName', '.archimuse.com']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!--chartbeat script -->
<script type="text/javascript">
var _sf_async_config={uid:3385,domain:"archimuse.com"};
(function(){
  function loadChartbeat() {
    window._sf_endpt=(new Date()).getTime();
    var e = document.createElement('script');
    e.setAttribute('language', 'javascript');
    e.setAttribute('type', 'text/javascript');
    e.setAttribute('src',
       (("https:" == document.location.protocol) ? "https://s3.amazonaws.com/" : "http://") +
       "static.chartbeat.com/js/chartbeat.js");
    document.body.appendChild(e);
  }
  var oldonload = window.onload;
  window.onload = (typeof window.onload != 'function') ?
     loadChartbeat : function() { oldonload(); loadChartbeat(); };
})();

</script>







</body><!--/htdig_noindex--><!-- Mirrored from www.museumsandtheweb.com/mw99/papers/milekic/milekic.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 19:32:39 GMT --></html>