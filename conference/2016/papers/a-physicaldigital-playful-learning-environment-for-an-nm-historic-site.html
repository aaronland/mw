<div id="primary">
<div id="content" role="main">
<article id="post-1845" class="post-1845 paper type-paper status-publish hentry">
<style type="text/css">
h2 { font-weight: bold; font-size: 18px; }
h3, h4, h5, h6 { font-weight: bold; font-size: 16px; }

td, th { padding: 5px; }
th { background-color: #ccc; font-weight: bold; }
tr:nth-child(odd) { background-color: #eee }
</style>


<h1 class="entry-title">A physical/digital playful learning environment for a New Mexico Historic Site</h1>
<p><a target="_blank" href="http://www.museumsandtheweb.com/member/jonathanlee/">Jonathan Lee</a>, NMHU, USA, <a target="_blank" href="http://www.museumsandtheweb.com/member/stseagle/">Simone Seagle</a>, New Mexico Highlands University / Cultural Technology Lab, USA, <a target="_blank" href="http://www.museumsandtheweb.com/member/mlanger/">Miriam Langer</a>, New Mexico Highlands University, USA</p><h2>Abstract</h2>
In the spring of 2015, an advanced exhibition design class from New Mexico Highlands University&#39;s Media Arts &amp; Technology Department redesigned the visitor&#39;s center at Coronado Historic Site in Bernalillo, New Mexico. Kuaua Village was a first-contact site between the native population and the Spanish entrada that was moving up the Rio Grande valley from Mexico in 1540.
The redesign featured, among other updates, a new interactive &#34;Sim&#34; pueblo in which three-dimensional-printed pieces are placed on a responsive iPad to reveal information, animation, and clues to life in the ancient village.

That project was reenvisioned using the HP Sprout, a device designed to scan two- and three-dimensional objects and then add them to a library of usable objects on a touchscreen and projected mat. For this demo, we will show the HP Sprout detecting individual printed objects, which are then made responsive as physical or digital objects. By moving the prints on the mat, puzzle pieces are unlocked on the touchscreen, and animations of pueblo life are added to the projection. Information about life in the pueblo from architecture, construction materials, pottery traditions, and agriculture is revealed.<p></p>
<p><b>Keywords:</b> cultural technology, native american, pueblo, southwest</p>
<h2 class="p1"><span class="s1"><b>1. A brief history of the Kuaua Village</b></span></h2>
<p class="p2"><span class="s1">In 1540, while searching for the Seven Cities of Gold, Spanish explorer Vasquez de Coronado came upon Kuaua Village in what is now northern New Mexico. Coronado Historic Site, although named for the explorer, is today the site of the ruins of this village. At the time of its discovery by Coronado, the village was already generations old (estimated foundation ca. 1325), but it would soon be abandoned forever. Kuaua was one of twelve Tiwa villages in this area. Coronado chose to spend the winter of 1540 here, and tensions soon rose between the indigenous people and the explorer’s party. The stay culminated in the Tiguex War between Coronado’s men and several of the surrounding Tiwa villages near what is now Albuquerque. The lasting effects of the war and subsequent missions are believed to have led to the abandonment of this group of villages less than a century after Coronado’s arrival. The Tiwa people moved elsewhere and still reside in Taos, Picuris, Sandia, and Isleta.</span></p>
<p class="p2"><a href="../../wp-content/uploads/2016/01/Kuaua_ruins_Coronado_State_Monument_1940.jpg" rel="attachment wp-att-1835"><img loading="lazy" class="alignnone size-medium wp-image-1835" src="../../wp-content/uploads/2016/01/Kuaua_ruins_Coronado_State_Monument_1940-300x218.jpg" alt="Kuaua_ruins,_Coronado_State_Monument,_1940" width="300" height="218" srcset="https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/Kuaua_ruins_Coronado_State_Monument_1940-300x218.jpg 300w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/Kuaua_ruins_Coronado_State_Monument_1940-413x300.jpg 413w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/Kuaua_ruins_Coronado_State_Monument_1940.jpg 432w" sizes="(max-width: 300px) 100vw, 300px"/></a></p>
<p class="p2"><span class="s1">Figure 1: aerial view of Kuaua ruins, circa 1940</span></p>
<p class="p2"><span class="s1">In the 1930s, archaeologists Edgar Lee Hewett and Marjorie F. Tichy led an excavation of the site, discovering a series of pre-1492 murals from the pueblo’s southern kiva. Fourteen of these murals have been restored and are displayed in the Coronado visitor’s center. Prior to these excavations, Hewett was instrumental in crafting the Antiquities Act and served as the first president of New Mexico Normal School (now New Mexico Highlands University).</span></p>
<p class="p2"><span class="s1">In 1940, Coronado Historic Site became New Mexico’s first state historic site. Many of the excavated rooms from the village had to be filled in again to preserve their fragile state. A visitor’s center designed by noted Southwest architect John Gaw Meem stands near the buried ruins today, giving visitors a glimpse at the past around them.</span></p>
<h2 class="p1"><span class="s1"><b>2. Redesigning the visitor’s center</b></span></h2>
<p class="p2"><span class="s1">In the spring of 2015, an exhibition design class from New Mexico Highlands University’s Media Arts &amp; Technology Department redesigned the visitor’s center. Among other updates, an interactive Sim pueblo was introduced. In this interactive, visitors can place 3D-printed models of pueblo structures onto the iPad surface, allowing them to build up the village as they wish using pieces of various size. Each piece placed onto the screen will register with the application, and corresponding information about the village through its centuries of growth will be presented to the user. The is to allow the user to control the growth of the pueblo and learn about the actual history of its growth at the same time.</span></p>
<p class="p2"><a href="../../wp-content/uploads/2016/01/coronado_case1.jpg" rel="attachment wp-att-1836"><img loading="lazy" class="alignnone size-medium wp-image-1836" src="../../wp-content/uploads/2016/01/coronado_case1-300x225.jpg" alt="coronado_case1" width="300" height="225" srcset="https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/coronado_case1-300x225.jpg 300w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/coronado_case1-768x576.jpg 768w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/coronado_case1-1024x768.jpg 1024w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/coronado_case1-400x300.jpg 400w" sizes="(max-width: 300px) 100vw, 300px"/></a></p>
<p class="p2"><span class="s1">Figure 2: redesigned visitor’s center panels</span></p>
<p class="p2"><span class="s1">The iPad app was a success but did not align to the original vision. In the summer of 2015, Craig Cassidy, the lead designer of the iPad interactive, teamed with Simone Seagle to address the shortcomings and revisit the project with a new, promising technology.</span></p>
<p class="p2"><a href="../../wp-content/uploads/2016/01/SimPuebCloseUp.jpg" rel="attachment wp-att-1837"><img loading="lazy" class="alignnone size-medium wp-image-1837" src="../../wp-content/uploads/2016/01/SimPuebCloseUp-300x200.jpg" alt="SimPuebCloseUp" width="300" height="200" srcset="https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/SimPuebCloseUp-300x200.jpg 300w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/SimPuebCloseUp-768x512.jpg 768w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/SimPuebCloseUp-1024x683.jpg 1024w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/SimPuebCloseUp-450x300.jpg 450w" sizes="(max-width: 300px) 100vw, 300px"/></a></p>
<p class="p2"><span class="s1">Figure 3: Sim Pueblo iPad app in use at the visitor’s center</span></p>
<h2 class="p1"><span class="s1"><b>3. iPad limitations</b></span></h2>
<p class="p5"><span class="s1">We identified a lot of user-interface constraints on the iPad version of Sim Pueblo. First and foremost were the hardware limitations of the iPad, both of its size and of the way the buildings were originally detected.</span></p>
<p class="p5"><span class="s1">The physical size was an issue for the iPad because the buildings, while printed very small, still took up most of the screen, leaving only one small sidebar for the educational content. When visitors were building the pueblo, their arms would cover the small area of the screen where information about the pueblo was being displayed. Often they would miss the text entirely.</span></p>
<p class="p5"><span class="s1">One of the biggest limitations was that the iPad could not produce true object recognition. The iPad uses a capacitive touch screen, which means something that can disrupt the electromagnetic field created by the device (such as a finger) can be tracked as it moves across the screen by sensing where the field is being disrupted. The plastic piece alone will not disrupt the field to be sensed by the device. The app team decided to extend the field from the user’s finger to the piece by affixing a copper girdle around the plastic piece, but a building would only register as a touch while a visitor was holding it by this girdle. Therefore, even though the iPad has eleven simultaneous touch points that it can register, the app was only using one touch point throughout the entire cycle of the user placing buildings on the app. This posed a number of problems: </span></p>
<ul>
<li class="li5"><span class="s1">The iPad did not know which, if any, buildings were placed on the screen, let alone have any continuous feedback about which buildings were placed where. </span></li>
<li class="li5"><span class="s1">Because touches could not be distinguished from one another, the iPad would simply tally them up and then cycle through the information on the sidebar. Therefore, a visitor could also simulate the addition of a building to the screen by putting the same building down twice, or even simply by tapping the screen.</span></li>
<li class="li5"><span class="s1">The small size of the working area made it increasingly difficult for a visitor to hold the building by the copper girdle as more and more buildings were added to the screen. </span></li>
<li class="li5"><span class="s1">Because touches did not persist after a user’s hand was removed from a building, there was no way to know if buildings were removed from the screen, and if someone touched the copper girdle while removing a building, it would actually register as them having just placed a building.</span></li>
<li class="li5"><span class="s1">Because of the tallying of touches and impossibility of detecting building removal, the app needed a reset button that had to be pushed before beginning anew, even if all buildings were removed from the surface.</span></li>
</ul>
<p class="p6"><span class="s1">These problems inherent in the hardware made it obvious that the only way to drastically improve the interactive was to move to a different platform entirely. </span></p>
<h2 class="p1"><span class="s1"><b>4. Goals for Sim Pueblo 2.0</b></span></h2>
<p class="p5"><span class="s1">In order to combat the usability issues with the iPad implementation, we came up with a set of goals to meet with the new version:</span></p>
<ul>
<li class="li5"><span class="s1">Bring educational content to the forefront of the interactive.</span></li>
<li class="li5"><span class="s1">Allow for physical building identification and tracking in real time, regardless of user contact, with minimal adornment of the pieces.</span></li>
<li class="li5"><span class="s1">Create a model application that could be extensible enough to use for all of the New Mexico Historic Sites with a minimum of modification (that is, same general format, different assets). This includes both a simple UI structure and out-of-the-box hardware that can be purchased and set up easily.</span></li>
</ul>
<p class="p6"><span class="s1">The remainder of this paper is an exploration of how we strove to meet these goals.</span></p>
<h2 class="p1"><span class="s1"><b>5. Hardware consideration and selection</b></span></h2>
<p class="p5"><span class="s1">In order to really improve the Sim Pueblo interactive over what was available in the iPad version, we had to select a completely different hardware platform. We considered three main options.</span></p>
<p class="p5"><span class="s1">First, we considered building a custom solution with a computer, a 3D camera like a Leap or a Kinect, and a touchscreen. This would be very cost effective, somewhere on the order of $1,000 total, but could be difficult to maintain long term because there is minimal support available for the end user. Furthermore, without out-of-the-box hardware, it could be difficult for future developers to recreate the model solution for other historic sites.</span></p>
<p class="p5"><span class="s1">The second idea was to buy a touch table. Touch tables allow for a large working area, a built-in computer, support from the manufacturer, and a large number of available touch points. This path was ruled out for two reasons: first, the price was prohibitively expensive (approximately $8,000 for an appropriate table); and second, the vast majority of many-point touch tables are also capacitive touch like the iPad. Therefore, it is not obvious that they would have solved the original problem of only recognizing buildings while they were being held.</span></p>
<p class="p6"><span class="s1">The third option, and the solution that we settled on, was to use an HP Sprout. The Sprout is an all-in-one PC that includes a touch screen, downward-facing webcam, downward-facing Intel RealSense 3D camera, and touch mat with projected imagery. This is a reasonably priced (approximately $1,900) out-of-the-box solution that comes with the support and warranty of a name-brand manufacturer in case of hardware issues. It also allows for the monitoring of 3D objects on its mat and has a second screen that can be used solely for educational content.</span></p>
<h2 class="p1"><span class="s1"><b>6. Sim Pueblo user interface and experience</b></span></h2>
<p class="p5"><span class="s1">Moving to the Sprout solved many of the most egregious problems of the iPad implementation. The physical area available to build a pueblo was effectively tripled (a twenty-inch diagonal compared to an approximately eight-inch one). This allowed us to 3D print a new set of pueblo buildings at three times the iPad size, making it easier to see the detail on each one and also making them easier to hold. Furthermore, the buildings no longer had to be fitted with a copper girdle and touch point, so they were simpler to produce. </span></p>
<p class="p8"><a href="../../wp-content/uploads/2016/01/lee.fig4_.png" rel="attachment wp-att-1838"><img loading="lazy" class="alignnone size-medium wp-image-1838" src="../../wp-content/uploads/2016/01/lee.fig4_-300x200.png" alt="lee.fig4" width="300" height="200" srcset="https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig4_-300x200.png 300w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig4_-450x300.png 450w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig4_.png 469w" sizes="(max-width: 300px) 100vw, 300px"/></a></p>
<p class="p8"><span class="s1">Figure 4: 3D print for iPad (left); the same building for the Sprout version (right)<br/>
</span></p>
<p class="p5"><span class="s1">The addition of a second screen gave us much more flexibility to improve the flow of the interactive and information display. The educational content that we received from the Coronado monument did not have a 1:1 correlation with each building, and it also was not completely chronological. This led to the idea of having a visitor recreate the experience of living in the pueblo by rebuilding it like a puzzle. Each building is associated with one piece of a beautiful historical mural provided by the monument depicting puebloan life.</span></p>
<p class="p5"><span class="s1">As buildings are added to the gameplay area, mural shards are added to the upper screen, displaying text and an image if applicable. When the user is done reading the content, he or she simply closes the shard and it flips over, showing part of the mural, and pops into place. </span></p>
<p class="p5"><span class="s1">Each shard also has a set of small, unique interactive assets that can be added to the pueblo workspace below, bringing it to life. For example, one shard has facts about pueblo agriculture and allows you to add corn, beans, or squash to the building area. That way, even if the visitor follows the map of the original pueblo layout, her or his solution will not look the same as any other visitor’s.</span></p>
<p class="p5"><span class="s1">Once all buildings are added, the mural is complete, and visitors have seen all of the relevant information. </span></p>
<p class="p9"><a href="../../wp-content/uploads/2016/01/lee.fig5_.png" rel="attachment wp-att-1839"><img loading="lazy" class="alignnone size-medium wp-image-1839" src="../../wp-content/uploads/2016/01/lee.fig5_-300x169.png" alt="lee.fig5" width="300" height="169" srcset="https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig5_-300x169.png 300w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig5_-768x433.png 768w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig5_-500x282.png 500w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig5_.png 900w" sizes="(max-width: 300px) 100vw, 300px"/></a></p>
<p class="p9"><span class="s1">Figure 5: simple diagram of Sprout UI</span></p>
<h2 class="p1"><span class="s1"><b>7. Sprout software development and platform limitations</b></span></h2>
<p class="p5"><span class="s1">The HP Sprout Software Development Kit can be used with C++, QML, C#/WPF, or JavaScript. Our first attempt used the JavaScript application program interface (API), as it is a commonly used Web language and would be easy to build in, for both us and future developers who may join the project. Unfortunately, as it stands now, not all Sprout capabilities have been exposed through the JavaScript API. Many more capabilities are exposed to the CLR Binding, so after some experimentation with JavaScript, we moved to C#/WPF. </span></p>
<p class="p5"><span class="s1">The Sprout boasts real-time object tracking on the touch mat, but unfortunately the only objects it can track continuously at present are 2D (e.g., photos or documents). Even though our buildings have one preferred orientation, we were unable to use the built-in object tracking for them. Learning how to track them properly has turned out to be by far the most difficult part of the project.</span></p>
<p class="p5"><span class="s1">In the Sprout SDK, the Capture method allows the developer to get full the full 3D information available in a scene, but this takes on the order of five seconds and causes the whole mat screen to go blank. Therefore, it cannot be used to track the buildings and still allow for a satisfying user interaction.</span></p>
<p class="p5"><span class="s1">The Sprout itself uses the Intel RealSense 3D camera for its 3D sensing, and it occurred to us that perhaps we could use that to track the objects on the mat. However, even though the camera has its own SDK, that SDK is not exposed to developers on the Sprout, possibly because it could interfere with the functioning of the Sprout during object capture. There is no word on whether the ability to access that camera directly is something that HP will ever release to developers. (<a href="https://sprout-developers.rssx.hp.com/vanilla/index.php?p=/discussion/5/intel-realsense-camera-not-used-by-sprout/Index"><span class="s3">Sprout Developer Forums</span></a>)</span></p>
<p class="p6"><span class="s1">The most robust way we found to identify and track the buildings was to use the built-in downward facing webcam with extensive image analysis. </span></p>
<h2 class="p1"><span class="s1"><b>8. Object tracking methodology: Two approaches</b></span></h2>
<p class="p5"><span class="s1">Based on the archaeological information of the site, we took the original configuration of the pueblo and split it into nine different buildings. The goal of object tracking would be to compare the configuration of buildings on the mat and give the user constant feedback about where they have located the nine pieces.</span></p>
<p class="p5"><span class="s1">We used the AForge.NET image-processing library to filter the image from the downward facing webcam. Each frame is enhanced using a series of filters designed to bring out the relevant visual information in each frame. The image’s colors are modified, contrast enhanced, converted to grayscale, and finally converted to a simple black-and-white image by a threshold binary filter. This takes a full-color video frame and turns it into a black-and-white image with all relevant parts highlighted and ready to process. The processing is so fast that it creates virtually no lag whatsoever, a key component of our goal for ideal user interface. </span></p>
<p class="p5"><span class="s1">So while we had a very effective method to get data from the webcam, we needed a way to turn that data into an accurate map of the physical buildings on the mat.</span></p>
<p class="p10"><span class="s1">Note: for all subsequent figures in this section, the left portion represents the raw webcam output and the right portion shows analysis superimposed on the filtered image.</span></p>
<h3 class="p11"><span class="s1"><b>Outline polygon approach</b></span></h3>
<p class="p5"><span class="s1">The buildings that we are working with all have unique outlines and sizes, which originally led us to explore polygon-matching algorithms based on the outline of the building as seen from above. The polygon outline was easy to extract with a <a href="http://www.csie.ntu.edu.tw/~cyy/courses/vfx/07spring/lectures/handouts/lec04_feature_4up.pdf"><span class="s3">Moravec corner detection</span></a> algorithm combined with a blob detector. We explored the idea of using a turning function to identify buildings by outline. </span></p>
<p class="p5"><span class="s1">Figure 6 shows the polygons of the buildings when they are separated from each other. The right side shows the filtered image in black and white with building blob rectangles in blue, building outline polygons in green, and numerical guesses for building identity in peach on each blob. The algorithm guesses the identity of the building by area and is almost always correct, although it cannot determine rotation.</span></p>
<p class="p8"><a href="../../wp-content/uploads/2016/01/lee.fig6_.png" rel="attachment wp-att-1840"><img loading="lazy" class="alignnone size-medium wp-image-1840" src="../../wp-content/uploads/2016/01/lee.fig6_-300x91.png" alt="lee.fig6" width="300" height="91" srcset="https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig6_-300x91.png 300w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig6_-768x232.png 768w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig6_-500x151.png 500w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig6_.png 835w" sizes="(max-width: 300px) 100vw, 300px"/></a></p>
<p class="p8"><span class="s1">Figure 6: webcam output (left); analyzed image with polygon outlines and guesses as to which building is which (right)<br/>
</span></p>
<p class="p5"><span class="s1">Unfortunately, once buildings touch, the robust algorithm breaks down fairly quickly. You can see in Figure 7 that the large collection of buildings is no longer identified properly, and the polygon point-sorting algorithm becomes unstable as the points are no longer concentric around one central point of the building. </span></p>
<p class="p8"><a href="../../wp-content/uploads/2016/01/lee.fig7_.png" rel="attachment wp-att-1841"><img loading="lazy" class="alignnone size-medium wp-image-1841" src="../../wp-content/uploads/2016/01/lee.fig7_-300x89.png" alt="lee.fig7" width="300" height="89" srcset="https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig7_-300x89.png 300w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig7_-768x227.png 768w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig7_-500x148.png 500w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig7_.png 829w" sizes="(max-width: 300px) 100vw, 300px"/></a></p>
<p class="p8"><span class="s1">Figure 7: webcam output (left); same algorithm as Figure 1, but with buildings in contact (right)<br/>
</span></p>
<p class="p10"><span class="s1">Unfortunately, even though this approach was very promising at first, it is not likely to be a solid production solution. To reiterate the issues, each building polygon contains roughly one hundred to three hundred points, and sorting them gets more complex as the number of points increases. This complexity increases again once we have more than one physical building making up a polygon in the analysis, and as the complexity goes up, speed goes down, taking away from our goal of instantaneous user feedback.</span></p>
<h3 class="p11"><span class="s1"><b>Fiducial triangle approach</b></span></h3>
<p class="p5"><span class="s1">The next idea was to put identifying markers on the building. We settled on using contrasting green dots with three dots per building. That way, buildings can be identified by a unique triangular constellation of dots. This is not a perfect solution, because the buildings are now adorned and not exactly historically accurate, but this provides us with a reliable and very fast way of tracking the buildings.</span></p>
<p class="p8"><a href="../../wp-content/uploads/2016/01/lee.fig8_.png" rel="attachment wp-att-1842"><img loading="lazy" class="alignnone size-full wp-image-1842" src="../../wp-content/uploads/2016/01/lee.fig8_.png" alt="lee.fig8" width="247" height="237"/></a></p>
<p class="p8"><span class="s1">Figure 8: 3D-printed building, spray-painted brown with green fiducial dots on top</span></p>
<p class="p5"><span class="s1">Three dots were selected for the ID process, because triangles are the simplest geometry that can still be reliably located and oriented. An example of that analysis is shown in the following image.</span></p>
<p class="p8"><a href="../../wp-content/uploads/2016/01/lee.fig9_.png" rel="attachment wp-att-1843"><img loading="lazy" class="alignnone size-medium wp-image-1843" src="../../wp-content/uploads/2016/01/lee.fig9_-300x176.png" alt="lee.fig9" width="300" height="176" srcset="https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig9_-300x176.png 300w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig9_-768x450.png 768w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig9_-500x293.png 500w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig9_.png 900w" sizes="(max-width: 300px) 100vw, 300px"/></a></p>
<p class="p8"><span class="s1">Figure 9: Sim Pueblo debug window<span class="Apple-converted-space"> (r</span>aw video on left, processed on right)</span></p>
<p class="p5"><span class="s1">The image-filtering method is slightly modified for this approach in order to bring out the fiducial dots, rather than outline of the buildings. The window shown is an optional video debugging window in Sim Pueblo that can be turned on and off in the configuration of the program, allowing for easy error finding for staff.</span></p>
<p class="p5"><span class="s1">After the frame is converted to a binary black-and-white image, we use two instances of blob detection processor from the AForge.NET library. The first blob detector goes through and locates blobs of the size of the fiducial dots. These are seen as visualized as orange rectangles above. A second blob detector (not shown) isolates the buildings from their background and is used to filter out unwanted blobs from the first set, allowing us to discard false points like those shown in the upper left corner of the processed image in Figure 9.</span></p>
<p class="p6"><span class="s1">Once the array of viable blobs is pared down, they can then be arranged into all possible triangles (visualized in blue above). Each triangle is compared by side length with the database of triangles for each building. When a matching building is found, the triangle is analyzed for location and orientation on the map. The new location and orientation is compared against previous data in order to prevent false positives. When a building is verified as being truly present on the mat, that data is sent to the controller for the mural shards and the building tracker on the screen.</span></p>
<h2 class="p1"><span class="s1"><b>9. Usability limitations</b></span></h2>
<p class="p5"><span class="s1">Because the 3D-printed buildings are historical recreations of the actual pueblo, they allow for tactile exploration by the vision impaired. Unfortunately, we do not have the budget at present to have someone read and record the accompanying text that goes with the buildings, so the vision impaired would not be able to fully participate in the game.</span></p>
<p class="p5"><span class="s1">We do not yet have a Spanish translation of the text, which would be an excellent edition because New Mexico has a high proportion of native Spanish speakers.</span></p>
<p class="p6"><span class="s1">The fiducial dots are a robust and simple solution to building tracking, but are not ideal in terms of historical accuracy. All future 3D prints must be spray-painted the exact same color, and care must be taken to apply the dots in exactly the same locations, which could pose problems. We expect to make backups of all the buildings anyway, because while they are not exactly delicate, they can be destroyed by serious mishandling. For example, one of our dogs got a hold of one building and mangled it in seconds.</span></p>
<h2 class="p1"><span class="s1"><b>10. Conclusion</b></span></h2>
<p class="p5"><span class="s1">The current implementation of Sim Pueblo does an excellent job of meeting the goals set out at the beginning of the project, although it does have room for improvement.</span></p>
<p class="p5"><span class="s1">Educational content is now prominently displayed during the user experience. The physical experience of using the interactive matches how a visitor uses a typical computer, where the physical manipulation is below and information is displayed above. Therefore, the overall user experience should be intuitive and successful.</span></p>
<p class="p5"><span class="s1">Video-frame analysis is fast enough that there is virtually no lag between a user’s interaction and what is displayed on screen. The only lag is when a user’s hand is directly over a building, but persistence is built in to prevent any glitches, such as the program thinking a building was removed when really it was just blocked by a hand. However, a large number of hands blocking the webcam could become a problem that may need to be addressed.</span></p>
<p class="p5"><span class="s1">The 3D-printed buildings are adorned with the green dots, slightly detracting from our second goal, but we are now in the process of experimenting with infrared markers that would be picked up by the Intel RealSense camera.</span></p>
<p class="p5"><span class="s1">Finally, the program we have built can serve as a model for other New Mexico Historic Sites, and possibly other museums as well. The method for tracking of 3D objects with triangles would be robust even if a historic site has many buildings that have the same shape. New assets and information could easily be swapped out in the code. 3D models would have to be recreated for each site and then 3D printed. It is also possible that a new paradigm would have to be used to replace the mural building idea, but that change is easy compared to determining a new method to track the 3D models.</span></p>
<p class="p5"><a href="../../wp-content/uploads/2016/01/lee.fig10.png" rel="attachment wp-att-1844"><img loading="lazy" class="alignnone size-medium wp-image-1844" src="../../wp-content/uploads/2016/01/lee.fig10-212x300.png" alt="lee.fig10" width="212" height="300" srcset="https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig10-212x300.png 212w, https://mw2016.museumsandtheweb.com/wp-content/uploads/2016/01/lee.fig10.png 662w" sizes="(max-width: 212px) 100vw, 212px"/></a></p>
<p class="p1"><span class="s1">Figure 10: Sim Pueblo interactive in its current form</span></p>
<hr/>

<script type="text/javascript">
var d=new Date();
var month=new Array();
month[0]="January";
month[1]="February";
month[2]="March";
month[3]="April";
month[4]="May";
month[5]="June";
month[6]="July";
month[7]="August";
month[8]="September";
month[9]="October";
month[10]="November";
month[11]="December";

var day_number=d.getDate();
var month_name=month[d.getMonth()];
var year=d.getFullYear();
var full_date = month_name+" "+day_number+", "+year;
</script>

Cite as:<br/> 

Lee, Jonathan, Simone Seagle and Miriam Langer. &#34;A physical/digital playful learning environment for a New Mexico Historic Site.&#34; <i>MW2016: Museums and the Web 2016</i>. Published February 13, 2016. Consulted <script type="text/javascript">document.write(full_date);</script>.<br/>
https://mw2016.museumsandtheweb.com/paper/a-physicaldigital-playful-learning-environment-for-an-nm-historic-site/<br/><br/><hr/>
	<div id="comments">
	
	
	
	
</div><!-- #comments -->
</article>
</div><!-- #content -->
</div>