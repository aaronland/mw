<html><!-- #BeginTemplate "/Templates/mw2001paper.dwt" --><!-- DW6 --><!-- Mirrored from www.museumsandtheweb.com/mw2001/papers/ward/ward.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 17:48:49 GMT --><head>
<!-- templates applied after meeting -->
<!-- #BeginEditable "doctitle" --> 

<title>Collage and Content-based Image Retrieval: Collaboration for Enhanced Services for the London Guildhall Library</title>

<!-- #EndEditable --> 
<meta http-equiv="Content-Type" content="text/html; charset="/>
<script language="JavaScript">
<!--
function MM_swapImgRestore() { //v2.0
  if (document.MM_swapImgData != null)
    for (var i=0; i<(document.MM_swapImgData.length-1); i+=2)
      document.MM_swapImgData[i].src = document.MM_swapImgData[i+1];
}

function MM_preloadImages() { //v2.0
  if (document.images) {
    var imgFiles = MM_preloadImages.arguments;
    if (document.preloadArray==null) document.preloadArray = new Array();
    var i = document.preloadArray.length;
    with (document) for (var j=0; j<imgFiles.length; j++) if (imgFiles[j].charAt(0)!="#"){
      preloadArray[i] = new Image;
      preloadArray[i++].src = imgFiles[j];
  } }
}

function MM_swapImage() { //v2.0
  var i,j=0,objStr,obj,swapArray=new Array,oldArray=document.MM_swapImgData;
  for (i=0; i < (MM_swapImage.arguments.length-2); i+=3) {
    objStr = MM_swapImage.arguments[(navigator.appName == 'Netscape')?i:i+1];
    if ((objStr.indexOf('document.layers[')==0 && document.layers==null) ||
        (objStr.indexOf('document.all[')   ==0 && document.all   ==null))
      objStr = 'document'+objStr.substring(objStr.lastIndexOf('.'),objStr.length);
    obj = eval(objStr);
    if (obj != null) {
      swapArray[j++] = obj;
      swapArray[j++] = (oldArray==null || oldArray[j-1]!=obj)?obj.src:oldArray[j];
      obj.src = MM_swapImage.arguments[i+2];
  } }
  document.MM_swapImgData = swapArray; //used for restore
}
//-->
</script>
<style type="TEXT/CSS">
<!--
.heading {  font-family: Arial, Helvetica, sans-serif; font-size: 12px; font-style: normal; font-weight: bold}
.normal {  font-family: Arial, Helvetica, sans-serif; font-size: 12px}
.small {  font-family: Arial, Helvetica, sans-serif; font-size: 10px}
.verysmall {  font-family: Arial, Helvetica, sans-serif; font-size: 9px}
.red {  font-family: Arial, Helvetica, sans-serif; font-size: 12px; font-style: normal; font-weight: bold; color: #660000}
-->
</style>
<link rel="stylesheet" href="../paperStyles.css" type="text/css"/>
</head>

<body bgcolor="#FFFFFF" background="../../mw.images/mw2001_bg.gif" text="#000000" link="#003399" vlink="#660000" onload="MM_preloadImages(&#39;../../nav/mw2001_nav_registeron.gif&#39;,&#39;#943398414283&#39;);MM_preloadImages(&#39;../../nav/mw2001_nav_workshopson.gif&#39;,&#39;#943398455733&#39;);MM_preloadImages(&#39;../../nav/mw2001_nav_sessionson.gif&#39;,&#39;#943398500450&#39;);MM_preloadImages(&#39;../../nav/mw2001_nav_speakerson.gif&#39;,&#39;#943398534416&#39;);MM_preloadImages(&#39;../../nav/mw2001_nav_demoson.gif&#39;,&#39;#943398577050&#39;);MM_preloadImages(&#39;../../nav/mw2001_nav_exhibiton.gif&#39;,&#39;#943398612066&#39;);MM_preloadImages(&#39;../../nav/mw2001_nav_eventson.gif&#39;,&#39;#943398640266&#39;);MM_preloadImages(&#39;../../nav/mw2001_nav_beston.gif&#39;,&#39;#943398663166&#39;);MM_preloadImages(&#39;../../nav/mw2001_nav_keydateson.gif&#39;,&#39;#943398701050&#39;);MM_preloadImages(&#39;../../nav/mw2001_nav_seattleon.gif&#39;,&#39;#943398731383&#39;);MM_preloadImages(&#39;../../nav/mw2001_nav_sponsoron.gif&#39;,&#39;#943398934733&#39;)">
<table width="600" border="0" cellspacing="2" cellpadding="5">
  <tbody><tr> 
    <td width="145" align="LEFT" valign="TOP" height="646"> 
      <p><a href="../../index.html"><img src="../../mw.images/mw.gif" width="112" height="155" border="0" alt="MW2001"/></a></p>
      <p> <a href="../../register/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;document.register&#39;,&#39;document.register&#39;,&#39;../../nav/mw2001_nav_registeron.gif&#39;,&#39;#943398414283&#39;)"><img name="register" border="0" src="../../nav/mw2001_nav_registeroff.gif" width="125" height="15" alt="Register"/></a> 
        <br/>
        <a href="../../workshops/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;document.workshops&#39;,&#39;document.workshops&#39;,&#39;../../nav/mw2001_nav_workshopson.gif&#39;,&#39;#943398455733&#39;)"><img name="workshops" border="0" src="../../nav/mw2001_nav_workshopsoff.gif" width="125" height="15" alt="Workshops"/></a> 
        <br/>
        <a href="../../sessions/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;document.sessions&#39;,&#39;document.sessions&#39;,&#39;../../nav/mw2001_nav_sessionson.gif&#39;,&#39;#943398500450&#39;)"><img name="sessions" border="0" src="../../nav/mw2001_nav_sessionsoff.gif" width="125" height="15" alt="Sessions"/></a> 
        <br/>
        <a href="../../speakers/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;document.speakers&#39;,&#39;document.speakers&#39;,&#39;../../nav/mw2001_nav_speakerson.gif&#39;,&#39;#943398534416&#39;)"><img name="speakers" border="0" src="../../nav/mw2001_nav_speakersoff.gif" width="125" height="15" alt="Speakers"/></a> 
        <br/>
        <a href="../../interact/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;document.interact&#39;,&#39;document.interact&#39;,&#39;../../nav/mw2001_nav_interacton.gif&#39;,&#39;#943398534416&#39;)"><img name="interact" border="0" src="../../nav/mw2001_nav_interactoff.gif" width="125" height="15" alt="Interact"/></a> 
        <br/>
        <a href="../../demos/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;document.demos&#39;,&#39;document.demos&#39;,&#39;../../nav/mw2001_nav_demoson.gif&#39;,&#39;#943398577050&#39;)"><img name="demos" border="0" src="../../nav/mw2001_nav_demosoff.gif" width="125" height="15" alt="Demonstrations"/></a> 
        <br/>
        <a href="../../exhibit/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;document.exhibits&#39;,&#39;document.exhibits&#39;,&#39;../../nav/mw2001_nav_exhibiton.gif&#39;,&#39;#943398612066&#39;)"><img name="exhibits" border="0" src="../../nav/mw2001_nav_exhibitoff.gif" width="125" height="15" alt="Exhibits"/></a> 
        <br/>
        <a href="../../events/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;document.events&#39;,&#39;document.events&#39;,&#39;../../nav/mw2001_nav_eventson.gif&#39;,&#39;#943398640266&#39;)"><img name="events" border="0" src="../../nav/mw2001_nav_eventsoff.gif" width="125" height="15" alt="Events"/></a> 
        <br/>
        <a href="../../best/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;document.best&#39;,&#39;document.best&#39;,&#39;../../nav/mw2001_nav_beston.gif&#39;,&#39;#943398663166&#39;)"><img name="best" border="0" src="../../nav/mw2001_nav_bestoff.gif" width="125" height="15" alt="Best of the Web"/></a> 
        <br/>
        <a href="../../dates/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;document.dates&#39;,&#39;document.dates&#39;,&#39;../../nav/mw2001_nav_keydateson.gif&#39;,&#39;#943398701050&#39;)"><img name="dates" border="0" src="../../nav/mw2001_nav_keydatesoff.gif" width="125" height="15" alt="Key Dates"/></a> 
        <br/>
        <a href="../../seattle/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;document.seattle&#39;,&#39;document.seattle&#39;,&#39;../../nav/mw2001_nav_seattleon.gif&#39;,&#39;#943398731383&#39;)"><img name="seattle" border="0" src="../../nav/mw2001_nav_seattleoff.gif" width="125" height="15" alt="seattle"/></a> 
        <br/>
        <a href="../../sponsor/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;document.sponsor&#39;,&#39;document.sponsor&#39;,&#39;../../nav/mw2001_nav_sponsoron.gif&#39;,&#39;#943398934733&#39;)"><img name="sponsor" border="0" src="../../nav/mw2001_nav_sponsoroff.gif" width="125" height="15" alt="Sponsor"/></a> 
        <br/>
        <br/>
        <br/>
        <a href="http://www.archimuse.com/" target="_top"><img src="../../nav/nav_ami.gif" width="135" height="25" border="0" alt="A&amp;MI home"/></a> 
        <br/>
        <font face="Arial, Helvetica, sans-serif" class="verysmall"><span class="verysmall">Archives 
        &amp; Museum Informatics<br/>
        158 Lee Avenue<br/>
        Toronto, Ontario<br/>
        M4E 2P3 Canada<br/>
        info@ archimuse.com<br/>
        <a href="http://www.archimuse.com/">www.archimuse.com</a></span></font></p>
      <table width="74">
        <tbody><tr> 
          <td> <span class="verysmall"><a href="http://search.museumsandtheweb.com/search" target="_top"> 
            <img src="../../nav/search.gif" width="24" height="25" alt="Search" border="0" name="Search"/></a> 
            </span></td>
          <td valign="MIDDLE"> <span class="verysmall"><a href="http://search.museumsandtheweb.com/search"> 
            <font face="Arial, Helvetica, sans-serif">Search <br/>
            A&amp;MI</font></a> </span></td>
        </tr>
      </tbody></table>
      <p class="verysmall"><font face="Arial, Helvetica, sans-serif" class="verysmall">Join 
        our <a href="http://search.museumsandtheweb.com/mailinglist/"> Mailing List</a>. 
        <br/>
        <a href="http://search.museumsandtheweb.com/terms-of-use-privacy/"> Privacy</a>.</font> </p>
      <p>
        <font size="-2" class="verysmall">Published: March 15, 2001.<br/>
        </font>
<!--

document.write("<FONT SIZE='-2' class='verysmall'>"+"Last Updated: "+document.lastModified);

// -->



      </p>
      </td>
    <td width="429" align="LEFT" valign="TOP" height="646"><img src="../../speakers/papers.gif" alt="Papers"/><br/>
      <!-- #BeginEditable "Body" --> 

      <h1 class="PaperTitle"><a name="_Hlt503945349"><i>Collage</i> and Content-based 

        Image Retrieval: Collaboration for Enhanced Services for the London Guildhall 

        Library</a></h1>

      <h2 class="Author">Annette A. Ward , Margaret Graham, Jonathan Riley, Neil 

        Eliot, and John Eakins, University of Northumbria at Newcastle, Nic Sheen, 

        iBase Image Systems, Cathy Pringle, London Guildhall Library, United Kingdom 

      </h2>

      <h1 class="AbstractTitle">Abstract</h1>

      <span class="AbstractText">Museum, library, archive, and other cultural 

      heritage database collections are growing along with their numbers of users. 

      Traditional methods of image retrieval will be insufficient. Content-based 

      image retrieval (CBIR), a computer technique for retrieving images based 

      on color, texture, and shape, locates visually similar matches for a selected 

      painting, print, drawing, or other objects. The technique will become increasingly 

      useful when combined with traditional methods of accessing images. </span><span class="AbstractText"><b><i>Collage</i></b>, 

      the Corporation of London Guildhall Library and Guildhall Art Gallery 22,400 

      digital image collection, was selected as a test site for the application 

      and evaluation of CBIR. The Institute for Image Data Research (IIDR) at 

      the University of Northumbria at Newcastle and iBase Image Systems, developer 

      of the <b><i>Collage</i></b> software, collaborated with the London Guildhall 

      Library to introduce CBIR technology for image retrieval on the <b><i>Collage</i></b> 

      web site. </span><span class="AbstractText">Initial evaluation of the CBIR 

      feature by an online questionnaire indicated the majority of the respondents 

      thought CBIR was useful, results were satisfactory and interesting, it was 

      a good method to retrieve images, and they would like to use it again. Information 

      derived from the results is important for developing and applying software 

      to refine visual search retrieval.</span><span class="AbstractText">This 

      research is supported by a grant from Resource: The Council for Museums, 

      Archives and Libraries (CMAL/RE/103) and is part of an ongoing study, Evaluation 

      of Content-based Image Retrieval in an Operational Setting, conducted at 

      the University of Northumbria at Newcastle, Institute for Image Data Research.</span> 

      <p class="normal">As museum, library, archive, and other cultural heritage 

        collections grow along with their numbers of users, image retrieval using 

        only traditional methods will become insufficient. Retrieving images by 

        color, texture, or shape will be increasingly essential and especially 

        useful when combined with traditional methods of accessing images by text 

        data. </p>

      <p class="normal">Content-based image retrieval (CBIR), a computer-derived 

        technique for retrieving images based on elements such as color, texture, 

        and shape, uses features of a selected painting, print, drawing, or object 

        to find visually similar images. CBIR locates matches in a collection 

        regardless whether they share key words with the original image.</p>

      <p class="normal"><b><i>Collage</i></b>, the Corporation of London Guildhall 

        Library and Guildhall Art Gallery online digital collection, was selected 

        as a test site for the application and evaluation of CBIR. The web version 

        of <b><i>Collage</i></b> comprises over 22,400 images of London from the 

        15<sup>th</sup> century to the present and includes paintings, drawings, 

        sculptures, maps, and other images.</p>

      <p class="normal">The Institute for Image Data Research (IIDR) at the University 

        of Northumbria at Newcastle; iBase Image Systems, developer of the original 

        <b><i>Collage</i></b> software; and the Corporation of London Guildhall 

        Library and Guildhall Art Gallery collaborated to introduce CBIR technology 

        for image retrieval on the <b><i>Collage</i></b> site. This endeavor is 

        part of an on-going two-year research project based in the IIDR and funded 

        by Resource: The Council for Museums, Archives and Libraries (formerly 

        the Library and Information Commission).</p>

      <p class="normal">This paper explains the procedures required to integrate 

        content-based image retrieval within a museum&#39;s established online image 

        collection. The collaborative partnership is described, content-based 

        image retrieval (CBIR) is discussed, technical requirements and constraints 

        are outlined, preliminary results of the user evaluation are reported, 

        and future developments to the <b><i>Collage</i></b> site with application 

        to similar collections are delineated. </p>

      <h1>Museum, Business, and Education Collaboration: Forming a Partnership</h1>

      <p class="normal">The objective of the project, funded by Resource: The Council 

        for Museums, Archives and Libraries (<a href="http://www.resource.gov.uk/" target="new">http://www.resource.gov.uk</a>) 

        is to apply content-based image retrieval software in an operational setting 

        and evaluate its effectiveness. Several considerations were made regarding 

        selection of a site and its associated partners. Of critical importance 

        was selecting an organization possessing a digitized image collection 

        comprised of 10,000 or more images, a progressive outlook toward information 

        retrieval, and the willingness to adopt new technology. Since technical 

        expertise must be shared between a commercial business, iBase, and a university 

        research institute, IIDR, it is also important to establish a relationship 

        based on shared goals, shared outcomes, and trust. Confidentiality agreements 

        may be required and consensus regarding credit or acknowledgement of contributions 

        of partners must be agreed. </p>

      <p class="normal">It is essential that each collaborator benefit from the 

        partnership. In this instance, the Guildhall enhances their reputation 

        by offering advanced search capabilities. Demographic information supplied 

        by visitors to the questionnaire provides the Guildhall with a profile 

        that helps their staff meet client needs and assist in directing services 

        and products. Importantly, the Guildhall, a non-profit organization, does 

        not incur expenses for application of the enhanced retrieval feature, 

        conducting demographic research, evaluation of the system, and subsequent 

        analyses. Expenses incurred are shared between the Institute for Image 

        Data Research and iBase, freeing the Guildhall resources to accomplish 

        their original mission.</p>

      <p class="normal">Information collected regarding the users&#39; assessment of 

        <b><i>Collage</i></b> and content-based image retrieval provides essential 

        information for the Institute for Image Data Research and iBase Image 

        Systems as they develop and evaluate software to refine search retrieval 

        and apply software to other collections. Research such as this is important 

        to the future of information retrieval and the development of sophisticated 

        software such as that used by the Guildhall Library. </p>

      <h1>The Corporation of London Guildhall Library and Guildhall Art Gallery 

        and <i>Collage</i></h1>

      <p class="normal">The original medieval library at the London Guildhall was 

        founded in the 1420s through the will of Richard Wittington. The modern 

        institution dates from 1824 and is divided into three sections, the Print 

        Room, the Guildhall Library, and the Guildhall Art Gallery. The Guildhall 

        Art Gallery houses over 4,000 paintings of which approximately 250 are 

        exhibited at any one time in the newly renovated £83,000,000 facility. 

        Together, the collections from the Print Room and the Guildhall Art Gallery 

        present an extensive and comprehensive view of London and the foundation 

        for <b><i>Collage</i></b>.</p>

      <p class="normal">The collection includes paintings, engravings, maps, photographs, 

        prints, and drawings of which most, but not all, relate to London. The 

        majority of prints and drawings include topographical views of London 

        from the 17th to the 20th centuries. Extensive collections of satirical 

        prints, panoramas, and images relate to social themes. An unrivalled collection 

        of London maps dating from the 16th century to the present includes parish, 

        ward, borough, and thematic maps. Visitors to the Print Room have access 

        to a local database containing images and information on 36,000 items. 

        Due to copyright restrictions, visitors to <b><i>Collage</i></b>, the 

        web database, have access to 22,400 of the total 36,000 images. The application 

        described in this paper uses images exclusively from the web-based version 

        of the <b><i>Collage </i></b>database. </p>

      <p class="normal"><b><i>Collage </i></b>(Corporation of London Art Gallery 

        Electronic), conceived in 1995 as an ambitious project to digitize the 

        collection of the London Guildhall Library, resulted in a database in 

        1997 containing 36,200 works with associated text and indexing information. 

        Phase two of the project delivered public access within the library via 

        a simple user interface. This in-house database was translated onto the 

        Internet at the end of 1998, producing the site at <a href="http://collage.nhil.com/">http://<b><i>Collage</i></b>.nhil.com</a>. 

      </p>

      <p class="normal">At the time, <b><i>Collage</i></b> was the largest digital 

        imaging project in Europe and faced many technical and curatorial challenges. 

        These were successfully solved, leading the way for other organizations 

        in the UK heritage sector to adopt similar systems.</p>

      <h1>iBase</h1>

      <p class="normal">iBase Image Systems was formed in 1992, as the result of 

        collaboration between the founding directors and the National Museum of 

        Film Photography &amp; Television to provide an image database for an 

        early photographic collection of 1920s racing cars for Zoltan Glass. iBase 

        developed a revolutionary hard disk solution at a time when the average 

        hard disk was only 100MB and PC graphics cards could only handle 800 x 

        600 pixels with 16 colors. The solution was adopted by other UK heritage 

        institutions, including the British Library, the Natural History Museum, 

        as well as others. iBase, catering to diverse requirements in the heritage 

        sector, has provided the software for <b><i>Collage</i></b> since its 

        inception, working closely with the London Guildhall Library to provide 

        technical expertise to achieve their vision of a progressive database 

        system. </p>

      <h1>Institute for Image Data Research</h1>

      <p class="normal">The University of Northumbria, based in Newcastle upon Tyne 

        in the Northeast of England, was initially founded in 1969 as Newcastle 

        Polytechnic and achieved university status in 1992. Approximately 23,000 

        students and 800 academic staff are based in arts; engineering, science 

        and technology; health, social work, and education; social sciences; and 

        business. </p>

      <p class="normal">The Institute for Image Data Research (IIDR), established 

        in 1997 as a multidisciplinary research institute, integrates researchers 

        from computing, information and library management, psychology, art history, 

        philosophy, fashion, business and management, and engineering to investigate 

        relationships between images, computer technology, and people. Research 

        has investigated aspects of image retrieval and how people search for, 

        retrieve, and use images; impact of digital images on art historians; 

        developing and testing software for retrieving trademark and historic 

        watermark images; and assessing the feasibility of applying content-based 

        image retrieval software in a variety of applications such as the one 

        described in this paper. Additional information about the Institute is 

        provided on the web at <a href="http://www.unn.ac.uk/iidr" target="new">http://www.unn.ac.uk/iidr</a>.</p>

      <h1>Content-Based Image Retrieval</h1>

      <p class="normal">The term, content-based image retrieval (CBIR), appears 

        in literature as early as 1992 when Kato described his experiments to 

        automatically retrieve images from a database by color and shape. Since 

        then, the term has been widely used to describe the process of retrieving 

        images from a large collection on the basis of features such as color, 

        visual texture, shape, structure, and line that are automatically detected 

        from images themselves. Retrieval of images by keywords, subject descriptors, 

        or indexing terms is not CBIR, even if the keywords describe the content 

        of the image. </p>

      <p class="normal">Image databases differ fundamentally from text databases. 

        Computer files of images are essentially unstructured since they consist 

        purely of arrays of pixel intensities with no inherent meaning. Consequently, 

        it is important to extract useful information from the pixels; i.e., recognizing 

        the presence of particular shapes or textures before further computer 

        processing. Once that is accomplished, images are then mathematically 

        characterized and mathematically compared to one another to determine 

        their visual similarity. However, in text databases, raw data are words 

        stored as ASCII character strings that have been logically structured 

        by the indexer (Santini &amp; Jain, 1997). </p>

      <p class="normal">Research and development issues in CBIR cover a range of 

        topics, many of which are shared with traditional image processing and 

        information retrieval. These include: (a) understanding image users&#39; needs 

        and information-seeking behavior, (b) identification of suitable ways 

        of describing image content, (c) matching query and stored images in a 

        way that reflects human similarity judgments, and (d) providing usable 

        human interfaces to CBIR systems. A detailed review of CBIR is provided 

        by Eakins and Graham (1999).<a name="_Ref440361908"></a><a name="_Toc442192677"></a></p>

      <p class="normal"><span><u>Characteristics of Image Queries</u></span><u></u></p>

      <p class="normal">The kinds of queries users are likely to put to an image 

        database are affected by user needs; why they seek images, their use of 

        images, and how they judge the usefulness of the images retrieved. Although 

        results are limited in this area, research at IIDR suggest there are seven 

        discernable classes of image use which include illustration, information 

        processing, information dissemination, learning, generation of ideas, 

        aesthetic value, emotive/persuasive, and scalar attributes (Conniss, Ashford, 

        &amp; Graham, 2000).</p>

      <p class="normal">Access to a desired image from a repository might thus involve 

        a search for images depicting specific types of objects or scenes evoking 

        a particular mood, or simply containing a specific texture or pattern. 

        Potentially, images have many attributes that could be used for retrieval, 

        including: (a) presence of a particular combination of color, texture, 

        or shape features (e.g., green sparkling stars); (b) presence or arrangement 

        of specific types of objects (e.g., chairs around a table); (c) depiction 

        of a particular type of event (e.g., a football match); (d) presence of 

        named individuals, locations, or events (e.g., a celebrity greeting a 

        crowd); (e) subjective emotions one might associate with the image (e.g., 

        happiness); and (f) metadata such as who created the image, where it was 

        created, and when it was created. Each successive query type with the 

        exception of the last, represents a higher level of abstraction than its 

        predecessor, and each is progressively more difficult to satisfy. This 

        leads to a classification of query types into three levels of increasing 

        complexity (Eakins, 1998).</p>

      <h1>Classification of Search Queries</h1>

      <p class="normal">Classification of query types can be useful in illustrating 

        the strengths and limitations of different image retrieval techniques. 

        This was important in this application when selecting software for application 

        in this project. </p>

      <p class="normal">Level 1 comprises retrieval by features such as color, texture, 

        and shape or the spatial location of image elements. These are known as 

        primitive features. Examples of such queries might include &#34;find pictures 

        with long thin dark objects in the top left-hand corner,&#34; &#34;find images 

        containing yellow stars arranged in a ring,&#34; or more commonly, &#34;find more 

        pictures that look like this.&#34; This level of retrieval uses features, 

        such as a given shade of yellow, that are both objective and directly 

        derivable from the images themselves. Its use is largely limited to specialist 

        applications such as trademark registration, identification of drawings 

        in a design archive, or color matching of fashion accessories. </p>

      <p class="normal">Level 2 comprises retrieval by derived features, sometimes 

        known as logical features, that involve some degree of logical inference 

        about the identity of the objects depicted in the image. It can be divided 

        further into: (a) objects of a given type (e.g., &#34;find pictures of a double-decker 

        bus&#34;), and (b) individual objects or persons (e.g., &#34;find a picture of 

        the Eiffel Tower&#34;). To answer queries at this level, reference to additional 

        knowledge beyond the image itself is normally required, particularly for 

        more specific queries at level 2(b). In the first example, 2(a), some 

        prior knowledge is necessary to identify an object as a bus rather than 

        a truck. In the second example, one needs knowledge that a given structure 

        has a given name &#34;the Eiffel Tower&#34;. Search criteria at this level, particularly 

        at level 2(b), are reasonably objective. Generally, this level of query 

        is encountered more than level 1. For example, most queries received by 

        newspaper picture libraries generally fall in this category (Enser, 1995).</p>

      <p class="normal">Level 3 comprises retrieval by abstract attributes involving 

        a significant amount of high-level reasoning about the meaning and purpose 

        of the objects or scenes depicted. Again, this level of retrieval can 

        be subdivided into (a) retrieval of named events or types of activity 

        (e.g., &#34;find pictures of Scottish folk dancing&#34;) and (b) retrieval of 

        pictures with emotional or religious significance (e.g., &#34;find a picture 

        depicting suffering&#34;). Success in answering queries at this level may 

        require sophistication by the searcher. Complex reasoning, and often subjective 

        judgement, may be necessary to make the link between image content and 

        the abstract concepts represented. Queries at this level are often encountered 

        in both newspaper (perhaps less common than level 2) and art libraries, 

        such as those similar to <b><i>Collage</i></b>. </p>

      <p class="normal">Presently, the most significant gap between the classification 

        levels lies between levels 1 and 2. Many authors (Gudivada &amp; Raghavan, 

        1995) refer to levels 2 and 3 together as &#34;semantic image retrieval,&#34; 

        and hence the gap between levels 1 and 2 as the &#34;semantic gap.&#34; However, 

        it should be noted this classification ignores a further type of image 

        query, retrieval by associated metadata such as who created the image 

        and where and when it was created. This is not because such retrieval 

        is unimportant. It is especially important to museum collections. However, 

        such metadata is exclusively textual and its management is primarily a 

        text-retrieval issue.</p>

      <h1>Technical Application of CBIR to the <i>Collage</i> Web Site</h1>

      <h1>User Requirements and Development Criteria</h1>

      <p class="normal">Application of content-based image retrieval software to 

        the web-based version of <b><i>Collage </i></b>required a smooth transition 

        with no confusion to users and no disruption to the standard web-based 

        services. Additionally, it was important to: (a) establish use of CBIR 

        as voluntary, (b) provide a simple mechanism for users to test CBIR within 

        the <b><i>Collage</i></b> web site, (c) allow users the option to specify 

        preferences on search parameters, (d) return results of the CBIR search 

        in a format familiar to <b><i>Collage</i></b> users, (e) encourage users 

        to complete the online questionnaire, and (f) develop a system that would 

        work with common browsers. Development of the site also imposed technical 

        considerations and constraints: (a) Regular activities of the London Guildhall 

        Library could not be disrupted by the project; (b) service of the <b><i>Collage</i></b> 

        site could not be adversely impacted during CBIR software application; 

        (c) performance of the <b><i>Collage</i></b> site could not be diminished 

        by introduction of CBIR; and (d) the user interface had to be independent 

        of the CBIR software allowing different types of CBIR software to be applied 

        and tested throughout the duration of the project.</p>

      <h1>System Design</h1>

      <p class="normal">Application of the CBIR software to the computer system 

        comprised of five integrated stages consisting of creating the database, 

        developing the interface to initiate the CBIR search, conducting the CBIR 

        search, displaying results of the CBIR search, and developing the questionnaire. 

        General testing of the site was simplified because of the modular architecture 

        of the computer system. Components could be developed and tested before 

        integrating the complete system (Figure 1). </p>

      <p class="MsoCaption" align="center"><img src="ward.fig1.jpg" width="338" height="543" alt="Figure 1. Logical design of the CBIR/Collage system illustrating distribution of processing between the Collage website and the Institute for Image Data Research at the University of Northumbria at Newcastle. "/></p>

      <p class="MsoCaption"><u>Figure 1.</u> Logical design of the CBIR/<i>Collage</i> 

        system illustrating distribution of processing between the <i>Collage</i> 

        website and the Institute for Image Data Research at the University of 

        Northumbria at Newcastle. </p>

      <h1>Creating the Database</h1>

      <p class="normal">Each image had three data fields, the identification number, 

        feature vector length, and feature vector data, which is described in 

        more detail in the next section. Although the entire <b><i>Collage</i></b> 

        database consists of over 36,000 images which is used within the London 

        Guildhall on its in-house computer system, due to copyright restrictions, 

        only 22,400 images are used on the web database. Consequently, it was 

        necessary to develop the database to filter out any non-copyrighted images. 

      </p>

      <h1>Designing the Interface to Initiate the CBIR Search</h1>

      <p class="normal">The first content-based image retrieval software package 

        used in this project is from Virage<span>Ò</span> Incorporated and includes 

        the VIR Image Engine<span>ä</span> 2.5, Virage<span>Ò</span> Core Library 

        2.1, and the Image Read/Write Toolkit 1.6. The software is embedded into 

        the <b><i>Collage</i></b> system to perform two functions, image analysis 

        and image comparison. </p>

      <p class="normal">Image analysis is executed only once for the entire image 

        database resulting in feature vector information, a mathematical representation 

        of the visual content of an image. Image comparison involves assessing 

        two feature vectors resulting in a score that quantifies image characteristics. 

        Sizes of the feature vectors vary slight but are approximately 1.3 KB 

        for each image, producing a database of over 44 MB for all of the images, 

        and taking several hours to generate.</p>

      <p class="normal">In order not to affect the general performance of <b><i>Collage</i></b>, 

        it was decided to place the CBIR engine on a second server. This removed 

        a heavy processing load away from the main <b><i>Collage</i></b> database, 

        which is maintained exclusively by iBase, and shifting the maintenance 

        and monitoring of the CBIR segment to the Institute for Image Data Research. 

        Since it is imperative that both systems function compatibly; close communication 

        between the IIDR and iBase regarding day-to-day systems management is 

        maintained.</p>

      <h1>Conducting the CBIR Search</h1>

      <p class="normal">In order to activate content-based image retrieval on the 

        <b><i>Collage</i></b> site, the user must begin with the traditional <b><i>Collage</i></b> 

        search mechanism. A word must be entered in the search box or one of several 

        search categories must be selected. When results are returned, the user 

        may select a single image for closer inspection and conduct a &#34;Standard 

        Visual Search&#34; or an &#34;Advanced Visual Search&#34; (Figure 2).</p>

      <p class="MsoCaption" align="center"><img src="ward.fig2.JPG" width="504" height="647" alt="Figure 2. A Standard Visual Search or an Advanced Visual Search may be conducted once a specific image has been selected from a Collage traditional search."/></p>

      <p class="MsoCaption"><u>Figure 2.</u> A &#34;Standard Visual Search&#34; or an &#34;Advanced 

        Visual Search&#34; may be conducted once a specific image has been selected 

        from a <i>Collage</i> traditional search. </p>

      <p class="normal">When a user conducts a &#34;Standard Visual Search,&#34; search 

        parameters are set at default values. Color is set at 1, visual texture 

        at 60, and shape or structure (in the case of Virage<span>Ò</span>) at 

        30 out of a possible 100 for each component. The Virage<span>Ò</span> 

        system requires that each parameter must be set at a value greater than 

        0. Testing of the &#34;Standard Visual Search&#34; determined optimum values for 

        producing the most desirable matches. </p>

      <p class="normal">When an &#34;Advanced Visual Search&#34; is conducted, the user 

        ranks &#34;colors in the image,&#34; &#34;visual texture in the image,&#34; and &#34;shapes 

        in the image&#34; on a five-point Likert-type scale indicating the characteristic 

        as &#34;not at all important&#34; to &#34;very important&#34; (Figure 3). Values are assigned 

        to each button on the scale with &#34;not at all important&#34; set at 1, and 

        subsequent buttons set at 20, 40, 60, and 80, respectively. When CBIR 

        is initiated, the identification number (ID) and feature vector data of 

        the selected image are read. Data for all images in the database are also 

        read, and using Virage<span>Ò</span> routines, a similiarity measure is 

        produced and stored, together with the ID for recall later. Searching 

        all the images and producing the results takes about 10 seconds. </p>

      <p class="MsoCaption" align="center"><img src="ward.fig3.jpg" width="588" height="702" alt="Figure 3. Parameters for the Advanced Visual Search are selected by the user who indicates their preferences regarding the importance of color, visual texture, and shape. "/></p>

      <p class="MsoCaption"><u>Figure 3.</u> Parameters for the &#34;Advanced Visual 

        Search&#34; are selected by the user who indicates their preferences regarding 

        the importance of color, visual texture, and shape. </p>

      <h1>Displaying Results of the CBIR Search</h1>

      <p class="normal">At the end of conducting a CBIR search, measures for the 

        entire <b><i>Collage</i></b> database are sorted in ascending order. However, 

        only the first 18 images are collected for potential viewing. Although 

        18 images are returned, only 8 in addition to the original image are displayed. 

        Because the database contains over 10,000 images for which the London 

        Guildhall Library does not hold the copyright, those images are excluded 

        from transmission over the web. A surplus of images insures a sufficient 

        amount when non-copyrighted images are eliminated. Additionally, because 

        <b><i>Collage</i></b> displays 9 images with its traditional searches, 

        it was decided that the CBIR results page should use the same 9 image-format 

        (Figure 4.) </p>

      <p class="MsoCaption" align="center"><i><img src="ward.fig4.jpg" width="605" height="837" alt="Figure 4.  Results of the search are displayed using a gallery format similar to the tradition Collage gallery."/></i></p>

      <p class="MsoCaption"><u>Figure 4. </u> Results of the search are displayed 

        using a gallery format similar to the tradition <i>Collage</i> gallery.</p>

      <h1>Developing the Questionnaire</h1>

      <p class="normal">While the technical system was constructed, the questionnaire 

        was developed. The questionnaire, only accessible after using the CBIR 

        function, was designed to assess information useful to all three collaborators. 

        Questions regarding the CBIR function including usefulness of the feature, 

        satisfaction with the results, and enjoyment of the experience were devised. 

        Additional questions were developed to collect data regarding general 

        use of the web and the <b><i>Collage</i></b> service, along with demographic 

        information about the users. Format of the questionnaire, designed to 

        match the original <b><i>Collage</i></b> site was tested on browsers to 

        ensure compatibility on alternate systems. The questionnaire was pilot 

        tested with a panel of experts and questions revised before the final 

        instrument was integrated into the <b><i>Collage</i></b> web site. </p>

      <p class="normal">Data collection commenced in November and recruitment to 

        the site was initiated in December through University classes. Data will 

        be collected throughout the 2001. However, preliminary responses to the 

        introduction of CBIR on the <b><i>Collage</i></b> web indicate interesting 

        trends. </p>

      <h1>Preliminary Results of the Questionnaire</h1>

      <p class="normal">By mid-January, the 31 visitors to the site had completed 

        the questionnaire. They consisted of 11 males (36%) and 14 females (45%). 

        Age was fairly well distributed between the categories of 16-25 at 13%, 

        26-35 at 23%, and 36-45 and 46-55, both at 16%. Educational categories 

        most frequently reported by the users as their highest level of achievement 

        was &#34;degree&#34; and &#34;masters&#34; with 26% and 29% of the respondents, respectively. 

        Most individuals were employed fulltime (32%) whereas 26% were students 

        and most were UK residents (81%). It should be noted that most questions 

        had some non-responses. </p>

      <p class="normal">Half of the 31 respondents indicated this was their first 

        time to use the visual image search on <b><i>Collage</i></b>, whereas 

        10 of the respondents reported using the feature two or more times. The 

        majority of the users (74%) reported they would like to use the feature 

        again with almost 71% responding they would use it &#34;sometimes,&#34; &#34;often,&#34; 

        or &#34;always&#34;. </p>

      <p class="normal">Respondents indicated that over one-half (52%) of the images 

        retrieved by the CBIR software were good matches to the original, whereas 

        nearly 31% of the images were not. Interestingly, over 45% of the users 

        &#34;agreed&#34; or &#34;strongly agreed&#34; that results of the search met their expectations. 

        The same percentage &#34;strongly agreed&#34; results were useful and were satisfied 

        with what was retrieved. Over one-third of the users found what they wanted 

        by using the visual search.</p>

      <p class="normal">Nearly three-fourths of the respondents &#34;agreed&#34; or &#34;strongly 

        agreed&#34; that results of the search were interesting and they would like 

        to use the visual search again. Although 58% of the users responded the 

        visual image search was a good method of retrieving images, nearly one-third 

        responded negatively or &#34;neither agreed nor disagreed&#34; with the statement. 

      </p>

      <p class="normal">Almost 75% of the users &#34;agreed&#34; or &#34;strongly agreed&#34; the 

        search was fast and easy to use. Interestingly, 39% of the respondents 

        liked the visual search better than a word search and 39% were ambivalent 

        (&#34;neither agree nor disagree&#34;). Only three respondents provided a negative 

        rating of this item.</p>

      <p class="normal">Approximately the same percentage of users (42%) &#34;agreed&#34; 

        the search was fun to use as compared to the percentage who &#34;strongly 

        disagreed,&#34; &#34;disagreed,&#34; and &#34;neither agreed nor disagreed.&#34; Clearly, 

        reaction is mixed; however, none of the respondents indicated they &#34;strongly 

        agreed&#34; with the statement that the search was fun to use.</p>

      <p class="normal">About half of the respondents had visited the <b><i>Collage</i></b> 

        site before. Approximately 40% were told about the site, whereas 16% found 

        it by accident. Several, 42%, visited the <b><i>Collage</i></b> site to 

        browse. However over 45% were there to look for a particular print or 

        research the art collection. </p>

      <h1>Future Development and Application</h1>

      <p class="normal">Research regarding enhanced search capabilities, such as 

        content-based image retrieval, is important to the future of information 

        retrieval and the development of sophisticated software such as that used 

        by the London Guildhall Library and Art Gallery and other museums, libraries, 

        archives, and cultural heritage organizations. Growing collections necessitate 

        image retrieval technology that expands search capability beyond traditional 

        word-based indexing. However, there is much room for improvement and advancement. 

      </p>

      <p class="normal">For example, a hierarchical CBIR search initiated with a 

        small number of images that have very different characteristics would 

        allow the user to meander through the collection based only on visual 

        criteria. This would provide search capabilities that would expand the 

        breadth and depth of the returned images instead of being a linear exploration. 

        Additionally, using CBIR technology on specific areas of an image to extract 

        particular elements of an image would be an equally exciting advance, 

        as well as a useful development. </p>

      <p class="normal">CBIR may be also used to aid indexing of large collections, 

        particularly for subjective terms which would greatly benefit the heritage 

        sector. While digitization is a significant cost of any project, cataloguing 

        and indexing of the resultant images is often equally costly. Speeding 

        up and simplifying this process by identification of similar images is 

        an attractive proposition, although it would require a detailed study 

        to deliver a practical solution. </p>

      <p class="normal">With respect to the <b><i>Collage</i></b> site and the introduction 

        of CBIR, several enhancements can be made. Increasing the number of returned 

        images from the CBIR search will provided users to peruse a greater selection 

        of items. Allowing the user to conduct consecutive CBIR searches will 

        allow the individual to refine the search experience. </p>

      <h1>References</h1>

      <p class="ReferencesText">Conniss, L. R, Ashford, A. J., &amp; Graham, M. 

        E. (2000). Information seeking behaviour in image retrieval: VISOR I final 

        report. (Library and Information Commission Research Report 95). Newcastle-upon-Tyne, 

        United Kingdom: University of Northumbria at Newcastle, Institute for 

        Image Data Research </p>

      <p class="ReferencesText">Eakins, J. P. (1998). Techniques for image retrieval. 

        <u>Library and Information Briefings, 85,</u> London: South Bank University.</p>

      <p class="ReferencesText">Eakins, J. P., &amp; Graham, M. E . (1999). <u>Content-based 

        image retrieval</u> (A report to the JISC Technology Applications Programme). 

        Newcastle upon Tyne, United Kingdom: University of Northumbria at Newcastle, 

        Institute for Image Data Research.</p>

      <p class="ReferencesText">Enser, P. G. B. (1995). Pictorial information retrieval. 

        <u>Journal of Dcoumentation, 51</u>(2), 126-170.</p>

      <p class="ReferencesText">Gudivada, V. N. and Raghavan, V. V. (1995). Content-based 

        image retrieval systems. <u>IEEE Computer, 28</u>(9), 18-22.</p>

      <p class="ReferencesText">Kato, T. (1992). Database architecture for content-based 

        image retrieval. <u>Proceedings of the International Society of Optical 

        Engineering, USA, 3846,</u> 112-123.</p>

      <p class="ReferencesText">Santini, S. &amp; Jain, R. S. (1997). The graphical 

        specification of similarity queries. <u>Journal of Visual Languages and 

        Computing, <b>7</b>,</u> 403-421</p>

      <!-- #EndEditable --></td>
  </tr>
</tbody></table>
<!--htdig_noindex-->

<!-- analytics scripts -->
<!-- tynt script -->
<script type="text/javascript">tyntVariables = {"ap":"Read more: "};</script> 
<script type="text/javascript" src="http://tcr.tynt.com/javascripts/Tracer.js?user=aTNeQ-tzOr36a6adbiUzgI&amp;s=130&amp;cc=6&amp;st=1"></script>
<noscript></noscript>

<!-- google analytics script -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26332456-1']);
  _gaq.push(['_setDomainName', '.archimuse.com']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!--chartbeat script -->
<script type="text/javascript">
var _sf_async_config={uid:3385,domain:"archimuse.com"};
(function(){
  function loadChartbeat() {
    window._sf_endpt=(new Date()).getTime();
    var e = document.createElement('script');
    e.setAttribute('language', 'javascript');
    e.setAttribute('type', 'text/javascript');
    e.setAttribute('src',
       (("https:" == document.location.protocol) ? "https://s3.amazonaws.com/" : "http://") +
       "static.chartbeat.com/js/chartbeat.js");
    document.body.appendChild(e);
  }
  var oldonload = window.onload;
  window.onload = (typeof window.onload != 'function') ?
     loadChartbeat : function() { oldonload(); loadChartbeat(); };
})();

</script>

<!--/htdig_noindex-->







</body><!-- #EndTemplate --><!-- Mirrored from www.museumsandtheweb.com/mw2001/papers/ward/ward.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 17:48:50 GMT --></html>