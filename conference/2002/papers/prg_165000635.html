<html><!-- #BeginTemplate "/Templates/mw2002-papers.dwt" --><!-- DW6 --><!-- Mirrored from www.museumsandtheweb.com/mw2002/papers/woodruff/woodruff.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 17:46:50 GMT --><head>
<!-- #BeginEditable "doctitle" -->

	<title>MW2002: Papers: Eavesdropping on Electronic Guidebooks: Observing Learning Resources in Shared Listening Environments</title>

	<meta http-equiv="Content-Type" content="text/html; charset=en"/>

	<meta name="DC.Format" content="text/html"/>

	<meta name="DC.language" content="ISO 8859-1"/>

	<meta name="DC.Title" content="Eavesdropping on Electronic Guidebooks: Observing Learning Resources in Shared Listening Environments"/>

	<meta name="htDig.keywords" content="electronic guidebook, share audio information, visitors

studies, visitor interaction, learning resources "/>

	<meta name="keywords" content="electronic guidebook, share audio information, visitors

studies, visitor interaction, learning resources "/>

	<meta name="DC.Subject" content="electronic guidebook, share audio information, visitors

studies, visitor interaction, learning resources "/>

	<meta name="description" content="We describe an electronic guidebook, Sotto Voce, that enables visitors to share audio information by eavesdropping on each other?s guidebook activity.  We have conducted three studies of visitors using electronic guidebooks in a historic house: one study with open air audio played through speakers and two studies with eavesdropped audio.  An analysis of visitor interaction in these studies suggests that eavesdropped audio provides more social and interactive learning resources than open air audio played through speakers.



Sotto Voce runs on handheld computers that include a color LCD touchscreen display. Individual visitors obtain information about objects in their environment using a visual interface that resembles a set of Web browser imagemaps. The visitor sees a single photographic imagemap that depicts one wall of a room in a museum or historic house; visitors can choose which imagemap to display at a given time. When visitors tap on an imagemap target, the guidebook plays an audio clip that describes that object.



In previous experiments with the guidebook, visitors liked sharing descriptions by playing audio through speakers of the device. However, this solution is noisy and generally unsuitable for public settings. Therefore, we have developed a new prototype that uses wireless local-area networking to allow paired visitors to share audio content. Each visitor is able to eavesdrop on their companion&#39;s guidebook, using a special volume control. With this design, each person can operate their own guidebook and choose the descriptions they want to listen to, while preserving the ability to listen to descriptions synchronously with their companion. To facilitate conversation, Sotto Voce uses single-ear headsets that leave one ear available to hear sounds from the external environment. Since we use single-ear headsets, both personal and eavesdropped audio content are necessarily presented in the same ear.  We distinguish the two types of content using reverberation and volume differentiation.



Sotto Voce has been tested in several rooms at Filoli, a historic house in Woodside, California. Our most recent study included 47 members of the general public, who were observed in situ, interviewed, and monitored by video and audio recording and logging of guidebook activity. Our evaluation includes affinity clustering of interview data and the use of conversation analytic techniques. The results indicate that visitors are able to use the system effectively, both as a conversational resource and as an information source. Visitors who listen to audio together typically assign Sotto Voce a role in their conversations, verbally responding to it and treating it like a human storyteller. This promotes visitor interaction while preserving each visitor&#39;s ability to select individual objects. Further, our results suggest that the technologically mediated audio often coheres the visitors&#39; conversation and activity to a far greater degree than audio delivered through open air via speakers."/>

	<meta name="DC.Description" content="We describe an electronic guidebook, Sotto Voce, that enables visitors to share audio information by eavesdropping on each other?s guidebook activity.  We have conducted three studies of visitors using electronic guidebooks in a historic house: one study with open air audio played through speakers and two studies with eavesdropped audio.  An analysis of visitor interaction in these studies suggests that eavesdropped audio provides more social and interactive learning resources than open air audio played through speakers.



Sotto Voce runs on handheld computers that include a color LCD touchscreen display. Individual visitors obtain information about objects in their environment using a visual interface that resembles a set of Web browser imagemaps. The visitor sees a single photographic imagemap that depicts one wall of a room in a museum or historic house; visitors can choose which imagemap to display at a given time. When visitors tap on an imagemap target, the guidebook plays an audio clip that describes that object.



In previous experiments with the guidebook, visitors liked sharing descriptions by playing audio through speakers of the device. However, this solution is noisy and generally unsuitable for public settings. Therefore, we have developed a new prototype that uses wireless local-area networking to allow paired visitors to share audio content. Each visitor is able to eavesdrop on their companion&#39;s guidebook, using a special volume control. With this design, each person can operate their own guidebook and choose the descriptions they want to listen to, while preserving the ability to listen to descriptions synchronously with their companion. To facilitate conversation, Sotto Voce uses single-ear headsets that leave one ear available to hear sounds from the external environment. Since we use single-ear headsets, both personal and eavesdropped audio content are necessarily presented in the same ear.  We distinguish the two types of content using reverberation and volume differentiation.



Sotto Voce has been tested in several rooms at Filoli, a historic house in Woodside, California. Our most recent study included 47 members of the general public, who were observed in situ, interviewed, and monitored by video and audio recording and logging of guidebook activity. Our evaluation includes affinity clustering of interview data and the use of conversation analytic techniques. The results indicate that visitors are able to use the system effectively, both as a conversational resource and as an information source. Visitors who listen to audio together typically assign Sotto Voce a role in their conversations, verbally responding to it and treating it like a human storyteller. This promotes visitor interaction while preserving each visitor&#39;s ability to select individual objects. Further, our results suggest that the technologically mediated audio often coheres the visitors&#39; conversation and activity to a far greater degree than audio delivered through open air via speakers."/>

	<meta name="DC.Publisher" content="Archives &amp; Museum Informatics"/>

	<meta name="DC.Creator" content="Aoki, Paul M."/>

	<meta name="DC.Creator" content="Grinter, Rebecca E."/>

	<meta name="DC.Creator" content="Hurst, Amy"/>

	<meta name="DC.Creator" content="Szymanski, Margaret"/>

	<meta name="DC.Creator" content="Thornton, James"/>

	<meta name="DC.Creator" content="Woodruff, Allison"/>

<!-- #EndEditable --> 
<meta http-equiv="Content-Type" content="text/html; charset="/><!-- #BeginEditable "script" --><!-- #EndEditable -->
<script language="JavaScript">
<!--
function MM_swapImgRestore() { //v3.0
  var i,x,a=document.MM_sr; for(i=0;a&&i<a.length&&(x=a[i])&&x.oSrc;i++) x.src=x.oSrc;
}

function MM_preloadImages() { //v3.0
  var d=document; if(d.images){ if(!d.MM_p) d.MM_p=new Array();
    var i,j=d.MM_p.length,a=MM_preloadImages.arguments; for(i=0; i<a.length; i++)
    if (a[i].indexOf("#")!=0){ d.MM_p[j]=new Image; d.MM_p[j++].src=a[i];}}
}

function MM_findObj(n, d) { //v4.01
  var p,i,x;  if(!d) d=document; if((p=n.indexOf("?"))>0&&parent.frames.length) {
    d=parent.frames[n.substring(p+1)].document; n=n.substring(0,p);}
  if(!(x=d[n])&&d.all) x=d.all[n]; for (i=0;!x&&i<d.forms.length;i++) x=d.forms[i][n];
  for(i=0;!x&&d.layers&&i<d.layers.length;i++) x=MM_findObj(n,d.layers[i].document);
  if(!x && d.getElementById) x=d.getElementById(n); return x;
}

function MM_swapImage() { //v3.0
  var i,j=0,x,a=MM_swapImage.arguments; document.MM_sr=new Array; for(i=0;i<(a.length-2);i+=3)
   if ((x=MM_findObj(a[i]))!=null){document.MM_sr[j++]=x; if(!x.oSrc) x.oSrc=x.src; x.src=a[i+2];}
}
//-->
</script>
<link rel="stylesheet" href="../../Library/mw2002-paper.css" type="text/css"/>
</head>

<body bgcolor="#FFFFFF" background="../../images/mw2002.bg.gif" text="#000000" link="#003399" vlink="#660000" onload="MM_preloadImages(&#39;../../images/register_on.gif&#39;,&#39;../../images/workshops_on.gif&#39;,&#39;../../images/sessions_on.gif&#39;,&#39;../../images/speakers_on.gif&#39;,&#39;../../images/interact_on.gif&#39;,&#39;../../images/demos_on.gif&#39;,&#39;../../images/exhibit_on.gif&#39;,&#39;../../images/events_on.gif&#39;,&#39;../../images/best_on.gif&#39;,&#39;../../images/dates_on.gif&#39;,&#39;../../images/boston_on.gif&#39;,&#39;../../images/sponsors_on.gif&#39;)">
<table width="600" border="0" cellspacing="2" cellpadding="5">
  <tbody><tr> 
    <td width="145" align="LEFT" valign="TOP"> 
      <p><a href="../../index.html"><img src="../../images/mw.gif" width="112" height="155" border="0" alt="/mw/"/></a></p>
      <p> <a href="../../register/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;register&#39;,&#39;&#39;,&#39;../../images/register_on.gif&#39;,1)"><img name="register" border="0" src="../../images/register_off.gif" width="114" height="18" alt="Register"/></a><a href="../../workshops/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;workshops&#39;,&#39;&#39;,&#39;../../images/workshops_on.gif&#39;,1)"><img name="workshops" border="0" src="../../images/workshops_off.gif" width="114" height="18" alt="Workshops"/></a><a href="../../sessions/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;sessions&#39;,&#39;&#39;,&#39;../../images/sessions_on.gif&#39;,1)"><img name="sessions" border="0" src="../../images/sessions_off.gif" width="114" height="18" alt="Sessions"/></a><a href="../../speakers/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;speakers&#39;,&#39;&#39;,&#39;../../images/speakers_on.gif&#39;,1)"><img name="speakers" border="0" src="../../images/speakers_off.gif" width="114" height="18" alt="Speakers"/></a><a href="../../interact/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;interactions&#39;,&#39;&#39;,&#39;../../images/interact_on.gif&#39;,1)"><img name="interactions" border="0" src="../../images/interact_off.gif" width="114" height="18" alt="Interactions"/></a><a href="../../demos/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;demonstrations&#39;,&#39;&#39;,&#39;../../images/demos_on.gif&#39;,1)"><img name="demonstrations" border="0" src="../../images/demos_off.gif" width="114" height="18" alt="Demonstrations"/></a><a href="../../exhibit/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;exhibits&#39;,&#39;&#39;,&#39;../../images/exhibit_on.gif&#39;,1)"><img name="exhibits" border="0" src="../../images/exhibit_off.gif" width="114" height="18" alt="Exhibits"/></a><a href="../../events/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;events&#39;,&#39;&#39;,&#39;../../images/events_on.gif&#39;,1)"><img name="events" border="0" src="../../images/events_off.gif" width="114" height="18" alt="Events"/></a><a href="../../best/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;best&#39;,&#39;&#39;,&#39;../../images/best_on.gif&#39;,1)"><img name="best" border="0" src="../../images/best_off.gif" width="114" height="18" alt="Best of the Web"/></a><a href="../../dates/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;dates&#39;,&#39;&#39;,&#39;../../images/dates_on.gif&#39;,1)"><img name="dates" border="0" src="../../images/dates_off.gif" width="114" height="18" alt="Key Dates"/></a><a href="../../boston/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;boston&#39;,&#39;&#39;,&#39;../../images/boston_on.gif&#39;,1)"><img name="boston" border="0" src="../../images/boston_off.gif" width="114" height="18" alt="Boston"/></a><a href="../../sponsor/index.html" onmouseout="MM_swapImgRestore()" onmouseover="MM_swapImage(&#39;sponsors&#39;,&#39;&#39;,&#39;../../images/sponsors_on.gif&#39;,1)"><img name="sponsors" border="0" src="../../images/sponsors_off.gif" width="114" height="18" alt="Sponsors"/></a><br/>
        <br/>
        <a href="../http://www.archimuse.com/" target="_top"><img src="../../images/nav_ami.gif" width="135" height="25" border="0" alt="A&amp;MI home"/></a> 
        <br/>
        <span class="small">Archives &amp; Museum Informatics<br/>
        158 Lee Avenue<br/>
        Toronto, Ontario<br/>
        M4E 2P3 Canada</span></p>
      <p class="small">info @ archimuse.com<br/>
        <a href="../http://www.archimuse.com/" style="text-decoration: underline">www.archimuse.com</a></p>
      <table width="74">
        <tbody><tr> 
          <td> <a href="../http://search.museumsandtheweb.com/search" target="_top"> <img src="../../images/search.gif" width="24" height="25" alt="Search" border="0" name="Search"/></a> 
          </td>
          <td valign="MIDDLE"> <a href="../http://search.museumsandtheweb.com/search" style="text-decoration: underline"> 
            <span class="verysmall">Search<br/></span></a> </td>
        </tr>
      </tbody></table>
      <p><font face="Arial, Helvetica, sans-serif" class="verysmall"><span class="small">Join 
        our <a href="../http://search.museumsandtheweb.com/mailinglist/" style="text-decoration: underline"> 
        Mailing List</a>. <br/>
        <a href="../http://search.museumsandtheweb.com/terms-of-use-privacy/" style="text-decoration: underline"> 
        Privacy</a>.</span></font> </p>
       <p><font size="-2" class="verysmall">published: April, 2002 </font>
        <!--

document.write("<FONT SIZE='-2' class='verysmall'>"+"analytics scripts updated: "+document.lastModified);

// -->
      </p>
   <p><font face="Arial, Helvetica, sans-serif" class="small">© Archives &amp; Museum Informatics, 2002.</font><br/>
  <a rel="license" href="../http://creativecommons.org/licenses/by-nc-nd/3.0/"><img src="../http://i.creativecommons.org/l/by-nc-nd/3.0/88x31.png" alt="Creative Commons Att
   ribution-Noncommercial-No Derivative Works 3.0  License" width="88" height="31" style="border-width:0"/></a>      </p>
    </td>
    <td width="455" align="LEFT" valign="TOP" class="normal">
      <p><a href="../../speakers/index.html"><img src="../../images/papers.gif" width="390" height="55" border="0" alt="MW2002: Papers"/></a></p>
     <!-- #BeginEditable "Body of Page" --> 

      <p class="PaperTitle">Eavesdropping on Electronic Guidebooks:<br/>

        Observing Learning Resources in Shared Listening Environments</p>

      <p class="Author">Allison Woodruff, Paul M. Aoki, Rebecca E. Grinter, Amy 

        Hurst, Margaret H. Szymanski, and James D. Thornton, Xerox Palo Alto Research 

        Center, USA</p>

      <p class="AbstractTitle">Abstract</p>

      <p class="AbstractText">We describe an electronic guidebook, <i>Sotto Voce</i>, 

        that enables visitors to share audio information by eavesdropping on each 

        other’s guidebook activity.  We have conducted three studies of visitors 

        using electronic guidebooks in a historic house: one study with open air 

        audio played through speakers and two studies with eavesdropped audio.  

        An analysis of visitor interaction in these studies suggests that eavesdropped 

        audio provides more social and interactive learning resources than open 

        air audio played through speakers.</p>

      <h1>Introduction</h1>

      <p>Previous research suggests that users of electronic guidebooks prefer 

        <i>open air audio</i> delivered through speakers to audio delivered through 

        a headset (see, e.g., Kirk, 2001; Woodruff, Aoki, Hurst, &amp; Szymanski, 

        2001).  The well-known visitor desire for social interaction (Hood, 1983) 

        is a key reason for this preference: when visitors use open air audio, 

        they can listen to content together and discuss it, whereas headsets often 

        isolate visitors into experiential “bubbles” (Martin, 2000).  

        However, open air audio is problematic when many visitors are present 

        in the same location, as has been confirmed by informal experiments conducted 

        by commercial audio guide vendors (L. Mann, Antenna Audio, personal communication).</p>

      <p>We describe an alternative mechanism for sharing audio.  This mechanism, 

        which we call <i>eavesdropping</i>, preserves the social interaction enabled 

        by open air audio while avoiding the audio “clutter” that open 

        air audio necessarily entails.  In our system, visitors independently 

        select objects in their guidebooks and listen to the audio content through 

        one-ear headsets; these headsets allow them to hear each other speak and 

        interact conversationally.  Further, wireless networking enables visitors 

        to optionally listen to their companion’s guidebook in addition to 

        their own.  The intimate, often directed, nature of the resulting shared 

        audio context has led us to call the system <i>Sotto Voce</i>.</p>

      <p>Our design is guided by the following principle: we want to support visitor 

        interaction with three main entities that make demands on their attention.  

        These entities are the information source, the visitor’s companions, 

        and the physical environment – “the guidebook, the friend, and 

        the room” (Woodruff, Aoki et al., 2001).  As we add capabilities 

        that enhances visitor interaction with one entity, we must be careful 

        that we do not compromise visitor interaction with the others (e.g., we 

        do not want to improve visitor-visitor interaction at the expense of visitor-room 

        interaction.)</p>

      <p>To understand the impact of the eavesdropping mechanism on the overall 

        visitor experience, we conducted two studies of visitors using the system 

        to tour a historic house.  We applied qualitative methods to the resulting 

        data, including an analysis of visitor interviews and an applied conversation 

        analytic study of recorded audiovisual observations.  Because the eavesdropping 

        was an optional feature that visitors could turn on or off at will, we 

        observed several categories of use, e.g., pairs of visitors who did not 

        use eavesdropping, pairs of visitors who used eavesdropping intermittently, 

        and pairs who engaged in continuous <i>mutual eavesdropping</i>.</p>

      <p>In this paper, we focus on the visitors who engaged in mutual eavesdropping, 

        which is the category that most closely approximates open air audio.  

        We compare the typical behavior of these mutual eavesdroppers to that 

        of visitors in a previous study who used open air audio to create a shared 

        listening experience (Woodruff, Aoki et al., 2001; Woodruff, Szymanski, 

        Aoki, &amp; Hurst, 2001).  (The three studies are summarized in Table 

        1.)  Most of the discussion is based on analysis of the observational 

        data.  We observe that mutual eavesdroppers had a different activity structure 

        and were more mobile than visitors who used open air audio.  As a result 

        of these changes, mutual eavesdroppers had increased resources for engaging 

        in interactive learning: they had richer and more extensive social interaction, 

        and they had more resources for physically exploring their environment.  

        For example, visitors had more substantive discussion in response to guidebook 

        descriptions, and they were more likely to discuss objects not described 

        in the guidebook.  Given the importance of social learning in the museum 

        environment (Falk &amp; Dierking, 2000), the preliminary evidence presented 

        here is encouraging and suggests further avenues for work along these 

        lines.</p>

      <div align="center"><img src="WoodruffTable1.jpg" width="450" height="106"/><br/>

        <br clear="all"/>

      </div>

      <p class="normal">The remainder of the paper is organized as follows.  First, 

        we discuss the design of Sotto Voce.  Next, we describe the method employed 

        in our user study.  We then turn to findings.  These are divided into 

        the impact of the design on visitor behavior and the implications of these 

        behavioral changes for visitors’ learning resources.  After discussing 

        related work, we summarize our findings and describe future directions.</p>

      <h1>Prototype Design</h1>

      <p class="normal">In this section, we discuss the design and implementation 

        of the guidebook device, key aspects of its user interface, the design 

        goals for the audio environment, the eavesdropping mechanism, the audio 

        delivery mechanism, and the construction of the audio content.  The design 

        is the same as that used in Study 2, reported in (Aoki et al., 2002), 

        but we briefly discuss it here to provide context.  Overall, visitors 

        have a positive response to the guidebook and report that it is easy to 

        use (Aoki et al., 2002; Woodruff, Aoki et al., 2001).</p>

      <p><b><span class="normal">Guidebook device.</span></b><span class="normal">  

        We implemented the device using the Compaq iPAQÔ 3650 handheld computer, 

        which includes a color LCD touchscreen display.  With an IEEE 802.11b 

        wireless local-area network (WLAN) card, the device measures 163mm x 83mm 

        x 34mm (6.4” x 3.3” x 1.3”) and weighs 368g (13 oz.).</span></p>

      <p class="MsoCaption"><img src="Woodruff-Figure1.jpg" width="400" height="250"/></p>

      <p class="MsoCaption">Figure 1.  Electronic guidebook and headset.</p>

      <p class="normal">To support eavesdropping, paired devices communicate over 

        the WLAN using Internet protocols (UDP/IP).   The audio content is the 

        same on all devices, so the devices send and receive control messages 

        (“start playing clip 10,” “stop playing clip 8”) rather 

        than waveform audio.   Since our goal is to enhance co-present interaction, 

        the device does not support remote voice communication.</p>

      <p><b><span class="normal">User interface. </span></b><span class="normal"> This 

        part of the system is very similar to that used in previous studies, and 

        its design rationale is more thoroughly described elsewhere (Woodruff, 

        Aoki et al., 2001).  Individual visitors obtain information about objects 

        in their environment using a visual interface.  This helps visitors maintain 

        the flow of their visual task (looking at the room and its contents), 

        which tends to reduce demands on user attention.  The interface resembles 

        a set of Web browser imagemaps; at a given time, the visitor sees a single 

        photographic imagemap that depicts one wall of a room in the historic 

        house (Figure 1, center).  Visitors change the viewing perspective (i.e., 

        display a different imagemap) by pressing a hardware button.  When visitors 

        tap on an imagemap target, the guidebook plays an audio clip that describes 

        that object.  Many, but not all, of the objects visible on the screen 

        are targets; to help visitors identify targets, the guidebook displays 

        <i>tap tips </i>(Aoki, Hurst, &amp; Woodruff, 2001) – transient target 

        outlines that appear when the user taps and fails to “hit” a 

        target (Figure 1, bottom left).  A demonstration of the visual interface 

        is available online (<a href="../http://www.parc.com/guidebooks/">http://www.parc.com/guidebooks/</a>).</span></p>

      <p class="normal"><b>Audio design goals.</b>  Results from Study 1 suggested 

        several design criteria.  Visitors want to be able to share audio descriptions 

        and converse.  At the same time, visitors want to retain personal control 

        over the selection of descriptions.  Further, the design needs to facilitate 

        the ability of visitors to explore their physical environment, and the 

        design needs to be sufficiently lightweight that it makes minimal demands 

        on the users’ attention.  Finally, the design needs to be feasible 

        in public environments with many visitors.  These criteria ruled out a 

        number of options like open air audio (which is not feasible for large 

        numbers of visitors) or splitters that allow two visitors to listen to 

        audio from a single device (which restrict visitor movement and do not 

        allow visitors individual control over the audio content to which they 

        are listening).  The eavesdropping model described below is an alternative 

        that meets all of  the criteria. </p>

      <p class="normal"><b>Eavesdropping.</b>  In concrete terms, paired visitors 

        share audio content as follows.  When visitor A selects an object on her 

        device, she always hears her own audio clip.  If A is not currently playing 

        an audio clip, but her companion B is, then B’s audio clip can be 

        heard on A’s device.  In other words, audio clips are never mixed, 

        and A’s device always plays a personal clip (selected by A) in preference 

        to an eavesdropped clip (selected by B).  Audio playback on the paired 

        devices is synchronized; if A and B are both listening to their own clips 

        and A’s clip ends first, A will then hear the remainder of B’s 

        clip as if it had “started in the middle.”   To control a device’s 

        eavesdropping volume (i.e., the volume at which A hears B’s clips), 

        the interface includes three option buttons: “Off,” “Quiet” 

        and “Loud” (Figure 1, top left).  “Loud” is the same 

        as the volume for personal clips.</p>

      <p class="normal">In abstract terms, eavesdropping provides a relatively 

        simple <i>audio space</i> model (Mackay, 1999).  We did consider other 

        options, such as a telephony-like connection model in which visitors would 

        independently initiate and terminate audio sharing sessions with their 

        companions.   We also considered email-like asynchronous models in which 

        visitors would send and receive audio clips at their convenience.  We 

        rejected more complex abstractions that involved multiple actions (send/receive, 

        connect/accept/reject, etc.) because we believed that the necessary interface 

        gestures would distract visitors from their experience with the environment 

        and their companions.  In the audio space model, sharing requires no gestures 

        of its own.  To “receive,” a visitor merely sets the eavesdropping 

        volume.  To “send,” a visitor simply selects an object; playing 

        a description has the side effect of sharing it, if the companion chooses 

        to eavesdrop.  The audio space model has the further advantage that it 

        supports simultaneous listening, which enhances social interaction by 

        creating the feeling that the content is part of a shared conversation 

        (Woodruff, Szymanski et al., 2001).</p>

      <p class="normal"><b>Audio delivery.</b>  Visitors hear descriptions through 

        headsets.  We conducted a small study (n=8) to identify headsets that 

        would allow visitors to converse and that visitors would readily accept 

        (Grinter &amp; Woodruff, 2002).  Based on this study, we chose commercial 

        single-ear telephone headsets, locally modified by the removal of the 

        boom microphone (Figure 1, right).  This configuration leaves one ear 

        available to hear sounds from the external environment, and visitors find 

        the over-the-head design desirable because it is familiar and gives them 

        the sense that the headset is securely attached.</p>

      <p class="normal"><b>Audio content</b>.  The prototype contains descriptions 

        of 51 objects in three rooms of the house.  In most regards, the descriptions 

        are recorded along principles described in (Woodruff, Szymanski et al., 

        2001).  The audio clips vary in length between 5.5 and 27 seconds, with 

        the exception of one story that runs for 59 seconds.  The clip length 

        is much shorter than conventional audio tour clips, which often run to 

        180 seconds, and is intended to facilitate conversation by providing frequent 

        opportunities for visitors to take a conversational turn.</p>

      <p class="normal">Since we use single-ear headsets, both personal and eavesdropped 

        audio content are necessarily presented in the same ear.   We distinguish 

        the two types of content using two mechanisms.  First, we apply a small 

        amount of reverberation to the eavesdropped audio.  A single earphone 

        cannot effectively deliver spatialized audio (Blauert, 1997), but can 

        support other sound effects; we chose reverberation after conducting user 

        tests (n=6) involving scenario-based tasks using the guidebook.  Second, 

        the default eavesdropping volume (“Quiet”), which is most frequently 

        used by visitors, is softer than the personal volume.</p>

      <h1>Method</h1>

      <p class="normal">We have conducted three major user studies at Filoli, 

        a Georgian Revival historic house located in Woodside, California (<a href="../http://www.filoli.org/" target="_blank">http://www.filoli.org/</a>).  

        Study 1 used an earlier version of Sotto Voce that supported open air 

        audio, whereas Studies 2/3 used the current version of Sotto Voce that 

        supports eavesdropping as described in the design section of this paper.  

        Study 1 and Study 2 involved previously recruited participants on days 

        the house was closed to the general public, whereas Study 3 involved 47 

        visitors recruited on-site on days the house was open to the general public.  

        (Again, these studies are summarized in Table 1.)</p>

      <p class="normal">Because the participants and procedures for Study 1 and 

        Study 2 have been reported previously, below we report only the participants 

        and procedure for Study 3.  We then discuss our analytic methods, which 

        were the same in all studies.</p>

      <p class="normal"><b>Participants</b>.  In Study 3, we observed 20 pairs, 

        one group of three, and one group of four using the guidebooks.  These 

        pairs and larger groups were comprised of visitors who had come to Filoli 

        together, e.g., mother/daughter or friend/friend pairs.  The majority 

        of visitors had not previously used a handheld device.  The visitors covered 

        a wide range of ages: the youngest visitors were in the “18-29” 

        age range, and seven visitors who used the guidebook were “over 70.”  

        (While we had several children test Sotto Voce in the first and second 

        studies, visitors from the ages of approximately 5-17 are quite rare at 

        Filoli unless they are visiting with a school group.)</p>

      <p class="normal"><b>Procedure.</b>  Visitors to the house were recruited 

        at the entrance to the Library, the first room discussed in the guidebook.  

        After signing consent forms, visitors were fitted with a wireless microphone, 

        given guidebooks, and trained in their use.  Next, they visited the three 

        rooms for which the guidebook had content.  When they finished using the 

        guidebooks, they participated in a semi-structured interview.  </p>

      <p class="normal">The visitors’ conversation and comments during the 

        interview were recorded using the wireless microphones; the visitors were 

        videotaped by fixed cameras while using the guidebooks (all visitors to 

        the house were notified that videotaping was in progress); and the visitors’ 

        use of the guidebooks was logged by the device.</p>

      <p class="normal">Visitors typically spent about 15 minutes using the electronic 

        guidebooks.  Their participation in the study took approximately 30-45 

        minutes; no time limits were imposed during any portion of the procedure.</p>

      <p class="normal"><b>Analysis.</b>  We analyzed the data in several ways.  

        For example, we transcribed and analyzed the interview data to examine 

        the visitors’ attitudes and feelings about the technology and their 

        experience.  The majority of the findings presented in this paper are 

        based on another method we used, <i>conversation analysis</i> (Sacks, 

        1984).</p>

      <p class="normal">Conversation analysis is a sociological method used to 

        examine naturally occurring social interaction to reveal organized patterns.</p>

      <p class="normal">To find such patterns, conversation analysts study collections 

        of interactive encounters and identify <i>sequences</i> of actions that 

        were recurrently made by the participants.  Actions in our context might 

        include making a verbal utterance, pointing at an object, or selecting 

        a description.</p>

      <p class="normal">To this end, we create a composite video of visitors and 

        their guidebook screens and audio (re-created from the guidebook activity 

        logs).  We then transcribe the actions taken by visitors, including dialogue, 

        and look for recurring patterns to identify visitors’ systematic 

        practices.</p>

      <h1>From Open Air To Eavesdropping: Changes In Visitor Behavior</h1>

      <p class="normal">In this section, we compare the behavior of the pairs 

        who chose to use mutual eavesdropping in Studies 2/3 to that of similarly 

        engaged pairs who used open air audio in Study 1.</p>

      <p class="normal">Specifically, we discuss the structure of the visitors’ 

        interactions and their physical mobility.  The effect of these aspects 

        can be identified in the visitors’ learning-related behavior, which 

        is the subject of the following section.</p>

      <h2>Changed Activity Structure</h2>

      <p class="normal">Visitor activity was structured very differently with 

        eavesdropped audio than with open air audio.  The new structure had a 

        lower coordination cost, demanding less attention.  The decreased attention 

        burden was reflected in the visitors’ interactions.</p>

      <p class="normal">In all of the studies, a single overall structure pervaded 

        the interactions.  Specifically, they exhibited the sequential, multi-phase 

        organization known as <i>storytelling</i> in the conversation analytic 

        literature (Sacks, 1974); as part of this organization, visitors created 

        a conversational role for the audio descriptions, i.e., they treated the 

        guidebook like a “third party” taking an extended conversational 

        turn (Aoki et al., 2002; Woodruff, Szymanski et al., 2001).  Paired visitors 

        entered a state of <i>engagement</i> at the beginning of a given storytelling 

        sequence; levels of engagement generally rose and then fell over the course 

        of a given sequence; and visitors then had the options of dis-engaging 

        (resulting in independent activity), remaining engaged in shared activity, 

        or maintaining a nascent engagement in expectation of subsequent re-engagement 

        (Szymanski, 1999). </p>

      <p class="normal">With open air audio, visitor interactions tended to focus 

        on choosing individual objects and coordinating with their companions 

        to listen to the descriptions.  This setup, repeated for each sequence, 

        focused more attention on coordination activity than seems necessary or 

        desirable.  However, the open air audio did afford the opportunity to 

        participate in shared responses to the “story,” motivating the 

        visitors to begin setup for another sequence.</p>

      <p class="normal">By contrast, participation in mutual eavesdropping created 

        an ongoing assumption that the couple would continue in the shared activity.  

        This supposition of continuing shared activity meant that setup tended 

        to be cursory.  Further, while open air audio was primarily conducive 

        to follow-up discussions that related directly to descriptions, mutually 

        eavesdropped audio was conducive to many diverse types of follow-up sequences 

        such as discussion of objects not described in the guidebook.</p>

      <p><span class="normal">The change in activity structure had at least two 

        beneficial effects.</span>  </p>

      <ul>

        <li class="normal"><span class="normal"> First, by reducing the effort 

          needed to choose and listen to descriptions, mutual eavesdropping freed 

          visitors to direct more attention to meaningful interactions with their 

          environment and their companions (i.e., away from the guidebook and 

          routine coordination).  In other words, the reduction in low-quality 

          coordination talk meant that visitors had more time to investigate the 

          room and its contents and that a higher proportion of talk tended to 

          focus on topics of substance.  </span></li>

        <li class="normal"><span class="normal"> Second, since the new activity 

          structure supported more diverse types of sequences, visitors were more 

          likely to pursue new topics or investigate objects not described in 

          the guidebook.</span></li>

      </ul>

      <h2>Increased Mobility</h2>

      <p class="normal">Visitors in Studies 2/3 were noticeably more mobile during 

        periods of engagement.  In Study 1, the open air audio was played at a 

        low volume, so any movement that changed the relative position of the 

        visitors could cause significant sound attenuation due to distance or 

        blockage (e.g., due to interposed obstacles – even changes in body 

        orientation could cause the audio to be blocked).  As a result, couples 

        tended to remain close together and stationary while sharing audio descriptions.  

        See Figure 2a, in which a grandmother is bending over to listen to the 

        audio description that her granddaughter is playing of the portrait over 

        the fireplace.  Note how this position prevents her from examining the 

        painting while she listens.  In Studies 2/3, visitors were less constrained.  

        Because movement could not attenuate the audio information, visitors could 

        separate from each other physically while listening to descriptions and 

        remaining engaged.  See Figure 2b, in which both visitors are listening 

        to a description of the marble staircase.  While both visitors are examining 

        the staircase, they have each chosen different vantage points.  However, 

        this positioning does not compromise their social connection: when the 

        audio description reveals that only the first four steps are actually 

        solid marble, the male visitor looks to his companion and she laughs, 

        even though they are not standing together.</p>

      <div align="center"> 

        <table border="0" cellspacing="0" cellpadding="0" width="511">

          <tbody><tr> 

            <td width="240" valign="top" class="Normal"> 

              <p class="MsoCaption"><img src="Woodruff-Figure2A.jpg" width="240" height="158"/></p>

            </td>

            <td width="271" valign="top" class="Normal"> 

              <p align="center"><b><img src="Woodruff-Figure2B.jpg" width="240" height="158"/></b></p>

            </td>

          </tr>

          <tr> 

            <td width="240" valign="top" class="Normal"> 

              <p class="MsoCaption">(a) Visitors standing close together when using 

                open air audio.</p>

            </td>

            <td width="271" valign="top" class="Normal"> 

              <p align="center"><span class="MsoCaption">(b) Visitors standing far 

                apart when using mutually eavesdropped audio</span>.</p>

            </td>

          </tr>

          <tr> 

            <td colspan="2" valign="top" class="Normal"> 

              <p class="MsoCaption">Figure 1 .  Comparison of visitor mobility patterns.</p>

            </td>

          </tr>

        </tbody></table>

        <span class="normal"><br/>

        </span></div>

      <p><span class="normal">The increased mobility resulting from use of mutual 

        eavesdropping took many forms.  We observed several common behaviors that 

        rarely, if ever, occurred with open air audio.  For example, visitors 

        would often walk together while a description was playing, e.g., to approach 

        the object being described.  In other cases, a single visitor would walk 

        closer to the object currently being described while their companion remained 

        stationary.  In still other cases, a visitor would investigate a different 

        object from the one currently being described and then rejoin the companion.</span>  

      </p>

      <h1>From Open Air To Eavesdropping: Increased Resources For Learning</h1>

      <p class="normal">The study observations provide evidence that both of the 

        factors described in the previous section – the changed activity 

        structure and increased mobility during engagement – improved the 

        learning environment.   Here, we discuss two learning-related resources 

        that were enhanced by the guidebook: the nature of the visitors’ 

        social interaction and their opportunities for exploring the room and 

        its contents.</p>

      <p class="normal">Our analyses are based upon a collection of transcribed 

        excerpts from which the following extracts have been derived.  These extracts 

        are meant to exemplify and highlight specific behaviors rather than to 

        illustrate the organization of the visitors’ interactions (space 

        limitations preclude the use of representative excerpts of this kind).</p>

      <p class="normal">Table 2 summarizes the notation used in this section.  

        For clarity of presentation, the extracts have been simplified to use 

        conventional capitalization and punctuation (e.g., commas and periods).</p>

      <div align="center"> 

        <p><img src="WoodruffTable2.jpg" width="450" height="164"/><br/>

        </p>

      </div>

      <p class="normal">Note that the discussion in this section is limited to 

        the <i>increased availability</i> of <i>learning resources</i>.  A claim 

        of <i>increased learning</i> would require a different type of study, 

        e.g., one that measured the visitors’ knowledge before and after 

        their visit.  Such a study is beyond the scope of this paper.</p>

      <h2>Depth and Length of Social Interaction</h2>

      <p class="normal">When using mutual eavesdropping, visitors responded more 

        fully to audio descriptions.  Visitors were also more likely to discuss 

        features of the object not mentioned in the description or to discuss 

        objects that were not described in the guidebook at all.</p>

      <p class="normal">Each of these phenomena represents a way in which visitors 

        collaboratively built on the shared audio descriptions, working together 

        to construct mutual learning resources that broaden, deepen or expand 

        their discussion of the room’s contents.  The importance of such 

        social learning, particularly (but not limited to) conversation, has been 

        widely supported in the visitor studies literature (see, e.g., (Falk &amp; 

        Dierking, 2000; Russell, 1994)).  Social interaction around artifacts 

        affords the “opportunity for the visitor to make connections with 

        familiar concepts and objects” (Hein, 1995); adding resources for 

        interaction adds more such opportunities.  The remainder of this subsection 

        gives some examples, linking the behavioral changes of the previous section 

        to the construction of learning resources.</p>

      <p class="normal"><b><i>Characterizations</i>.</b>  With mutual eavesdropping, 

        response to an audio description was likely to be more reflective and 

        include a physical focus relative to the object being described.  With 

        open air audio, visitors would often have a very minimal response, and 

        even the more substantive responses were generally limited to reactions 

        to the description that had just occurred.</p>

      <p class="normal">The following extracts are representative of this effect.  

        Consider V and W (Extract I, Study 1) who were listening with open air 

        audio.</p>

      <p class="BlockQuote"><b>V-PDA:</b> Many of the top shelves contain false 

        books.  They are lighter than normal books, so they reduce the stress 

        on the bookcases.  Many are made of greeting cards, clothing, fabric, 

        et cetera.</p>

      <p class="BlockQuote"><b>W: </b> Eh hah, that’s a riot.  ((W looks at 

        V and smiles))  (0.2) They’re just for looks.</p>

      <p class="MsoCaption">Extract I.</p>

      <p class="normal">While V and W do share a response, the substance is limited 

        to a single paraphrase of the audio description, analogous to “text 

        echo” of exhibit labels (McManus, 1989) (though possibly more affective, 

        because of the audio delivery).</p>

      <p><span class="normal">By contrast, consider an interaction in which J 

        and L (Extract II, Study 2) were mutually eavesdropping. </span> </p>

      <p class="BlockQuote"><b>L-PDA:</b>… All of the architectural features 

        of this room, including the walnut panelling, are modelled on an 18th 

        century British library.  In the original library, each of the outlined 

        panels would have contained framed pictures.</p>

      <p class="BlockQuote"><b>L:</b> Really.</p>

      <p class="BlockQuote"><b>J: </b>Yeah.</p>

      <p class="BlockQuote"><b>L:</b> That&#39;s a lot of pictures.  ((points at wall 

        and sweeps arm across walls))</p>

      <p class="BlockQuote"><b>J:</b>That&#39;s a lot of pictures.  ((nods &#34;yes”))</p>

      <p class="BlockQuote"> (.)</p>

      <p class="BlockQuote"><b>J:</b>That would’ve been very cluttered. </p>

      <p class="MsoCaption">Extract II.</p>

      <p class="normal">This interaction is richer in many respects than that 

        shown in the previous extract.  J and L both speak, taking more turns 

        to discuss the description than V and W.  By making a statement about 

        the number of pictures, L reinforces for J a quantitative observation 

        that is not made in the description itself.  By gesturing at the many 

        empty wall panels, L adds physical, spatial, and visual elements to the 

        experience, linking both visitors to a vision of the “original” 

        library that overlays their actual surroundings.  J agrees with the quantitative 

        statement, pauses, and then responds by saying it would have been “cluttered,” 

        a qualitative assessment that indicates that she has in fact visualized 

        the room as it might have been.</p>

      <p class="normal">This increased reflection on descriptions was evidenced 

        in many ways.  Visitors worked together more to understand descriptions, 

        e.g., a visitor would sometimes express confusion about a description 

        and the companion would help explain  it.  Further, with mutual eavesdropping, 

        visitors more frequently branched off into sequences that were not directly 

        related to the description of the content.  For example, they might point 

        out a specific physical feature of the object that was not mentioned in 

        the description, or discuss some way that it related to their own life.</p>

      <p class="normal">Additionally, visitors showed more evidence of establishing 

        complex relationships between objects.  One visitor pointed at a series 

        of paintings on different walls, saying, “Okay, so that’s his 

        wife, and that’s his mother, right?”  Or consider T’s comments 

        (Extract III, from Study 2) when he first enters a particular room.  His 

        statements indicate that he has constructed a category of “secret 

        cabinets” that occur in this house and that he is alert to instances 

        of this category as he moves from room to room.</p>

      <p class="BlockQuote"><b>T:</b>Ah, more secret cabinets.</p>

      <p class="BlockQuote">(0.4)</p>

      <p class="BlockQuote"><b>T:</b> I like that a lot about this house.  ((walks 

        into the bar closet))</p>

      <p class="MsoCaption">Extract III.</p>

      <p class="normal">Interactions displaying this kind of orientation – 

        i.e., at the granularity of a thematic collection rather than a single 

        object – almost never occurred with open air audio.</p>

      <p class="normal">Moreover, mutually eavesdropping visitors often discussed 

        objects that were not described in the guidebook, unlike open air audio 

        visitors.  The following sequence, in which J teaches L about a plant, 

        occurred immediately after they finished their response to a description:</p>

      <p class="BlockQuote"><b>J:</b> Okay, your- your test for the day, what&#39;s 

        that one? ((points to plant))</p>

      <p class="BlockQuote">(0.2)</p>

      <p class="BlockQuote"><b>J:</b> The plant.</p>

      <p class="BlockQuote">(0.4)  ((L leans in to look))</p>

      <p class="BlockQuote"><b>L:</b> Morning glory.  Eh heh heh heh, I don&#39;t know, 

        what is it?</p>

      <p class="BlockQuote"><b>J:</b> I think it&#39;s a mandevilla vine, but I&#39;m not 

        sure.</p>

      <p class="BlockQuote"><b>L:</b> God, I can&#39;t believe you know that. </p>

      <p class="MsoCaption">Extract IV.</p>

      <p class="normal">Reasons.  Both of the behavioral changes resulting from 

        use of mutually eavesdropped audio had impact on social interaction.  

        The primary factor was the new activity structure, which allowed more 

        space for reflection and for visitors to initiate new conversational sequences 

        that were not structured around the audio descriptions.  Increased mobility 

        constituted a secondary factor.  Visitors would often start descriptions 

        while they were far away from objects.  As mentioned above, visitors were 

        unlikely to walk toward the object while the description was playing with 

        open air audio.  However, with eavesdropped audio, they were more likely 

        to approach the object; being close to the object when the description 

        ended gave them more opportunities to observe and discuss its specific 

        features.</p>

      <h2>Expanded Resources for Physical Exploration</h2>

      <p class="normal">With mutually eavesdropped audio, the examination of objects 

        was more frequently occasioned by their presence in the <i>room</i> rather 

        than their presence in the <i>guidebook</i>.  Once visitors began to examine 

        an object, they might discuss it or play a description of it if one were 

        available. </p>

      <p class="normal">This implicit shift in emphasis from the guidebook to 

        the room as the impetus for exploration is important because it shifts 

        the visitor&#39;s role.  It is broadly (though perhaps not universally) accepted 

        that learning is enhanced by enabling visitors to navigate the museum 

        without leading them through it (Falk &amp; Dierking, 2000).    However, 

        even &#34;free choice&#34; navigation can be constrained by, e.g., which 

        objects have descriptive content associated with them.  Visitor behavior 

        indicates that use of mutual eavesdropping increased the guidebook’s 

        utility as a reference (an adjunct to the room) as opposed to an inventory 

        (a directed guide to the room).</p>

      <p><b><i><span class="normal">Characterizations</span></i></b><span class="normal"><b>.</b>  

        In the study using open air audio, examination of objects often began 

        with objects contained in the guidebook and proceeded by spatial locality.  

        That is, visitors tended to switch the visual interface to a given wall 

        and then look at the objects in the guidebook that interested them on 

        that wall.  Object choice was often based on targets seen in the visual 

        interface or on short-term memory of such targets.</span></p>

      <p class="normal">In the eavesdropping studies, the next object to examine 

        was less frequently chosen based on availability in the guidebook.  (In 

        many of these cases, we know that the examination was prompted by the 

        room rather than the guidebook because the objects were not described 

        in the guidebook.  In the other cases, the visitors spoke their thoughts 

        aloud – which was entirely self-prompted since none of the studies 

        involved a speak-aloud protocol.)  Instead, visitors would encounter objects 

        in their field of view, e.g., objects that were near an object they had 

        just examined, or they would deliberately examine sequences of objects 

        they perceived as being related.</p>

      <p class="normal">For example, in Extract III, T walks into a new room, 

        notices the bar closet and actually walks into it.  <i>After</i> this, 

        his companion D finds the description in the guidebook and plays it.  

        Note that because the sound does not attenuate, the visitors can listen 

        to the description together while T stands inside the tiny closet and 

        D stands outside.</p>

      <p class="normal"><b><i>Reasons. </i></b><i> </i>While the same resources 

        were available with open air audio, they were used much more frequently 

        in the mutual eavesdropped case due to the changed activity structure 

        and the increased mobility in the room.  Specifically, the mutually eavesdropped 

        audio was more conducive to sequences that were not directly responsive 

        to guidebook content; visitors were generally more open to external triggers 

        with the new activity structure.  Visitors acted in a manner more consistent 

        with “Let’s see what’s here in the room” than with 

        “Let’s see what’s here in the guidebook.”  Further, 

        visitors had more attention to give to the room due to the reduced attentional 

        demands and wandered more in the room due to increased mobility, so they 

        were more likely to encounter and investigate objects.</p>

      <h1>Related Work</h1>

      <p class="normal">Our work draws together three main areas of research.  

        Space limitations preclude an extended discussion; additional references 

        are contained in (Aoki et al., 2002; Woodruff, Aoki et al., 2001; Woodruff, 

        Szymanski et al., 2001). </p>

      <p class="normal"><b><i>Interaction in museum settings</i></b>.  The importance 

        of social interaction to museum visitors is well known (e.g., (Hood, 1983)).  

        There are two types of studies of particular interest.  McManus observed 

        visitor usage of text labels; she noted that visitors were inclined to 

        treat exhibit labels <i>as conversation</i> to which they had been party 

        (McManus, 1989).  A number of studies of museum visitors have been conducted 

        using methods derived from conversation analysis (see, e.g., (Falk &amp; 

        Dierking, 2000), Ch. 6, and (vom Lehn, Heath, &amp; Hindmarsh, 2001).  

        These studies focus on talk, interaction and learning in conventional 

        environments; here, we have focused on the effects of electronic guidebooks 

        on social interaction and learning resources.</p>

      <p class="normal"><b><i>Electronic guidebooks</i></b>.  The cultural heritage 

        community has formally studied electronic guidebooks for many years (Screven, 

        1975).  Related work in HCI has focused on aspects such as location-aware 

        computing (Abowd et al., 1997), and only recently have significant user 

        studies been reported (e.g., (Cheverst, Davies, Mitchell, Friday, &amp; 

        Efstratiou, 2000)).  The HCI studies focus on system design and evaluation; 

        here, we focus on the effects of our system on visitor interaction.  </p>

      <p class="normal"><b><i>Media and interaction</i></b>.  There is an extremely 

        rich literature on collaborative multimedia environments; of particular 

        interest are media spaces (Mackay, 1999).  Many of these systems have 

        been evaluated, but most apply either ethnographic techniques or quantitative 

        methods to studies of installed workplace systems.  In this study, we 

        apply conversation analytic techniques to the study of a mobile, leisure-activity 

        system that provides shared access to application content.  </p>

      <h1>Conclusions</h1>

      <p class="normal">In this paper, we have described an eavesdropping mechanism 

        that allows visitors to listen to each other’s guidebooks.  Our findings 

        show that mutual use of this eavesdropping mechanism can lead to increased 

        learning resources as compared with the use of speakers in open air: couples 

        using mutual eavesdropping in Studies 2/3 had more substantive interactions 

        and exhibited an increased awareness of the room and its contents when 

        compared to those using open air audio in Study 1.</p>

      <p class="normal">New work is addressing some of the open issues from this 

        study.  We are preparing a discussion of the ways in which the visitors 

        creatively used our eavesdropping mechanism for tasks other than enhancing 

        their social interaction, e.g., for monitoring their children.  We are 

        also planning an experiment using bone conduction headsets that can provide 

        binaural audio without occluding the ears.<b></b></p>

      <h2>Acknowledgements</h2>

      <p class="AcknowedgementsText">We are deeply grateful to Tom Rogers and Anne 

        Taylor of Filoli Center for their assistance with this project.  Amy Hurst 

        performed this work during an internship from the College of Computing, 

        Georgia Institute of Technology.</p>

      <h1>References</h1>

      <p class="ReferencesText">Abowd, G. D., Atkeson, C. G., Hong, J., Long, S., 

        Kooper, R., &amp; Pinkerton, M. (1997). Cyberguide: A Mobile Context-Aware 

        Tour Guide. Wireless Networks, 3(5), 421-433.</p>

      <p class="ReferencesText">Aoki, P. M., Grinter, R. E., Hurst, A., Szymanski, 

        M. H., Thornton, J. D., &amp; Woodruff, A. (2002). Sotto Voce: Exploring 

        the Interaction Between Conversation and Mobile Audio Spaces. In  Proc. 

        ACM SIGCHI Conference on Human Factors in Computing Systems.  New York: 

        ACM Press, to appear.</p>

      <p class="ReferencesText">Aoki, P. M., Hurst, A., &amp; Woodruff, A. (2001). 

        Tap Tips: Lightweight Discovery of Touchscreen Targets. In Extended Abstracts, 

        ACM SIGCHI Conference on Human Factors in Computing Systems.  New York: 

        ACM Press, 237-238.</p>

      <p class="ReferencesText">Blauert, J. (1997). Spatial Hearing (rev. ed.). 

        Cambridge, MA: MIT Press.</p>

      <p class="ReferencesText">Cheverst, K., Davies, N., Mitchell, K., Friday, 

        A., &amp; Efstratiou, C. (2000). Developing a Context-Aware Electronic 

        Tourist Guide: Some Issues and Experiences. In  Proc. ACM SIGCHI Conference 

        on Human Factors in Computing Systems.  New York: ACM Press, 17-24.</p>

      <p class="ReferencesText">Falk, J. H., &amp; Dierking, L. D. (2000). Learning 

        From Museums.  Walnut Creek, CA: Altamira Press.</p>

      <p class="ReferencesText">Grinter, R. E., &amp; Woodruff, A. (2002). Ears 

        and Hair: What Headsets Will People Wear?  In Extended Abstracts, ACM 

        SIGCHI Conf. on Human Factors in Computing Systems.  New York: ACM Press, 

        to appear.</p>

      <p class="ReferencesText">Hein, G. E. (1995). The Constructivist Museum. Journal 

        of Education in Museums, 16, 21-23.</p>

      <p class="ReferencesText">Hood, M. G. (1983). Staying Away: Why People Choose 

        Not to Visit Museums. Museum News, 61(4), 50-57.</p>

      <p class="ReferencesText">Kirk, J. (2001). MUSEpad.  Presentation at the Electronic 

        Guidebook Forum, San Francisco, CA, October 2001.</p>

      <p class="ReferencesText">Mackay, W. E. (1999). Media Spaces: Environments 

        for Multimedia Interaction. In M. Beaudouin-Lafon (Ed.), Computer-Supported 

        Cooperative Work.  Chichester, UK: Wiley &amp; Sons, 55-82.</p>

      <p class="ReferencesText">Martin, D. (2000). Audio Guides. Museum Practice, 

        5(1), 71-81.</p>

      <p class="ReferencesText">McManus, P. M. (1989). Oh, Yes They Do!  How Visitors 

        Read Labels and Interact with Exhibit Text. Curator, 32(3), 174-189.</p>

      <p class="ReferencesText">Russell, T. (1994). The Enquiring Visitor: Usable 

        Learning Theory for Museum Contexts. Journal of Education in Museums, 

        15, 19-21.</p>

      <p class="ReferencesText">Sacks, H. (1974). An Analysis of the Course of a 

        Joke&#39;s Telling in Conversation. In R. Bauman &amp; J. Sherzer (Eds.), 

        Explorations in the Ethnography of Speaking. Cambridge: Cambridge Univ. 

        Press, 337-353.</p>

      <p class="ReferencesText">Sacks, H. (1984). Notes on Methodology. In J. M. 

        Atkinson &amp; J. Heritage (Eds.), Structures of Social Action. Cambridge: 

        Cambridge Univ. Press, 21-27.</p>

      <p class="ReferencesText">Screven, C. G. (1975). The Effectiveness of Guidance 

        Devices on Visitor Learning. Curator, 18(3), 219-243.</p>

      <p class="ReferencesText">Szymanski, M. H. (1999). Re-engaging and Dis-engaging 

        Talk in Activity. Language in Society, 28(1), 1-23.</p>

      <p class="ReferencesText">vom Lehn, D., Heath, C., &amp; Hindmarsh, J. (2001). 

        Exhibiting Interaction: Conduct and Collaboration in Museums and Galleries. 

        Symbolic Interaction, 24(2), 189-216.</p>

      <p class="ReferencesText">Woodruff, A., Aoki, P. M., Hurst, A., &amp; Szymanski, 

        M. H. (2001). Electronic Guidebooks and Visitor Attention. In D. Bearman 

        &amp; J. Trant (Eds.), Cultural Heritage Informatics 2001 (Proc. 6th ICHIM). 

        Philadelphia: A&amp;MI, 437-454.</p>

      <p class="ReferencesText">Woodruff, A., Szymanski, M. H., Aoki, P. M., &amp; 

        Hurst, A. (2001). The Conversational Role of Electronic Guidebooks. In 

        G. D. Abowd, S. Shafer &amp; B. Brumitt (Eds.), Ubiquitous Computing (Proc. 

        3rd International Conference). Berlin: Springer-Verlag, 187-208.</p>

      <!-- #EndEditable --></td>
  </tr>
</tbody></table>
<!--htdig_noindex-->

<!-- analytics scripts -->
<!-- tynt script -->
<script type="text/javascript">tyntVariables = {"ap":"Read more: "};</script> 
<script type="text/javascript" src="../http://tcr.tynt.com/javascripts/Tracer.js?user=aTNeQ-tzOr36a6adbiUzgI&amp;s=130&amp;cc=6&amp;st=1"></script>
<noscript></noscript>

<!-- google analytics script -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26332456-1']);
  _gaq.push(['_setDomainName', '.archimuse.com']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!--chartbeat script -->
<script type="text/javascript">
var _sf_async_config={uid:3385,domain:"archimuse.com"};
(function(){
  function loadChartbeat() {
    window._sf_endpt=(new Date()).getTime();
    var e = document.createElement('script');
    e.setAttribute('language', 'javascript');
    e.setAttribute('type', 'text/javascript');
    e.setAttribute('src',
       (("https:" == document.location.protocol) ? "https://s3.amazonaws.com/" : "http://") +
       "static.chartbeat.com/js/chartbeat.js");
    document.body.appendChild(e);
  }
  var oldonload = window.onload;
  window.onload = (typeof window.onload != 'function') ?
     loadChartbeat : function() { oldonload(); loadChartbeat(); };
})();

</script>

<!--/htdig_noindex-->





</body><!-- #EndTemplate --><!-- Mirrored from www.museumsandtheweb.com/mw2002/papers/woodruff/woodruff.html by HTTrack Website Copier/3.x [XR&CO'2008], Mon, 22 Jul 2013 17:46:51 GMT --></html>