<div id="primary" class="content-area">
		<main id="main" class="site-main" role="main">

	


<style>
td { padding: 5px;vertical-align: top; }
.year { background-color:#ccc; padding:5px; margin-bottom: 10px; }
</style>

<h2 class="page-title">Bibliography</h2>
<div class="entry-content">
<table>
<tbody><tr><td style="text-align: right;">Title:</td><td><b>Mixing Realities to Connect People, Places, and Exhibits Using Mobile Augmented-Reality Applications</b></td></tr>
<tr><td style="text-align: right;">Authors:</td><td><a href="?mwa=Rob:|:Rothfarb">Rob Rothfarb</a></td></tr>
<tr><td style="text-align: right;">Type:</td><td>Paper</td></tr>
<tr><td style="text-align: right;">Publication:</td><td>MW2011: Museums and the Web 2011</td></tr>
<tr><td style="text-align: right;">Year:</td><td>2011</td></tr>
<tr><td style="text-align: right;">Abstract:</td><td><p>With mobile augmented-reality technologies and applications, museums can extend their relationship with visitors beyond physical boundaries to engage them further in discovery-based learning.<sup> </sup></p>
<p>Using freely available mobile augmented-reality (AR) authoring platforms and publishing tools, the Exploratorium is experimenting with extensions to both its physical and web exhibit spaces to allow visitors to interact with exhibits and natural phenomenon around the San Francisco Bay Area.  Applications developed with two platforms, Layar and Junaio, allow mobile users with AR-capable smart phones (equipped with a camera and GPS) to explore their surroundings through live camera views of these devices and to interact with overlaid multilayered, geo-referenced information. Interactive content &#34;layers&#34; let visitors with compatible devices, including iPhone and Android smartphones, see annotated information about physical exhibits and locations in outdoor spaces, leave &#34;markers,&#34;of their visit experience in places where others can see them, and explore temporal data about objects and locations. While it&#39;s possible to get started right away developing content and user-experiences with mobile AR, advances in mobile image processing, tagging technologies, and wearable computing-combined with the convergence of distributed networks and location-aware applications-will help define more intimate modes of human-computer interaction that museum exhibit and experience developers can further explore.</p>
<p>This paper discusses content creation for mobile AR experience design using these two platforms, strategies for incorporating preparation of mobile AR-ready information into a digital content creation workflow, and measuring impact via mobile analytics. It covers key processes including  geotagging  different types of assets (images, videos, audio, and 3-D objects) and methods of interfacing the AR authoring platforms with content in external systems including event calendars, media portal/content management systems, and social-sharing sites such as YouTube, and Flickr.</p>
<p> </p>
</td></tr>
<tr><td style="text-align: right;">Link:</td><td><a href="https://www.museumsandtheweb.com/mw2011/papers/mixing_realities_to_connect_people_places_and_">https://www.museumsandtheweb.com/mw2011/papers/mixing_realities_to_connect_people_places_and_</a></td></tr>
</tbody></table>


</div>
		</main><!-- #main -->
	</div>